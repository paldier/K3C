# HG changeset patch
# Parent 27b21e08064cfedc68dafbfea4362c5e4e22f132

--- a/arch/x86/Kconfig
+++ b/arch/x86/Kconfig
@@ -484,28 +484,14 @@ config PAL_CPPI41_APPCPU
 	  This is the cppi41 on appcpu support for Intel CE2600 platform.
 
 menu  "Intel PUMA7 AVALANCHE support"
-    config ARM_AVALANCHE_PDSP_PP
+		config ARM_AVALANCHE_PDSP
+			bool "PDSP General Driver"
+			default y
+		config ARM_AVALANCHE_PDSP_PP
         bool "TI Packet processor support for net-infra structure"
         depends on X86_PUMA7
+				depends on ARM_AVALANCHE_PDSP
         default n
-    config  TI_PACKET_PROCESSOR
-        bool "Packet processor data pipe"
-        depends on ARM_AVALANCHE_PDSP_PP
-        default n
-	---help---
-	  Say yes here to enable the TI packet processor
-	  The TIPP implements packet filtering and logging rules
-	  and is part of the netfilter framework.
-	  Package is part of the P7 platform netfiltering capabilities.
-    config TI_PACKET_PROCESSOR_STATS
-        bool "Packet processor stats"
-        depends on TI_PACKET_PROCESSOR
-        default n
-	---help---
-	  Say yes here to enable the TI packet processor stats feature
-	  TIPP_STATS implements a feature that allows the reading of
-	  TIPP filters.
-	  Package is part of the P7 platform netfiltering capabilities.
     config X86_AVALANCHE_SOC
         bool "Packet processor data pipe support"
         depends on TI_PACKET_PROCESSOR
@@ -515,12 +501,45 @@ menu  "Intel PUMA7 AVALANCHE support"
 	  X86_AVALANCHE_SOC implements packet processing features
 	  used by the Puma7 SoC.
 	  Package is part of the P7 platform packet processing capabilities.
-    config TI_META_DATA
-        bool "Packet processor meta data support"
-        depends on X86_AVALANCHE_SOC
-        default n
 endmenu
 
+choice
+	prompt "Intel PUMA7 AVALANCHE SOC Type"
+	depends on X86_PUMA6 || X86_PUMA7
+	default MACH_PUMA7
+	help
+	  Select the Intel BoardBand SoC Type that you want the kernel port for.
+	  If unsure, contact your software vendor.
+
+config MACH_PUMA5
+ bool "Puma5 SOC"
+
+config MACH_PUMA6
+ bool "Puma6 SOC"
+
+config MACH_PUMA7
+ bool "Puma7 SOC"
+
+endchoice
+
+# Get to know the reference board the user wants to compile for
+choice
+ prompt "Puma7 reference board type"
+ depends on MACH_PUMA7
+ default MACH_PUMA7_BOARD
+ help
+   Select the Puma7 Ref. Design Board that you are using. If you
+   are not using any of these, choose the one closest to your
+   design and make modifications to the kernel as required.
+
+config MACH_PUMA7_FPGA
+ bool "Puma7 FPGA Board"
+
+config MACH_PUMA7_BOARD
+ bool "Puma7 Board"
+
+endchoice
+
 config HW_MUTEXES
 	bool "MUTEX controller support for Intel CE2600 platform"
 	depends on X86_PUMA7 || X86_PUMA6
--- a/arch/x86/pal_cppi41/Makefile
+++ b/arch/x86/pal_cppi41/Makefile
@@ -20,9 +20,6 @@
 obj-$(CONFIG_PAL_CPPI41_APPCPU) := pal_cppi41.o
 obj-$(CONFIG_PAL_CPPI41_APPCPU) += cru_ctrl.o
 
-ccflags-y := -Werror \
-		-DCONFIG_X86_AVALANCHE_SOC \
-		-DPUMA7_SOC_TYPE \
-		-DPUMA7_OR_NEWER_SOC_TYPE\
+ccflags-y :=	-DCONFIG_X86_AVALANCHE_SOC \
 		-DCONFIG_TI_META_DATA\
 		-DCONFIG_INET_LRO
--- a/arch/x86/pal_cppi41/cru_ctrl.c
+++ b/arch/x86/pal_cppi41/cru_ctrl.c
@@ -46,6 +46,10 @@
 
 #include <linux/avalanche/generic/pal.h>
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
 #if PUMA7_SOC_TYPE
 #include <linux/avalanche/puma7/puma7.h>
 #include <linux/avalanche/puma7/puma7_cru_ctrl.h>
--- a/arch/x86/pal_cppi41/pal_cppi41.c
+++ b/arch/x86/pal_cppi41/pal_cppi41.c
@@ -82,9 +82,11 @@
 #include<linux/slab.h>
 #include <asm/io.h>
 #include <asm/byteorder.h>
-#include <linux/avalanche/generic/pal_cppi41.h>
 #include <linux/avalanche/puma7/puma7.h>
 #include <linux/avalanche/puma7/puma7_cppi_prv.h>
+#include <linux/avalanche/generic/avalanche_pp_api.h>
+#include <linux/avalanche/generic/pal_cppi41.h>
+#include <linux/avalanche/generic/pal_os.h>
 
 #include "cppi41_hw_mbox_if.h"
 #include <linux/hw_mailbox.h>
@@ -122,6 +124,7 @@
 #define EPRINTK(fmt, args...) printk(KERN_ERR "****** %s(%d): " fmt " ******\n", __FUNCTION__ , __LINE__, ## args)
 
 #define QUEUE_MNG_TO_QUEUE_STAT_OFFSET                      (0x10000)
+#define QUEUE_MNG_TO_QMGR_REGS_OFFSET                       (-0x20000)
 #define QUEUE_NUMBER_TO_QUEUE_ADDR_SHIFT                    (sizeof(CSL_Queue_Mgmt_Regs) / 4)
 #define QUEUE_NUM_TO_QUEUE_BASE_ADDR(qMgr_base, qNum)       ((qMgr_base) + ((qNum) << QUEUE_NUMBER_TO_QUEUE_ADDR_SHIFT))
 
@@ -130,6 +133,7 @@
 /***************/
 unsigned int qMgrs_qMngBase [PAL_CPPI41_NUM_QUEUE_MGR] = { 0 };     /* queue manager's queue management base */
 unsigned int qMgrs_qStatBase[PAL_CPPI41_NUM_QUEUE_MGR] = { 0 };     /* queue manager's queue stats base */
+unsigned int qMgrs_regsBase [PAL_CPPI41_NUM_QUEUE_MGR] = { 0 };     /* queue manager's managment registers */
 
 
 /***************************************/
@@ -169,7 +173,6 @@ typedef enum
 /*********************************/
 /**  local Functions declaration  **/
 /*********************************/
-static bool  PAL_cppiChangeEndianness( Cppi41HwMboxAccChOpenMsg_t *destCfgData, dataPipeEndianNess_e datapipe_endian);
 
 /*********************************/
 /**  Functions Implementations  **/
@@ -188,13 +191,15 @@ PAL_Handle PAL_cppi4Init(unsigned int qM
 
     qMgrs_qMngBase [PAL_CPPI_PP_QMGR_G1] = (unsigned long)(qMgr1Base);
     qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G1] = (unsigned long)(qMgr1Base) + QUEUE_MNG_TO_QUEUE_STAT_OFFSET;
+    qMgrs_regsBase [PAL_CPPI_PP_QMGR_G1] = (unsigned long)(qMgr1Base) + QUEUE_MNG_TO_QMGR_REGS_OFFSET;
     qMgrs_qMngBase [PAL_CPPI_PP_QMGR_G2] = (unsigned long)(qMgr2Base);
     qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G2] = (unsigned long)(qMgr2Base) + QUEUE_MNG_TO_QUEUE_STAT_OFFSET;
+    qMgrs_regsBase [PAL_CPPI_PP_QMGR_G2] = (unsigned long)(qMgr2Base) + QUEUE_MNG_TO_QMGR_REGS_OFFSET;
 
-    DPRINTK("qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G1] = 0x%08x, qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G1] = 0x%08x",
-            qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G1], qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G1]);
-    DPRINTK("qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G2] = 0x%08x, qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G2] = 0x%08x",
-            qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G2], qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G2]);
+    DPRINTK("qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G1] = 0x%08x, qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G1] = 0x%08x, qMgrs_regsBase[PAL_CPPI_PP_QMGR_G1] = 0x%08x\n",
+            qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G1], qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G1], qMgrs_regsBase [PAL_CPPI_PP_QMGR_G1]);
+    DPRINTK("qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G2] = 0x%08x, qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G2] = 0x%08x, Mgrs_regsBase[PAL_CPPI_PP_QMGR_G2] = 0x%08x",
+            qMgrs_qMngBase[PAL_CPPI_PP_QMGR_G2], qMgrs_qStatBase[PAL_CPPI_PP_QMGR_G2], qMgrs_regsBase [PAL_CPPI_PP_QMGR_G2]);
 
     return NULL;
 }
@@ -293,188 +298,230 @@ int PAL_cppi4QueueGetEntryCount(PAL_Hand
 }
 EXPORT_SYMBOL(PAL_cppi4QueueGetEntryCount);
 
-static bool  PAL_cppiChangeEndianness( Cppi41HwMboxAccChOpenMsg_t *destCfgData, dataPipeEndianNess_e datapipe_endian )
+#define SIZE_IN_WORD(p) ((sizeof(p) + 0x3) >> 2)
+
+static Int32 (*__pdsp_cmd_send)(pdsp_id_t, pdsp_cmd_t, void *, Uint32, void *, Uint32) = NULL;
+
+PAL_Result PAL_cppi4PdspCmdSendUnregister(void)
+{
+    BUG_ON(!__pdsp_cmd_send);
+
+    __pdsp_cmd_send = NULL;
+
+    printk("%s:%d: pdsp_cmd_send unregister done.", __func__, __LINE__);
+    return (PAL_SOK);
+}
+EXPORT_SYMBOL(PAL_cppi4PdspCmdSendUnregister);
+
+PAL_Result PAL_cppi4PdspCmdSendRegister(Int32 (*cb)(pdsp_id_t, pdsp_cmd_t, void *, Uint32, void *, Uint32))
 {
-    if( !destCfgData )
+    BUG_ON(__pdsp_cmd_send);
+
+    __pdsp_cmd_send = cb;
+
+    printk("%s:%d: pdsp_cmd_send register done.", __func__, __LINE__);
+    return (PAL_SOK);
+}
+EXPORT_SYMBOL(PAL_cppi4PdspCmdSendRegister);
+
+#define PDSP_PREP_CMD(cmd, option, index)           \
+                        (((cmd) & 0xffu) << 0) |    \
+                        (((option) & 0xffu) << 8) | \
+                        (((index) & 0xffffu) << 16)
+
+static inline AVALANCHE_PP_ACC_CH_INFO_t
+PAL_cppi4AccChInfo_cpu_to_be(AVALANCHE_PP_ACC_CH_INFO_t *src)
+{
+    AVALANCHE_PP_ACC_CH_INFO_t dst;
+
+    memset(&dst, 0, sizeof(AVALANCHE_PP_ACC_CH_INFO_t));
+
+    dst.Index = cpu_to_be16(src->Index);
+    dst.Channel = src->Channel;
+    dst.Command = src->Command;
+    dst.Param0Ret = cpu_to_be32(src->Param0Ret);
+    dst.Param1 = cpu_to_be32(src->Param1);
+    dst.Param2 = cpu_to_be32(src->Param2);
+
+    return dst;
+}
+
+static AVALANCHE_PP_RET_e __cppi4AccChClose(AVALANCHE_PP_ACC_CH_INFO_t *ptr_ch_cfg)
+{
+    pdsp_cmd_t pdsp_cmd = cpu_to_be32(PDSP_PREP_CMD(PDSP_ACCUMULATOR_DISABLE_CH, ptr_ch_cfg->Channel, ptr_ch_cfg->Index));
+    AVALANCHE_PP_RET_e rc;
+
+    BUG_ON(!__pdsp_cmd_send);
+
+    rc = __pdsp_cmd_send(PDSP_ID_Accumulator,
+                         pdsp_cmd,
+                         NULL, 0, NULL, 0);
+    if (rc)
     {
-        EPRINTK(" null pointer reference ");
-        return false;
+        printk("%s:%d ERROR !!! Failed to close accumulator channel !!!\n",__FUNCTION__,__LINE__);
+        return (rc + PP_RC_FAILURE);
     }
-    if( (datapipe_endian != DataPipeBig) && (datapipe_endian != DataPipeLittle) )
+
+	return (PP_RC_SUCCESS);
+}
+
+static AVALANCHE_PP_RET_e __cppi4AccChOpen(AVALANCHE_PP_ACC_CH_INFO_t *ptr_ch_cfg)
+{
+    AVALANCHE_PP_ACC_CH_INFO_t info = PAL_cppi4AccChInfo_cpu_to_be(ptr_ch_cfg);
+    pdsp_cmd_t pdsp_cmd = cpu_to_be32(PDSP_PREP_CMD(PDSP_ACCUMULATOR_ENABLE_CH, ptr_ch_cfg->Channel, ptr_ch_cfg->Index));
+    AVALANCHE_PP_RET_e rc;
+
+    BUG_ON(!__pdsp_cmd_send);
+
+    rc = __pdsp_cmd_send(PDSP_ID_Accumulator,
+                         pdsp_cmd,
+                         &(info.Param0Ret),
+                         SIZE_IN_WORD(AVALANCHE_PP_ACC_CH_INFO_t) - SIZE_IN_WORD(Int32) /* Size of the parameters = total size - command size*/,
+                         NULL,   0);
+
+    if (rc)
     {
-        EPRINTK(" Endianness value pass in datapipe is not correct ");
-        return false;
-    }
-
-    if(datapipe_endian == DataPipeBig)
-    {
-        (*destCfgData).initCfg.accChanNum               =   cpu_to_be32((*destCfgData).initCfg.accChanNum);
-        (*destCfgData).initCfg.mode                     =   cpu_to_be32((*destCfgData).initCfg.mode);
-        (*destCfgData).initCfg.queue.qMgr               =   cpu_to_be32((*destCfgData).initCfg.queue.qMgr);
-        (*destCfgData).initCfg.queue.qNum               =   cpu_to_be32((*destCfgData).initCfg.queue.qNum);
-        (*destCfgData).initCfg.pacingTickCnt            =   cpu_to_be32((*destCfgData).initCfg.pacingTickCnt);
-        (*destCfgData).initCfg.list.listBase            =   (void *)cpu_to_be32((unsigned int)(*destCfgData).initCfg.list.listBase);
-        (*destCfgData).initCfg.list.maxPageEntry        =   cpu_to_be32((*destCfgData).initCfg.list.maxPageEntry);
-        (*destCfgData).initCfg.list.pacingMode          =   cpu_to_be32((*destCfgData).initCfg.list.pacingMode);
-        (*destCfgData).initCfg.list.stallAvoidance      =   cpu_to_be32((*destCfgData).initCfg.list.stallAvoidance);
-        (*destCfgData).initCfg.list.listCountMode       =   cpu_to_be32((*destCfgData).initCfg.list.listCountMode);
-        (*destCfgData).initCfg.list.listEntrySize       =   cpu_to_be32((*destCfgData).initCfg.list.listEntrySize);
-        (*destCfgData).initCfg.list.maxPageCnt          =   cpu_to_be32((*destCfgData).initCfg.list.maxPageCnt);
-        (*destCfgData).initCfg.monitor.pktCountThresh   =   cpu_to_be32((*destCfgData).initCfg.monitor.pktCountThresh);
-        (*destCfgData).initCfg.monitor.pacingMode       =   cpu_to_be32((*destCfgData).initCfg.monitor.pacingMode);
-    }
-    if(datapipe_endian == DataPipeLittle)
-    {
-        (*destCfgData).initCfg.accChanNum               =   be32_to_cpu((*destCfgData).initCfg.accChanNum);
-        (*destCfgData).initCfg.mode                     =   be32_to_cpu((*destCfgData).initCfg.mode);
-        (*destCfgData).initCfg.queue.qMgr               =   be32_to_cpu((*destCfgData).initCfg.queue.qMgr);
-        (*destCfgData).initCfg.queue.qNum               =   be32_to_cpu((*destCfgData).initCfg.queue.qNum);
-        (*destCfgData).initCfg.pacingTickCnt            =   be32_to_cpu((*destCfgData).initCfg.pacingTickCnt);
-        (*destCfgData).initCfg.list.listBase            =   (void *)be32_to_cpu((*destCfgData).initCfg.list.listBase);
-        (*destCfgData).initCfg.list.maxPageEntry        =   be32_to_cpu((*destCfgData).initCfg.list.maxPageEntry);
-        (*destCfgData).initCfg.list.pacingMode          =   be32_to_cpu((*destCfgData).initCfg.list.pacingMode);
-        (*destCfgData).initCfg.list.stallAvoidance      =   be32_to_cpu((*destCfgData).initCfg.list.stallAvoidance);
-        (*destCfgData).initCfg.list.listCountMode       =   be32_to_cpu((*destCfgData).initCfg.list.listCountMode);
-        (*destCfgData).initCfg.list.listEntrySize       =   be32_to_cpu((*destCfgData).initCfg.list.listEntrySize);
-        (*destCfgData).initCfg.list.maxPageCnt          =   be32_to_cpu((*destCfgData).initCfg.list.maxPageCnt);
-        (*destCfgData).initCfg.monitor.pktCountThresh   =   be32_to_cpu((*destCfgData).initCfg.monitor.pktCountThresh);
-        (*destCfgData).initCfg.monitor.pacingMode       =   be32_to_cpu((*destCfgData).initCfg.monitor.pacingMode);
+        printk("%s:%d ERROR !!! Failed to open accumulator channel !!!\n",__FUNCTION__,__LINE__);
+        __cppi4AccChClose(ptr_ch_cfg);
+        return (rc + PP_RC_FAILURE);
     }
-    return true;
+
+	return (PP_RC_SUCCESS);
 }
 
-/* Following API will use HW mailbox provide Accumulator fuctionalities */
 PAL_Cppi4AccChHnd PAL_cppi4AccChOpen(PAL_Handle hnd, Cppi4AccumulatorCfg* accCfg)
 {
-
-    /*Return pointer to the caller */
+    Uint32 cookie;
     PAL_Cppi4AccChObj *accChObj;
-    /* transport message over HW_MBOX */
-    Cppi41HwMboxAccChOpenMsg_t  openAccChObj;
-    /* local temporary varaibles */
-    Cppi41HwMboxAccChOpenReplyMsg_t* tmp;
-    unsigned long tmpPtr;
-    /* transport message over HW_MBOX */
-    /* Return length of HW mailbox Op-Code channle */
-    Uint32 dataLen = sizeof(Cppi41HwMboxAccChOpenMsg_t);
-    if(!accCfg)
-    {
-        EPRINTK("NULL pointer reference.");
+#if PUMA7_OR_NEWER_SOC_TYPE
+    AVALANCHE_PP_ACC_CH_INFO_t ptr_ch_cfg;
+    AVALANCHE_PP_RET_e rc;
+#else
+    Uint32 i;
+    Cppi4PALObj *palCppi4Obj = (Cppi4PALObj *) hnd;
+    Cppi4InitCfg * initCfg = palCppi4Obj->initCfg;
+    APDSP_Command_Status_RegsOvly cmdRegs = initCfg->apdspInfo.pdspCmdBase;
+#endif
+    if (PAL_osMemAlloc(0, sizeof(PAL_Cppi4AccChObj), 0, (Ptr *) &accChObj) != PAL_SOK) {
+        EPRINTK ("\nERROR:PAL: PAL_cppi4AccChOpen: Failed to allocate Acc channel object structure.");
         return NULL;
     }
 
-    /* kmalloc returns cache line aligned memory unless you are debugging the slab allocator (2.6.18) */
-    accChObj = (PAL_Cppi4AccChObj *)kzalloc(sizeof(PAL_Cppi4AccChObj) ,GFP_KERNEL);
-    if(!accChObj)
-    {
-        EPRINTK("could not allocate memeory for local accumulator ojbect");
-        return NULL;
-    }
+    PAL_osMemSet (accChObj, 0, sizeof (PAL_Cppi4AccChObj));
 
-    /*copy accCfg data to accumulator channel onject */
-    if(!accCfg->list.listBase)
-    {
+    PAL_osMemCopy(&accChObj->initCfg, accCfg, sizeof(Cppi4AccumulatorCfg));
 
-        EPRINTK("NULL pointer reference. for accCfg.list.base");
-        return NULL;
-    }
+    accChObj->palCppi4Obj = hnd;
 
-    /* Copy datapipe accumulator init paramters into the message container */
-    memcpy(&openAccChObj.initCfg, accCfg, sizeof(Cppi4AccumulatorCfg));
-    DPRINTK(" Virtual  list.listBase=%p, address received=%p before sending to HWMbox.\n",  openAccChObj.initCfg.list.listBase,  accCfg->list.listBase );
-
-    /* APPCPU virtual address need to converted to Physical address before sending to HW mailbox */
-    tmpPtr = (unsigned long)virt_to_phys(openAccChObj.initCfg.list.listBase);
-    openAccChObj.initCfg.list.listBase = (void*)tmpPtr;
-    DPRINTK(" Physical  list.listBase=%p, Original address received=%p before sending to HWMbox.\n",  openAccChObj.initCfg.list.listBase,  accCfg->list.listBase );
+    /* Need to protect the accumulator register writes. They are shared with pre-fetcher */
+    PAL_osProtectEntry(PAL_OSPROTECT_INTERRUPT, &cookie);
 
-    /* hardware mailbox implementation to open accumulator channel goes here */
-    if(hwMbox_isReady())
-    {
-        EPRINTK("HW mailbox isn't ready yet.");
-        kfree(accChObj);
-        return NULL;
-    }
-     ACCUM_CH_PARAM_DEBUG(openAccChObj.initCfg);
-    /* need to convert data from cpu_to_be(); */
-    if(!PAL_cppiChangeEndianness(&openAccChObj, DataPipeBig))
-    {
-        EPRINTK("data conversion fo endianness failed");
-        kfree(accChObj);
-        return NULL;
-    }
+#if PUMA7_OR_NEWER_SOC_TYPE
+    ptr_ch_cfg.Channel      =   accCfg->accChanNum ;
+    ptr_ch_cfg.Command      =   0 ;
+    ptr_ch_cfg.Param0Ret    =   (Uint32)PAL_CPPI4_VIRT_2_PHYS((void *)accCfg->list.listBase) ;
+    ptr_ch_cfg.Param1       =   (accCfg->queue.qNum) | (accCfg->queue.qMgr << 12) | (accCfg->list.maxPageEntry << 16);
+    ptr_ch_cfg.Param2       =   (accCfg->pacingTickCnt)             |
+                                (accCfg->list.maxPageCnt    << 16)  | (accCfg->list.listEntrySize  << 18)|
+                                (accCfg->list.listCountMode << 20)  | (accCfg->list.stallAvoidance << 21)|
+                                (accCfg->list.pacingMode    << 22);
 
-    /* need to send accumulator handler as well  though we are not using it right now but incase needed in future */
-    /*  will receive back Object address in SendReplyOp() at npcpuAddress variable */
-     openAccChObj.cmd = cpu_to_be32(CPPI41_HWMBOX_CMD_ACC_CH_OPEN);
-     ACCUM_CH_PARAM_DEBUG(openAccChObj.initCfg);
-    /* send a message to NP-CPU and expect a 64 byte reply back using SendReplyOp()*/
-    DPRINTK(" size of data length=%d.", sizeof(Cppi41HwMboxAccChOpenMsg_t));
-    if(hwMbox_sendOpcode(HW_MBOX_MASTER_NP_CPU, NPCPU_APPCPU_HW_MBOX_TAG_CPPI41_MBX , (uint8_t *)&openAccChObj, sizeof(Cppi41HwMboxAccChOpenMsg_t) , sizeof(Cppi41HwMboxAccChOpenMsg_t) , &dataLen))
+    rc = __cppi4AccChOpen ( &ptr_ch_cfg);
+    if (PP_RC_SUCCESS != rc)
     {
-        EPRINTK("HW mailbox hwMbox_sendOpcode failed.");
-        kfree(accChObj);
+        EPRINTK("Error: Accumulator PDSP is not responding, return code: %u\n", rc);
+        PAL_osProtectExit(PAL_OSPROTECT_INTERRUPT, cookie);
+
+        PAL_osMemFree( 0, accChObj, sizeof(PAL_Cppi4AccChObj) );
         return NULL;
     }
-    if(dataLen != sizeof(Cppi41HwMboxAccChOpenReplyMsg_t))
+#else
+
+    if(accCfg->mode) {
+        /* monitor mode */
+        cmdRegs->Config_A = (accCfg->queue.qNum) | (accCfg->queue.qMgr << 8) | (accCfg->monitor.pktCountThresh << 16);
+        cmdRegs->Config_B = (accCfg->pacingTickCnt) | (accCfg->monitor.pacingMode << 22) | (0x1 << 31);
+    } else {
+        /* list mode */
+        cmdRegs->List_Buffer_Address = PAL_CPPI4_VIRT_2_PHYS(accCfg->list.listBase);
+        cmdRegs->Config_A = (accCfg->queue.qNum) | (accCfg->queue.qMgr << 8) | (accCfg->list.maxPageEntry << 16);
+        cmdRegs->Config_B = (accCfg->pacingTickCnt) | (accCfg->list.maxPageCnt << 16)
+                | (accCfg->list.listEntrySize << 18) | (accCfg->list.listCountMode << 20)
+                | (accCfg->list.stallAvoidance << 21)| (accCfg->list.pacingMode << 22);
+    }
+    cmdRegs->Command = (accCfg->accChanNum) | (APDSP_CMD_ENABLE << 8);
+
+    dbgPrint("APDSP config @%p, value %x\n", &cmdRegs->List_Buffer_Address, cmdRegs->List_Buffer_Address);
+    dbgPrint("APDSP config @%p, value %x\n", &cmdRegs->Config_A, cmdRegs->Config_A);
+    dbgPrint("APDSP config @%p, value %x\n", &cmdRegs->Config_B, cmdRegs->Config_B);
+    dbgPrint("APDSP config @%p, value %x\n", &cmdRegs->Command, cmdRegs->Command);
+
+    /* TODO: 1000000 is a magic word picked up from mike's code. Need to understand
+     * timeout values and fix the code
+     */
+    for(i=0; (i < 1000000) && (cmdRegs->Command & (0xFF << 8)); i++);
+
+    if( i==1000000 )
     {
-        EPRINTK("HW mailbox hwMbox_sendOpcode reply wasnt of desire length Cppi41HwMboxAccChOpenReplyMsg=%d dataLen=%d ",sizeof(Cppi41HwMboxAccChOpenReplyMsg_t), dataLen);
-        kfree(accChObj);
+        EPRINTK("Error: APDSP firmware not responding!, APDSP return code: 0x%02X\n", (cmdRegs->Command & (0xFF << 24)));
+        PAL_osProtectExit(PAL_OSPROTECT_INTERRUPT, cookie);
+
+        PAL_osMemFree( 0, accChObj, sizeof(PAL_Cppi4AccChObj) );
+
         return NULL;
     }
+#endif
 
-    DPRINTK("HW mailbox adpHwMboxmessageObj.msgData.initCfg.list.listBase before Endian change=%p.", openAccChObj.initCfg.list.listBase);
-    /* need to conver data from be_to_cpu(); */
-
-    DPRINTK("HW mailbox Received adpHwMboxmessageObj.msgData.initCfg.list.listBase after Endian change=%p.", openAccChObj.initCfg.list.listBase);
-    DPRINTK("HW mailbox called to  accumulator open successful.");
-    /* copy HW_Mbox message to kmalloced object for return */
-    DPRINTK("data length=%d.",dataLen );
-    memcpy(accChObj, accCfg, sizeof(Cppi4AccumulatorCfg));
-    tmp = (Cppi41HwMboxAccChOpenReplyMsg_t *) &openAccChObj;
-    accChObj->curPage = be32_to_cpu( tmp->curPage);
-    DPRINTK("curPage=%d.", accChObj->curPage );
-    accChObj->npcpuAddress = (unsigned int)tmp->accChHnd;
-    DPRINTK("npcpuAddress=%d.", accChObj->npcpuAddress );
+    accChObj->curPage = 0;
 
-    DPRINTK("HW mailbox Received accChObj->initCfg.list.listBase after phys_to_virt=%p.", accChObj->initCfg.list.listBase);
+    PAL_osProtectExit(PAL_OSPROTECT_INTERRUPT, cookie);
 
-    return (PAL_Cppi4AccChHnd)accChObj;
+    return (PAL_Cppi4AccChHnd) accChObj;
 }
 EXPORT_SYMBOL(PAL_cppi4AccChOpen);
 
 int PAL_cppi4AccChClose(PAL_Cppi4AccChHnd hnd, void *closeArgs)
 {
-    /* local pointer to free */
-    PAL_Cppi4AccChObj *accChObj;
-    /* transport message over HW_MBOX */
-    Cppi41HwMboxAccChCloseMsg_t adpHwMboxmessageObj;
-    Uint32 dataLen = sizeof(Cppi41HwMboxAccChCloseMsg_t);
-
-    if(!hnd)
-    {
-        EPRINTK("NULL pointer reference.");
-        return false;
-    }
-
-    accChObj = (PAL_Cppi4AccChObj *)hnd;
-    /*copy PAL_Cppi4AccChObj data to accumulator channel onject */
-    /* convert data since CPPI need ch_num for accumulator close  */
-    adpHwMboxmessageObj.accChHnd =  (void *)accChObj->npcpuAddress;
-    DPRINTK("npcpuAddress=%d.", accChObj->npcpuAddress );
-
-    adpHwMboxmessageObj.cmd = cpu_to_be32(CPPI41_HWMBOX_CMD_ACC_CH_CLOSE);
-    /* send a message to NP-CPU and expect to pointer get free in NPCPUaddress space make sure correct poiter by reply*/
-    if(hwMbox_sendOpcode(HW_MBOX_MASTER_NP_CPU,NPCPU_APPCPU_HW_MBOX_TAG_CPPI41_MBX, (uint8_t *)&adpHwMboxmessageObj, sizeof(Cppi41HwMboxAccChCloseMsg_t), sizeof(Cppi41HwMboxAccChCloseMsg_t), &dataLen))
-    {
-        EPRINTK("HW mailbox hwMbox_sendOpcode failed.");
-        return false;
-    }
-    /* free local onject which was created in Open call */
-    kfree(accChObj);
-    /* hardware mailbox implementation to close accumulator channel goes here */
-    DPRINTK("HW mailbox called to free accumulator channel successful.");
-    return true;
+    PAL_Cppi4AccChObj *accChObj = (PAL_Cppi4AccChObj *) hnd;
+#if PUMA7_OR_NEWER_SOC_TYPE
+    AVALANCHE_PP_ACC_CH_INFO_t ptr_ch_cfg;
+    AVALANCHE_PP_RET_e rc; //return code
+
+    ptr_ch_cfg.Channel      =   accChObj->initCfg.accChanNum ;
+    ptr_ch_cfg.Command      =   0 ;
+    ptr_ch_cfg.Param0Ret    =   0 ;
+    ptr_ch_cfg.Param1       =   0 ;
+    ptr_ch_cfg.Param2       =   0 ;
+
+    if ((rc = __cppi4AccChClose ( &ptr_ch_cfg)) !=  PP_RC_SUCCESS )
+    {
+        DPRINTK("\nError: APDSP firmware not responding!");
+        DPRINTK("APDSP return code: %d\n", rc);
+        return PAL_ERROR_FLAG;
+    }
+#else
+    Cppi4PALObj *palCppi4Obj = accChObj->palCppi4Obj;
+    Cppi4InitCfg * initCfg = palCppi4Obj->initCfg;
+    Uint32 i;
+    APDSP_Command_Status_RegsOvly cmdRegs = initCfg->apdspInfo.pdspCmdBase;
+    cmdRegs->List_Buffer_Address = 0;
+    cmdRegs->Config_A = 0;
+    cmdRegs->Config_B = 0;
+    cmdRegs->Command = (accChObj->initCfg.accChanNum) | (APDSP_CMD_DISABLE << 8);
+
+    /* TODO: 1000000 is a magic word picked up from mike's code. Need to understand
+     * timeout values and fix the code
+     */
+    for(i=0; (i < 1000000) && (cmdRegs->Command & (0xFF << 8)); i++);
+    if( i==1000000 ) {
+        dbgPrint("\nError: APDSP firmware not responding!");
+        dbgPrint("APDSP return code: %x\n", (cmdRegs->Command & (0xFF << 24)));
+        return PAL_ERROR_FLAG;
+    }
+#endif
+    PAL_osMemFree(0, hnd, sizeof(PAL_Cppi4AccChObj));
+
+    return PAL_SOK;
 }
 EXPORT_SYMBOL(PAL_cppi4AccChClose);
 
@@ -504,6 +551,37 @@ void* PAL_cppi4AccChGetNextList(PAL_Cppi
 }
 EXPORT_SYMBOL(PAL_cppi4AccChGetNextList);
 
+
+int PAL_cppi4Control (PAL_Handle hnd, Uint32 cmd, Ptr cmdArg, Ptr param)
+{
+    PAL_CPPI_PP_QMGRs_e qMgr = *(Uint32 *)param;
+    switch (cmd)
+    {
+        case PAL_CPPI41_IOCTL_QUEUE_DIVERT:
+        {
+            CSL_Queue_Manager_Region_RegsOvly regs;
+            if (qMgr != PAL_CPPI_PP_QMGR_G1 && qMgr != PAL_CPPI_PP_QMGR_G2) {
+                pr_err("%s:%d: unsupported queue manager!\n", __func__, __LINE__);
+                return 1;
+            }
+            regs = (CSL_Queue_Manager_Region_RegsOvly)qMgrs_regsBase[qMgr];
+            if (!regs) {
+                pr_err("%s:%d: queue manager %d not initialized!\n",__func__, __LINE__, qMgr);
+                return 1;
+            }
+            regs->Queue_Diversion = cpu_to_be32((Uint32)cmdArg);
+            break;
+        }
+        default:
+        {
+            pr_err("%s:%d:: Unsupported ioctl code %d",__func__, __LINE__, cmd);
+            return 1;
+        }
+    }
+    return 0;
+}
+EXPORT_SYMBOL(PAL_cppi4Control);
+
 static int __init pal_cppi41_init(void)
 {
 	DPRINTK("pal_cppi41_init\n");
--- a/arch/x86/pp_init/puma7_pp_init.c
+++ b/arch/x86/pp_init/puma7_pp_init.c
@@ -45,15 +45,45 @@
 #include <linux/netip_subsystem.h>
 
 
-/*Defines*/
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+/* interrupts NPCPU*/
+#define DWC_REQUEST_IRQ(irq, handler, flags, name, dev) \
+                                    request_irq(irq, handler, flags, name, dev)
+#define DWC_FREE_IRQ(irq, dev)      free_irq(irq, dev)
+#define DWC_ENABLE_IRQ(irq)         enable_irq(irq)
+#define DWC_DISABLE_IRQ(irq)        disable_irq(irq)
+#define DWC_DISABLE_IRQ_NOSYC(irq)  disable_irq_nosync(irq)
+#define DWC_ACK_IRQ(irq)            ack_irq(irq)
+
+#else
+
+/* interrupts APPCPU */
+#define DWC_REQUEST_IRQ(irq, handler, flags, name, dev) \
+                                    netss_request_npcpu_irq(irq, name, handler, dev)
+#define DWC_FREE_IRQ(irq, dev)      do {} while(0) /* TODO: need to implement free_irq for netss module */
+#define DWC_ENABLE_IRQ(irq)         avalanche_intc_enable_irq(irq)
+#define DWC_DISABLE_IRQ(irq)        avalanche_intc_disable_irq(irq)
+#define DWC_DISABLE_IRQ_NOSYC(irq)  avalanche_intc_disable_irq(irq)
+#define DWC_ACK_IRQ(irq)            avalanche_intc_clear_status(irq)
+#endif
+
 #define PAL_CPPI41_ACC_MAX_PAGE_ENTRIES                32
 #define PAL_CPPI41_ACC_LIST_NULL_TERM                  0
 #define PAL_CPPI41_ACC_PACE_MODE_LASTINTR              1
 #define PAL_CPPI41_ACC_PACE_TICK_CNT                   40
 #define PAL_CPPI41_ACC_MAX_PAGE_COUNT                  2
+#define NETDEV_TX_SERVICE_MAX                          ((PAL_CPPI41_ACC_MAX_PAGE_ENTRIES - 1) * 2)
+
+//#define TX_COMPLETE_NETDEV_USE_TASKLET
+#define TX_COMPLETE_NETDEV_USE_NAPI
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+    struct napi_struct      gTxCompleteNapi;
+    struct net_device       dummyDev;
+    static int              netdev_tx_poll(struct napi_struct *napi , int budget);
+#elif defined(TX_COMPLETE_NETDEV_USE_TASKLET)
+    struct tasklet_struct   gTxCompleteTasklet;     /* Tx completion processing tasklet */
+#endif
 
-/*Function decleration*/
-static void __do_tx_complete(unsigned long data);
 static int __init_acc_channel(PAL_Handle pal_hnd, int chan_num, Cppi4Queue queue, PAL_Cppi4AccChHnd *acc_hnd);
 irqreturn_t tx_complete_interrupt(int irq, void *dev);
 Int32 __setup_txcomplete(PAL_Handle palHnd);
@@ -61,13 +91,10 @@ static int replace_npcpu_memory_for_queu
 static int replace_npcpu_memory(PAL_Handle palHnd);
 static int __init tx_comp_init(void);
 static void __exit tx_comp_cleanup (void);
-
-
-/*Declerations*/
-struct tasklet_struct   gTxCompleteTasklet;     /* Tx completion processing tasklet */
 PAL_Cppi4AccChHnd       gTxCompleteAccChHnd[PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT];
 Ptr                     gTxCompleteAccListBase[PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT];
-Cppi4HostDescLinux **gTxCompleteAccList[PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT];
+Cppi4HostDescLinux**    gTxCompleteAccList[PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT];
+
 PAL_Cppi4QueueHnd       gHost2ppFreeHostDescQueueHnd[PAL_CPPI_PP_HOST2PP_INFRA_DMA_CH_COUNT];
 
 static unsigned int q_info[] = {
@@ -81,32 +108,48 @@ static unsigned int q_info[] = {
     PAL_CPPI_PP_QMGR_G2_HOST2PP_HI_HOST_FD_Q_NUM,
 };
 
-/*Code section*/
-
-static void __do_tx_complete(unsigned long data)
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+static inline int get_list_entry_count(int priority)
 {
-	Cppi4HostDescLinux *hostDesc;
-	Uint32      packets_processed = 0;
-	Int32       priority;
-
-	/* Start with high priority channel */
-	for (priority = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT - 1; priority >= 0; priority--) {
-		/* While there are ready pages... */
-		while (avalanche_intd_get_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority))) {
-            int list_entry_count;
-            unsigned long long timeout = 1<<31; /* long timeout */
+    int list_entry_count;
+    unsigned long long timeout = 1<<31; /* long timeout */
 
             do {
                 PAL_CPPI4_CACHE_INVALIDATE(gTxCompleteAccList[priority], sizeof(int *));
                 list_entry_count = be32_to_cpu((unsigned long)*gTxCompleteAccList[priority]);
-                pr_debug("%s:%d: list_entry_count %x\n", __func__, __LINE__, list_entry_count);
-            } while(!list_entry_count && --timeout);
+            pr_debug("%s:%d: list_entry_count %x\n", __func__, __LINE__, list_entry_count);
+    } while(!list_entry_count && --timeout);
 
-            BUG_ON(!timeout);
+    BUG_ON(!timeout);
 
             *gTxCompleteAccList[priority] = NULL;
             PAL_CPPI4_CACHE_INVALIDATE(gTxCompleteAccList[priority], sizeof(int *));
             gTxCompleteAccList[priority]++;
+    return list_entry_count;
+}
+#endif
+
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+static int  __do_tx_complete(struct net_device* dev, int budget)
+#elif defined(TX_COMPLETE_NETDEV_USE_TASKLET)
+static void __do_tx_complete(unsigned long data)
+#else
+#error "Please choose packet processing framework"
+#endif // TX_COMPLETE_NETDEV_USE_NAPI
+{
+    Cppi4HostDescLinux* hostDesc;
+    Uint32      packets_processed = 0;
+    Int32       priority;
+
+    /* Start with high priority channel */
+	for (priority = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT - 1; priority >= 0; priority--) {
+        /* While there are ready pages... */
+		while (avalanche_intd_get_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority)) &&
+                       (packets_processed <= NETDEV_TX_SERVICE_MAX)) {
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+        int list_entry_count = get_list_entry_count(priority);
+
+        BUG_ON(list_entry_count > PAL_CPPI41_ACC_MAX_PAGE_ENTRIES);
 
             while(list_entry_count--) {
                 do {
@@ -117,8 +160,13 @@ static void __do_tx_complete(unsigned lo
 
                 *gTxCompleteAccList[priority] = NULL;
                 PAL_CPPI4_CACHE_INVALIDATE(gTxCompleteAccList[priority], sizeof(int *));
-                hostDesc = PAL_CPPI4_PHYS_2_VIRT(hostDesc);
 
+#else
+            /* While there are descriptors in the page... */
+            while((hostDesc = (Cppi4HostDescLinux*)((unsigned long)*gTxCompleteAccList[priority] & QMGR_QUEUE_N_REG_D_DESC_ADDR_MASK))) {
+#endif
+
+                hostDesc = PAL_CPPI4_PHYS_2_VIRT(hostDesc);
                 PAL_CPPI4_CACHE_INVALIDATE(hostDesc, PAL_CPPI_PP_QMGR_GLOBAL_DEFAULT_DESC_SIZE);
 
                 dev_kfree_skb_any(be32_to_cpu(hostDesc->skb));
@@ -129,130 +177,215 @@ static void __do_tx_complete(unsigned lo
 
                 packets_processed++;
                 gTxCompleteAccList[priority]++;
-			}
+            }
 
-			/* Update the list entry for next time */
-			gTxCompleteAccList[priority] = PAL_cppi4AccChGetNextList(gTxCompleteAccChHnd[priority]);
+            /* Update the list entry for next time */
+            gTxCompleteAccList[priority] = PAL_cppi4AccChGetNextList(gTxCompleteAccChHnd[priority]);
 
-			/* Decrement number of pages by 1 */
-			avalanche_intd_set_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority), 1);
-		}
-	}
+            /* Decrement number of pages by 1 */
+            avalanche_intd_set_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority), 1);
 
-	/* First clear the IRQ in order not to get a false interrupt since INTD is level */
-	avalanche_intc_clear_status(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+            /* thats it, we did enough. Jump out now! */
+            if(packets_processed >= budget)
+            {
+                return packets_processed;
+            }
+#endif // TX_COMPLETE_NETDEV_USE_NAPI
+        }
+    }
+#if defined(TX_COMPLETE_NETDEV_USE_TASKLET)
+    /* First clear the IRQ in order not to get a false interrupt since INTD is level */
+    DWC_ACK_IRQ(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
 
     /* Send INTD EOI */
-	avalanche_intd_write_eoi(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM);
+    avalanche_intd_write_eoi(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM);
 
-	/* It could be that between INTD count decrement and EOI the accumulator will issue another interrupt.
-	   The logic of INTD is such that level will remain active high even after EOI is set, so INTC will
-	   lose the interrupt after ack_irq is done (it now expects INTD polarity change).
-	   Therefore we must check INTD count and if it is not 0 - reschedule the tasklet */
+    /* It could be that between INTD count decrement and EOI the accumulator will issue another interrupt.
+       The logic of INTD is such that level will remain active high even after EOI is set, so INTC will
+       lose the interrupt after ack_irq is done (it now expects INTD polarity change).
+       Therefore we must check INTD count and if it is not 0 - reschedule the tasklet */
 	for (priority = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT - 1; priority >= 0; priority--) {
 		if (avalanche_intd_get_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority))) {
             tasklet_schedule(&gTxCompleteTasklet);
-			return;
-		}
+            return;
+        }
 	}
 
-	avalanche_intc_enable_irq(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+    DWC_ENABLE_IRQ(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+#endif
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+    return packets_processed;
+#endif
 }
 
-static int __init_acc_channel(PAL_Handle pal_hnd, int chan_num, Cppi4Queue queue, PAL_Cppi4AccChHnd *acc_hnd)
+static int __init_acc_channel(PAL_Handle pal_hnd, int chan_num, Cppi4Queue queue, PAL_Cppi4AccChHnd* acc_hnd)
 {
-	Cppi4AccumulatorCfg cfg;
-	unsigned int accListSize;
+    Cppi4AccumulatorCfg cfg;
+    unsigned int accListSize;
 
-	*acc_hnd = NULL;
+    *acc_hnd = NULL;
 
-	cfg.accChanNum             = chan_num;
-	cfg.list.maxPageEntry      = PAL_CPPI41_ACC_MAX_PAGE_ENTRIES;   /* This is entries per page (and we have 2 pages) */
-	cfg.list.listEntrySize     = PAL_CPPI41_ACC_ENTRY_TYPE_D;   /* Only interested in register 'D' which has the desc pointer */
-    cfg.list.listCountMode     = 1;                                 /* 1 => Entry Count Mode */
+    cfg.accChanNum             = chan_num;
+    cfg.list.maxPageEntry      = PAL_CPPI41_ACC_MAX_PAGE_ENTRIES;   /* This is entries per page (and we have 2 pages) */
+    cfg.list.listEntrySize     = PAL_CPPI41_ACC_ENTRY_TYPE_D;   /* Only interested in register 'D' which has the desc pointer */
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+    cfg.list.listCountMode     = PAL_CPPI41_ACC_PACE_MODE_LASTINTR;    /* One indicates Entry Count Mode */
+#else
+    cfg.list.listCountMode     = PAL_CPPI41_ACC_LIST_NULL_TERM;        /* Zero indicates null terminated list. */
+#endif
     cfg.list.pacingMode        = PAL_CPPI41_ACC_PACE_MODE_LASTINTR; /* Wait for time since last interrupt */
-	cfg.pacingTickCnt          = PAL_CPPI41_ACC_PACE_TICK_CNT;      /* Wait for 1000uS == 1ms */
-	cfg.list.maxPageCnt        = PAL_CPPI41_ACC_MAX_PAGE_COUNT;     /* Use two pages */
-	cfg.list.stallAvoidance    = 1;                             /* Use the stall avoidance feature */
-	cfg.queue                  = queue;
-	cfg.mode                   = 0;
+    cfg.pacingTickCnt          = PAL_CPPI41_ACC_PACE_TICK_CNT;      /* Wait for 1000uS == 1ms */
+    cfg.list.maxPageCnt        = PAL_CPPI41_ACC_MAX_PAGE_COUNT;     /* Use two pages */
+    cfg.list.stallAvoidance    = 1;                             /* Use the stall avoidance feature */
+    cfg.queue                  = queue;
+    cfg.mode                   = 0;
 
-	accListSize = (cfg.list.maxPageEntry * (cfg.list.listEntrySize + 1)) * cfg.list.maxPageCnt * sizeof(Uint32);
+    accListSize = (cfg.list.maxPageEntry * (cfg.list.listEntrySize + 1)) * cfg.list.maxPageCnt * sizeof(Uint32);
 	if (!(cfg.list.listBase = kzalloc(accListSize, GFP_KERNEL))) {
 		pr_err("Unable to allocate list page of size %d\n", accListSize);
-		return -1;
-	}
+        return -1;
+    }
 
-	PAL_CPPI4_CACHE_WRITEBACK((unsigned long)cfg.list.listBase, accListSize);
+    PAL_CPPI4_CACHE_WRITEBACK((unsigned long)cfg.list.listBase, accListSize);
 
 	if (!(*acc_hnd = PAL_cppi4AccChOpen(pal_hnd, &cfg))) {
 		pr_err("Unable to open accumulator channel #%d\n", chan_num);
-		kfree(cfg.list.listBase);
-		return -1;
-	}
+        kfree(cfg.list.listBase);
+        return -1;
+    }
 
-	return 0;
+    return 0;
 }
 
 irqreturn_t tx_complete_interrupt(int irq, void *dev)
 {
-	/* Since the INTD interrupts are level, need to disable the IRQ in order to run the tasklet */
-	avalanche_intc_disable_irq(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+    DWC_DISABLE_IRQ_NOSYC(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
 
-	tasklet_schedule(&gTxCompleteTasklet);
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+    napi_schedule(&gTxCompleteNapi);
+#elif defined(TX_COMPLETE_NETDEV_USE_TASKLET)
+    tasklet_schedule(&gTxCompleteTasklet);
+#endif
 
-	return IRQ_RETVAL(1);
+    return IRQ_RETVAL(1);
 }
 
 
 Int32 __setup_txcomplete(PAL_Handle palHnd)
 {
-	Cppi4Queue  txCmplQ;
-	Cppi4Queue  fdHostQ;
-	Uint8       priority;
+    Cppi4Queue  txCmplQ;
+    Cppi4Queue  fdHostQ;
+    Uint8       priority;
 
 	for (priority = 0; priority < PAL_CPPI_PP_HOST2PP_INFRA_DMA_CH_COUNT; priority++) {
-		/************************************************/
-		/* reset Tx complete queue                      */
-		/************************************************/
-		txCmplQ.qMgr = PAL_CPPI_PP_QMGR_G2;
-		txCmplQ.qNum = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_Q_NUM(priority);
-		PAL_cppi4QueueClose(palHnd, PAL_cppi4QueueOpen(palHnd, txCmplQ));
+        /************************************************/
+        /* reset Tx complete queue                      */
+        /************************************************/
+        txCmplQ.qMgr = PAL_CPPI_PP_QMGR_G2;
+        txCmplQ.qNum = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_Q_NUM(priority);
+        PAL_cppi4QueueClose(palHnd, PAL_cppi4QueueOpen(palHnd, txCmplQ));
 
-		fdHostQ.qMgr = PAL_CPPI_PP_QMGR_G2;
-		fdHostQ.qNum = PAL_CPPI_PP_HOST2PP_HOST_FD_Q_NUM(priority);
+        fdHostQ.qMgr = PAL_CPPI_PP_QMGR_G2;
+        fdHostQ.qNum = PAL_CPPI_PP_HOST2PP_HOST_FD_Q_NUM(priority);
 
 		if (!(gHost2ppFreeHostDescQueueHnd[priority] = PAL_cppi4QueueOpen(palHnd, fdHostQ))) {
 			pr_err("unable to open FD Host Queue #%d for TX Complete task\n", fdHostQ.qNum);
-			return -1;
-		}
+            return -1;
+        }
 
-		/************************************************/
-		/* Init the Tx complete accumulator channel     */
-		/************************************************/
+        /************************************************/
+        /* Init the Tx complete accumulator channel     */
+        /************************************************/
 		if (__init_acc_channel(palHnd, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority), txCmplQ, &gTxCompleteAccChHnd[priority])) {
 			pr_err("unable to open accumulator channel #%d for TX Complete task\n", PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority));
-			return -1;
-		}
+            return -1;
+        }
 
-		gTxCompleteAccListBase[priority] = gTxCompleteAccList[priority] = PAL_cppi4AccChGetNextList(gTxCompleteAccChHnd[priority]);
+        gTxCompleteAccListBase[priority] = gTxCompleteAccList[priority] = PAL_cppi4AccChGetNextList(gTxCompleteAccChHnd[priority]);
 
-		/* request the Tx Complete IRQs - one IRQ per all TX complete priorities */
+        /* request the Tx Complete IRQs - one IRQ per all TX complete priorities */
 		if (priority == 0) {
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+            init_dummy_netdev(&dummyDev);
+            netif_napi_add(&dummyDev, &gTxCompleteNapi, netdev_tx_poll, NETDEV_TX_SERVICE_MAX); 
+            napi_enable(&gTxCompleteNapi); 
+#elif defined(TX_COMPLETE_NETDEV_USE_TASKLET)
             tasklet_init(&gTxCompleteTasklet, __do_tx_complete, 0);
-			if (netss_request_npcpu_irq(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM), "TX Complete", tx_complete_interrupt, NULL))
-			{
+#endif
+            if(DWC_REQUEST_IRQ(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM), tx_complete_interrupt, IRQF_DISABLED, "TX Complete", NULL))
+            {
 				pr_err("unable to get IRQ #%d for TX Complete task\n", MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
-				return -1;
-			}
-		}
-	}
+                return -1;
+            }
+        }
+    }
 
-	return 0;
+    return 0;
 }
-
 EXPORT_SYMBOL(__setup_txcomplete);
 
+#if defined(TX_COMPLETE_NETDEV_USE_NAPI)
+/**************************************************************************/
+/*! \fn         netdev_tx_poll
+ **************************************************************************
+ *
+ *
+ *  \param[in]  Net Device
+ *  \param[in]  Processed packets budget
+ *  \return     Number of processed packets
+ **************************************************************************/
+static int netdev_tx_poll(struct napi_struct *napi , int budget)
+{
+    int work_done, priority;
+    unsigned long flags;
+
+    work_done = __do_tx_complete(NULL, budget);
+
+    if (likely(work_done >= budget))
+        return budget;
+
+    /* order is important here. If we do EOI before calling netif_tx_complete, an interrupt
+     * can occur just before we take ourselves out of the poll list; we will not
+     * schedule NAPI thread on that interrupt, no further Tx interrupts and
+     * Tx will stall forever. Scary...
+     * */
+    napi_complete(napi);
+
+    /* Accumulator looks at INTD counter in order to know if it can issue another interrupt.
+       Since we decrement the counter at l2sw_netdev_tx_complete it is possible that accumulator issued another interrupt.
+       Due to the fact that interrupt is level and we do not want to get a false interrupt, we clear the INTC at the end of l2sw_netdev_tx_complete.
+       Next time INTC will wait for INTD to become active.
+       But, since INTD is level there is a possibility that INTD will remain active.
+       This can happen if accumulator issues an interrupt before the host sent EOI (this is done in next line of code).
+       So, in this case we have INTD status not changed - still active, while INTC now waits for it to become active.
+       This can lead to not getting the interrupt forever. This is why we must check if counter>0 and if so re-schedule NAPI.
+       We lock the interrupts b4 doing EOI and up until NAPI schedule in order not to get double interrupt in the case that
+       an interrupt is really issued between EOI and checking INTD count - we are going to reschedule NAPI anyway... */
+
+    DWC_ACK_IRQ(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+    avalanche_intd_write_eoi(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM);
+
+    /* It could be that between INTD count decrement and EOI the accumulator will issue another interrupt.
+       The logic of INTD is such that level will remain active high even after EOI is set, so INTC will
+       lose the interrupt after ack_irq is done (it now expects INTD polarity change).
+       Therefore we must check INTD count and if it is not 0 - reschedule the tasklet */
+
+    for (priority = PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_COUNT - 1; priority >= 0; priority--)
+    {
+        if (avalanche_intd_get_interrupt_count(0, PAL_CPPI_PP_HOST2PP_TX_COMPLETE_ACC_CH_NUM(priority)))
+        {
+                napi_schedule(napi);
+                return work_done;
+        }
+    }
+
+    DWC_ENABLE_IRQ(MAP_INTD_TO_INTC(PAL_CPPI_PP_HOST2PP_TX_COMPLETE_INTD0_ACC_INTV_NUM));
+    return work_done;
+}
+
+#endif
+
 static int replace_npcpu_memory_for_queue(PAL_Handle palHnd, int qnum)
 {
 
--- /dev/null
+++ b/include/linux/avalanche/generic/avalanche_pdsp_api.h
@@ -0,0 +1,396 @@
+/*
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2015 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+#ifndef _AVALANCHE_PDSP_H
+#define _AVALANCHE_PDSP_H
+
+////////////////////////////////////////////////////// 
+
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include <asm-arm/arch-avalanche/generic/_tistdtypes.h>
+#else
+#include <linux/avalanche/puma7/puma7_defs.h>
+#include <linux/avalanche/generic/_tistdtypes.h>
+#endif
+
+#include <linux/ioctl.h>
+
+#ifndef __KERNEL__
+#include <puma_autoconf.h>
+#endif
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+    #define AVALANCHE_PDSP_H_PUMA7
+#if defined(CONFIG_MACH_PUMA7_FPGA_PP) || defined (CONFIG_MACH_PUMA7_BOARD)
+    //#define FPGA_SANITY_UNITEST     0
+#endif
+#elif defined(PUMA6_SOC_TYPE)
+    #define AVALANCHE_PDSP_H_PUMA6
+#else
+    #undef  AVALANCHE_PDSP_H_PUMA6
+    #undef  AVALANCHE_PDSP_H_PUMA7
+#endif
+
+#ifdef CONFIG_WIFI_MESH_TUNNEL
+#define WIFI_MESH_MODE                      (1<<0)
+#endif
+
+/* PP PDSP commands */
+typedef enum
+{
+#if defined (AVALANCHE_PDSP_H_PUMA7)
+
+    // Global PDSP  commands
+    PDSP_ENABLE                     = 0x80,
+    PDSP_GET_STATUS                 = 0x81,
+    PDSP_PSM                        = 0x82,
+    PDSP_SANITY_CHECK_EXECUTE       = 0x90,
+
+    // Sequencer    commands
+    PDSP_SEQUENCER_SET_TDQ          = 0x83,
+    PDSP_SEQUENCER_PID_COMMAND      = 0x84,
+
+    // Classifier1  commands
+    PDSP_CLASSIFIER1_VPID_COMMAND   = 0x83,
+
+    // Classifier2  commands
+    PDSP_CLASSIFIER2_PID_COMMAND    = 0x83,
+    PDSP_CLASSIFIER2_CLASSIFICATION_MODE_COMMAND = 0x84,
+    PDSP_CLASSIFIER2_MOCA_IRREG_SESS_OPEN = 0x85,
+
+    // PDSP ReSequencer commands
+    PDSP_RESEQUENCER_SET_SYNC_Q_THRSHOLD = 0x83,
+
+    // QoS          commands
+    PDSP_QOS_CMD_CONFIG_CLUSTER     = 0x83,
+
+    // Accumulator  commands
+    PDSP_ACCUMULATOR_ENABLE_CH      = 0x83,
+    PDSP_ACCUMULATOR_DISABLE_CH     = 0x84,
+
+    // Session Cache Commands
+    PDSP_SESSION_CACHE_SESSION_CMD  = 0x83,
+    PDSP_SESSION_CACHE_FLUSH_ALL    = 0x84,
+    PDSP_SESSION_CACHE_SESSION_TIMEOUT  = 0x85,
+
+#else
+    PP_HAL_PDSP_CMD_OPEN    =   0x80,
+    PP_HAL_PDSP_CMD_FLUSH_ALL,
+    PP_HAL_PDSP_CMD_FLUSH_MANY,
+    PP_HAL_PDSP_CMD_reserved_x83,
+    PP_HAL_PDSP_CMD_PID,
+    PP_HAL_PDSP_CMD_VPID,
+    PP_HAL_PDSP_CMD_SESSION,
+    PP_HAL_PDSP_CMD_STATUS,
+    PP_HAL_PDSP_CMD_PSM,
+    PP_HAL_PDSP_CMD_VERSION,
+    PP_HAL_PDSP_CMD_reserved_x8A,
+    PP_HAL_PDSP_CMD_reserved_x8B,
+    PP_HAL_PDSP_CMD_ACK_SUPPRESS,
+    PP_HAL_PDSP_CMD_QOS_CLUSTER = 0xA0,
+
+    PDSP_PREFETCHER_CONFIG_TDQ = 0x87,
+    PDSP_PREFETCHER_ENABLE  = 0x83
+#endif
+}PP_HAL_PDSP_CMD_e;
+
+#if defined (AVALANCHE_PDSP_H_PUMA7)
+
+typedef enum
+{
+    PDSP_ID_START,
+    PDSP_ID_Sequencer = PDSP_ID_START,      //  Sequencer
+
+    PDSP_ID_Prefetcher_0,                   //  Prefetcher   group - PDSP 0
+    PDSP_ID_Prefetcher_1,                   //  Prefetcher   group - PDSP 1
+    PDSP_ID_Prefetcher_2,                   //  Prefetcher   group - PDSP 2
+    PDSP_ID_Prefetcher_3,                   //  Prefetcher   group - PDSP 3
+
+    PDSP_ID_Classifier1_0,                  //  Classifier1  group - PDSP 0
+    PDSP_ID_Classifier1_1,                  //  Classifier1  group - PDSP 1
+    PDSP_ID_Classifier1_2,                  //  Classifier1  group - PDSP 2
+    PDSP_ID_Classifier1_3,                  //  Classifier1  group - PDSP 3
+
+    PDSP_ID_Classifier2_0,                  //  Classifier2  group - PDSP 0
+    PDSP_ID_Classifier2_1,                  //  Classifier2  group - PDSP 1
+    PDSP_ID_Classifier2_2,                  //  Classifier2  group - PDSP 2
+    PDSP_ID_Classifier2_3,                  //  Classifier2  group - PDSP 3
+
+    PDSP_ID_Modifier_0,                     //  Modifier     group - PDSP 0
+    PDSP_ID_Modifier_1,                     //  Modifier     group - PDSP 1
+    PDSP_ID_Modifier_2,                     //  Modifier     group - PDSP 2
+    PDSP_ID_Modifier_3,                     //  Modifier     group - PDSP 3
+
+    PDSP_ID_ReSequencer,                    //  ReSequencer
+
+    PDSP_ID_QoS_0,                          //  QoS          group - PDSP 0
+    PDSP_ID_QoS_1,                          //  QoS          group - PDSP 1
+
+    PDSP_ID_Recycler,                       //  Recycler PDSP
+    PDSP_ID_Accumulator,                    //  Accumulator PDSP
+    PDSP_ID_Wifi_0,                         //  Wifi group - PDSP 0
+    PDSP_ID_Wifi_1,                         //  Wifi group - PDSP 1
+    PDSP_ID_Moca,                           //  Moca PDSP
+    PDSP_ID_FCC_0,                          //  FCC_1  PDSP
+    PDSP_ID_FCC_1,                          //  FCC_0  PDSP
+
+    PDSP_ID_Session_Cache,                  //  Session Cache PDSP
+    PDSP_ID_AQM,                            //  AQM PDSP
+    PDSP_ID_MC,                             //  MC PDSP
+    PDSP_ID_TurboDOX,                       //  TurboDOX PDSP
+
+    PDSP_ID_DS_RESEQ,
+    PDSP_ID_US_START,                           //  US PDSP first index
+    PDSP_ID_US_Preprocessor = PDSP_ID_US_START, //  US Preprocessing PDSP
+    PDSP_ID_US_Request_Builder,                 //  US REQuest Builder PDSP
+    PDSP_ID_US_Frag_Divert,                     //  US Frag& Divert PDSP
+    PDSP_ID_US_END = PDSP_ID_US_Frag_Divert,    //  US PDSP last index
+    PDSP_ID_MAX
+}pdsp_id_t;
+
+/* PDSP Timers definitions */
+#define AVALANCHE_PDSP_TIMER_CTRL_OFF                       0x00
+#define AVALANCHE_PDSP_TIMER_LOAD_OFF                       0x04
+#define AVALANCHE_PDSP_TIMER_CTRL_PRESCALER_ENABLE_SHIFT    15
+#define AVALANCHE_PDSP_TIMER_CTRL_PRESCALER_VALUE_SHIFT     2
+#define AVALANCHE_PDSP_TIMER_CTRL_AUTO_LOAD_SHIFT           1
+#define AVALANCHE_PDSP_TIMER_CTRL_START_SHIFT               0
+
+#elif defined (AVALANCHE_PDSP_H_PUMA6)
+typedef enum
+{
+    PDSP_ID_START,
+    PDSP_ID_Prefetcher_0 = PDSP_ID_START,   //  Prefetcher   group - PDSP 0
+    PDSP_ID_Classifier1_0,                  //  Classifier1  group - PDSP 0
+    PDSP_ID_Classifier2_0,                  //  Classifier2  group - PDSP 0
+    PDSP_ID_Modifier_0,                     //  Modifier     group - PDSP 0
+    PDSP_ID_QoS_0,                          //  QoS          group - PDSP 0
+    PDSP_ID_LAN_Proxy,                      //  _PrxPDSP only in P6
+    PDSP_ID_CoE,                            //  _CoePDSP only in P6
+    PDSP_ID_MAX
+}pdsp_id_t;
+
+#else // PUMA5
+typedef enum
+{
+    PDSP_ID_START,
+    PDSP_ID_Prefetcher_0 = PDSP_ID_START,   //  Prefetcher
+    PDSP_ID_Classifier1_0,                  //  Classifier
+    PDSP_ID_Modifier_0,                     //  Modifier
+    PDSP_ID_QoS_0,                          //  QoS
+    PDSP_ID_MAX
+}pdsp_id_t;
+#endif
+
+
+typedef Uint32 pdsp_cmd_t;
+
+typedef struct
+{
+    pdsp_id_t       pdsp_id;
+    pdsp_cmd_t      cmd;
+    Uint32          params_len;
+    Uint32          params[64];
+}
+pdsp_cmd_params_t;
+
+/********************************************************************************************************/
+/* IOCTL commands:
+
+   If you are adding new ioctl's to the kernel, you should use the _IO
+   macros defined in <linux/ioctl.h> _IO macros are used to create ioctl numbers:
+
+    _IO(type, nr)         - an ioctl with no parameter.
+   _IOW(type, nr, size)  - an ioctl with write parameters (copy_from_user), kernel would actually read data from user space
+   _IOR(type, nr, size)  - an ioctl with read parameters (copy_to_user), kernel would actually write data to user space
+   _IOWR(type, nr, size) - an ioctl with both write and read parameters
+
+   'Write' and 'read' are from the user's point of view, just like the
+    system calls 'write' and 'read'.  For example, a SET_FOO ioctl would
+    be _IOW, although the kernel would actually read data from user space;
+    a GET_FOO ioctl would be _IOR, although the kernel would actually write
+    data to user space.
+
+    The first argument to _IO, _IOW, _IOR, or _IOWR is an identifying letter
+    or number from the SoC_ModuleIds_e enum located in this file.
+
+    The second argument to _IO, _IOW, _IOR, or _IOWR is a sequence number
+    to distinguish ioctls from each other.
+
+   The third argument to _IOW, _IOR, or _IOWR is the type of the data going
+   into the kernel or coming out of the kernel (e.g.  'int' or 'struct foo').
+
+   NOTE!  Do NOT use sizeof(arg) as the third argument as this results in
+   your ioctl thinking it passes an argument of type size_t.
+
+*/
+#define PDSP_DRIVER_MODULE_ID                   (0xDE)
+
+#define PDSP_DRIVER_RESET_PDSP                      _IOW (PDSP_DRIVER_MODULE_ID,  1, pdsp_id_t)
+#define PDSP_DRIVER_START_PDSP                      _IOW (PDSP_DRIVER_MODULE_ID,  2, pdsp_id_t)
+#define PDSP_DRIVER_DOWNLOAD_START                  _IOW (PDSP_DRIVER_MODULE_ID,  3, pdsp_id_t)
+#define PDSP_DRIVER_DOWNLOAD_FINISH                 _IOW (PDSP_DRIVER_MODULE_ID,  4, pdsp_id_t)
+#define PDSP_DRIVER_TEST_IRAM                       _IOW (PDSP_DRIVER_MODULE_ID,  5, pdsp_id_t)
+#define PDSP_DRIVER_PUT_CMD                         _IOWR(PDSP_DRIVER_MODULE_ID,  6, pdsp_cmd_params_t)
+#define PDSP_DRIVER_SANITY_CHECK_START              _IOW (PDSP_DRIVER_MODULE_ID,  7, pdsp_id_t)
+#define PDSP_DRIVER_EXECUTE_SANITY_CHECK            _IOWR(PDSP_DRIVER_MODULE_ID,  8, pdsp_cmd_params_t)
+#define PDSP_DRIVER_SANITY_CHECK_END                _IOW (PDSP_DRIVER_MODULE_ID,  9, pdsp_id_t)
+#define PDSP_DRIVER_EXECUTE_TURBODOX_SANITY_CHECK   _IOWR(PDSP_DRIVER_MODULE_ID, 10, pdsp_cmd_params_t)
+#define PDSP_DRIVER_HALT_PDSP                       _IOWR(PDSP_DRIVER_MODULE_ID, 11, pdsp_cmd_params_t)
+#define PDSP_DRIVER_RESUME_PDSP                     _IOWR(PDSP_DRIVER_MODULE_ID, 12, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_BREAKPOINT_ENABLE          _IOWR(PDSP_DRIVER_MODULE_ID, 13, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_BREAKPOINT_DELETE_ALL      _IOWR(PDSP_DRIVER_MODULE_ID, 14, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_BREAKPOINT_DISABLE         _IOWR(PDSP_DRIVER_MODULE_ID, 15, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_BREAKPOINT_PRINT           _IOWR(PDSP_DRIVER_MODULE_ID, 16, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_SINGLE_STEP_ENABLE         _IOWR(PDSP_DRIVER_MODULE_ID, 17, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_SINGLE_STEP_DISABLE        _IOWR(PDSP_DRIVER_MODULE_ID, 18, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_RUN_TO_OP_CODE             _IOWR(PDSP_DRIVER_MODULE_ID, 19, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_MODIFY_DBG_REG             _IOWR(PDSP_DRIVER_MODULE_ID, 20, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_SHOW_STATUS                _IOWR(PDSP_DRIVER_MODULE_ID, 21, pdsp_cmd_params_t)
+#define PDSP_DRIVER_PDSP_PRINT_CTRL_REGS            _IOWR(PDSP_DRIVER_MODULE_ID, 22, pdsp_cmd_params_t)
+
+
+#ifdef __KERNEL__
+
+/* Success Code */
+#define SR_RETCODE_SUCCESS          1
+
+/* PDSP error codes */
+#define SRPDSP_ENORES                   -1
+#define SRPDSP_EINVCMD                  -2
+#define SRPDSP_EINVOPT                  -3
+#define SRPDSP_EINVINDEX                -4
+#define SRPDSP_EALREADYOPEN             -5
+#define SRPDSP_ENOTOPEN                 -6
+#define SRPDSP_EMAPERROR                -7
+#define SRPDSP_EINVPORT                 -8
+#define SRPDSP_EINVPID                  -9
+#define SRPDSP_EPAUSELIMITEXCEED        -10
+#define SRPDSP_ESESSIONNOTPAUSED        -11
+#define SRPDSP_ESESSIONPAUSED           -12
+#define SRPDSP_EREOPENINVALID           -13
+#define SRPDSP_EINTERROR                -99
+
+
+
+
+Int32 pdsp_cmd_send    (pdsp_id_t               id,
+                        pdsp_cmd_t              cmd_word,
+                        void *wr_ptr,   Uint32  wr_word,
+                        void *rd_ptr,   Uint32  rd_word);
+
+typedef enum
+{
+    PDSPCTRL_HLT      ,
+    PDSPCTRL_STEP     ,
+    PDSPCTRL_FREERUN  ,
+    PDSPCTRL_RESUME   ,
+    PDSPCTRL_RST      ,
+    PDSPCTRL_START    ,
+}
+pdsp_ctrl_op_t;
+/*
+ * pdsp_control -
+ *
+ * Description: This API provides interface to control PDSPs. Following
+ * operations are supported :-
+ *  PDSPCTRL_HLT
+ *      HALT pdsp execution
+ *  PDSPCTRL_STEP
+ *      Set PDSP Single step mode. This option halts the PDSP and successive
+ *      RESUMEs are carried as single steps.
+ *  PDSPCTRL_FREERUN
+ *      Set free running mode, i.e., disable single step. PDSP execution is
+ *      implicitly RESUMEd as a result of this command.
+ *  PDSPCTRL_RESUME
+ *      RESUME pdsp execution
+ *  PDSPCTRL_RST
+ *      RESET PDSP and start execution from specified program counter. The
+ *      16-bit program counter shoule be passed by ctl_data pointer.
+ *  PDSPCTRL_PSM
+ *      Enable or Disable PSM mode. ctl_data should be passed as pointer to
+ *      boolean (32-bit integer) flag indicating desired enable (!0) or disable
+ *      (0) status of PSM. Note that pdsp_id value is ignored for this option.
+ *
+ * Note:
+ *   Setting option PDSPCTRL_STEP just sets the PDSP in single step
+ *  mode and halts its execution, actual single stepping should be performed by
+ *  calling this API with PDSPCTRL_RESUME option per step till free
+ *  running is enabled explicitly with option PDSPCTRL_FREERUN
+ *  single step or halting the pdsp
+ *
+ * Precondition:
+ *  -   ti_ppd_init
+ *
+ * Parameters:
+ *  id (IN)         - Id of PDSP to control: CPDSP(0), MPDSP(1), QPDSP(2).
+ *  ctl_op (IN)     - Eiter of the PDSP control options as explained above.
+ *  ctl_data (IN)   - Pointer to data corresponding the pdsp control option.
+ *
+ * Return:
+ *  0 on Success, <0 on error.
+ */
+Int32 pdsp_control (pdsp_id_t   pdsp_id, Uint32 ctl_op, Ptr ctl_data);
+
+#endif
+
+#endif
--- a/include/linux/avalanche/generic/avalanche_pp_api.h
+++ b/include/linux/avalanche/generic/avalanche_pp_api.h
@@ -30,38 +30,50 @@
 #ifndef     _AVALANCHE_PP_H
 #define     _AVALANCHE_PP_H
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
 #include <linux/avalanche/generic/_tistdtypes.h>
+#else
+#include <asm-arm/arch-avalanche/generic/_tistdtypes.h>
+#endif
 
 #ifdef __KERNEL__
 
-#if PUMA6_SOC_TYPE
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
+#ifdef PUMA6_SOC_TYPE
 #include <asm-arm/arch-avalanche/puma6/puma6_cppi_prv.h>
 #endif
 
 #if PUMA7_SOC_TYPE
+#ifndef CONFIG_ARM_AVALANCHE_SOC
 #include <linux/avalanche/puma7/puma7_cppi.h>
+#else
+#include <asm-arm/arch-avalanche/puma7/puma7_cppi.h>
+#endif
 #endif
 
 #else
 #include <puma_autoconf.h>
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 #include <puma6_cppi_prv.h>
 #endif
-#if PUMA7_SOC_TYPE
+#ifdef PUMA7_SOC_TYPE
 #include <puma7_cppi_prv.h>
 #endif
 
 #endif
 
 #include <linux/ioctl.h>
-
+#include <asm/byteorder.h>
 /**************************************************************************
  ****************************** Limit Definitions *************************
  **************************************************************************/
 
 
 /* These are the maximum number of PID,VPID & Sessions that are supported.*/
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 #define AVALANCHE_PP_MAX_PID                            32
 #define AVALANCHE_PP_MAX_VPID                           32
 #define AVALANCHE_PP_MAX_ACCELERATED_SESSIONS           2048
@@ -268,7 +280,7 @@ AVALANCHE_PP_PID_RANGE_t;
 /*                                                                      */
 /*                                                                      */
 /* ******************************************************************** */
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 #define AVALANCHE_PP_QOS_CLST_MAX_INDX          31
 #define AVALANCHE_PP_QOS_QUEUE_MAX_INDX         (PAL_CPPI41_SR_QPDSP_QOS_Q_LAST - PAL_CPPI41_SR_QPDSP_QOS_Q_BASE)
 #endif
@@ -288,10 +300,10 @@ typedef struct // former TI_PP_QOS_QUEUE
     Uint8               flags;                  /* Control how packets in the queue should be handled. Available options: AVALANCHE_PP_QOS_Q_REALTIME - Disable scaling of the credit. */
     Uint16              egr_q;                  /* Queue manager and queue index of forwarding queue */
 
-    Uint32              it_credit_bytes;        /* The amount of forwarding byte credit that the queue receives every 25us. */
-    Uint16              it_credit_packets;      /* The amount of forwarding packets credit that the queue receives every 25us. */
-    Uint32              max_credit_bytes;       /* The maximum amount of forwarding byte credit that the queue is allowed to hold at the end of the 25us iteration. */
-    Uint16              max_credit_packets;     /* The maximum amount of forwarding byte credit that the queue is allowed to hold at the end of the 25us iteration. */
+    Uint32              it_credit_bytes;        /* The amount of forwarding byte ?credit? that the queue receives every 25us. */
+    Uint16              it_credit_packets;      /* The amount of forwarding packets ?credit? that the queue receives every 25us. */
+    Uint32              max_credit_bytes;       /* The maximum amount of forwarding byte ?credit? that the queue is allowed to hold at the end of the 25us iteration. */
+    Uint16              max_credit_packets;     /* The maximum amount of forwarding byte ?credit? that the queue is allowed to hold at the end of the 25us iteration. */
     Uint32              congst_thrsh_bytes;     /* The size in bytes at which point the QOS queue is considered to be congested. */
     Uint16              congst_thrsh_packets;   /* The maximum number of packets to be kept in QOS queue */
 }
@@ -427,13 +439,13 @@ typedef struct // former TI_PP_VPID
      * or AVALANCHE_PP_VLAN_PPPoE */
     Uint16                          vlan_identifier;
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
     /* These are the QoS related settings */
     AVALANCHE_PP_QOS_CLST_CFG_t *   qos_cluster[ MAX_ALLOWED_QOS_CLUSTERS_PER_DEVICE ];
     unsigned char                   qos_clusters_count;
 #else
     /* This is the name of the interface. */
-    char                            devName[VPID_IF_NAME_SIZE];
+	char			                devName[VPID_IF_NAME_SIZE];
 #endif
 }
 AVALANCHE_PP_VPID_INFO_t;
@@ -454,6 +466,7 @@ typedef struct // former TI_PP_VPID_STAT
     Uint64      rx_multicast_pkt;
     Uint64      rx_discard_pkt;
     Uint64      rx_res[3];
+
     Uint64      tx_byte;
     Uint64      tx_unicast_pkt;
     Uint64      tx_broadcast_pkt;
@@ -493,14 +506,14 @@ typedef struct // former TI_PP_VPID_STAT
 /*                                                                      */
 /*                                                                      */
 /* ******************************************************************** */
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 typedef enum
 {
     AVALANCHE_PP_LUT_ENTRY_L2_ETHERNET,
 #ifdef CONFIG_WIFI_MESH_TUNNEL
     AVALANCHE_PP_LUT_ENTRY_WIFI_MESH,
 #else
-    AVALANCHE_PP_LUT_ENTRY_reserved_1,
+   AVALANCHE_PP_LUT_ENTRY_reserved_1,
 #endif
     AVALANCHE_PP_LUT_ENTRY_reserved_2,
     AVALANCHE_PP_LUT_ENTRY_reserved_3,
@@ -607,6 +620,7 @@ typedef enum
 }
 AVALANCHE_PP_LUT2_FIELD_ENABLE_e;
 
+
 #ifndef CONFIG_WIFI_MESH_TUNNEL
 typedef struct
 {
@@ -646,28 +660,39 @@ typedef struct
     }u;
 }
 __Avalanche_PP_LUT2_inputs_t;
+
 #else
 typedef struct
 {
     union
     {
+        /*------------------------------------------*/
         Uint8       raw[32];
+        /*------------------------------------------*/
         struct
         {
+
             Uint16                                  vlan_id;
             Uint8                                   frame_control_flags;
             Uint8                                   packet_type;
+
             Uint16                                  src_intf_id;
             Uint16                                  dst_intf_id;
+
             Uint8                                   receive_mac[6];
             Uint8                                   transmit_mac[6];
             Uint8                                   dst_mac[6];
 			Uint8                                   src_mac[6];
+
+
         }
         fields;
+        /*------------------------------------------*/
+
     }u;
 }
 __Avalanche_PP_LUT2_inputs_t;    /* For WIFI MESH mode*/
+
 #endif
 
 typedef struct
@@ -687,17 +712,18 @@ __Avalanche_PP_LUTs_Data_t;
 
 /* Define for EtherType 0xFFFF - special MoCA packets */
 #define ETH_P_CTP_MOCA          (0xFFFF)
-
-/* Enum for Classification mode */
+/* Enum for MoCA Classification mode */
 typedef enum
 {
     CLASSIFICATION_MODE_IPV4_IPV6_L4   = 0,   // Accelerate packets with ip v4/6 and tcp/udp (L4 is mandatory)
     CLASSIFICATION_MODE_IPV4_IPV6      = 1,   // Accelerate packets with ip v4/6 (L4 is optional)
     CLASSIFICATION_MODE_MOCA_IRREG     = 2    // Accelerate packets with ip v4/6/ and L3=ffff for MoCA only (L4 is optional)
 }PP_CLASSIFICATION_MODE_e;
-
+//#ifdef CONFIG_SYSTEM_MOCA2_0
+//#define MOCA_CLASSIFICATION_MODE_DEFAULT MOCA_CLASSIFICATION_MODE_RESTRICTIVE
+//#else
 #define CLASSIFICATION_MODE_DEFAULT CLASSIFICATION_MODE_IPV4_IPV6
-
+//#endif
 
 typedef enum
 {
@@ -734,36 +760,46 @@ typedef enum
 typedef struct
 {
     Uint8       PID;                    /* Type: PP_PID_NUM_e                                    */
+#if defined(__BIG_ENDIAN_BITFIELD)
     Uint8       L2_type:4,              /* Type: PP_LOOKUP_FIELD_L2_TYPES_e                      */
                 L3_type:4;              /* Type: PP_LOOKUP_FIELD_L3_TYPES_e                      */
+#elif defined (__LITTLE_ENDIAN_BITFIELD)
+    Uint8       L3_type:4,              /* Type: PP_LOOKUP_FIELD_L2_TYPES_e                      */
+		L2_type:4;              /* Type: PP_LOOKUP_FIELD_L3_TYPES_e                      */
+#endif
+#if defined(__BIG_ENDIAN_BITFIELD)
     Uint8       L4_Protocol:4,          /* Type: PP_LOOKUP_FIELD_L4_TYPES_e                      */
                 Tunnel_type:4;          /* Type: PP_LOOKUP_FIELD_TUNNEL_TYPE_e                   */
+#elif defined (__LITTLE_ENDIAN_BITFIELD)
+    Uint8       Tunnel_type:4,          /* Type: PP_LOOKUP_FIELD_L4_TYPES_e                      */
+                L4_Protocol:4;          /* Type: PP_LOOKUP_FIELD_TUNNEL_TYPE_e                   */
+#endif
     Uint8       Flags;                	/* Type: PP_LOOKUP_FIELD_FLAGS_e                         */
     Uint8       dstmac[6];              /* Destination MAC address                               */
     Uint8       srcmac[6];              /* Source MAC address                                    */
-    Uint16      Vlan1;                  /* Packet's external VLAN if exists                      */
-    Uint16      Vlan2;                  /* Packet's internal VLAN if exists                      */
+    __be16      Vlan1;                  /* Packet's external VLAN if exists                      */
+    __be16      Vlan2;                  /* Packet's internal VLAN if exists                      */
 
     union
     {
-        Uint32  v4;
-        Uint32  v6[ 4 ];
+        __be32  v4;
+        __be32  v6[ 4 ];
     }
     SRC_IP;                             /* For IPv4 only the first 4 MSB are set, all other bytes must be 0          */
 
     union
     {
-        Uint32  v4;
-        Uint32  v6[ 4 ];
+        __be32  v4;
+        __be32  v6[ 4 ];
     }
     DST_IP;                             /* For IPv4 only the first 4 MSB are set, all other bytes must be 0          */
 
     Uint8       IPv6_Flow_Label[4];     /* IPv6 Flow Label (MSbits must be 0). For DS-Lite holds IPv4 destination IP */
     Uint8       ToS;                    /* IP TOS for IPv4, Traffic Class for IPv6               */
     Uint8       Reserved;               /* Must be 0                                             */
-    Uint16      PPPoE_session_id;       /* 0xFFFF if none                                        */
-    Uint16      L4_SRC_PORT;            /* UDP/TCP Source       Port. If not set, must be 0      */
-    Uint16      L4_DST_PORT;            /* UDP/TCP Destintation Port. If not set, must be 0      */
+    __be16      PPPoE_session_id;       /* 0xFFFF if none                                        */
+    __be16      L4_SRC_PORT;            /* UDP/TCP Source       Port. If not set, must be 0      */
+    __be16      L4_DST_PORT;            /* UDP/TCP Destintation Port. If not set, must be 0      */
 }
 __Avalanche_PP_LUTs_Data_t;
 
@@ -797,14 +833,14 @@ typedef struct // former TI_PP_SESSION_P
 #endif
     Uint16                              reserved1;
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
     Bool                                isTunnel;
 #endif
+
     __Avalanche_PP_LUTs_Data_t          lookup;
 
 }AVALANCHE_PP_INGRESS_SESSION_PROPERTY_t;
 
-
 #if PUMA7_OR_NEWER_SOC_TYPE
 #define AVALNCHE_PP_WRAP_HEADER_MAX_LEN 96
 #else
@@ -851,9 +887,13 @@ typedef struct
 }
 AVALANCHE_PP_PSI_t;
 #endif
+
 #ifndef CONFIG_WIFI_MESH_TUNNEL
+
 #define AVALANCHE_PP_EGRESS_DROP_SESS    0x01
 
+
+
 /**************************************************************************
  * STRUCTURE NAME : AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t
  **************************************************************************
@@ -879,8 +919,6 @@ typedef struct
 
     __Avalanche_PP_LUTs_Data_t  lookup;
 
-
-
     union
     {
         AVALANCHE_PP_PSI_t      us_fields;
@@ -891,6 +929,7 @@ typedef struct
     Uint16                      eth_type;
     Uint8                       wrapHeaderOffLayer3;
     Uint8                       wrapHeaderLen;
+
     Uint8                       wrapHeader[ AVALNCHE_PP_WRAP_HEADER_MAX_LEN ];
 
 } AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t;
@@ -899,6 +938,7 @@ typedef struct // former TI_PP_SESSION_P
 {
     Uint8                               vpid_handle;
     Uint8                               pid_type;       /* Needed for WAN/LAN direction selection */
+
     Uint16                              enable;             /* Type: AVALANCHE_PP_EGRESS_FIELD_ENABLE_e */
     Bool                                isTunnel;
 
@@ -945,6 +985,7 @@ typedef struct // former TI_PP_SESSION_P
 
     Uint16                              L4_SrcPort;
     Uint16                              L4_DstPort;
+
     Uint16                              pppoe_sid;
     Uint8                               drop_sess;
     Uint8                               wrapHeader_type;     /* Type : AVALANCHE_PP_LUT_ENTRY_TYPE_e */
@@ -952,13 +993,18 @@ typedef struct // former TI_PP_SESSION_P
 AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t;
 #endif
 #else
+
 typedef enum
 {
     AVALANCHE_PP_WIFI_MESH_B_HEADER_SIZE  = 22,   /* ethernet header + 2 Vlans (22B) */
     AVALANCHE_PP_WIFI_MESH_CB_HEADER_SIZE = 49,   /* ethernet header (18B) + dragon header (13B) + ethernet header (18B) */
     AVALANCHE_PP_WIFI_MESH_CA_HEADER_SIZE = 61,   /* ethernet header (18B)- 2bytes of ethernet type + dragon header (13B) + wifi header (30B)*/
+
 }AVALANCHE_PP_WIFI_MESH_HEADER_SIZE_e;
+
+
 #define AVALNCHE_PP_WIFI_MESH_HEADER_MAX_LEN        (61)
+
 /**************************************************************************
  * STRUCTURE NAME : AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t
  **************************************************************************
@@ -973,13 +1019,18 @@ typedef struct // former TI_PP_SESSION_P
     Uint8                               vpid_handle;
     Uint8                               reserved;
     Uint16                              enable;             /* Type: AVALANCHE_PP_EGRESS_FIELD_ENABLE_e */
+
     Uint8                               dstmac[6];
     Uint8                               srcmac[6];
+
     Uint8                               newHeader[AVALNCHE_PP_WIFI_MESH_HEADER_MAX_LEN];
+
 }
 AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t;
+
 #endif
 
+
 #if PUMA7_OR_NEWER_SOC_TYPE
 typedef enum
 {
@@ -1018,7 +1069,7 @@ typedef struct // former TI_PP_SESSION
      * successful creation of the session. */
     Uint32                  session_handle;
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
     /* Session Timeout indicates the number of micro-seconds of inactivity
      * after which the PP generates an event to the host. The field if set
      * to 0 indicates that the session needs to be configured permanently
@@ -1027,7 +1078,7 @@ typedef struct // former TI_PP_SESSION
 #endif
 
     /* Flag which indicates the priority of the session.
-     * With the introduction of QoS this will play an important part.
+     * With the introduction of QoS this will play an important part. 
      * priority 0 is the lowest priority, highest priority is depend
      * on the number of queues in the cluster*/
     Uint8                   priority;
@@ -1061,8 +1112,9 @@ typedef struct // former TI_PP_SESSION
     AVALANCHE_PP_EGRESS_SESSION_PROPERTY_t  egress;
 
     AVALANCHE_PP_SESSION_TDOX_STATS_t   tdox_stats;
+
 #if PUMA7_OR_NEWER_SOC_TYPE
-    Uint8                   is_irreg_moca;
+    Uint8                   is_irreg_moca; 
 #endif
 }
 AVALANCHE_PP_SESSION_INFO_t;
@@ -1350,8 +1402,7 @@ typedef struct
 #define AVALANCHE_PP_US_SERVICE_FLOW_COUNTERS 16
 typedef struct
 {
-    /* one 64-bit counter per service flow. 16 is a reasonable upper bound on
-    the number of active service flows, although the system supports more (56?).*/
+    // one 64-bit counter per service flow. 16 is a reasonable upper bound on the number of active service flows, although the system supports more (56?). 
     // In reality, only 1-2 flows are used.
     Uint64 us_sent_packets[AVALANCHE_PP_US_SERVICE_FLOW_COUNTERS];
 } AVALANCHE_PP_US_STATS_t;
@@ -1461,6 +1512,7 @@ extern AVALANCHE_PP_RET_e    avalanche_p
 #ifdef CONFIG_WIFI_MESH_TUNNEL
 extern AVALANCHE_PP_RET_e    avalanche_pp_wifi_mesh_get_vpid_packet_header_size           ( AVALANCHE_PP_VPID_TYPE_e        vpid_type, AVALANCHE_PP_WIFI_MESH_HEADER_SIZE_e* headerSize);
 #endif
+
 /* Session Management API */
 extern AVALANCHE_PP_RET_e    avalanche_pp_session_create        ( AVALANCHE_PP_SESSION_INFO_t *  ptr_session, void * pkt_ptr );
 extern AVALANCHE_PP_RET_e    avalanche_pp_session_delete        ( Uint32    session_handle,     AVALANCHE_PP_SESSION_STATS_t *  ptr_session_stats );
@@ -1476,12 +1528,13 @@ extern AVALANCHE_PP_RET_e   avalanche_pp
 #ifdef CONFIG_WIFI_MESH_TUNNEL
 extern AVALANCHE_PP_RET_e    avalanche_pp_sessions_delete_by_addr ( Uint8 mask, Uint8* srcMacAdr, Uint8* dstMacAdr, Uint8* rxMacAdr, Uint8* txMacAdr, Uint32* num_deleted_sessions);
 #endif
+
 /* Statistics API */
-extern AVALANCHE_PP_RET_e   avalanche_pp_modify_stats_counters      ( Uint32 session_handle, Uint32 packet_size);
-extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_session          ( Uint32 session_handle, AVALANCHE_PP_SESSION_STATS_t* ptr_session_stats );
-extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_vpid             ( Uint8  vpid_handle, AVALANCHE_PP_VPID_STATS_t* ptr_vpid_stats );
-extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_global           ( AVALANCHE_PP_GLOBAL_STATS_t* ptr_stats );
-extern AVALANCHE_PP_RET_e   avalanche_pp_reset_stats_global          ( void );
+extern AVALANCHE_PP_RET_e   avalanche_pp_modify_stats_counters              ( Uint32 session_handle, Uint32 packet_size);
+extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_session                  ( Uint32 session_handle, AVALANCHE_PP_SESSION_STATS_t* ptr_session_stats );
+extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_vpid                     ( Uint8  vpid_handle, AVALANCHE_PP_VPID_STATS_t* ptr_vpid_stats );
+extern AVALANCHE_PP_RET_e   avalanche_pp_get_stats_global                   ( AVALANCHE_PP_GLOBAL_STATS_t* ptr_stats );
+extern AVALANCHE_PP_RET_e   avalanche_pp_reset_stats_global                 ( void );
 
 #ifdef CONFIG_WIFI_MESH_TUNNEL
 
@@ -1489,6 +1542,7 @@ extern AVALANCHE_PP_RET_e   avalanche_pp
 #define DST_MAC_ADDR_COMPARE       BIT1
 #define TX_MAC_ADDR_COMPARE        BIT2
 #define RX_MAC_ADDR_COMPARE        BIT3
+
 #define MAC_ADDR_SIZE              6
 #endif
 
@@ -1523,7 +1577,7 @@ extern AVALANCHE_PP_RET_e   avalanche_pp
 extern AVALANCHE_PP_RET_e   avalanche_pp_event_handler_unregister   ( Uint32    handle_event_handler );
 extern AVALANCHE_PP_RET_e   avalanche_pp_event_report( AVALANCHE_PP_EVENT_e  event, Uint32 param1, Uint32 param2 );
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 /* QoS API. */
 extern AVALANCHE_PP_RET_e   avalanche_pp_qos_cluster_setup      ( Uint8     clst_indx,  AVALANCHE_PP_QOS_CLST_CFG_t*    clst_cfg );
 extern AVALANCHE_PP_RET_e   avalanche_pp_qos_cluster_enable     ( Uint8     clst_indx );
@@ -1561,7 +1615,7 @@ typedef struct
     Uint32                              lut2_starvation;
     Uint32                              tdox_starvation;
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
     Uint32                              lut1_histogram[AVALANCHE_PP_LUT_HISTOGRAM_SIZE];
     Uint32                              lut1_starvation;
     Uint32                              active_lut1_keys;
@@ -1585,7 +1639,7 @@ extern AVALANCHE_PP_RET_e    avalanche_p
 extern AVALANCHE_PP_RET_e    avalanche_pp_set_mta_mac_address ( Uint8 * mtaAddress );
 extern AVALANCHE_PP_RET_e    avalanche_pp_get_db_stats ( AVALANCHE_PP_Misc_Statistics_t * stats_ptr );
 extern AVALANCHE_PP_RET_e    avalanche_pp_reset_db_stats ( void );
-extern AVALANCHE_PP_RET_e    avalanche_pp_modify_stats_counters   ( Uint32 session_handle, Uint32 packet_size);
+extern AVALANCHE_PP_RET_e   avalanche_pp_modify_stats_counters   ( Uint32 session_handle, Uint32 packet_size);
 
 extern Bool                  avalanche_pp_state_is_active( void );
 extern Bool                  avalanche_pp_state_is_psm( void );
@@ -1605,7 +1659,7 @@ typedef     Uint8     avalanche_pp_psm_i
 typedef     Uint32    avalanche_pp_frag_mode_ioctl_param_t;
 typedef     Uint8     avalanche_pp_mtaMacAddr_ioctl_param_t[6];
 
-#if PUMA6_SOC_TYPE
+#ifdef PUMA6_SOC_TYPE
 typedef     struct
 {
 
--- a/include/linux/avalanche/generic/pal_cppi41.h
+++ b/include/linux/avalanche/generic/pal_cppi41.h
@@ -80,7 +80,13 @@
 #ifndef __PAL_CPPI4_H__
 #define __PAL_CPPI4_H__
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#include <linux/avalanche/generic/avalanche_pdsp_api.h>
+#endif
+
 #include <linux/avalanche/generic/_tistdtypes.h>
+#include <linux/avalanche/generic/pal.h>
 #include <asm/io.h>
 
 /**
@@ -94,7 +100,6 @@ typedef volatile unsigned int CSL_Reg32;
 /* convert cppi descriptor size tp descriptor hint */
 #define PAL_CPPI4_DESCSIZE_2_QMGRSIZE(size)                 ((size - 24) / 4)
 
-
 /**
  * Accumulator PDSP list entry types
  */
@@ -104,6 +109,22 @@ typedef volatile unsigned int CSL_Reg32;
 
 
 /**
+ *  \defgroup CPPI4_PAL_Ioctl_Codes CPPI4 PAL Ioctl Codes
+ */
+/*@{*/
+#define PAL_CPPI41_IOCTL_GET_SWVER               0       /**< Get software version */
+#define PAL_CPPI41_IOCTL_GET_HWVER               1       /**< Get hardware version */
+#define PAL_CPPI41_IOCTL_GET_FDQ_STARVE_CNT      2       /**< Get free descriptor queue starvation count */
+#define PAL_CPPI41_IOCTL_GET_FDBQ_STARVE_CNT     3       /**< Get the free descriptor/buffer queue starvation count */
+#define PAL_CPPI41_IOCTL_GET_QUEUE_PEND_STATUS   4       /**< Get the queue pending status */
+#define PAL_CPPI41_IOCTL_GET_QUEUE_ENTRY_COUNT   5       /**< Get the queue entry count */
+#define PAL_CPPI41_IOCTL_GET_QUEUE_BYTE_COUNT    6       /**< Get the queue byte count */
+#define PAL_CPPI41_IOCTL_GET_QUEUE_HEAD_PKT_SIZE 7       /**< Get the head packet size */
+#define PAL_CPPI41_IOCTL_QUEUE_DIVERT            8       /**< Divert contents of one queue to another */
+#define PAL_CPPI41_IOCTL_BUFMGR_SOFT_RESET       9       /**< Soft reset the buffer manager */
+#define PAL_CPPI41_IOCTL_BUF_REFCNT_INCR        10       /**< Increment buffer reference count */
+
+/**
  * PAL Handles
  */
 /* The PAL layer handle */
@@ -303,6 +324,41 @@ typedef volatile struct
 
 } CSL_Queue_Status_Regs;
 
+
+/**
+ * \brief Queue Manager region
+ *
+ * The structure instance variable points to CPPI4 Queue manager region
+ * register space in  SOC memory map directly.
+ * This is a template only, no memory is ever allocated for this!
+ *
+ * Register naming comes directly from the spec names, with redundant words
+ * dropped and abbreviations made where appropriate.
+ */
+typedef volatile struct
+{
+    CSL_Reg32   Revision;                     /* Major and Minor verisions of the module */
+    CSL_Reg32   Reserved;                     /* Reserved */
+    CSL_Reg32   Queue_Diversion;              /* Queue Diversion register */
+    CSL_Reg32   Reserved0[5];                 /* Reserved */
+    CSL_Reg32   Free_Desc_Buf_Starvation[4];  /* Free Descriptor/Buffer starvation count */
+    CSL_Reg32   Free_Desc_Starvation[4];      /* Free Descriptor starvation count */
+    CSL_Reg32   Reserved1[16];                /* Reserved */
+    CSL_Reg32   Linking_RAM_Reg0_Base;        /* Linking RAM Region 0 Base Address */
+    CSL_Reg32   Linking_RAM_Reg0_Size;        /* Linking RAM Region 0 Size */
+    CSL_Reg32   Linking_RAM_Reg1_Base;        /* Linking RAM Region 1 Base  */
+    CSL_Reg32   Reserved2;                    /* Reserved */
+    CSL_Reg32   Queue_Pending[((/*PAL_CPPI_PP_QMGR_G0_TOTAL_Q_COUNT*/ 1 )/sizeof(CSL_Reg32)) + 1]; /* Pending status for all queues. */
+
+} CSL_Queue_Manager_Region_Regs;
+
+/**
+ * \brief CPPI4 Queue Manager region overlay pointer
+ *
+ * Can be used in PAL layer directly for performance considerations.
+ */
+typedef CSL_Queue_Manager_Region_Regs* CSL_Queue_Manager_Region_RegsOvly;
+
 #define QMGR_QUEUE_N_REG_C_PKTSZ_SHIFT                  (0)
 #define QMGR_QUEUE_N_REG_C_PKTSZ_MASK                   (0x3FFF << QMGR_QUEUE_N_REG_C_PKTSZ_SHIFT)
 
@@ -385,27 +441,41 @@ typedef struct
 } Cppi4AccumulatorCfg;
 
 /**
- *  \brief CPPI4 PAL Accumulator Channel object used to transport message over HWMbox
+ *  \brief CPPI4 PAL Accumulator Channel object
  *
  *  CPPI4 PAL layer Object - encapsulates all bookeeping and data structures for
  *  CPPI4 PAL
  */
 typedef struct PAL_Cppi4AccChObj_t
 {
-    Cppi4AccumulatorCfg initCfg;         /**< The accumulator channel init configuration */
+    struct Cppi4PALObj_t *palCppi4Obj;  /**< Back reference to the CPPI 4.1 structure */
     Uint32 curPage;                     /**< Current accumulator page. */
-    Uint32 npcpuAddress;              /**< to make it 64-bytes for cache line flush.*/
+    Cppi4AccumulatorCfg initCfg;         /**< The accumulator channel init configuration */
 
 } PAL_Cppi4AccChObj;
 
+typedef enum cppi_desc_type
+{
+    CPPI41_DESC_TYPE_EMBEDDED = 0,
+    CPPI41_DESC_TYPE_HOST,
+    CPPI41_DESC_TYPE_MONOLITHIC,
+    CPPI41_DESC_TYPE_TEARDOWN
+} CPPI41_DESC_TYPE;
 
+typedef enum desc_type
+{
+    DESC_EMBEDDED = 0,
+    DESC_HOST = 16,
+    DESC_MONOLITHIC = 18,
+    DESC_TEARDOWN = 19
+} DESC_TYPE;
 
 #ifdef __KERNEL__
 
 /* convert DDR physical address to DDR virtual address */
-#define PAL_CPPI4_PHYS_2_VIRT(addr)                        (netip_mmio_to_virtual((unsigned long)addr))  /* X86 implementation here */
+#define PAL_CPPI4_PHYS_2_VIRT(addr)                        (netip_mmio_to_virtual(addr))  /* X86 implementation here */
 /* convert DDR virtual address to DDR physical address */
-#define PAL_CPPI4_VIRT_2_PHYS(addr)                        (netip_mmio_to_physical((unsigned long)addr))  /* X86 implementation here */
+#define PAL_CPPI4_VIRT_2_PHYS(addr)                        (netip_mmio_to_physical(addr))  /* X86 implementation here */
 /* force writing to HW */
 #define PAL_CPPI4_CACHE_WRITEBACK(addr, size)          cache_flush_buffer(addr, size)     /* X86 cache writeback implementation here */
 /* force reading from HW and not from cache */
@@ -506,6 +576,29 @@ PAL_Cppi4BD *PAL_cppi4QueuePop(PAL_Cppi4
 int PAL_cppi4QueueGetEntryCount(PAL_Handle hnd, Cppi4Queue queue, unsigned int *entryCount);
 
 /**
+ *  \brief PAL CPPI 4.1 pdsp_cmd_send registration.
+ *
+ * Sets up the pdsp_cmd_send function callback used by PAL CPPI
+ * driver.
+ *
+ *  @param  cb            [IN]      pdsp_cmd_send callback
+ *                                  function
+ *
+ *  @return PAL_SOK on success, else failure code.
+ */
+PAL_Result PAL_cppi4PdspCmdSendRegister(Int32 (*cb)(pdsp_id_t, pdsp_cmd_t, void *, Uint32, void *, Uint32));
+
+/**
+ *  \brief PAL CPPI 4.1 pdsp_cmd_send unregistration.
+ *
+ * Unregisters the pdsp_cmd_send function callback used by PAL
+ * CPPI driver.
+ *
+ *  @return PAL_SOK on success, else failure code.
+ */
+PAL_Result PAL_cppi4PdspCmdSendUnregister(void);
+
+/**
  *  \brief PAL CPPI 4.1 accumulator channel setup.
  *
  * Sets up an accumulator channel to monitor a queue.
@@ -565,6 +658,29 @@ void* PAL_cppi4AccChGetNextList(PAL_Cppi
  */
 PAL_Cppi4AccChHnd PAL_cppi4AccChOpenSharedMemory(PAL_Handle hnd, Cppi4AccumulatorCfg* accCfg, unsigned long SharedMemoryBase, unsigned long accListPageSize);
 
+/**
+ *  \brief PAL CPPI4.1 control API.
+ *
+ *  This function provides the capability for control operations to be performed
+ *  on the PAL CPPI4 module.
+ *
+ *  The command (cmd) is used to direct the function to perform one or more of
+ *  the supported operations.  The commands supported are:
+ *
+ *  - #PAL_CPPI41_IOCTL_QUEUE_DIVERT
+ *          - cmdArg defines the source and destination queue. Also defines if packets
+ *          should be added to head/tail of destination queue. This argument is a 32-bit integer
+ *          and an exact map of the diversion register in the hardware. param provides the queue manager
+ *          index to which the queue belongs.
+ *
+ *  @param  hnd           [IN]      Handle to the PAL Layer.
+ *  @param  cmd           [IN]      Operation to be performed.
+ *  @param  cmdArg    [IN/OUT]      Provides additional info for the operation.
+ *  @param  param     [IN/OUT]      Cmd specific argument.
+ *
+ *  @return PAL_SOK on success, else failure code.
+ */
+int PAL_cppi4Control (PAL_Handle hnd, Uint32 cmd, Ptr cmdArg, Ptr param);
 
 #endif /* __KERNEL__ */
 
--- a/include/linux/avalanche/generic/pal_defs.h
+++ b/include/linux/avalanche/generic/pal_defs.h
@@ -83,6 +83,7 @@
 
 /* Import the TI standard primitive "C" types defines */
 #include "_tistdtypes.h"
+#include <linux/spinlock.h>
 
 /**
  * \defgroup PALDefines PAL Defines
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_os.h
@@ -0,0 +1,217 @@
+/*
+ *
+ * pal_os.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+
+/** \file   pal_os.h
+    \brief  OS Abstraction Header File
+
+    This file provides visibility to OS abstraction APIs by including
+    only the configured service modules interface files.
+
+
+    \author     PSP Architecture Team
+    \version    1.0
+ */
+
+#ifndef __PAL_OS_H__
+#define __PAL_OS_H__
+
+
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include "pal_osCfg.h"
+#else
+#include "linux/avalanche/generic/pal_osCfg.h"
+#endif
+
+
+/* Added:
+ * PAL OS module type to be placed in section D of the final "ERROR CODE"
+ * as described in pal_defs.h
+ */
+#define PAL_OS_COMMON_ERR   (0)
+#define PAL_OSMEM_ERR       (1)
+#define PAL_OSBUF_ERR       (2)
+#define PAL_OSSEM_ERR       (3)
+#define PAL_OSMUTEX_ERR     (4)
+#define PAL_OSWAIT_ERR      (5)
+#define PAL_OSLIST_ERR      (6)
+#define PAL_OSPROTECT_ERR   (7)
+#define PAL_OSTIMER_ERR     (8)
+
+/* Common error codes for ALL PAL OS modules */
+#define PAL_OS_COMMON_ERROR_CREATE(x)   (PAL_ERROR(PAL_CRITICAL_ERROR, PAL_OS_COMMON_ERR, 0, (x)))
+
+/* Invalid parameter passed to the function error */
+#define PAL_OS_ERROR_INVALID_PARAM      (PAL_OS_COMMON_ERROR_CREATE(1))
+
+/* Feature not supported error */
+#define PAL_OS_ERROR_NOT_SUPPORTED      (PAL_OS_COMMON_ERROR_CREATE(2))
+
+/* No resources available error */
+#define PAL_OS_ERROR_NO_RESOURCES       (PAL_OS_COMMON_ERROR_CREATE(3))
+
+/* OS specific error */
+#define PAL_OS_ERROR_OS_SPECIFIC        (PAL_OS_COMMON_ERROR_CREATE(4))
+
+
+/* Default (memory) segment Id - Many of the modules (like OSSEM, OSBUF),
+ * depend upon a segment id to be passed in the API's. The macro below
+ * defines a default segment Id that can be used in these API's
+ */
+#define PAL_OSMEM_DEFAULT_SEGID         0
+
+
+#ifdef INLINE
+#define PAL_INLINE static inline
+#else
+#define PAL_INLINE
+#endif
+
+#ifdef PAL_INCLUDE_OSMEM
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include "pal_osMem.h"          /* OsMEM Services */
+#else
+#include "linux/avalanche/generic/pal_osMem.h"          /* OsMEM Services */
+#endif
+#endif /* PAL_INCLUDE_OSMEM */
+
+#ifdef PAL_INCLUDE_OSBUF
+#include "pal_osBuf.h"          /* OsBUF Services */
+#endif /* PAL_INCLUDE_OSBUF */
+
+#ifdef PAL_INCLUDE_OSSEM
+#include "pal_osSem.h"          /* OsSEM Services */
+#endif /* PAL_INCLUDE_OSSEM */
+
+#ifdef PAL_INCLUDE_OSMUTEX
+#include "pal_osMutex.h"        /* OsMUTEX Services */
+#endif /* PAL_INCLUDE_OSMUTEX */
+
+#ifdef PAL_INCLUDE_OSWAIT
+#include "pal_osWait.h"        /* OsWAIT Services */
+#endif /* PAL_INCLUDE_OSWAIT */
+
+#ifdef PAL_INCLUDE_OSLIST
+#include "pal_osList.h"         /* OsLIST Services */
+#endif /* PAL_INCLUDE_OSLIST */
+
+#ifdef PAL_INCLUDE_OSPROTECT
+#include "pal_osProtect.h"      /* OsPROTECT Services */
+#endif /* PAL_INCLUDE_OSPROTECT */
+
+#ifdef PAL_INCLUDE_OSCACHE
+#include "pal_osCache.h"      /* OsCACHE Services */
+#endif /* PAL_INCLUDE_OSCACHE */
+
+#ifdef PAL_INCLUDE_OSTIMER
+#include "pal_osTimer.h"        /* OsSEM Services */
+#endif /* PAL_INCLUDE_OSTIMER */
+
+#ifdef INLINE
+
+#ifdef PAL_INCLUDE_OSBUF
+#include "pal_osBuf_inline.h"
+#endif /* PAL_INCLUDE_OSBUF */
+
+#ifdef PAL_INCLUDE_OSMEM
+#include "pal_osMem_inline.h"
+#endif /* PAL_INCLUDE_OSMEM */
+
+#ifdef PAL_INCLUDE_OSMUTEX
+#include "pal_osMutex_inline.h"
+#endif /* PAL_INCLUDE_OSMUTEX */
+
+#ifdef PAL_INCLUDE_OSSEM
+#include "pal_osSem_inline.h"
+#endif /* PAL_INCLUDE_OSSEM */
+
+#ifdef PAL_INCLUDE_OSWAIT
+#include "pal_osWait_inline.h"
+#endif /* PAL_INCLUDE_OSWAIT */
+
+#ifdef PAL_INCLUDE_OSPROTECT
+#include "pal_osProtect_inline.h"
+#endif /* PAL_INCLUDE_OSPROTECT */
+
+#ifdef PAL_INCLUDE_OSLIST
+#include "pal_osList_inline.h"
+#endif /* PAL_INCLUDE_OSLIST */
+
+#ifdef PAL_INCLUDE_OSCACHE
+#include "pal_osCache_inline.h"      /* OsCACHE Services */
+#endif /* PAL_INCLUDE_OSCACHE */
+
+#ifdef PAL_INCLUDE_OSTIMER
+#include "pal_osTimer_inline.h"
+#endif /* PAL_INCLUDE_OSTIMER */
+
+#endif /* INLINE */
+
+#endif /* _PAL_OS_H_ */
+
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_osCfg.h
@@ -0,0 +1,98 @@
+/*
+ *
+ * pal_osCfg.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+
+/** \file   pal_osCfg.h
+    \brief  OS Configuration Header File
+
+    This file provides the OS configuration.
+
+
+    \author     Ajay Singh
+    \version    0.1
+ */
+
+#ifndef __PAL_OSCFG_H__
+#define __PAL_OSCFG_H__
+
+#define INLINE
+
+#define PAL_INCLUDE_OSMEM
+#define PAL_INCLUDE_OSPROTECT
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#define PAL_INCLUDE_OSBUF
+#define PAL_INCLUDE_OSSEM
+#define PAL_INCLUDE_OSMUTEX
+#define PAL_INCLUDE_OSWAIT
+#define PAL_INCLUDE_OSLIST
+#define PAL_INCLUDE_OSCACHE
+#define PAL_INCLUDE_OSTIMER
+#endif
+
+#endif
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_osMem.h
@@ -0,0 +1,346 @@
+/*
+ *
+ * pal_osMem.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+/** \file   pal_osMem.h
+    \brief  OsMEM Services Header File
+
+    This file declares OS abstraction services for variable length heap
+    memory management operations. The PAL module implementing these APIs
+    is called OsMEM
+
+
+    \author     PSP Architecture Team
+    \version    1.0
+ */
+
+#ifndef __PAL_OSMEM_H__
+#define __PAL_OSMEM_H__
+
+#include "pal_defs.h"
+#include "pal_os.h"
+
+/**
+ * \defgroup PALOSMem PAL OS Memory Interface
+ *
+ * PAL OS Memory Interface
+ * @{
+ */
+
+/** \name PAL OS Memory Interface
+ *  PAL OS Memory Interface
+ * @{
+ */
+
+/**
+ * \brief PAL OS MEM Init
+ *
+ * This is an idempotent function that must be called ahead of
+ * calling any other OsMEM services. It initializes OsMEM internal
+ * data structures (ex: segment tables) and does any book-keep
+ * necessary to implement the published services of OsMEM.
+ *
+ * \param   param [IN] is an arbitrary void* data type used to pass platform
+ * specific initialization information for OsMEM. This can be used
+ * to extend OsMEM configurability to decisions made at run-time.
+ * This is added for future extensions only.
+ * \return  PAL_SOK if successful else a suitable error code.
+ */
+PAL_INLINE PAL_Result PAL_osMemInit(Ptr param);
+
+/**
+ * \brief PAL OS Memory Address Space
+ *
+ * Specifies type of memory address space
+ */
+typedef enum
+{
+    PAL_OSMEM_ADDR_PRG      = 0,    /**< Program only address space */
+    PAL_OSMEM_ADDR_DAT      = 1,    /**< Data only address */
+    PAL_OSMEM_ADDR_IO       = 2,    /**< I/O only space address */
+    PAL_OSMEM_ADDR_PRGDAT   = 3,    /**< Unified prog-data */
+    PAL_OSMEM_ADDR_PRGIO    = 4,    /**< Unified prog-io */
+    PAL_OSMEM_ADDR_DATIO    = 5,    /**< Unified data-io */
+    PAL_OSMEM_ADDR_UNIFIED  = 6,    /**< Homogeneous, unified prog/data/io memory */
+    PAL_OSMEM_ADDR_SPECIAL  = 7     /**< Special or un-classified address range */
+} PAL_OsMemAddrSpace;
+
+/**
+ * \brief PAL OS Memory attributes
+ *
+ * Memory attributes
+ */
+typedef struct
+{
+  PAL_OsMemAddrSpace addrSpace;
+} PAL_OsMemAttrs;
+
+/**
+ * \brief PAL OS Memory Segment Define
+ *
+ * This function defines a segment of memory at specified
+ * start address with given attributes. Once defined, user can allocate
+ * variable length memory buffers at desired address alignments
+ * via the PAL_osMemAlloc() call.
+ *
+ * \param   name [IN]       Name of memory segment being defined
+ * \param   startAddr [IN]  The start address (byte granular) of memory segment
+ * \param   numBytes [IN]   The length in bytes of the memory segment
+ * \param   attrs [IN]      Optional memory attributes characterizing the
+ *                          region of memory being defined. Ex: Program or
+ *                          Data memory etc.,
+ * \param   segId [OUT]     Location to recieve the numeric identifier of the
+ *                          just defined memory segment.
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemSegDefine(const char* name,
+                              Uint32 startAddr,
+                              Uint32 numBytes,
+                              PAL_OsMemAttrs *attrs,
+                              Uint32 *segId);
+
+/**
+ * \brief PAL OS Memory Segment Undefine
+ *
+ * This function undefines specified segment of memory. Once
+ * undefined, the region is no longer available for PAL_osMemAlloc().
+ *
+ * \param   segId [IN] Identifier of the memory segment being undefined.
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemSegUndefine(Uint32 segId);
+
+/**
+ * \brief PAL OS Memory Alloc
+ *
+ * This function allocates specified length of memory from
+ * the given memory segment.
+ * \note The memory segment must already be defined before calling this API.
+ * \note Alignment = 0 or 1 results is NO special alignments being done. A
+ * value of 2 forces the buffer to start at even byte boundary
+ *
+ * \param   segId [IN]      Identifier of the hosting memory segment
+ * \param   numBytes [IN]   The length in bytes of buffer being allocated
+ * \param   alignment [IN]  A power-of-2 alignment constraint specifier.
+ *                          If non-zero, OsMEM will allocate specified length
+ *                          of memory ensuring that it is aligned to an
+ *                          address boundary as specified.
+ * \param   memAddr [OUT]   Address of just allocated memory buffer
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemAlloc(Uint32 segId,
+                          Uint32 numBytes,
+                          Uint16 alignment,
+                          Ptr *memAddr);
+
+/**
+ * \brief PAL OS Memory Free
+ *
+ * This function counters the PAL_osMemAlloc() call in that it frees
+ * the specified memory buffer and returns it to the hosting memory
+ * segment for others to allocate.
+ * \note    The memory segment must already be defined before calling this API.
+ *
+ * \param   segId [IN]      Identifier of the hosting memory segment
+ * \param   memAddr [IN]    The start address of memory buffer being freed.
+ * \param   numBytes [IN]   The length in bytes of buffer being freed.
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemFree(Uint32 segId, Ptr memAddr, Uint32 numBytes);
+
+/**
+ * \brief PAL OS Memory Copy
+ *
+ * This function copies specified number of bytes from give source
+ * address to given destination address
+ * \note The user is responsible of making sure that adequate free memory
+ * is indeed available at the specified destination address.
+ *
+ * \param   dest [IN/OUT]   Address of destination buffer
+ * \param   src [IN]        Address of buffer to copy data from
+ * \param   numBytes [IN]   The number of contigious bytes to copy
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemCopy(Ptr dest, const Ptr src, Uint32 numBytes);
+
+/**
+ * \brief PAL OS Memory Set
+ *
+ * This function stamps the specified region of memory with
+ * the given bit pattern (fill character).
+ *
+ * \param   memAddr [IN/OUT]    Address of memory region to be stamped with
+ *                              fill character
+ * \param   fillVal [IN]        Address of buffer to copy data from
+ * \param   numBytes [IN]       The number of contigious bytes to fill
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemSet(Ptr memAddr, Char fillVal, Uint32 numBytes);
+
+/**
+ * \brief PAL OS Memory Lock
+ *
+ * This function locks out the specified region of memory from
+ * any page-swap operations effected by OS virtual memory manager.
+ * Once locked, the region of memory will stay resident untill
+ * its unlocked via PAL_osMemUnlock().
+ *
+ * \param   memAddr [IN]    Address of memory region to be locked from VM opserations
+ * \param   byteLen [IN]    Length of memory region in bytes
+ * \param   cookie [OUT]    Space to recieve an arbitrary platform specific data
+ *                          associated with just performed locking. User is not
+ *                          expected to interpret it any way. It is intended to
+ *                          be passed as-is during matching unlocking operation
+ *                          via PAL_osMemUnlock().
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemLock(Ptr memAddr,
+                         Uint32 byteLen,
+                         Uint32 *cookie);
+
+/**
+ * \brief PAL OS Memory Un-Lock
+ *
+ * This function counter to PAL_osMemLock() in that it unlocks the
+ * specified region of memory thereby exposing it to any swaps
+ * performed by OS virtual memory manager.
+ *
+ * \param   memAddr [IN]    Address of memory to be unlocked for VM operations
+ * \param   byteLen [IN]    Length of memory region in bytes
+ * \param   cookie [IN]     Platform specific data obtained when the specific
+ *                          memory region was locked by a corresponding
+ *                          PAL_osMemLock() function
+ * \return  PAL_SOK if successful, else a suitable error code
+ */
+PAL_INLINE PAL_Result PAL_osMemUnlock(Ptr memAddr,
+                           Uint32 byteLen,
+                           Uint32 *cookie);
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+/**
+ * \brief PAL OS Memory Virtual To Physical
+ *
+ * This function is relevant in platforms where OS is running
+ * a virtual memory manager. It inputs a logical or virtual
+ * memory address (as seen by application) and returns the
+ * corresponding physical memory address (as seen by the h/w
+ * devices).
+ * \note A macro equivalent of this API will also be available
+ *
+ * \param   virtAddress [IN] The virtual memory address
+ * \return  A 32bit unsigned physical memory address.
+ */
+PAL_INLINE Uint32 PAL_osMemVirt2Phy(Ptr virtAddress);
+
+/**
+ * \brief PAL OS Memory Physical To Virtual
+ *
+ * This function is relevant in platforms where OS is running
+ * a virtual memory manager. It inputs a physical memory
+ * address (as seen by the h/w devices) and returns the corresponding
+ * virtual memory address (as seen by the application).
+ * \note A macro equivalent of this API will also be available
+ *
+ * \param   phyAddress [IN] The physical memory address
+ * \return  Virtual memory address (unadorned void* type)
+ */
+PAL_INLINE Ptr PAL_osMemPhy2Virt(Uint32 phyAddress);
+
+#endif
+/**
+ * \brief PAL OS Memory Report Attributes
+ *
+ * PAL OS Memory Report attributes
+ */
+typedef struct
+{
+  Int segBytesSz;           /**< Segment size in bytes */
+  Int segBytesUsed;         /**< Number of bytes allocated */
+  Int numBufs;              /**< Number of buffers allocated */
+  Int maxLengthFree;        /**< Max contigious bytes free */
+  Int maxLengthAllocated;   /**< Max contigious bytes allocated */
+} PAL_OsMemReport;
+
+/**
+ * \brief PAL OS Memory Report
+ *
+ * This function reports assorted usage statistics information
+ * regarding the specified memory segment
+ *
+ * \param   segId [IN]      Identifier of memory segment to report statistics
+ * \param   report [IN/OUT] Location where information must be reported. If
+ *                          NULL, structure is not filled.
+ * \param   buf [IN/OUT]    String buffer where a text formatted report will
+ *                          be printed. If NULL, no text reporting is done
+ * \return  PAL_SOK if successful, else a suitable error code.
+ */
+PAL_INLINE PAL_Result PAL_osMemReport(Uint32 segId, PAL_OsMemReport *report, Char* buf);
+
+/*@}*/
+/*@}*/
+
+#endif /* _PAL_OSMEM_H_ */
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_osMem_inline.h
@@ -0,0 +1,307 @@
+/*
+ *
+ * pal_osMem_inline.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+
+/** \file   pal_osMem_inline.h
+    \brief  OsMEM Services Source File
+
+    This file implements the OsMEM services for Linux.
+
+
+    \author     PSP Architecture Team
+    \version   0.1
+*/
+
+#ifndef __PAL_OSMEM_INLINE_H__
+#define __PAL_OSMEM_INLINE_H__
+
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include "pal_os.h"
+#include "pal_defs.h"
+#include <asm/page.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <asm/memory.h>
+#else
+#include "linux/avalanche/generic/pal_os.h"
+#include "linux/avalanche/generic/pal_defs.h"
+#include <asm/page.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <asm/io.h>
+#endif
+
+
+/**
+ * \brief PAL OS MEM Init
+ */
+PAL_INLINE PAL_Result PAL_osMemInit (Ptr param)
+{
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Segment Define
+ * For Linux, the whole available memory is considered into one segment.
+ * No further segments are made in the memory. This function designates that
+ * segment with id 0.
+ */
+PAL_INLINE PAL_Result PAL_osMemSegDefine (    const char * name,
+                                Uint32 startAddr,
+                                Uint32 numBytes,
+                                PAL_OsMemAttrs * attrs,
+                                Uint32 *segId)
+{
+    /* always return the segment id 0.
+     * Only one segment is defined and used
+     */
+    *segId = 0;
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Segment Undefine
+ * Only segment 0 is recognized.
+ */
+PAL_INLINE PAL_Result PAL_osMemSegUndefine (Uint32 segId)
+{
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Alloc
+ * Only segment 0 is recognized.
+ * This function allocates only contiguous memory.
+ * specify alignment as 0 if all you
+ */
+PAL_INLINE PAL_Result PAL_osMemAlloc (
+                Uint32 segId,
+                Uint32 numBytes,
+                Uint16 alignment,
+                Ptr* memAddr)
+{
+    *memAddr = kmalloc(numBytes, GFP_KERNEL);
+
+    if(*memAddr == NULL)
+    {
+        return PAL_OS_ERROR_NO_RESOURCES;
+    }
+
+     return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Free
+ * Only segment 0 is recognized.
+ */
+PAL_INLINE PAL_Result PAL_osMemFree (Uint32 segId, Ptr memAddr, Uint32 numBytes)
+{
+    kfree(memAddr);
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Copy
+ * \note This will misbehave if presented with invalid arguments.
+ */
+PAL_INLINE PAL_Result PAL_osMemCopy (Ptr dest, const Ptr src, Uint32 numBytes)
+{
+    memcpy(dest, src, numBytes);
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Set
+ * This will crash if presented with invalid arguments.
+ */
+PAL_INLINE PAL_Result PAL_osMemSet (Ptr memAddr, Char fillVal, Uint32 numBytes)
+{
+    memset(memAddr, fillVal, numBytes);
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Lock
+ * In linux, memory locking/Unlocking is supported only at page granularity.
+ * This implementation, locks all the pages from memAddr to memAddr + byteLen
+ * pages containing both addresses inclusive.
+ */
+PAL_INLINE PAL_Result PAL_osMemLock (Ptr memAddr, Uint32 byteLen, Uint32 *cookie)
+{
+    Uint32 temp;
+
+    /*
+     * Get the page associated with the memory address
+     * and set the reserved bit for that page
+     */
+    for (temp = (Uint32)memAddr; temp < PAGE_ALIGN((Uint32)memAddr+byteLen); temp += PAGE_SIZE)
+	{
+        SetPageReserved(virt_to_page(temp));
+    }
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Un-Lock
+ * In linux, memory locking/Unlocking is supported only at page granularity.
+ * This implementation, locks all the pages from memAddr to memAddr + byteLen
+ * pages containing both addresses inclusive.
+ */
+PAL_INLINE PAL_Result PAL_osMemUnlock (Ptr memAddr, Uint32 byteLen, Uint32 *cookie)
+{
+    Uint32 temp;
+
+    /*
+     * Get the page associated with the memory address
+     * and unset the reserved bit for that page
+     */
+    for (temp = (Uint32)memAddr; temp < PAGE_ALIGN((Uint32)memAddr+byteLen); temp += PAGE_SIZE)
+	{
+        ClearPageReserved(virt_to_page(temp));
+    }
+    return PAL_SOK;
+}
+
+/**
+ * \brief PAL OS Memory Virtual To Physical
+ */
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+PAL_INLINE Uint32 PAL_osMemVirt2Phy (Ptr virtAddress)
+{
+    return (Uint32) __virt_to_phys((Uint32)virtAddress);
+}
+#endif
+
+/**
+ * \brief PAL OS Memory Physical To Virtual
+ */
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+PAL_INLINE Ptr PAL_osMemPhy2Virt (Uint32 phyAddress)
+{
+
+    return (Ptr) __phys_to_virt(phyAddress);
+}
+#endif
+
+/**
+ * \brief PAL OS Memory Report
+ * No reporting is supported inherently by the Linux kernel.
+ */
+PAL_INLINE PAL_Result PAL_osMemReport (Uint32 segId, PAL_OsMemReport * report, Char *buf)
+{
+    return PAL_OS_ERROR_NOT_SUPPORTED;
+}
+
+/**
+ *  \brief PAL os Memory Allocation API. Allocated memory
+ *  memory will be aligned to requested size. For smaller
+ *  memory chunks (less than page size) use PAL_osMemAlloc
+ */
+
+PAL_INLINE void* PAL_osMemAllocSizeAligned(Uint32 segId, Uint32 numBytes)
+{
+    Uint32 order;
+    Uint32 ret;
+
+    /* find number of pages */
+    numBytes = (numBytes/PAGE_SIZE) + ((numBytes % PAGE_SIZE)?1:0);
+
+    /* find allocation order */
+    for(order = 0; (1 << order) < numBytes; order++);
+
+    ret = __get_free_pages(GFP_KERNEL, order);
+
+    /* really defensive stuff: just to make sure we are good */
+    if((ret % (1 << order)) != 0) {
+        free_pages(ret, order);
+        ret = 0;
+    }
+
+    return (void*) ret;
+}
+
+/**
+ *  \brief PAL os Memory Free API. This API can only free memory
+ *  allocated using PAL_osMemAllocSizeAligned.
+ */
+PAL_INLINE void PAL_osMemFreeSizeAligned(Uint32 segId, void* addr, Uint32 numBytes)
+{
+    Uint32 order;
+
+    /* find number of pages */
+    numBytes = (numBytes/PAGE_SIZE) + ((numBytes % PAGE_SIZE)?1:0);
+
+    /* find allocation order */
+    for(order = 0; (1 << order) < numBytes; order++);
+
+    free_pages((unsigned long)addr, order);
+}
+
+#endif
+
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_osProtect.h
@@ -0,0 +1,161 @@
+/*
+ *
+ * pal_osProtect.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+
+/** \file   pal_osProtect.h
+    \brief  OsPROTECT Services Header File
+    ===================================================================
+    The OsPROTECT models various levels of reentrancy protection
+    for use while writing critical sections in user code. critical
+    sections are those parts of user code that needs to run atomically
+    in some sense. Meaning, single threading is called for. However,
+    the degree of protection sought by user varies based on nature
+    of code he is writing.
+
+    It is possible that for some regions of code, user needs ultimate
+    degree of protection where all external interrupts are blocked,
+    essentially locking out the CPU exclusively for the critical
+    section of code. On the other hand user may wish to merely avoid
+    thread or task switch from occuring inside said region of code,
+    but he may wish to entertain ISRs to run if so required.
+
+    Depending on the underlying OS, the number of levels of protection
+    offered may vary. At the least, two basic levels of protection are
+    supported --
+
+    - PAL_OSPROTECT_INTERRUPTS - Mask interrupts globally. This has
+      real-time implications and must be used with descretion.
+      If blocking/unblocking of specific interrupt lines is desired,
+      one is reffered to APIs listed in pal_sys.h file.
+
+    - PAL_OSPROTECT_SCHEDULER - Only turns off Kernel scheduler
+      completely, but still allows h/w interrupts from being serviced.
+
+    Protection levels 0 to N (max positive Int) are platform specific
+    ===================================================================
+
+
+    \author     PSP Architecture Team
+    \version    1.0
+ */
+
+#ifndef __PAL_OSPROTECT_H__
+#define __PAL_OSPROTECT_H__
+
+#include "pal_defs.h"
+#include "pal_os.h"
+
+/**
+ * \defgroup PalOSProtect PAL OS Protect Interface
+ *
+ * PAL OS Protect Interface
+ * \{
+ */
+
+/** \name PAL OS Protect Interface
+ *  PAL OS Protect Interface
+ * \{
+ */
+
+#define PAL_OSPROTECT_INTERRUPT (-1)
+#define PAL_OSPROTECT_SCHEDULER (-2)
+
+/**
+ * \brief   PAL OS Protect Entry
+ *
+ *      This function saves the current state of protection in cookie
+ *      variable passed by caller. It then applies the requested level
+ *      of protection
+ * \param   level is numeric identifier of the desired degree of protection.
+ * \param   cookie is memory location where current state of protection is
+ *      saved for future use while restoring it via PAL_osProtectExit()
+ * \note    user is not expected to interpret the cookie in any manner. It
+ *      is intended for use in terminating the presently enforced
+ *      protection via a matching PAL_osProtectExit() call discssed
+ *      later in this file.
+ * \return  None
+ */
+PAL_INLINE void PAL_osProtectEntry(Int level, Uint32* cookie);
+
+/**
+ * \brief   PAL OS Protect Exit
+ *
+ *      This function undoes the protection enforced to original state
+ *      as is specified by the cookie passed.
+ * \param   level is numeric identifier of the desired degree of protection.
+ * \param   cookie is original state of protection at time when the
+ *      corresponding PAL_osProtectEnter() was called.
+ * \return  None
+ */
+PAL_INLINE void PAL_osProtectExit(Int level, Uint32 cookie);
+
+/*\}*/
+/*\}*/
+
+#endif /* _PAL_OSPROTECT_H_ */
--- /dev/null
+++ b/include/linux/avalanche/generic/pal_osProtect_inline.h
@@ -0,0 +1,127 @@
+/*
+ *
+ * pal_osProtect_inline.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+/** \file   pal_osProtect_inline.h
+    \brief  OsPROTECT Services Source File
+
+
+    \author     PSP Architecture Team
+    \version    1.0
+ */
+
+#ifndef __PAL_OSPROTECT_INLINE_H__
+#define __PAL_OSPROTECT_INLINE_H__
+
+#include "pal_os.h"
+#include "pal_defs.h"
+#include "pal_osCfg.h"
+#include <linux/spinlock.h>
+#include <linux/slab.h>
+
+/**
+ * \defgroup PalOSProtect PAL OS Protect Interface
+ *
+ * PAL OS Protect Interface
+ * \{
+ */
+
+/** \name PAL OS Protect Interface
+ *  PAL OS Protect Interface
+ * \{
+ */
+
+
+/**
+ * \brief   PAL OS Protect Entry
+ */
+PAL_INLINE void PAL_osProtectEntry(Int level, Uint32* cookie)
+{
+	Ulong flags;
+    if(level == PAL_OSPROTECT_INTERRUPT)
+	{
+        local_irq_save(flags);
+		*cookie = flags;
+	}
+}
+/**
+ * \brief   PAL OS Protect Exit
+ */
+PAL_INLINE void PAL_osProtectExit(Int level, Uint32 cookie)
+{
+    if(level == PAL_OSPROTECT_INTERRUPT)
+	{
+        local_irq_restore((Ulong)cookie);
+	}
+}
+
+/*\}*/
+/*\}*/
+
+#endif
+
--- /dev/null
+++ b/include/linux/avalanche/generic/ramtest.h
@@ -0,0 +1,84 @@
+/*
+ *
+ * ramtest.h
+ * Description:
+ * see below
+ *
+ *
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or 
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify 
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but 
+  WITHOUT ANY WARRANTY; without even the implied warranty of 
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU 
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License 
+  along with this program; if not, write to the Free Software 
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution 
+  in the file called LICENSE.GPL.
+
+
+  Contact Information:
+  Intel Corporation
+  2200 Mission College Blvd.
+  Santa Clara, CA  97052
+
+  BSD LICENSE 
+
+  Copyright(c) 2008-2014 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without 
+  modification, are permitted provided that the following conditions 
+  are met:
+
+    * Redistributions of source code must retain the above copyright 
+      notice, this list of conditions and the following disclaimer.
+
+    * Redistributions in binary form must reproduce the above copyright 
+      notice, this list of conditions and the following disclaimer in 
+      the documentation and/or other materials provided with the 
+      distribution.
+
+    * Neither the name of Intel Corporation nor the names of its 
+      contributors may be used to endorse or promote products derived 
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS 
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT 
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR 
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT 
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, 
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT 
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, 
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY 
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT 
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE 
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*/
+
+
+/*
+ * Generic RAM testing code 
+ *
+ */
+
+#define AVALANCHE_RAMTEST_BASIC_DATA_FAIL   -1
+#define AVALANCHE_RAMTEST_ADDRESS_FAIL      -2
+#define AVALANCHE_RAMTEST_DATA_FAIL         -3
+
+int avalanche_ram_basic_data_test(volatile unsigned int* base);
+int avalanche_ram_address_test(volatile unsigned int* base, unsigned int size);
+int avalanche_ram_data_test(volatile unsigned int* base, unsigned int size);
+int avalanche_do_ram_test(volatile unsigned int* base, unsigned int size);
+
--- a/include/linux/avalanche/puma7/puma7.h
+++ b/include/linux/avalanche/puma7/puma7.h
@@ -72,6 +72,7 @@
 #define AVALANCHE_SOC_NAME         "PUMA7"
 #include <linux/avalanche/puma7/puma7_interrupts.h>
 
+#define IO_ADDRESS(addr) ((unsigned long)netip_mmio_to_virtual(addr))
 #define IO_PHY2VIRT(addr)              (netip_mmio_to_virtual((unsigned long)addr))   /* X86 implementation here */
 /* convert hardware virtual address to hardware physical address */
 #define IO_VIRT2PHY(addr)             (netip_mmio_to_physical((unsigned long)addr))   /* X86 implementation here */
@@ -119,6 +120,22 @@
  * Convert INTD1 interrupt to INTC interrupt line.
  */
 #define MAP_INTD1_TO_INTC(intv)                 ((intv) + AVALANCHE_INTD1_BASE_INT)
+typedef enum
+{
+    e_Interrupt_Disable = 0,
+    e_Interrupt_Enable
+} AVALANCHE_INTRPT_MODE_T;
+
+typedef volatile struct interrupt_bundle_struct
+{
+    volatile unsigned int      interrupt_enable;                //  Read/Write.
+    volatile unsigned int      sw_interrupt;                    //  Write Only.
+    volatile unsigned int      edge_or_level;                   //  Read/Write. Edge=0, Level=1
+    volatile unsigned int      mask;                            //  Read/Write.
+    volatile unsigned int      interrupt_status_pre_masked;     //  Read Only.
+    volatile unsigned int      interrupt_status_post_masked;    //  Read Only.  Note: Reading cause to status bit clear !
+} interrupt_bundle_struct_t;
+
 #if 0
 /**
  * Packet Processor Queue Managers
--- a/include/linux/avalanche/puma7/puma7_cppi.h
+++ b/include/linux/avalanche/puma7/puma7_cppi.h
@@ -40,9 +40,11 @@
 
 #include "puma7_cppi_prv.h"
 
-//#define PAL_CPPI4_CACHE_INVALIDATE(addr, size)              dma_cache_inv ((unsigned long)(addr), (size))
-//#define PAL_CPPI4_CACHE_WRITEBACK(addr, size)               dma_cache_wback ((unsigned long)(addr), (size))
-//#define PAL_CPPI4_CACHE_WRITEBACK_INVALIDATE(addr, size)    dma_cache_wback_inv ((unsigned long)(addr), (size))
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#define PAL_CPPI4_CACHE_INVALIDATE(addr, size)              dma_cache_inv ((unsigned long)(addr), (size))
+#define PAL_CPPI4_CACHE_WRITEBACK(addr, size)               dma_cache_wback ((unsigned long)(addr), (size))
+#define PAL_CPPI4_CACHE_WRITEBACK_INVALIDATE(addr, size)    dma_cache_wback_inv ((unsigned long)(addr), (size))
+#endif
 
 extern int Puma_DOCSIS_CPPI_Init(void);
 extern int Puma_FCC_CPPI_Init(void);
--- a/include/linux/avalanche/puma7/puma7_cppi_prv.h
+++ b/include/linux/avalanche/puma7/puma7_cppi_prv.h
@@ -36,12 +36,16 @@
 #include "puma7_cppi_gqmgr2_q.h"
 #include "puma7_cppi_dsgqmgr_q.h"
 #include "puma7_cppi_usqmgr_q.h"
+#ifndef CONFIG_ARM_AVALANCHE_SOC
 #include <linux/netip_mem_util.h>
+#endif
 
 #ifndef PUMA7_CPPI_PRV_H
 #define PUMA7_CPPI_PRV_H
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
 #define IO_ADDRESS(addr) ((unsigned long)netip_mmio_to_virtual(addr))
+#endif
 
 /**********************************************************************************************************************
 
--- /dev/null
+++ b/include/linux/avalanche/puma7/puma7_defs.h
@@ -0,0 +1,69 @@
+/*
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2016 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+  Contact Information:
+    Intel Corporation
+    2200 Mission College Blvd.
+    Santa Clara, CA  97052
+
+  BSD LICENSE
+
+  Copyright(c) 2016 Intel Corporation. All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*/
+
+#ifndef _PUMA7_DEFS_H
+#define _PUMA7_DEFS_H
+
+#define PUMA7_OR_NEWER_SOC_TYPE     (1)
+#define PUMA7_SOC_TYPE              (1)
+#define PUMA6_OR_NEWER_SOC_TYPE     (1)
+
+#endif
--- a/include/linux/avalanche/puma7/puma7_pp.h
+++ b/include/linux/avalanche/puma7/puma7_pp.h
@@ -84,6 +84,10 @@
 #define MAX_IP_PACKET_SIZE      1514
 #define MIN_IP_PACKET_SIZE      64
 
+/* Queue threshold (short/long/xl) */
+#define THRESHOLD_0_VALUE       (384)
+#define THRESHOLD_1_VALUE       (1920)
+
 /*
  * PID Range configurations
  */
@@ -266,7 +270,7 @@ typedef enum PAL_CPPI41_PP_QOS_CLUSTERS
 {                                                                           \
     volatile USHORT *mtu_per_qos_q = 0;                                     \
     mtu_per_qos_q = (USHORT *)AVALANCHE_PP_MODIFIER_MTU_TABLE_BASE + (qNum);\
-    *mtu_per_qos_q = (mtuSize) + ETH_HLEN;                                  \
+    *mtu_per_qos_q = cpu_to_be16((mtuSize) + ETH_HLEN);                                  \
 }
 
 #define AVALANCHE_PP_DS_RESEQ_CMD_RGN_BASE         (IO_ADDRESS(0xF3ec0000))
@@ -478,7 +482,7 @@ typedef enum PAL_CPPI41_PP_QOS_CLUSTERS
 {                                                                       \
     volatile USHORT *mtu_per_qos_q = 0;                                 \
     mtu_per_qos_q = (USHORT *)AVALNACHE_PP_MC_MTU_TABLE_BASE + (qNum);  \
-    *mtu_per_qos_q = (mtuSize) + ETH_HLEN;                              \
+    *mtu_per_qos_q = cpu_to_be16((mtuSize) + ETH_HLEN);                 \
 }
 
 #define AVALANCHE_PP_DPI_CMD_RGN_BASE                   (IO_ADDRESS(0xF3F40000))
@@ -507,10 +511,10 @@ typedef enum PAL_CPPI41_PP_QOS_CLUSTERS
 /*********************/
 
 /* PP Free running counter */
-#define FREE_RUNNING_COUNTER_ENABLE()                   {(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S1_CTL_BASE |= 0x1); (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_CTL_BASE |= 0x1);}
-#define FREE_RUNNING_COUNTER_RESET()                    {(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S1_RESET_BASE |= 0x1); (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_RESET_BASE |= 0x1);}
-#define FREE_RUNNING_COUNTER_L_GET()                    (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_L_BASE)
-#define FREE_RUNNING_COUNTER_H_GET()                    (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_H_BASE)
+#define FREE_RUNNING_COUNTER_ENABLE()                   {(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S1_CTL_BASE) |= cpu_to_be32(0x1); (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_CTL_BASE) |= cpu_to_be32(0x1);}
+#define FREE_RUNNING_COUNTER_RESET()                    {(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S1_RESET_BASE) |= cpu_to_be32(0x1); (*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_RESET_BASE) |= cpu_to_be32(0x1);}
+#define FREE_RUNNING_COUNTER_L_GET()                    be32_to_cpu(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_L_BASE)
+#define FREE_RUNNING_COUNTER_H_GET()                    be32_to_cpu(*(volatile unsigned int *)AVALANCHE_PP_STATISTICAL_FRC_S2_H_BASE)
 
 /* PP MTU size */
 #define UPDATE_MTU_TABLE_IN_PDSP_DMEM(qNum, mtuSize)        \
--- a/include/linux/ipv6.h
+++ b/include/linux/ipv6.h
@@ -194,7 +194,12 @@ struct ipv6_pinfo {
                                 rxflow:1,
 				rxtclass:1,
 				rxpmtu:1,
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+				rxorigdstaddr:1,
+				ti_rxinfo:1;
+#else
 				rxorigdstaddr:1;
+#endif
 				/* 2 bits hole */
 		} bits;
 		__u16		all;
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -21,7 +21,7 @@
 
 /* Free memory management - zoned buddy allocator.  */
 #ifndef CONFIG_FORCE_MAX_ZONEORDER
-#define MAX_ORDER 11
+#define MAX_ORDER 14
 #else
 #define MAX_ORDER CONFIG_FORCE_MAX_ZONEORDER
 #endif
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -22,9 +22,17 @@
  *
  *		Moved to /usr/include/linux for NET3
  */
+/*
+Includes Intel Corporation's changes/modifications dated: 2014.
+Changed/modified portions - Copyright  2014, Intel Corporation.
+*/
 #ifndef _LINUX_NETDEVICE_H
 #define _LINUX_NETDEVICE_H
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
 #include <linux/pm_qos.h>
 #include <linux/timer.h>
 #include <linux/bug.h>
@@ -36,6 +44,14 @@
 #include <linux/percpu.h>
 #include <linux/rculist.h>
 #include <linux/dmaengine.h>
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/generic/avalanche_pp_api.h>
+#else
+#include <linux/ti_ppm.h>
+#include <asm-arm/arch-avalanche/generic/avalanche_pp_api.h>
+#endif
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 #include <linux/workqueue.h>
 #include <linux/dynamic_queue_limits.h>
 
@@ -133,9 +149,6 @@ static inline bool dev_xmit_complete(int
 	return false;
 }
 
-#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
-#define TI_MAX_DEVICE_INDEX     64
-#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
 /*
  *	Compute the worst case header length according to the protocols
  *	used.
@@ -158,6 +171,15 @@ static inline bool dev_xmit_complete(int
 #define MAX_HEADER (LL_MAX_HEADER + 48)
 #endif
 
+#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
+/* Maximum number of net devices supported. TI L2 Selective forwarder uses
+ * 64 bits to mark the packet to indicate the device on which the packets should
+ * be forwarded. Hence Max Device Index is limited to 64.
+ * Do not increment the number.
+ */
+#define TI_MAX_DEVICE_INDEX     64
+#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
+
 /*
  *	Old network device statistics. Fields are native words
  *	(unsigned long) so they can be read and written atomically.
@@ -1414,35 +1436,65 @@ struct net_device {
 #if IS_ENABLED(CONFIG_NETPRIO_CGROUP)
 	struct netprio_map __rcu *priomap;
 #endif
+
 #ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
     int (*packet_handler)(struct sk_buff *skb);
 #endif
+
 #ifdef CONFIG_INTEL_NS_DEVICE_FILTER
    int (*ns_handler)(struct net_device *dev,struct	in6_addr* dst_addr,unsigned char banned_flags);
 #endif
+
 #ifdef CONFIG_TI_EGRESS_HOOK
     int (*egress_hook)(struct sk_buff *skb);
 #endif
+
 #ifdef CONFIG_TI_DOCSIS_EGRESS_HOOK
     int (*docsis_egress_hook)(struct sk_buff *skb);
 #endif
+
 #ifdef CONFIG_TI_GW_EGRESS_HOOK
     int (*gw_egress_hook)(struct sk_buff *skb);
 #endif
+
 #ifdef CONFIG_TI_PACKET_PROCESSOR
+    /* PPM Device Information. Each networking device can be considered as a VPID
+     * instance executing on a PID. The PID is created when the hardware associated
+     * with the device has been initialized; the VPID Information is initialized and
+     * every subsequent call to bring the interface UP and DOWN results in VPID
+     * creation and deletion. Virtual networking interfaces do not have a matching
+     * VPID. So if the PID handle is -1 then there is no VPID manipulation done on the
+     * device. */
     int         pid_handle;
     int         vpid_handle;
+
+    /* The VPID Information block which is associated with the networking device.
+     * This field is kept in the networking device because it gives us a convenient
+     * place to store all the VPID specific information. As mentioned above not all
+     * networking devices are a networking endpoint. In such cases the values in this
+     * structure are ignored. */
 #ifdef CONFIG_MACH_PUMA5
     TI_PP_VPID                  vpid_block;
 #else
     AVALANCHE_PP_VPID_INFO_t    vpid_block;
 #endif
+
 #if PUMA7_OR_NEWER_SOC_TYPE
     int (*netdev_copy_priv_hook)(struct net_device *newDev, struct net_device *origDev);
+
+    /* For GMAC it will be set with NULL. for VLAN netdev we will set the original netdev pointer */
     struct net_device   *parentDev;
 #endif
+
+    /* There QoS may be defined either for physical or virtual device
+       The QoS setting hooks are being triggered by PID creation.
+       In case there is a need in alternative QoS scheme to be created it can be
+       specified by setting the  qos_virtual_scheme_idx to a valid non default index
+       This alternative scheme creation is being triggered from VPID creation.
+       It has to be defined by the appropriate device drived */
 #define NETDEV_PP_QOS_PROFILE_DEFAULT   (-1)
     int qos_virtual_scheme_idx;
+
     int (*qos_setup_hook)   (struct net_device *dev_p);
     int (*qos_shutdown_hook)(struct net_device *dev_p);
     int (*qos_select_hook)  (struct sk_buff    *skb);
@@ -3117,10 +3169,6 @@ do {								\
 })
 #endif
 
-#ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
-extern int ti_register_protocol_handler (struct net_device* dev, int (*packet_handler)(struct sk_buff *skb));
-extern int ti_deregister_protocol_handler (struct net_device* dev);
-#endif /* CONFIG_TI_DEVICE_PROTOCOL_HANDLING */
 /*
  * netdev_WARN() acts like dev_printk(), but with the key difference
  * of using a WARN/WARN_ON to get the message out, including the
@@ -3187,6 +3235,12 @@ do {								\
 })
 #endif
 
+
+#ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
+extern int ti_register_protocol_handler (struct net_device* dev, int (*packet_handler)(struct sk_buff *skb));
+extern int ti_deregister_protocol_handler (struct net_device* dev);
+#endif /* CONFIG_TI_DEVICE_PROTOCOL_HANDLING */
+
 /*
  *	The list of packet types we will receive (as opposed to discard)
  *	and the routines to invoke.
--- /dev/null
+++ b/include/linux/proc_fs_macros.h
@@ -0,0 +1,41 @@
+/*
+ * The proc filesystem macros 
+ */
+
+#ifndef _LINUX_PROC_FS_MACROS_H
+#define _LINUX_PROC_FS_MACROS_H
+
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+
+#define DECLARE_PROCFS_ENTRY(name, read_proc, write_proc) \
+static int name##_proc_open(struct inode *inode, struct file *file) \
+{ \
+    return single_open(file, read_proc, PDE_DATA(inode)); \
+} \
+static const struct file_operations name##_proc_fops = { \
+    .open     = name##_proc_open, \
+    .read     = seq_read, \
+    .llseek   = seq_lseek, \
+    .release  = single_release, \
+    .write    = write_proc \
+};
+
+#define DECLARE_PROCFS_READ_ENTRY(name, read_proc) \
+static int name##_proc_open(struct inode *inode, struct file *file) \
+{ \
+    return single_open(file, read_proc, PDE_DATA(inode)); \
+} \
+static const struct file_operations name##_proc_fops = { \
+    .open     = name##_proc_open, \
+    .read     = seq_read, \
+    .llseek   = seq_lseek, \
+    .release  = single_release, \
+};
+
+#define DECLARE_PROCFS_WRITE_ENTRY(name, write_proc) \
+static const struct file_operations name##_proc_fops = { \
+    .write    = write_proc \
+};
+
+#endif /* _LINUX_PROC_FS_MACROS_H */
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -40,6 +40,10 @@
 #include <linux/netdev_features.h>
 #include <net/flow_keys.h>
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
 /* Don't change this without changing skb_csum_unnecessary! */
 #define CHECKSUM_NONE 0
 #define CHECKSUM_UNNECESSARY 1
@@ -124,11 +128,12 @@ struct nf_conntrack {
 
 #ifdef CONFIG_BRIDGE_NETFILTER
 struct nf_bridge_info {
-	atomic_t		use;
-	unsigned int		mask;
-	struct net_device	*physindev;
-	struct net_device	*physoutdev;
-	unsigned long		data[32 / sizeof(unsigned long)];
+    atomic_t        use;
+    unsigned int        mask;
+    struct net_device   *physindev;
+    struct net_device   *physoutdev;
+    struct net_bridge_port *forward_port;
+    unsigned long       data[32 / sizeof(unsigned long)];
 };
 #endif
 
@@ -297,8 +302,10 @@ enum {
 /*
     return pointer to pp_packet_info struct within the skb
 */
-#ifdef CONFIG_TI_PACKET_PROCESSOR  
+#if PUMA7_OR_NEWER_SOC_TYPE
 #define SKB_GET_PP_INFO_P(skb)          (skb->pp_packet_info)
+#else
+#define SKB_GET_PP_INFO_P(skb)          (&skb->pp_packet_info)
 #endif 
 
 #endif /* CONFIG_TI_PACKET_PROCESSOR */
@@ -522,9 +529,9 @@ struct sk_buff {
 	struct nf_conntrack	*nfct;
 #endif
 #ifdef CONFIG_BRIDGE_NETFILTER
-	struct nf_bridge_info	*nf_bridge;
+    struct nf_bridge_info   *nf_bridge;
 #ifdef CONFIG_BRIDGE_EBT_FORWARD
-	struct net_bridge_port	*bridge_forward_port;
+    struct net_bridge_port  *bridge_forward_port;
 #endif
 #endif
 
@@ -587,12 +594,29 @@ struct sk_buff {
     __u16           mac_header;
 
 #ifdef CONFIG_TI_META_DATA
-    __u32   ti_meta_info;
-    __u32   ti_meta_info2;
+    unsigned int    ti_meta_info;
+    unsigned int    ti_meta_info2;
+#endif /* CONFIG_TI_META_DATA */
+#ifdef CONFIG_INTEL_NF_GWMETA_SUPPORT
+    __u32    ti_gw_meta;
 #endif /* CONFIG_TI_META_DATA */
 
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+    struct net_device   *ti_docsis_input_dev;
+#endif /* CONFIG_TI_DOCSIS_INPUT_DEV */
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+    int         docsis_icmp_iif;
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    unsigned long long   ti_selective_fwd_dev_info;
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 #ifdef CONFIG_TI_PACKET_PROCESSOR
+    #if PUMA7_OR_NEWER_SOC_TYPE
     PP_PACKET_INFO_t    *pp_packet_info;
+    #else
+    PP_PACKET_INFO_t    pp_packet_info;
+    #endif
+    __u16               vpid_vlan_tci;
 #endif  /* CONFIG_TI_PACKET_PROCESSOR */
 
     /* These elements must be at the end, see alloc_skb() for details.  */
--- a/include/linux/ti_hil.h
+++ b/include/linux/ti_hil.h
@@ -1,28 +1,25 @@
 /*
-  GPL LICENSE SUMMARY
-
-  Copyright(c) 2016 Intel Corporation.
-
-  This program is free software; you can redistribute it and/or modify
-  it under the terms of version 2 of the GNU General Public License as
-  published by the Free Software Foundation.
-
-  This program is distributed in the hope that it will be useful, but
-  WITHOUT ANY WARRANTY; without even the implied warranty of
-  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-  General Public License for more details.
-
-  You should have received a copy of the GNU General Public License
-  along with this program; if not, write to the Free Software
-  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
-  The full GNU General Public License is included in this distribution
-  in the file called LICENSE.GPL.
-
-  Contact Information:
-    Intel Corporation
-    2200 Mission College Blvd.
-    Santa Clara, CA  97052
-*/
+ * ti_hil.h - Header file for HIL
+ *
+ * Description:
+ *  This file contains structures and definitions that are used by the
+ *  HIL Framework.
+ *
+ * Copyright (C) <2008>, Texas Instruments, Incorporated
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
 
 #ifndef __TI_HIL_H__
 #define __TI_HIL_H__
@@ -39,10 +36,20 @@ struct hil_core_notifier_param
 };
 #endif /* CONFIG_APPCPU_GW_PP_HANDLE */
 
+#define TI_HIL_PACKET_FLAG_PP_SESSION_INGRESS_RECORDED          0x00000001
 #define TI_HIL_PACKET_FLAG_PP_SESSION_BYPASS                    0x00000002
 #define TI_HIL_PACKET_FLAG_PP_SESSION_DROP_OFFSET               24
 
 /**************************************************************************
+ ****************************** Module Identifers *************************
+ **************************************************************************/
+
+/* Module Identifers: These describe the module which generated the event. */
+#define TI_DEVICE   1
+#define TI_INET     2
+#define TI_PP       3
+
+/**************************************************************************
  **************************** PP Event Identifiers ************************
  **************************************************************************/
 
@@ -65,11 +72,11 @@ struct hil_core_notifier_param
 /* Event generated when an interface is removed from the bridge. */
 #define TI_BRIDGE_PORT_DELETE        (TI_BRIDGE_EVENT + 0x1)
 
-/* Event generated when an interface moves into the forwarding state.
+/* Event generated when an interface moves into the forwarding state. 
  * Note: The event needs to be handled only if the system support STP. */
 #define TI_BRIDGE_PORT_FORWARD       (TI_BRIDGE_EVENT + 0x2)
 
-/* Event generated when an interface is moved into the blocked state.
+/* Event generated when an interface is moved into the blocked state. 
  * Note: The event needs to be handled only if the system support STP. */
 #define TI_BRIDGE_PORT_DISABLED      (TI_BRIDGE_EVENT + 0x3)
 
@@ -120,9 +127,245 @@ struct hil_core_notifier_param
 #define TI_IP_DISCARD_PKT_IPV4   (TI_IP_EVENT + 0x1)
 #define TI_IP_DISCARD_PKT_IPV6   (TI_IP_EVENT + 0x2)
 
+/**************************************************************************
+ **************************** PP Routing Event Identifiers *****************
+ **************************************************************************/
+
+/* Base for all routing PP Event identifiers. */
+#define TI_ROUTE_EVENT              0x10
+
+/* Event generated when a route is added. */
+#define TI_ROUTE_ADDED              (TI_ROUTE_EVENT + 0x1)
+
+/* Event generated when a route is deleted. */
+#define TI_ROUTE_DELETED            (TI_ROUTE_EVENT + 0x2)
+
+/**************************************************************************
+ **************************** PP VLAN Event Identifiers *****************
+ **************************************************************************/
+
+/* Base for all VLAN PP Event identifiers. */
+#define TI_VLAN_EVENT               0x20
+
+/* Event generated when a VLAN device is created. */
+#define TI_VLAN_DEV_CREATED         (TI_VLAN_EVENT + 0x1)
+
+/* Event generated when a VLAN device is deleted. */
+#define TI_VLAN_DEV_DELETED         (TI_VLAN_EVENT + 0x2)
+
+
+/**************************************************************************
+ ********************* PP Connection Tracking Event Identifiers ***********
+ **************************************************************************/
+
+/* Base for all connection tracking PP Event identifiers. */
+#define TI_CT_EVENT                  0x30
+
+/* Event generated when a connection tracking entry has been created. */
+#define TI_CT_ENTRY_CREATED          (TI_CT_EVENT + 0x1)
+
+/* Event generated when a connection tracking entry has timed-out */
+#define TI_CT_DEATH_BY_TIMEOUT       (TI_CT_EVENT + 0x2)
+
+/* Event generated when a Netfilter table is being updated. */
+#define TI_CT_NETFILTER_TABLE_UPDATE (TI_CT_EVENT + 0x3)
+
+/* Event generated once Netfilter decides to drop the packet */
+#define TI_CT_NETFILTER_DISCARD_PKT  (TI_CT_EVENT + 0x4)
+
+/* Event generated once Netfilter decides to cancel drop acceleration */
+#define TI_CT_NETFILTER_CANCEL_DISCARD_ACCELERATION     (TI_CT_EVENT + 0x5)
+
+/* Event generated once Netfilter decides to delete a session */
+#define TI_CT_NETFILTER_DELETE_SESSION     (TI_CT_EVENT + 0x6)
+
+/**************************************************************************
+ ********************* PP Multicast Routing Event Identifiers *************
+ **************************************************************************/
+
+/* Base for all Multicast Routing PP Event identifiers. */
+#define TI_MFC_EVENT                  0x40
+
+/* Event generated when a multicast routing entry is created. */
+#define TI_MFC_ENTRY_CREATED          (TI_MFC_EVENT + 0x1)
+
+/* Event generated when a multicast routing entry is deleted. */
+#define TI_MFC_ENTRY_DELETED          (TI_MFC_EVENT + 0x2)
+
+#define TI_MC_SESSION_DELETED         (TI_MFC_EVENT + 0x3)
+
+/**************************************************************************
+ **************************** PP PPP Event Identifiers *****************
+ **************************************************************************/
+
+/* Base for all PPP PP Event identifiers. */
+#define TI_PPP_EVENT               0x50
+
+/* Event generated when a PPP interface is created. */
+#define TI_PPP_INTERFACE_CREATED    (TI_PPP_EVENT + 0x1)
+
+/* Event generated when a PPP interface is deleted. */
+#define TI_PPP_INTERFACE_SHUTDOWN   (TI_PPP_EVENT + 0x2)
+
+
+/**************************************************************************
+ ************************* PP DOCSIS Event Identifiers ********************
+ **************************************************************************/
+
+/* Base for all DOCSIS PP Event identifiers. */
+#define TI_DOCSIS_EVENT         0x60
+
+/* Event generated when DOCSIS Bridge decides to drop(filter) the packet */
+#define TI_DOCSIS_FLTR_DISCARD_PKT          (TI_DOCSIS_EVENT + 0x1)
+
+/* Event generated when a new filter rule is added */
+#define TI_DOCSIS_FLTR_ADD                  (TI_DOCSIS_EVENT + 0x2)
+
+/* Event generated when a filter rule is deleted */
+#define TI_DOCSIS_FLTR_DEL                  (TI_DOCSIS_EVENT + 0x3)
+
+/* Event generated when a filter rule is being changed */
+#define TI_DOCSIS_FLTR_CHG                  (TI_DOCSIS_EVENT + 0x4)
+
+/* Event generated when a new classifier rule is added */
+#define TI_DOCSIS_CLASSIFY_ADD              (TI_DOCSIS_EVENT + 0x5)
+
+/* Event generated when a classifier rule is deleted */
+#define TI_DOCSIS_CLASSIFY_DEL              (TI_DOCSIS_EVENT + 0x6)
+
+/* Event generated when a classifier rule is being changed */
+#define TI_DOCSIS_CLASSIFY_CHG              (TI_DOCSIS_EVENT + 0x7)
+
+/* Event generated when DSID encoding is being changed, added or deleted */
+#define TI_DOCSIS_DSID_CHG                  (TI_DOCSIS_EVENT + 0x8)
+
+/* Event generated when MCAST filter is deleted */
+#define TI_DOCSIS_MCAST_DEL                 (TI_DOCSIS_EVENT + 0x9)
+
+/* Event generated when need to delete sessions from PP */
+#define TI_DOCSIS_SESSIONS_DEL              (TI_DOCSIS_EVENT + 0xA)
+
+/* Event generated when need to delete voice sessions from PP */
+#define TI_DOCSIS_VOICE_SESSIONS_DEL        (TI_DOCSIS_EVENT + 0xB)
+
+
+
+/**************************************************************************
+ ************************* PP General Event Identifiers *******************
+ **************************************************************************/
+
+/* Base for all general PP Event identifiers. */
+#define TI_PP_GENERAL_EVENT         0x70
+/* Event generated when create vpid */
+#define TI_PP_ADD_VPID          (TI_PP_GENERAL_EVENT + 0x1)
+
+/* Event generated when remove vpid */
+#define TI_PP_REMOVE_VPID       (TI_PP_GENERAL_EVENT + 0x2)
+
+/* DOCSIS Packet processor start/delete session notification defines */
+#define TI_DOCSIS_PP_SESSION_TYPE_FORWARDING                    0x1
+#define TI_DOCSIS_PP_SESSION_TYPE_DISCARDING                    0x2
+
+typedef enum
+{
+    TUNNEL_TYPE_L2TPv3 = 0,
+    TUNNEL_TYPE_GRE_MPLS = 1
+} TUNNEL_TYPE_E;
+
+/**************************************************************************
+ ************************* PP IP Event Identifiers ************************
+ **************************************************************************/
+
+/* Base for all IP PP Event identifiers. */
+#define TI_IP_EVENT                 0x80
+
+/* Event generated for general packet drop */
+#define TI_IP_DISCARD_PKT_IPV4   (TI_IP_EVENT + 0x1)
+#define TI_IP_DISCARD_PKT_IPV6   (TI_IP_EVENT + 0x2)
+
+/**************************************************************************
+ **************************** HIL Profile Structures **********************
+ **************************************************************************/
+
+/* Prototype Declaration for the profile handler. */
+typedef int (*TI_PROFILE_HANDLER)(unsigned int module_id, unsigned long event_id, void* ptr);
+typedef int (*TI_PROFILE_INIT)(void);
+typedef int (*TI_PROFILE_DEINIT)(void);
+
+/**************************************************************************
+ * STRUCTURE NAME : TI_HIL_PROFILE
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The structure describes the HIL Profile.
+ **************************************************************************/
+typedef struct TI_HIL_PROFILE
+{
+    char*               name;
+    TI_PROFILE_INIT     profile_init;
+    TI_PROFILE_HANDLER  profile_handler;
+    TI_PROFILE_DEINIT   profile_deinit;
+}TI_HIL_PROFILE;
+
+/**************************************************************************
+ ********************* PP Multicast Routing Event param *************
+ **************************************************************************/
+struct pp_mr_param {
+	struct vif_device *vif_table;
+    struct mfc_cache *cache;
+};
+
+/**************************************************************************
+ **************************** HIL Core Exported API ***********************
+ **************************************************************************/
+#if defined(__KERNEL__)
+/* Initialization and Cleanup API */
+extern int ti_hil_initialize (void);
+
+/* Profile Management API */
+extern int ti_hil_register_profile (TI_HIL_PROFILE* ptr_profile);
+
+/* This is the API which is used for the event generation to the PP chain.
+ * This should only be used in the networking subsystem to generate events 
+ * which do not already exist and which are needed for the packet processor. 
+ * This is needed only if the packet processor has been built into the system. */
 #ifdef CONFIG_TI_PACKET_PROCESSOR
 extern int ti_hil_pp_event(unsigned long val, void *v);
+extern void ti_hil_clone_netdev_pp_info(struct net_device *newDev, struct net_device *origDev);
+
 #else
 #define ti_hil_pp_event(val, v)
+#define ti_hil_clone_netdev_pp_info(newDev, origDev)
 #endif /* CONFIG_TI_PACKET_PROCESSOR */
+
+#ifdef CONFIG_TI_PACKET_PROCESSOR_STATS
+/* DOCSIS Packet processor session notification API */
+typedef int (*TI_HIL_START_SESSION)(unsigned int sessionHandle, 
+                                    unsigned int sessionType,
+                                    struct sk_buff* skb);
+/* DOCSIS Packet processor delete session notification Callback */
+typedef int (*TI_HIL_DELETE_SESSION)(unsigned int sessionHandle, 
+                                     unsigned int sessionPacketsFw,
+									 unsigned long long sessionOcttestsFw);
+
+extern int ti_hil_register_start_session_notification(TI_HIL_START_SESSION ti_hil_start_session_notification);
+extern int ti_hil_unregister_start_session_notification(void);
+extern int ti_hil_register_delete_session_notification(TI_HIL_DELETE_SESSION ti_hil_delete_session_notification);
+extern int ti_hil_unregister_delete_session_notification(void);
+#endif /* CONFIG_TI_PACKET_PROCESSOR_STATS */
+
+#ifdef CONFIG_MACH_PUMA5
+/* Power Saving Mode (PSM) API */
+extern int ti_hil_enable_psm (void);
+extern int ti_hil_disable_psm (void);
+#endif /* CONFIG_MACH_PUMA5 */
+#ifdef CONFIG_INTEL_PP_TUNNEL_SUPPORT
+extern int ti_hil_set_tunnel_mode(unsigned char tunnelMode);
+extern int ti_hil_set_cm_mac_address(unsigned char *cmAddress);
+extern int ti_hil_create_tunnel(char *tunnelHeader, unsigned char tunnelHeaderLen, unsigned char l2L3HeaderLen,
+                         TUNNEL_TYPE_E tunnelType, unsigned char udpMode);
+extern int ti_hil_delete_tunnel(void);
+#endif /*CONFIG_INTEL_PP_TUNNEL_SUPPORT*/
+#endif /*KERNEL*/
 #endif /* __TI_HIL_H__ */
+
+
--- a/include/net/addrconf.h
+++ b/include/net/addrconf.h
@@ -84,6 +84,11 @@ int __ipv6_get_lladdr(struct inet6_dev *
 		      unsigned char banned_flags);
 int ipv6_get_lladdr(struct net_device *dev, struct in6_addr *addr,
 		    unsigned char banned_flags);
+#ifdef CONFIG_INTEL_NS_DEVICE_FILTER
+extern int intel_ipv6_ns_filter(struct net_device *dev,
+								struct in6_addr* dst_addr,
+								unsigned char banned_flags);
+#endif
 int ipv6_rcv_saddr_equal(const struct sock *sk, const struct sock *sk2);
 void addrconf_join_solict(struct net_device *dev, const struct in6_addr *addr);
 void addrconf_leave_solict(struct inet6_dev *idev, const struct in6_addr *addr);
--- a/include/net/ip.h
+++ b/include/net/ip.h
@@ -55,6 +55,9 @@ static inline unsigned int ip_hdrlen(con
 struct ipcm_cookie {
 	__be32			addr;
 	int			oif;
+#ifdef CONFIG_TI_META_DATA
+    unsigned int        ti_meta_info;
+#endif /* CONFIG_TI_META_DATA */
 	struct ip_options_rcu	*opt;
 	__u8			tx_flags;
 };
--- a/include/net/netfilter/nf_conntrack.h
+++ b/include/net/netfilter/nf_conntrack.h
@@ -25,7 +25,7 @@
 #include <net/netfilter/ipv6/nf_conntrack_icmpv6.h>
 #include <net/netfilter/nf_conntrack_tuple.h>
 
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR 
 /* Flag definitions that are carried in the PP status flag in the connection tracking
  *  * structure. */
 
@@ -115,6 +115,9 @@ struct nf_conn {
 #ifdef CONFIG_NET_NS
 	struct net *ct_net;
 #endif
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    int             ti_pp_status_flag;
+#endif
 
 #if defined(CONFIG_NETFILTER_XT_MATCH_LAYER7) || \
     defined(CONFIG_NETFILTER_XT_MATCH_LAYER7_MODULE)
@@ -131,7 +134,6 @@ struct nf_conn {
 		unsigned int app_data_len;
 	} layer7;
 #endif
-	int ti_pp_status_flag;
 #ifdef CONFIG_APPCPU_GW_PP_HANDLE
 	/*flag used to indicate ct client mrpc call in progress b/w ATOM/ARM */
 	int ct_tuple_arm_sync_wait;
--- a/include/net/netfilter/nf_conntrack_tuple.h
+++ b/include/net/netfilter/nf_conntrack_tuple.h
@@ -117,6 +117,25 @@ static inline void nf_ct_dump_tuple(cons
 /* Connections have two entries in the hash table: one for each way */
 struct nf_conntrack_tuple_hash {
 	struct hlist_nulls_node hnnode;
+
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+#define    TI_PP_SESSION_CT_IDLE            0xA000
+#define    TI_PP_SESSION_CT_TCP_UPDATE      0xB000
+#define IS_TI_PP_SESSION_CT_INVALID(s)      ((s) >= TI_PP_SESSION_CT_IDLE)
+#define IS_TI_PP_SESSION_CT_IDLE(s)         ((s) == TI_PP_SESSION_CT_IDLE)
+#else
+#define    TI_PP_SESSION_CT_IDLE            0x8000
+#define    TI_PP_SESSION_CT_TCP_UPDATE      0x4000
+#define IS_TI_PP_SESSION_CT_INVALID(s)      ((s) & 0xF000)
+#define IS_TI_PP_SESSION_CT_IDLE(s)         ((s) & TI_PP_SESSION_CT_IDLE)
+#endif
+
+    unsigned short        ti_pp_session_handle;
+    unsigned short        ti_pp_sessions_count;
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
+
 	struct nf_conntrack_tuple tuple;
 };
 
--- a/include/uapi/linux/in.h
+++ b/include/uapi/linux/in.h
@@ -100,6 +100,9 @@ struct in_addr {
 #define IP_PASSSEC	18
 #define IP_TRANSPARENT	19
 
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+#define TI_IP_PKTINFO	23
+#endif
 /* BSD compatibility */
 #define IP_RECVRETOPTS	IP_RETOPTS
 
@@ -110,6 +113,9 @@ struct in_addr {
 #define IP_MINTTL       21
 #define IP_NODEFRAG     22
 
+#ifdef CONFIG_TI_META_DATA
+#define TI_IP_META_DATA 18
+#endif /* CONFIG_TI_META_DATA */
 /* IP_MTU_DISCOVER values */
 #define IP_PMTUDISC_DONT		0	/* Never send DF frames */
 #define IP_PMTUDISC_WANT		1	/* Use per route hints	*/
@@ -202,6 +208,16 @@ struct in_pktinfo {
 	struct in_addr	ipi_spec_dst;
 	struct in_addr	ipi_addr;
 };
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+#ifndef TI_PKTINFO_STRUCT
+#define TI_PKTINFO_STRUCT
+struct ti_pktinfo
+{
+	int		ifcpe_side;
+    char    mac_addr[6];
+};
+#endif
+#endif
 
 /* Structure describing an Internet (IP) socket address. */
 #define __SOCK_SIZE__	16		/* sizeof(struct sockaddr)	*/
--- a/include/uapi/linux/in6.h
+++ b/include/uapi/linux/in6.h
@@ -288,4 +288,17 @@ enum {
  * ...
  * MRT6_MAX
  */
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+#define TI_IPV6_PKTINFO	81
+#endif
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+# ifndef TI_PKTINFO_STRUCT
+# define TI_PKTINFO_STRUCT
+struct ti_pktinfo
+{
+	int		ifcpe_side;
+    char    mac_addr[6];
+};
+# endif
+#endif
 #endif /* _UAPI_LINUX_IN6_H */
--- a/include/uapi/linux/mii.h
+++ b/include/uapi/linux/mii.h
@@ -8,6 +8,10 @@
 #ifndef _UAPI__LINUX_MII_H__
 #define _UAPI__LINUX_MII_H__
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
 #include <linux/types.h>
 #include <linux/ethtool.h>
 
--- a/include/uapi/linux/netfilter.h
+++ b/include/uapi/linux/netfilter.h
@@ -19,6 +19,9 @@
  * number or errno values. Not nice, but better than additional function
  * arguments. */
 #define NF_VERDICT_MASK 0x000000ff
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#define NF_VERDICT_FLAG_PP_BYPASS		0x00000100
+#endif  /* CONFIG_TI_PACKET_PROCESSOR */
 
 /* extra verdict flags have mask 0x0000ff00 */
 #define NF_VERDICT_FLAG_QUEUE_BYPASS	0x00008000
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -2547,6 +2547,7 @@ __alloc_pages_slowpath(gfp_t gfp_mask, u
 	 * too large.
 	 */
 	if (order >= MAX_ORDER) {
+        pr_err("TOMER: order=%d, MAX_ORDER=%d\n", order, MAX_ORDER);
 		WARN_ON_ONCE(!(gfp_mask & __GFP_NOWARN));
 		return NULL;
 	}
--- a/net/8021q/vlan.c
+++ b/net/8021q/vlan.c
@@ -37,6 +37,7 @@
 #include <asm/uaccess.h>
 
 #include <linux/if_vlan.h>
+#include <linux/ti_hil.h>
 #include "vlan.h"
 #include "vlanproc.h"
 
@@ -87,7 +88,9 @@ void unregister_vlan_dev(struct net_devi
 
 	vlan_info = rtnl_dereference(real_dev->vlan_info);
 	BUG_ON(!vlan_info);
-
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event(TI_VLAN_DEV_DELETED, (void *)dev);
+#endif //CONFIG_TI_PACKET_PROCESSOR
 	grp = &vlan_info->grp;
 
 	grp->nr_vlan_devs--;
@@ -272,7 +275,11 @@ static int register_vlan_device(struct n
 	err = register_vlan_dev(new_dev);
 	if (err < 0)
 		goto out_free_newdev;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_clone_netdev_pp_info(new_dev, real_dev);
 
+    ti_hil_pp_event(TI_VLAN_DEV_CREATED, (void *)new_dev);
+#endif
 	return 0;
 
 out_free_newdev:
--- a/net/8021q/vlan_core.c
+++ b/net/8021q/vlan_core.c
@@ -48,6 +48,16 @@ bool vlan_do_receive(struct sk_buff **sk
 	}
 
 	skb->priority = vlan_get_ingress_priority(vlan_dev, skb->vlan_tci);
+
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    /* 
+     * Need to save the vpid vlan_tci before it will erased
+     * We will use it later in the ingress hook to reproduce 
+     * the vlan_tci of the real internal vpid's Vlan. 
+     */
+    skb->vpid_vlan_tci = vlan_tx_tag_get(skb); 
+#endif
+
 	skb->vlan_tci = 0;
 
 	rx_stats = this_cpu_ptr(vlan_dev_priv(vlan_dev)->vlan_pcpu_stats);
--- a/net/8021q/vlan_dev.c
+++ b/net/8021q/vlan_dev.c
@@ -75,6 +75,12 @@ static inline u16
 vlan_dev_get_egress_qos_mask(struct net_device *dev, struct sk_buff *skb)
 #endif
 {
+#if defined(CONFIG_MACH_PUMA6)
+	return (VLAN_PRIO_MASK & (((u16)(skb->ti_meta_info)) << VLAN_PRIO_SHIFT));
+#elif defined(CONFIG_MACH_PUMA7)
+	return (VLAN_PRIO_MASK & (((u16)(skb->pp_packet_info->pp_session.priority)) << VLAN_PRIO_SHIFT));
+#elif defined(CONFIG_MACH_PUMA5)
+
 	struct vlan_priority_tci_mapping *mp;
 
 	smp_rmb(); /* coupled with smp_wmb() in vlan_dev_set_egress_priority() */
@@ -89,6 +95,9 @@ vlan_dev_get_egress_qos_mask(struct net_
 		mp = mp->next;
 	}
 	return 0;
+#else
+	#error Update required for target Puma SoC
+#endif
 }
 
 /*
--- a/net/Kconfig
+++ b/net/Kconfig
@@ -184,7 +184,7 @@ config BRIDGE_NETFILTER
 	bool "Bridged IP/ARP packets filtering"
 	depends on BRIDGE && NETFILTER && INET
 	depends on NETFILTER_ADVANCED
-	default y
+	default n
 	---help---
 	  Enabling this option will let arptables resp. iptables see bridged
 	  ARP resp. IP traffic. If you want a bridging firewall, you probably
@@ -349,6 +349,8 @@ source "net/rxrpc/Kconfig"
 config FIB_RULES
 	bool
 
+# TI Specific Networking Extensions
+source "net/ti.Kconfig"
 menuconfig WIRELESS
 	bool "Wireless"
 	depends on !S390
--- a/net/Makefile
+++ b/net/Makefile
@@ -73,3 +73,4 @@ obj-$(CONFIG_NFC)		+= nfc/
 obj-$(CONFIG_OPENVSWITCH)	+= openvswitch/
 obj-$(CONFIG_VSOCKETS)	+= vmw_vsock/
 obj-$(CONFIG_NET_MPLS_GSO)	+= mpls/
+obj-y				+= ti/pp/
--- a/net/bridge/Makefile
+++ b/net/bridge/Makefile
@@ -6,10 +6,13 @@ obj-$(CONFIG_BRIDGE) += bridge.o
 
 bridge-y	:= br.o br_device.o br_fdb.o br_forward.o br_if.o br_input.o \
 			br_ioctl.o br_notify.o br_stp.o br_stp_bpdu.o \
-			br_stp_if.o br_stp_timer.o br_netlink.o
+			br_stp_if.o br_stp_timer.o br_netlink.o ti_br_notify.o
 
 bridge-$(CONFIG_SYSFS) += br_sysfs_if.o br_sysfs_br.o
 
+bridge-$(CONFIG_TI_L2_SELECTIVE_FORWARDER) += ti_br_sf.o
+bridge-$(CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING) += ti_br_sph.o
+bridge-$(CONFIG_INTEL_L2VPN_L2CP_FORWARD) += intel_br_l2vpn.o
 bridge-$(CONFIG_BRIDGE_NETFILTER) += br_netfilter.o
 
 bridge-$(CONFIG_BRIDGE_IGMP_SNOOPING) += br_multicast.o br_mdb.o
--- a/net/bridge/br_device.c
+++ b/net/bridge/br_device.c
@@ -382,4 +382,7 @@ void br_dev_setup(struct net_device *dev
 	br_netfilter_rtable_init(br);
 	br_stp_timer_init(br);
 	br_multicast_init(br);
+#ifdef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING
+    br->selective_packet_handler = NULL;
+#endif /* CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING */
 }
--- a/net/bridge/br_fdb.c
+++ b/net/bridge/br_fdb.c
@@ -19,6 +19,7 @@
 #include <linux/times.h>
 #include <linux/netdevice.h>
 #include <linux/etherdevice.h>
+#include <linux/ti_hil.h>
 #include <linux/jhash.h>
 #include <linux/random.h>
 #include <linux/slab.h>
@@ -26,6 +27,9 @@
 #include <asm/unaligned.h>
 #include <linux/if_vlan.h>
 #include "br_private.h"
+#ifdef CONFIG_INTEL_MAX_BRIDGE_MACS_LIMIT
+static int fdb_insert_cnt = 0;
+#endif
 
 #if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
   #include <net/ppa_api.h>
@@ -95,6 +99,11 @@ static void fdb_delete(struct net_bridge
 	hlist_del_rcu(&f->hlist);
 	fdb_notify(br, f, RTM_DELNEIGH);
 	call_rcu(&f->rcu, fdb_rcu_free);
+#ifdef CONFIG_INTEL_MAX_BRIDGE_MACS_LIMIT
+	if (fdb_insert_cnt >= 1) {
+		fdb_insert_cnt--;
+	}
+#endif
 }
 
 void br_fdb_changeaddr(struct net_bridge_port *p, const unsigned char *newaddr)
@@ -208,7 +217,16 @@ void br_fdb_cleanup(unsigned long _data)
 				continue;
 			this_timer = f->updated + delay;
 			if (time_before_eq(this_timer, jiffies))
+			{
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+                if(!f->is_local)
+                    ti_hil_pp_event(TI_BRIDGE_FDB_DELETED, (void*)f);
+                if (!(f->ti_pp_fdb_status & TI_PP_FDB_ACTIVE))
 				fdb_delete(br, f);
+#else
+                    fdb_delete(br, f);
+#endif
+			}
 			else if (time_before(this_timer, next_timer))
 				next_timer = this_timer;
 		}
@@ -411,6 +429,12 @@ static struct net_bridge_fdb_entry *fdb_
 {
 	struct net_bridge_fdb_entry *fdb;
 
+#ifdef CONFIG_INTEL_MAX_BRIDGE_MACS_LIMIT
+    if (fdb_insert_cnt >= CONFIG_INTEL_MAX_BRIDGE_MACS) {
+        printk(KERN_WARNING "\n fdb_create reached max bridge macs limit \n");
+		return 0;
+    }
+#endif
 	fdb = kmem_cache_alloc(br_fdb_cache, GFP_ATOMIC);
 	if (fdb) {
 		memcpy(fdb->addr.addr, addr, ETH_ALEN);
@@ -419,7 +443,17 @@ static struct net_bridge_fdb_entry *fdb_
 		fdb->is_local = 0;
 		fdb->is_static = 0;
 		fdb->updated = fdb->used = jiffies;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+        fdb->ti_pp_fdb_status = TI_PP_FDB_INACTIVE;
+#endif
 		hlist_add_head_rcu(&fdb->hlist, head);
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+        if (!fdb->is_local)
+            ti_hil_pp_event(TI_BRIDGE_FDB_CREATED, (void *)fdb);
+#endif
+#ifdef CONFIG_INTEL_MAX_BRIDGE_MACS_LIMIT
+        fdb_insert_cnt++;
+#endif
 	}
 	return fdb;
 }
@@ -494,6 +528,9 @@ void br_fdb_update(struct net_bridge *br
 			/* fastpath: update of existing entry */
 			fdb->dst = source;
 			fdb->updated = jiffies;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+            ti_hil_pp_event(TI_BRIDGE_FDB_CREATED, (void *)fdb);
+#endif
 #if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
 	//update an existing bridge entry used from xrx500
         if ( ppa_hook_bridge_entry_add_fn != NULL && source->dev )
--- a/net/bridge/br_input.c
+++ b/net/bridge/br_input.c
@@ -20,6 +20,12 @@
 #include <linux/rculist.h>
 #include "br_private.h"
 
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+extern int ti_selective_packet_handler (struct sk_buff *skb);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
+#ifdef CONFIG_INTEL_L2VPN_L2CP_FORWARD
+extern int intel_l2vpn_packet_handler (struct sk_buff *skb, int *l2vpnRelate);
+#endif /* CONFIG_INTEL_L2VPN_L2CP_FORWARD */
 /* Hook for brouter */
 br_should_route_hook_t __rcu *br_should_route_hook __read_mostly;
 EXPORT_SYMBOL(br_should_route_hook);
@@ -128,6 +134,11 @@ int br_handle_frame_finish(struct sk_buf
 		skb2 = skb;
 		unicast = false;
 	} else if (is_multicast_ether_addr(dest)) {
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+        if (ti_selective_packet_handler(skb) != 0) {
+            goto out;
+		}
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 		mdst = br_mdb_get(br, skb, vid);
 		if ((mdst || BR_INPUT_SKB_CB_MROUTERS_ONLY(skb)) &&
 		    br_multicast_querier_exists(br, eth_hdr(skb))) {
@@ -154,8 +165,13 @@ int br_handle_frame_finish(struct sk_buf
 		if (dst) {
 			dst->used = jiffies;
 			br_forward(dst->dst, skb, skb2);
-		} else
+		} else {
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+			if (ti_selective_packet_handler(skb) != 0)
+				goto out;
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 			br_flood_forward(br, skb, skb2, unicast);
+		}
 	}
 
 	if (skb2)
@@ -193,6 +209,9 @@ rx_handler_result_t br_handle_frame(stru
 	const unsigned char *dest = eth_hdr(skb)->h_dest;
 	br_should_route_hook_t *rhook;
 
+#ifdef CONFIG_INTEL_L2VPN_L2CP_FORWARD
+        int l2vpnRelated = 0;
+#endif /* CONFIG_INTEL_L2VPN_L2CP_FORWARD */
 	if (unlikely(skb->pkt_type == PACKET_LOOPBACK))
 		return RX_HANDLER_PASS;
 
@@ -203,9 +222,28 @@ rx_handler_result_t br_handle_frame(stru
 	if (!skb)
 		return RX_HANDLER_CONSUMED;
 
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+	if(!skb->ti_docsis_input_dev) {
+		skb->ti_docsis_input_dev = skb->dev;
+	}
+#endif
 	p = br_port_get_rcu(skb->dev);
 
+	if (WARN(p == NULL, "%s - %d: br_port_get_rcu(skb->dev) returned NULL, dropping packet (dev == %s)", 
+	         __func__, __LINE__, skb->dev ? skb->dev->name : "NULL"))
+	{
+		goto drop;
+	}
 	if (unlikely(is_link_local_ether_addr(dest))) {
+#ifdef CONFIG_INTEL_L2VPN_L2CP_FORWARD
+        if (!intel_l2vpn_packet_handler(skb, &l2vpnRelated)) 
+        {
+            if (l2vpnRelated)
+            {
+                goto forward;
+            }
+        }
+#endif /* CONFIG_INTEL_L2VPN_L2CP_FORWARD */
 		/*
 		 * See IEEE 802.1D Table 7-10 Reserved addresses
 		 *
--- a/net/bridge/br_notify.c
+++ b/net/bridge/br_notify.c
@@ -23,6 +23,9 @@ struct notifier_block br_device_notifier
 	.notifier_call = br_device_event
 };
 
+#ifdef CONFIG_TI_UNMANAGED_BRIDGE
+extern int ti_unmanaged_bridge_handler (struct net_device *dev, unsigned long event);
+#endif /* CONFIG_TI_UNMANAGED_BRIDGE */
 /*
  * Handle changes in state of network devices enslaved to a bridge.
  *
@@ -36,6 +39,12 @@ static int br_device_event(struct notifi
 	struct net_bridge *br;
 	bool changed_addr;
 	int err;
+#ifdef CONFIG_TI_UNMANAGED_BRIDGE
+    if (ti_unmanaged_bridge_handler(dev, event) == 0)
+    {
+        return NOTIFY_DONE;
+    }
+#endif /* CONFIG_TI_UNMANAGED_BRIDGE */
 
 	/* register of bridge completed, add sysfs entries */
 	if ((dev->priv_flags & IFF_EBRIDGE) && event == NETDEV_REGISTER) {
--- a/net/bridge/br_private.h
+++ b/net/bridge/br_private.h
@@ -54,6 +54,10 @@ struct mac_addr
 	unsigned char	addr[6];
 };
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#define     TI_PP_FDB_INACTIVE      0x0
+#define     TI_PP_FDB_ACTIVE        0x1
+#endif //CONFIG_TI_PACKET_PROCESSOR
 struct br_ip
 {
 	union {
@@ -105,6 +109,10 @@ struct net_bridge_fdb_entry
 	unsigned char			is_local;
 	unsigned char			is_static;
 	__u16				vlan_id;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    int                 ti_pp_session_handle;
+    int                 ti_pp_fdb_status;
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 };
 
 struct net_bridge_port_group {
@@ -219,6 +227,15 @@ struct br_cpu_netstats {
 	struct u64_stats_sync	syncp;
 };
 
+#ifdef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING
+struct l2_sph
+{
+    int (*packet_handler)(struct sk_buff *skb);
+    int priority;
+    struct l2_sph *prev;
+    struct l2_sph *next;
+};
+#endif /* CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING */
 struct net_bridge
 {
 	spinlock_t			lock;
@@ -302,6 +319,12 @@ struct net_bridge
 	u8				vlan_enabled;
 	struct net_port_vlans __rcu	*vlan_info;
 #endif
+#ifdef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING
+    struct l2_sph    *selective_packet_handler;
+#endif /* CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING */
+#ifdef CONFIG_INTEL_L2VPN_L2CP_FORWARD
+    int (*l2vpn_packet_handler)(struct sk_buff *skb, int *l2vpnRelate);
+#endif
 };
 
 struct br_input_skb_cb {
--- /dev/null
+++ b/net/bridge/intel_br_l2vpn.c
@@ -0,0 +1,135 @@
+/* 
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2014 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify 
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but 
+  WITHOUT ANY WARRANTY; without even the implied warranty of 
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU 
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License 
+  along with this program; if not, write to the Free Software 
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution 
+  in the file called LICENSE.GPL.
+
+  Contact Information:
+    Intel Corporation
+    2200 Mission College Blvd.
+    Santa Clara, CA  97052
+*/
+
+/*
+ * intel_br_l2vpn.c
+ * Description:
+ * Intel L2VPN implementation
+ */
+
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+//#include <net/net_namespace.h>
+#include "br_private.h"
+
+
+/**************************************************************************
+ * FUNCTION NAME : intel_l2vpn_packet_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called from the bridge to verify if the packet is l2vpn l2vpn related.
+ *  If so, bridge will skip the special handling of link-local packets, and the handling 
+ *  will be done in docsis bridge
+ *    
+ * RETURNS       :
+ *  0   -   No packet handler. invoke default behavior 
+ *  ret -   Returns the return code passed by the registered functions
+ ***************************************************************************/
+int intel_l2vpn_packet_handler (struct sk_buff *skb, int *l2vpnRelate)
+{
+
+	struct net_bridge       *br;
+	struct net_bridge_port  *p;
+    struct l2_sph       *handle;
+ 
+    int                 ret = 0;
+	/* Get bridge port. */ 
+    if ((p = br_port_get_rcu(skb->dev)) == NULL) 
+    {       
+        return -1;
+    }
+    
+    /* Get  bridge is valid. */ 
+    if ((br = p->br) == NULL) 
+    {        
+        return -1;
+    }
+    if (br->l2vpn_packet_handler  == NULL)
+    {
+        return -1;
+
+    }
+    ret = br->l2vpn_packet_handler(skb, l2vpnRelate); 
+    
+}
+
+/**************************************************************************
+ * FUNCTION NAME : intel_register_l2vpn_packet_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers/Unregisters a l2vpn packet handler for a bridge.
+ *  
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int intel_register_l2vpn_packet_handler (char *br_name, int (*packet_handler)(struct sk_buff *skb, int *sfIndex, int *phsIndex, int *l2vpnRelate))
+{
+    struct net_bridge       *br;
+	struct net_device       *dev;
+	struct net_bridge_port  *p;
+
+    /* Check if device is valid. */ 
+    if ((dev = dev_get_by_name (&init_net, br_name)) == NULL)
+    {
+        printk ("Error: Device %s does not exist\n", br_name);
+        return -1;
+    }
+
+    /* Check if bridge port. */ 
+    if ((p = br_port_get_rcu(dev)) == NULL) 
+    {
+        printk ("Error: Bridge port %s does not exist\n", br_name);
+        return -1;
+    }
+    
+    /* Check if bridge is valid. */     
+    if ((br = p->br) == NULL) 
+    {
+        printk ("Error: Bridge %s does not exist\n", br_name);
+        return -1;
+    }
+
+    br->l2vpn_packet_handler = packet_handler; 
+
+    if (packet_handler)
+    {
+        printk ("DEBUG: Register l2vpn packet handler successful\n"); 
+    }
+    else
+    {
+        printk ("DEBUG: Unregister l2vpn packet handler successful\n"); 
+    }
+
+
+    return 0;
+}
+
+EXPORT_SYMBOL(intel_register_l2vpn_packet_handler); 
--- a/net/bridge/netfilter/Kconfig
+++ b/net/bridge/netfilter/Kconfig
@@ -181,6 +181,16 @@ config BRIDGE_EBT_FORWARD
 
 	  To compile it as a module, choose M here.  If unsure, say N.
 
+config BRIDGE_EBT_FORWARD
+	tristate "ebt: forward target support"
+	help
+	  This option adds the forward target, which allows bypassing the normal
+	  bridging logic and forcing an Ethernet frame to be forwarded to a specific
+	  device, as long as it is connected to the same bridge the frame
+	  arrived on.
+
+	  To compile it as a module, choose M here.  If unsure, say N.
+
 config BRIDGE_EBT_SNAT
 	tristate "ebt: snat target support"
 	help
--- /dev/null
+++ b/net/bridge/ti_br_notify.c
@@ -0,0 +1,77 @@
+/*
+ * ti_br_notify.c
+ * Description:
+ * TI unmanaged bridge implementation
+ *
+ *  Copyright (C) 2009 Texas Instruments Incorporated - http://www.ti.com/
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
+
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+
+#ifdef CONFIG_TI_UNMANAGED_BRIDGE
+
+/**************************************************************************
+ * FUNCTION NAME : ti_blackhole
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is the registered blackhole routine which swallows all
+ *  packets received from the bridge management interface before they reach 
+ *  the networking stacks.
+ *
+ * RETURNS       :
+ *  Always return -1 i.e. never pass the packet up the stack
+ ***************************************************************************/
+int ti_blackhole(struct sk_buff *skb)
+{       
+	kfree_skb(skb);
+    return -1;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_unmanaged_bridge_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  This function is registered with the device notifier and its function
+ *  is to detect if a bridged management interface has been bought up. If 
+ *  one is detected it blackholes the management interface
+ *
+ * RETURNS       :
+ *  0   - Bridged Management Interface; event has been processed.
+ *  1   - Process the event normally as Open Source...
+ ***************************************************************************/
+int ti_unmanaged_bridge_handler (struct net_device *dev, unsigned long event)
+{
+    /* Check if the interface is a bridged management interface? */
+    if ((dev->priv_flags & IFF_EBRIDGE) == 0)
+        return 1;
+
+    /* Check if the bridged management interface is being bought up? */
+    if (event == NETDEV_UP)
+    {
+        ti_register_protocol_handler (dev, ti_blackhole);
+        return 0;
+    }
+
+    /* All other events are handled as open source. */
+    return 1;
+}
+
+#endif /* CONFIG_TI_UNMANAGED_BRIDGE */
--- /dev/null
+++ b/net/bridge/ti_br_sf.c
@@ -0,0 +1,150 @@
+/*
+ * ti_br_sf.c
+ * Description:
+ * TI Selective forwarding implementation
+ *
+ *  Copyright (C) 2009 Texas Instruments Incorporated - http://www.ti.com/
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
+
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+#include "br_private.h"
+
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+
+#undef CONFIG_TI_L2_SELECTIVE_FORWARDER_DEBUG
+
+/**************************************************************************
+ *************************** Extern Data Structures ***********************
+ **************************************************************************/
+extern struct net_device *ti_netdevice[TI_MAX_DEVICE_INDEX];
+
+/**************************************************************************
+ * FUNCTION NAME : get_enabled_bit_count
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function counts the number of bits enabled. 
+ *
+ * RETURNS       :
+ *  Number of enabled bits 0 to 32 (max)
+ ***************************************************************************/
+static int get_enabled_bit_count(unsigned long long value)
+{
+    int count = 0;
+    while (value != 0)
+    {
+        value &= value - 1;
+        count ++;
+    }
+    return count;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_selective_forward
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function selectively forwards the packets on the interfaces that are 
+ *  marked. If the mark is zero, packet is flooded.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ *
+ ***************************************************************************/
+int ti_selective_forward(struct sk_buff *skb)
+{
+    if (!skb->ti_selective_fwd_dev_info)
+    {
+        /* Mark is zero. Return zero to flood the packet */
+        return 0;
+    }
+    else
+    {
+        unsigned long long  interface_list = skb->ti_selective_fwd_dev_info; 
+        unsigned int        dev_index = 0, count;
+        struct sk_buff      *skb2;
+        struct net_device   *dev = skb->dev;
+       
+        /* Get number of bits that are marked */ 
+        count = get_enabled_bit_count(interface_list);
+        
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    /* Check if the packet is about to be forwarded to single egress interface ONLY.
+       For all the cases of cloning make sure the BYPASS flag is set. */
+        if (1 != count)
+        {
+            SKB_GET_PP_INFO_P(skb)->flags |= TI_HIL_PACKET_FLAG_PP_SESSION_BYPASS;
+        }
+#endif
+
+        /* Iterate and forward the cloned packet on all interfaces that are marked */
+        while (interface_list)
+        {
+            if (interface_list & 0x1)
+            {
+                if (((dev = ti_netdevice[dev_index]) != NULL) && (br_port_get_rcu(dev) != NULL))
+                {
+                    if (count == 1)
+                        break;
+
+                    if ((skb2 = skb_clone(skb, GFP_ATOMIC)) != NULL)
+                    {
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER_DEBUG
+                        printk ("DEBUG Local Bridge: Forwarding Cloned multicast packet from (%s) to (%s) index (%d)\n", skb2->dev->name, dev->br_port->dev->name, dev_index+1);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER_DEBUG */
+                        br_forward(br_port_get_rcu(dev), skb2,NULL);
+                    }
+                    else
+                    {
+                        printk ( KERN_DEBUG "Local Bridge: SKB Clone failed. Freeing original packet\n");
+                        dev_kfree_skb_any(skb); 
+                        return -1;
+                    }
+                }
+                else
+                {    
+                    printk ( KERN_DEBUG "Local Bridge: Device info not found for device index (%d), info = 0x%llx\n", dev_index+1, skb->ti_selective_fwd_dev_info);
+                }
+                count--;
+            }
+            dev_index++;
+            interface_list >>= 1;
+        }
+        if ((dev != NULL) && (br_port_get_rcu(dev)!= NULL))
+        {
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER_DEBUG
+            printk (KERN_DEBUG "Local Bridge: Forwarding Original multicast packet from (%s) to (%s) index (%d)\n", skb->dev->name, dev->br_port->dev->name, dev_index+1);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER_DEBUG */
+
+            /* Send the original packet on the last interface */
+            br_forward(br_port_get_rcu(dev), skb,NULL);
+        }
+        else
+        {
+            dev_kfree_skb_any(skb);
+        }
+        return 1;
+    }
+}
+
+EXPORT_SYMBOL(ti_selective_forward);
+
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
+
--- /dev/null
+++ b/net/bridge/ti_br_sph.c
@@ -0,0 +1,275 @@
+/*
+ * ti_br_sph.c
+ * Description:
+ * TI Selective packet handler implementation
+ *
+ *  Copyright (C) 2009 Texas Instruments Incorporated - http://www.ti.com/
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
+
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+#include <net/net_namespace.h>
+#include "br_private.h"
+
+#ifdef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING
+
+#undef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING_DEBUG
+
+/**************************************************************************
+ * FUNCTION NAME : ti_selective_packet_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called from the bridge to selective handle packets.
+ *  The function calls all registered packet handler in the order of priority.
+ *  Currently only multicast and broadcast packets are handled selectively.
+ *  
+ * RETURNS       :
+ *  0   -   No packet handlers. invoke default behavior 
+ *  ret -   Returns the return code passed by the registered functions
+ *
+ * NOTES         :
+ *  In the case of error; the packet memory is freed by the registered handlers.
+ ***************************************************************************/
+int ti_selective_packet_handler (struct sk_buff *skb)
+{
+	struct net_bridge       *br;
+	struct net_bridge_port  *p;
+
+    struct l2_sph       *handle;
+ 
+    int                 ret = 0;
+
+	/* Get bridge port. */ 
+    if ((p = br_port_get_rcu(skb->dev)) == NULL) 
+    {       
+        return -1;
+    }
+    
+    /* Get  bridge is valid. */ 
+    if ((br = p->br) == NULL) 
+    {        
+        return -1;
+    }
+	handle = br->selective_packet_handler;
+    /* Check if packet handler is installed. If no packet handler is installed 
+     * return 0 to invoke default behavior i.e., flood the packet  */
+    if (handle == NULL)
+    {
+#ifdef CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING_DEBUG
+        printk ("No selective packet handler installed. Flooding packet\n"); 
+#endif /* CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING_DEBUG */
+        return ret;
+    }
+    /* Run all registered packet handlers. */
+    while (handle != NULL)
+    {
+        if ((ret = handle->packet_handler(skb)) == -1)
+        {
+            /* Incase of error packet memory is freed by the registered handler. */
+            printk ("Error running selective packet handler (%d)\n", ret);
+            break;
+        }
+        handle = handle->next;
+    }
+    return ret;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_register_selective_packet_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers a selective packet handler for a bridge.
+ *  
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_register_selective_packet_handler (char *br_name, int (*packet_handler)(struct sk_buff *skb), int priority)
+{
+    struct l2_sph           *handle, *temp, *next_node;
+	struct net_bridge       *br;
+	struct net_device       *dev;
+	struct net_bridge_port  *p;
+
+    /* Check if device is valid. */ 
+    if ((dev = dev_get_by_name (&init_net,br_name)) == NULL)
+    {
+        printk ("Error: Device %s does not exist\n", br_name);
+        return -1;
+    }
+
+    /* Check if bridge port. */ 
+    if ((p = br_port_get_rcu(dev)) == NULL) 
+    {
+        printk ("Error: Bridge port %s does not exist\n", br_name);
+        return -1;
+    }
+    
+    /* Check if bridge is valid. */ 
+    if ((br = p->br) == NULL) 
+    {
+        printk ("Error: Bridge %s does not exist\n", br_name);
+        return -1;
+    }
+
+    /* Allocate memory for packet handler. */
+    handle = (struct l2_sph *) kmalloc(sizeof(struct l2_sph), GFP_KERNEL);
+    if (handle == NULL)
+    {
+        printk ("Error: Failed to allocate memory for packet handler\n");
+        return -1;
+    }
+
+    handle->packet_handler = packet_handler;
+    handle->priority = priority;
+    handle->next = NULL;
+    handle->prev = NULL;
+
+    /* Install the handler */    
+    if (br->selective_packet_handler == NULL)
+        br->selective_packet_handler = handle;
+    else
+    {
+        temp = br->selective_packet_handler;
+        while (temp != NULL)
+        {  
+            if (temp->priority == priority)
+            {
+                printk ("Error: Packet handler with priority %d already exists\n", priority); 
+                kfree (handle);
+                return -1;
+            }
+            else if (temp->priority > priority)
+            {
+                if (temp->prev == NULL)
+                {
+                    br->selective_packet_handler = handle;
+                    temp->prev = handle;
+                    handle->next = temp;
+                }
+                else
+                {
+                    next_node = temp->next;
+                    if (next_node != NULL)
+                    {
+                        handle->next = next_node;
+                        next_node->prev = handle;
+                        handle->prev = temp;
+                        temp->next = handle;
+                    }
+                    else
+                    {
+                        handle->prev = temp;
+                        temp->next = handle;
+                    }
+                }
+                break;
+            }
+            else if (temp->next == NULL)
+            {
+                handle->prev = temp;
+                temp->next = handle;
+                break;
+            }
+            temp = temp->next;
+        }
+    }   
+    printk ("DEBUG: Register selective packet handler successful\n"); 
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_deregister_selective_packet_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the selective packet handler for a bridge
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_unregister_selective_packet_handler (char *br_name, int (*packet_handler)(struct sk_buff *skb), int priority)
+{
+	struct net_bridge       *br;
+	struct net_device       *dev;
+    struct l2_sph           *temp;
+   	struct net_bridge_port  *p;
+ 
+    if ((dev = dev_get_by_name (&init_net,br_name)) == NULL)
+    {
+        printk ("Error: Device %s does not exist\n", br_name);
+        return -1;
+    }
+
+    if ((p = br_port_get_rcu(dev)) == NULL) 
+    {
+        printk ("Error: Bridge port %s does not exist\n", br_name);
+        return -1;
+    }
+    
+    if ((br = p->br) == NULL) 
+    {
+        printk ("Error: Bridge %s does not exist\n", br_name);
+        return -1;
+    }
+
+    if (br->selective_packet_handler == NULL)
+    {
+        printk ("Error: Bridge %s has no selective packet handler installed\n", br->dev->name);
+        return -1;
+    }
+
+    /* Unregister the packet handler. */
+    temp = br->selective_packet_handler;
+    while (temp != NULL)
+    { 
+        if (temp->priority == priority)
+        {
+            if (temp->prev == NULL)
+            {
+                br->selective_packet_handler = temp->next;
+                if (temp->next != NULL)
+                    temp->next->prev = NULL;
+            }
+            else
+            {
+                if (temp->next == NULL)
+                    temp->prev->next = NULL;
+                else
+                {
+                    temp->prev->next = temp->next;
+                    temp->next->prev = temp->prev;
+                }
+            }
+            break;
+        }
+        temp = temp->next;
+    }
+
+    if (temp != NULL)
+        kfree (temp);
+    return 0;
+}
+
+EXPORT_SYMBOL(ti_register_selective_packet_handler); 
+EXPORT_SYMBOL(ti_unregister_selective_packet_handler);
+EXPORT_SYMBOL(ti_selective_packet_handler); 
+#endif /* CONFIG_TI_L2_SELECTIVE_PACKET_HANDLING */
+
--- a/net/core/Makefile
+++ b/net/core/Makefile
@@ -1,9 +1,6 @@
 #
 # Makefile for the Linux networking core.
 #
-ifeq ($(CONFIG_ARM_AVALANCHE_PDSP_PP),y)
-    ccflags-y += -DPUMA7_OR_NEWER_SOC_TYPE
-endif
 
 obj-y := sock.o request_sock.o skbuff.o iovec.o datagram.o stream.o scm.o \
 	 gen_stats.o gen_estimator.o net_namespace.o secure_seq.o flow_dissector.o
@@ -11,7 +8,7 @@ obj-y := sock.o request_sock.o skbuff.o
 obj-$(CONFIG_SYSCTL) += sysctl_net_core.o
 
 obj-y		     += dev.o ethtool.o dev_addr_lists.o dst.o netevent.o \
-			neighbour.o rtnetlink.o utils.o link_watch.o filter.o \
+			neighbour.o rtnetlink.o utils.o link_watch.o filter.o ti_dev.o \
 			dev_ioctl.o
 
 obj-$(CONFIG_SOCK_DIAG) += sock_diag.o
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -114,6 +114,7 @@
 #include <linux/dmaengine.h>
 #include <linux/err.h>
 #include <linux/ctype.h>
+#include <linux/ti_hil.h>
 #include <linux/if_arp.h>
 #include <linux/if_vlan.h>
 #include <linux/ip.h>
@@ -134,6 +135,10 @@
 
 #include "net-sysfs.h"
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
 /* Instead of increasing this, you should create a hash table. */
 #define MAX_GRO_SKBS 8
 
@@ -337,6 +342,25 @@ static inline void netdev_set_addr_lockd
 }
 #endif
 
+#ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
+extern int ti_protocol_handler (struct net_device* dev, struct sk_buff *skb);
+#endif
+#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
+extern int ti_dev_new_index(struct net *net);
+#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+extern void ti_save_netdevice_info(struct net_device *dev);
+extern void ti_free_netdevice_info(struct net_device *dev);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
+#ifdef CONFIG_TI_EGRESS_HOOK
+extern int ti_egress_hook_handler (struct net_device* dev, struct sk_buff *skb);
+#endif /* CONFIG_TI_EGRESS_HOOK */
+#ifdef CONFIG_TI_DOCSIS_EGRESS_HOOK
+extern int ti_docsis_egress_hook_handler (struct net_device* dev, struct sk_buff *skb);
+#endif /* CONFIG_TI_DOCSIS_EGRESS_HOOK */
+#ifdef CONFIG_TI_GW_EGRESS_HOOK
+extern int ti_gw_egress_hook_handler (struct net_device* dev, struct sk_buff *skb);
+#endif /* CONFIG_TI_GW_EGRESS_HOOK */
 /*******************************************************************************
 
 		Protocol management and registration routines
@@ -2840,6 +2864,22 @@ int dev_queue_xmit(struct sk_buff *skb)
 	struct Qdisc *q;
 	int rc = -ENOMEM;
 
+#ifdef CONFIG_TI_META_DATA_CONSOLE_DUMP
+    if (skb->ti_meta_info != 0x0)
+        printk ("Core Networking Device Layer: %s SKB 0x%p has META Data 0x%x\n", skb->dev->name, skb, skb->ti_meta_info);
+#endif /* CONFIG_TI_META_DATA_CONSOLE_DUMP */
+#ifdef CONFIG_TI_GW_EGRESS_HOOK
+    if (ti_gw_egress_hook_handler(dev, skb) < 0)
+       return rc;
+#endif /* CONFIG_TI_GW_EGRESS_HOOK */
+#ifdef CONFIG_TI_EGRESS_HOOK
+    if (ti_egress_hook_handler(dev, skb) < 0)
+       return rc;
+#endif /* CONFIG_TI_EGRESS_HOOK */
+#ifdef CONFIG_TI_DOCSIS_EGRESS_HOOK
+    if (ti_docsis_egress_hook_handler(dev, skb) < 0)
+       return rc;
+#endif /* CONFIG_TI_DOCSIS_EGRESS_HOOK */
 	skb_reset_mac_header(skb);
 
 	/* Disable soft irqs for various locks below. Also
@@ -3543,6 +3583,13 @@ static int __netif_receive_skb_core(stru
 	pt_prev = NULL;
 
 another_round:
+#ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
+    if (ti_protocol_handler (skb->dev, skb) < 0)
+    {
+        ret = NET_RX_SUCCESS;
+		goto unlock;
+    }
+#endif /* CONFIG_TI_DEVICE_PROTOCOL_HANDLING */
 	skb->skb_iif = skb->dev->ifindex;
 
 	__this_cpu_inc(softnet_data.processed);
@@ -5293,6 +5340,9 @@ EXPORT_SYMBOL(dev_get_phys_port_id);
  */
 static int dev_new_index(struct net *net)
 {
+#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
+    return (ti_dev_new_index(net));
+#else
 	int ifindex = net->ifindex;
 	for (;;) {
 		if (++ifindex <= 0)
@@ -5300,6 +5350,7 @@ static int dev_new_index(struct net *net
 		if (!__dev_get_by_index(net, ifindex))
 			return net->ifindex = ifindex;
 	}
+#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
 }
 
 /* Delayed registration/unregisteration */
@@ -5679,8 +5730,16 @@ int register_netdevice(struct net_device
 	}
 
 	ret = -EBUSY;
-	if (!dev->ifindex)
+	if (!dev->ifindex) {
 		dev->ifindex = dev_new_index(net);
+#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
+		if (dev->ifindex == -1)
+		{
+			ret = -EINVAL;
+			goto err_uninit;
+		}
+#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
+	}
 	else if (__dev_get_by_index(net, dev->ifindex))
 		goto err_uninit;
 
@@ -5733,6 +5792,9 @@ int register_netdevice(struct net_device
 
 	dev_init_scheduler(dev);
 	dev_hold(dev);
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    ti_save_netdevice_info(dev);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 	list_netdevice(dev);
 	add_device_randomness(dev->dev_addr, dev->addr_len);
 
@@ -6132,6 +6194,18 @@ struct net_device *alloc_netdev_mqs(int
 	INIT_LIST_HEAD(&dev->upper_dev_list);
 	INIT_LIST_HEAD(&dev->lower_dev_list);
 	dev->priv_flags = IFF_XMIT_DST_RELEASE;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    dev->pid_handle     = -1;
+    dev->vpid_handle    = -1;
+    memset ((void *)&dev->vpid_block, 0xFF, sizeof(dev->vpid_block));
+    dev->vpid_block.qos_clusters_count = 0;
+#ifdef CONFIG_MACH_PUMA5
+    dev->vpid_block.priv_vpid_flags = 0;
+#else
+    dev->vpid_block.flags = 0;
+#endif
+    dev->qos_virtual_scheme_idx = NETDEV_PP_QOS_PROFILE_DEFAULT;
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 	setup(dev);
 
 	dev->num_tx_queues = txqs;
@@ -6245,6 +6319,9 @@ EXPORT_SYMBOL(synchronize_net);
 void unregister_netdevice_queue(struct net_device *dev, struct list_head *head)
 {
 	ASSERT_RTNL();
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    ti_free_netdevice_info(dev);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 
 	if (head) {
 		list_move_tail(&dev->unreg_list, head);
@@ -6777,6 +6854,27 @@ static int __init net_dev_init(void)
 	if (register_pernet_subsys(&netdev_net_ops))
 		goto out;
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    if (ti_hil_initialize() < 0)
+    {
+        printk ("Error: Unable to initialize the HIL Core\n");
+        return -1;
+    }
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
+#ifdef CONFIG_TI_HIL_PROFILE_INTRUSIVE
+    {
+        extern TI_HIL_PROFILE hil_intrusive_profile;
+        if (ti_hil_register_profile(&hil_intrusive_profile) < 0)
+            return -1;
+    }
+#endif /* CONFIG_TI_HIL_PROFILE_INTRUSIVE */
+#ifdef CONFIG_TI_HIL_PROFILE_STATIC
+    {
+        extern TI_HIL_PROFILE hil_static_profile;
+        if (ti_hil_register_profile(&hil_static_profile) < 0)
+            return -1;
+    }
+#endif /* CONFIG_TI_HIL_PROFILE_STATIC */
 	/*
 	 *	Initialise the packet receive queues.
 	 */
--- a/net/core/neighbour.c
+++ b/net/core/neighbour.c
@@ -764,6 +764,8 @@ static void neigh_periodic_work(struct w
 	nht = rcu_dereference_protected(tbl->nht,
 					lockdep_is_held(&tbl->lock));
 
+	if (atomic_read(&tbl->entries) < tbl->gc_thresh1)
+		goto out;
 	/*
 	 *	periodically recompute ReachableTime from random function
 	 */
@@ -776,8 +778,6 @@ static void neigh_periodic_work(struct w
 				neigh_rand_reach_time(p->base_reachable_time);
 	}
 
-	if (atomic_read(&tbl->entries) < tbl->gc_thresh1)
-		goto out;
 
 	for (i = 0 ; i < (1 << nht->hash_shift); i++) {
 		np = &nht->hash_buckets[i];
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -86,6 +86,20 @@
 #include <trace/events/skb.h>
 #include <linux/highmem.h>
 
+#ifndef CONFIG_ARM_AVALANCHE_SOC
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+#define DBRIDGE_IFINDEX_CHK(__ifindex, format, args...) \
+{ \
+    if (((__ifindex) < 0) || ((__ifindex) >= TI_MAX_DEVICE_INDEX)) \
+    { \
+        printk("\n===>>> %s - %d: Currupt " #__ifindex " - %d\n" format, __func__, __LINE__, __ifindex, ##args); \
+        BUG(); \
+    } \
+}
+#endif
 
 int skb_init_intel(struct sk_buff *skb);
 struct kmem_cache *skbuff_head_cache __read_mostly;
@@ -264,6 +278,18 @@ int skb_init_intel(struct sk_buff *skb)
     skb->ti_meta_info = 0;
     skb->ti_meta_info2= 0;
 #endif /* CONFIG_TI_META_DATA */
+#ifdef CONFIG_INTEL_NF_GWMETA_SUPPORT
+    skb->ti_gw_meta= 0;
+#endif /* INTEL_NF_GWMETA_SUPPORT */
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+    skb->ti_docsis_input_dev = NULL;
+#endif /* CONFIG_TI_DOCSIS_INPUT_DEV */
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+    skb->docsis_icmp_iif = 0;
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    skb->ti_selective_fwd_dev_info = 0;
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 
 #ifdef CONFIG_TI_PACKET_PROCESSOR
     memset((void *)SKB_GET_PP_INFO_P(skb), 0, sizeof(*SKB_GET_PP_INFO_P(skb)));
@@ -943,6 +969,19 @@ static struct sk_buff *__skb_clone(struc
     C(ti_meta_info);
     C(ti_meta_info2);
 #endif /* CONFIG_TI_META_DATA */
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+    C(ti_docsis_input_dev);
+    if (n->ti_docsis_input_dev)
+    {
+        DBRIDGE_IFINDEX_CHK(n->ti_docsis_input_dev->ifindex, "dev %p, devname %s, ti_docsis_input_dev %p, ti_docsis_input_dev->name %s", n->dev, n->dev ? n->dev->name : NULL, n->ti_docsis_input_dev, n->ti_docsis_input_dev->name);
+    }
+#endif /* CONFIG_TI_DOCSIS_INPUT_DEV */
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+    C(docsis_icmp_iif);
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    C(ti_selective_fwd_dev_info);
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 #ifdef CONFIG_TI_PACKET_PROCESSOR
 memcpy((void *)SKB_GET_PP_INFO_P(n), (void *)SKB_GET_PP_INFO_P(skb), sizeof(*SKB_GET_PP_INFO_P(skb)));
 #ifdef PPP_DEBUG
@@ -1110,6 +1149,22 @@ static void copy_skb_header(struct sk_bu
     new->ti_meta_info = old->ti_meta_info;
     new->ti_meta_info2 = old->ti_meta_info2;
 #endif /* CONFIG_TI_META_DATA */
+#ifdef CONFIG_INTEL_NF_GWMETA_SUPPORT
+    new->ti_gw_meta = old->ti_gw_meta;
+#endif /* INTEL_NF_GWMETA_SUPPORT */
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+    new->ti_docsis_input_dev = old->ti_docsis_input_dev ;
+    if (new->ti_docsis_input_dev)
+    {
+        DBRIDGE_IFINDEX_CHK(new->ti_docsis_input_dev->ifindex, "dev %p, devname %s, ti_docsis_input_dev %p, ti_docsis_input_dev->name %s", new->dev, new->dev ? new->dev->name : NULL, new->ti_docsis_input_dev, new->ti_docsis_input_dev->name);
+    }
+#endif /* CONFIG_TI_DOCSIS_INPUT_DEV */
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+    new->docsis_icmp_iif = old->docsis_icmp_iif;
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    new->ti_selective_fwd_dev_info = old->ti_selective_fwd_dev_info;
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
 #ifdef CONFIG_TI_PACKET_PROCESSOR
     memcpy((void *)SKB_GET_PP_INFO_P(new), (void *)SKB_GET_PP_INFO_P(old), sizeof(*SKB_GET_PP_INFO_P(old)));
 #ifdef PPP_DEBUG
--- /dev/null
+++ b/net/core/ti_dev.c
@@ -0,0 +1,513 @@
+/*
+ * ti_dev.c
+ * Description:
+ * TI network device implementation
+ *
+ *  Copyright (C) 2009 Texas Instruments Incorporated - http://www.ti.com/
+ *
+ *  This program is free software; you can distribute it and/or modify it
+ *  under the terms of the GNU General Public License (Version 2) as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope it will be useful, but WITHOUT
+ *  ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ *  FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+ *  for more details.
+ *
+ *  You should have received a copy of the GNU General Public License along
+ *  with this program; if not, write to the Free Software Foundation, Inc.,
+ *  59 Temple Place - Suite 330, Boston MA 02111-1307, USA.
+ */
+
+#include <linux/bitops.h>
+#include <linux/cpu.h>
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/skbuff.h>
+#include <linux/if_vlan.h>
+#include <net/sock.h>
+#include <net/ip.h>
+#include <net/dsfield.h>
+#include <linux/udp.h>
+
+#ifdef CONFIG_TI_DEVICE_PROTOCOL_HANDLING
+
+/**************************************************************************
+ * FUNCTION NAME : ti_protocol_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called before the packet is passed to the networking 
+ *  stacks so that any custom protocol handling can be done. 
+ *
+ * RETURNS       :
+ *  0   -   Packet can be passed up the NET stack
+ *  <0  -   The packet should NOT be passed up the networking stack
+ *
+ * NOTES         :
+ *  In the case of error; it is the responsibility of the registered packet
+ *  handler to clean memory.
+ ***************************************************************************/
+int ti_protocol_handler (struct net_device* dev, struct sk_buff *skb)
+{
+    /* Check if there is a packet handler installed on the device or not? */
+    if (dev->packet_handler == NULL)
+        return 0;
+
+    /* Pass the control to the packet handler. */
+    return dev->packet_handler(skb);
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_register_protocol_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers a packet handler which passes all the received
+ *  packets to the packet handler for the device.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_register_protocol_handler (struct net_device* dev, int (*packet_handler)(struct sk_buff *skb))
+{
+    if (dev->packet_handler != NULL)
+    {
+        printk ("Info: Device %s already has a packet handler 0x%p installed\n", dev->name, dev->packet_handler);
+        return -1;
+    }
+
+    /* Register the packet handler. */
+    dev->packet_handler = packet_handler;
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_deregister_protocol_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the packet handler
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_deregister_protocol_handler (struct net_device* dev)
+{
+    if (dev->packet_handler == NULL)
+    {
+        printk ("Info: Device %s has no packet handler installed\n", dev->name);
+        return -1;
+    }
+
+    /* Register the packet handler. */
+    dev->packet_handler = NULL;
+    return 0;
+}
+
+
+EXPORT_SYMBOL(ti_register_protocol_handler); 
+EXPORT_SYMBOL(ti_deregister_protocol_handler);
+
+#endif /* CONFIG_TI_DEVICE_PROTOCOL_HANDLING */
+
+
+#ifdef CONFIG_INTEL_NS_DEVICE_FILTER
+/**************************************************************************
+ * FUNCTION NAME : intel_ns_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function calls the ns_handler function of the device
+ *
+ * RETURNS       :
+ *  0   -   drop
+ *  1  -   accept
+ ***************************************************************************/
+ 
+int intel_ns_handler (struct net_device *dev,struct	in6_addr* dst_addr,unsigned char banned_flags)
+{
+    if (dev->ns_handler == NULL)
+        return 1;
+
+    return dev->ns_handler(dev,dst_addr,banned_flags);
+}
+
+
+/**************************************************************************
+ * FUNCTION NAME : intel_register_ns_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers a neighbour solicitation handler which passes all the received
+ *  packets to the ns handler for the device.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int intel_register_ns_handler (struct net_device* dev, int (*ns_handler)(struct net_device *dev,struct	in6_addr* dst_addr,unsigned char banned_flags))
+{
+    if (dev->ns_handler != NULL)
+    {
+        printk ("Info: Device %s already has a packet handler 0x%p installed\n", dev->name, dev->ns_handler);
+        return -1;
+    }
+
+    /* Register the packet handler. */
+    dev->ns_handler = ns_handler;
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : intel_deregister_ns_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the ns handler
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int intel_deregister_ns_handler (struct net_device* dev)
+{
+    if (dev->ns_handler == NULL)
+    {
+        printk ("KERN_INFO : Device %s has no packet handler installed\n", dev->name);
+        return -1;
+    }
+
+    /* Register the packet handler. */
+    dev->ns_handler = NULL;
+    return 0;
+}
+
+EXPORT_SYMBOL(intel_register_ns_handler); 
+EXPORT_SYMBOL(intel_deregister_ns_handler);
+EXPORT_SYMBOL(intel_ns_handler);
+#endif
+
+
+
+
+#ifdef CONFIG_TI_DEVICE_INDEX_REUSE
+
+/**************************************************************************
+ * FUNCTION NAME : ti_dev_new_index
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called to allocate a new unique device index. The maximum 
+ *  number of device index is 64
+ *  stacks so that any custom protocol handling can be done. 
+ *
+ * RETURNS       :
+ *  >0  -   Allocated device index
+ *  -1  -   No free device Index. 
+ *
+ * NOTES         :
+ *  In the case of error; The netdevice_register() function should 
+ *          handle the error condition and return error
+ ***************************************************************************/
+int ti_dev_new_index(struct net *net)
+{
+	int ifindex = 0;
+
+    while (ifindex++ < TI_MAX_DEVICE_INDEX)
+    {
+		if (!__dev_get_by_index(net,ifindex))
+			return ifindex;
+	}
+    printk ("Error: Failed to allocate netdevice index\n");
+    return -1;
+}
+#endif /* CONFIG_TI_DEVICE_INDEX_REUSE */
+
+
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+
+/**************************************************************************
+ *************************** Global Definitions ***************************
+ **************************************************************************/
+/* Global array used to store the net device info. Max is 32 devices */
+struct  net_device  *ti_netdevice[TI_MAX_DEVICE_INDEX];
+
+/**************************************************************************
+ * FUNCTION NAME : ti_save_netdevice_info
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function saves the net_device pointer in the global array. Called by 
+ *  register_netdevice() function
+ *
+ * RETURNS       :
+ *  None
+ *
+ * NOTES         :
+ *  The device index is 1 based and the array access is zero based
+ ***************************************************************************/
+void ti_save_netdevice_info(struct net_device *dev)
+{
+    if (dev != NULL)
+        ti_netdevice[dev->ifindex - 1] = dev;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_free_netdevice_info
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function free the net_device pointer stored in the global array. 
+ *  Called by unregister_netdevice() function
+ *
+ * RETURNS       :
+ *  None
+ *
+ * NOTES         :
+ *  The device index is 1 based and the array access is zero based
+ ***************************************************************************/
+void ti_free_netdevice_info(struct net_device *dev)
+{
+    if (dev != NULL)
+        ti_netdevice[dev->ifindex - 1] = NULL;
+}
+
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
+
+
+#ifdef CONFIG_TI_EGRESS_HOOK
+
+/**************************************************************************
+ * FUNCTION NAME : ti_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called before the packet is passed to the driver for
+ *  transmission. 
+ *
+ * RETURNS       :
+ *  0   -   Packet can be passed to the driver.
+ *  <0  -   The packet should NOT be passed to the driver.
+ *
+ * NOTES         :
+ *  If the hook does not want the packet to be passed to the driver it
+ *  is the responsibility of the hook to clean the packet memory.
+ ***************************************************************************/
+int ti_egress_hook_handler (struct net_device* dev, struct sk_buff *skb)
+{
+    /* Check if there is an egress hook installed on the device or not? */
+    if (dev->egress_hook == NULL)
+        return 0;
+
+    /* Pass the control to the egress hook */
+    return dev->egress_hook(skb);
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_register_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers an egress hook which is attached to a networking
+ *  device. 
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_register_egress_hook_handler (struct net_device* dev, int (*egress_hook)(struct sk_buff *skb))
+{
+    /* Check if an egress hook is already attached. */
+    if (dev->egress_hook != NULL)
+    {
+        printk ("Info: Device %s already has an egress hook 0x%p installed\n", dev->name, dev->egress_hook);
+        return -1;
+    }
+
+    /* Register the egress hook. */
+    dev->egress_hook = egress_hook;
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_deregister_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the egress hook.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_deregister_egress_hook_handler (struct net_device* dev)
+{
+    if (dev->egress_hook == NULL)
+    {
+        printk ("Info: Device %s has no egress hook installed\n", dev->name);
+        return -1;
+    }
+
+    /* De-register the egress hook. */
+    dev->egress_hook = NULL;
+    return 0;
+}
+
+EXPORT_SYMBOL(ti_register_egress_hook_handler); 
+EXPORT_SYMBOL(ti_deregister_egress_hook_handler);
+EXPORT_SYMBOL(ti_protocol_handler); 
+
+#endif /* CONFIG_TI_EGRESS_HOOK */
+
+#ifdef CONFIG_TI_DOCSIS_EGRESS_HOOK
+
+/**************************************************************************
+ * FUNCTION NAME : ti_docsis_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called before the packet is passed to the driver for
+ *  transmission. 
+ *
+ * RETURNS       :
+ *  0   -   Packet can be passed to the driver.
+ *  <0  -   The packet should NOT be passed to the driver.
+ *
+ * NOTES         :
+ *  If the hook does not want the packet to be passed to the driver it
+ *  is the responsibility of the hook to clean the packet memory.
+ ***************************************************************************/
+int ti_docsis_egress_hook_handler (struct net_device* dev, struct sk_buff *skb)
+{
+    /* Check if there is an egress hook installed on the device or not? */
+    if (dev->docsis_egress_hook == NULL)
+        return 0;
+
+    /* Pass the control to the egress hook */
+    return dev->docsis_egress_hook(skb);
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_register_docsis_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers an egress hook which is attached to a networking
+ *  device. 
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_register_docsis_egress_hook_handler (struct net_device* dev, int (*docsis_egress_hook)(struct sk_buff *skb))
+{
+    /* Check if an egress hook is already attached. */
+    if (dev->docsis_egress_hook != NULL)
+    {
+        printk ("Error: Device %s has an egress hook 0x%p installed\n", dev->name, dev->docsis_egress_hook);
+        return -1;
+    }
+
+    /* Register the egress hook. */
+    dev->docsis_egress_hook = docsis_egress_hook;
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_deregister_docsis_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the egress hook.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_deregister_docsis_egress_hook_handler (struct net_device* dev)
+{
+    if (dev->docsis_egress_hook == NULL)
+    {
+        printk ("Error: Device %s has no egress hook installed\n", dev->name);
+        return -1;
+    }
+
+    /* De-register the egress hook. */
+    dev->docsis_egress_hook = NULL;
+    return 0;
+}
+
+EXPORT_SYMBOL(ti_register_docsis_egress_hook_handler); 
+EXPORT_SYMBOL(ti_deregister_docsis_egress_hook_handler);
+
+#endif /* CONFIG_TI_DOCSIS_EGRESS_HOOK */
+
+#ifdef CONFIG_TI_GW_EGRESS_HOOK
+
+/**************************************************************************
+ * FUNCTION NAME : ti_gw_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is called before the packet is passed to the driver for
+ *  transmission. 
+ *
+ * RETURNS       :
+ *  0   -   Packet can be passed to the driver.
+ *  <0  -   The packet should NOT be passed to the driver.
+ *
+ * NOTES         :
+ *  If the hook does not want the packet to be passed to the driver it
+ *  is the responsibility of the hook to clean the packet memory.
+ ***************************************************************************/
+int ti_gw_egress_hook_handler (struct net_device* dev, struct sk_buff *skb)
+{
+    /* Check if there is an egress hook installed on the device or not? */
+    if (dev->gw_egress_hook == NULL)
+        return 0;
+
+    /* Pass the control to the egress hook */
+    return dev->gw_egress_hook(skb);
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_register_gw_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function registers an egress hook which is attached to a networking
+ *  device. 
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_register_gw_egress_hook_handler (struct net_device* dev, int (*gw_egress_hook)(struct sk_buff *skb))
+{
+    /* Check if an egress hook is already attached. */
+    if (dev->gw_egress_hook != NULL)
+    {
+        printk ("Error: Device %s has an egress hook 0x%p installed\n", dev->name, dev->gw_egress_hook);
+        return -1;
+    }
+	
+    /* Register the egress hook. */
+    dev->gw_egress_hook = gw_egress_hook;
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_deregister_gw_egress_hook_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function deregisters the egress hook.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ ***************************************************************************/
+int ti_deregister_gw_egress_hook_handler (struct net_device* dev)
+{
+    if (dev->gw_egress_hook == NULL)
+    {
+        printk ("Error: Device %s has no egress hook installed\n", dev->name);
+        return -1;
+    }
+
+    /* De-register the egress hook. */
+    dev->gw_egress_hook = NULL;
+    return 0;
+}
+
+EXPORT_SYMBOL(ti_register_gw_egress_hook_handler); 
+EXPORT_SYMBOL(ti_deregister_gw_egress_hook_handler);
+
+#endif /* CONFIG_TI_GW_EGRESS_HOOK */
+
--- a/net/ipv4/fib_trie.c
+++ b/net/ipv4/fib_trie.c
@@ -79,6 +79,7 @@
 #include <net/tcp.h>
 #include <net/sock.h>
 #include <net/ip_fib.h>
+#include <linux/ti_hil.h>
 #include "fib_lookup.h"
 
 #define MAX_STAT_DEPTH 32
@@ -1322,6 +1323,9 @@ int fib_table_insert(struct fib_table *t
 			  (fa ? &fa->fa_list : fa_head));
 
 	rt_cache_flush(cfg->fc_nlinfo.nl_net);
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event(TI_ROUTE_ADDED, (void *)new_fa);
+#endif //CONFIG_TI_PACKET_PROCESSOR
 	rtmsg_fib(RTM_NEWROUTE, htonl(key), new_fa, plen, tb->tb_id,
 		  &cfg->fc_nlinfo, 0);
 succeeded:
@@ -1681,6 +1685,9 @@ int fib_table_delete(struct fib_table *t
 		return -ESRCH;
 
 	fa = fa_to_delete;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event(TI_ROUTE_DELETED, (void *)fa);
+#endif // CONFIG_TI_PACKET_PROCESSOR
 	rtmsg_fib(RTM_DELROUTE, htonl(key), fa, plen, tb->tb_id,
 		  &cfg->fc_nlinfo, 0);
 
--- a/net/ipv4/icmp.c
+++ b/net/ipv4/icmp.c
@@ -350,6 +350,9 @@ static void icmp_reply(struct icmp_bxm *
 
 	inet->tos = ip_hdr(skb)->tos;
 	daddr = ipc.addr = ip_hdr(skb)->saddr;
+#ifdef CONFIG_TI_META_DATA
+    ipc.ti_meta_info = 0;
+#endif
 	saddr = fib_compute_spec_dst(skb);
 	ipc.opt = NULL;
 	ipc.tx_flags = 0;
@@ -363,6 +366,10 @@ static void icmp_reply(struct icmp_bxm *
 	fl4.saddr = saddr;
 	fl4.flowi4_tos = RT_TOS(ip_hdr(skb)->tos);
 	fl4.flowi4_proto = IPPROTO_ICMP;
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+	if(skb->docsis_icmp_iif)
+		fl4.flowi4_oif = skb->docsis_icmp_iif,
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
 	security_skb_classify_flow(skb, flowi4_to_flowi(&fl4));
 	rt = ip_route_output_key(net, &fl4);
 	if (IS_ERR(rt))
@@ -609,6 +616,9 @@ void icmp_send(struct sk_buff *skb_in, i
 	ipc.opt = &icmp_param->replyopts.opt;
 	ipc.tx_flags = 0;
 
+#ifdef CONFIG_TI_META_DATA
+    ipc.ti_meta_info = 0;
+#endif
 	rt = icmp_route_lookup(net, &fl4, skb_in, iph, saddr, tos,
 			       type, code, icmp_param);
 	if (IS_ERR(rt))
--- a/net/ipv4/ip_input.c
+++ b/net/ipv4/ip_input.c
@@ -147,6 +147,9 @@
 #include <linux/mroute.h>
 #include <linux/netlink.h>
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#include <linux/ti_hil.h>
+#endif
 /*
  *	Process Router Attention IP option (RFC 2113)
  */
@@ -463,6 +466,9 @@ csum_error:
 inhdr_error:
 	IP_INC_STATS_BH(dev_net(dev), IPSTATS_MIB_INHDRERRORS);
 drop:
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event (TI_IP_DISCARD_PKT_IPV4, (void *)skb);
+#endif //CONFIG_TI_PACKET_PROCESSOR
 	kfree_skb(skb);
 out:
 	return NET_RX_DROP;
--- a/net/ipv4/ip_output.c
+++ b/net/ipv4/ip_output.c
@@ -79,11 +79,30 @@
 #include <linux/mroute.h>
 #include <linux/netlink.h>
 #include <linux/tcp.h>
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include <asm-arm/arch-avalanche/generic/pal_cppi41.h>
+#else
+#include <linux/avalanche/generic/pal_cppi41.h>
+#endif
+#endif
+
 #if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
   #include <net/ppa_api.h>
 #endif
 
 
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+#define DBRIDGE_IFINDEX_CHK(__ifindex, format, args...) \
+{ \
+    if (((__ifindex) < 0) || ((__ifindex) >= TI_MAX_DEVICE_INDEX)) \
+    { \
+        printk("\n===>>> %s - %d: Currupt " #__ifindex " - %d\n" format, __func__, __LINE__, __ifindex, ##args); \
+        BUG(); \
+    } \
+}
+#endif
 int sysctl_ip_default_ttl __read_mostly = IPDEFTTL;
 EXPORT_SYMBOL(sysctl_ip_default_ttl);
 
@@ -101,6 +120,14 @@ int __ip_local_out(struct sk_buff *skb)
 
 	iph->tot_len = htons(skb->len);
 	ip_send_check(iph);
+#ifdef CONFIG_TI_ICMP_ECHO_REPLY_NETFILTER_BYPASS
+    if(iph->protocol == IPPROTO_ICMP) {
+        struct icmphdr *icmph = (struct icmphdr *)((unsigned char *)(iph)+iph->ihl*4);
+        if(icmph->type == ICMP_ECHOREPLY) {
+            return 1;                   
+        } 
+    } 
+#endif /* CONFIG_TI_ICMP_ECHO_REPLY_NETFILTER_BYPASS */
 	return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT, skb, NULL,
 		       skb_dst(skb)->dev, dst_output);
 }
@@ -195,6 +222,15 @@ static inline int ip_finish_output2(stru
 		consume_skb(skb);
 		skb = skb2;
 	}
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+    const struct nf_conn *ct = (struct nf_conn *)skb->nfct;
+    if (ct != NULL)
+    {
+        ti_hil_pp_event( TI_CT_NETFILTER_CANCEL_DISCARD_ACCELERATION, (void *)ct );
+    }
+#endif
+#endif
 
 #if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
         if ( ppa_hook_session_add_fn != NULL )
@@ -452,6 +488,22 @@ static void ip_copy_metadata(struct sk_b
 #ifdef CONFIG_APPCPU_GW_PP_HANDLE
     memcpy((void *)SKB_GET_PP_INFO_P(to), (void *)SKB_GET_PP_INFO_P(from), sizeof(*SKB_GET_PP_INFO_P(from)));
 #endif
+#ifdef CONFIG_TI_DOCSIS_INPUT_DEV
+    to->ti_docsis_input_dev = from->ti_docsis_input_dev;
+    if (to->ti_docsis_input_dev)
+    {
+        DBRIDGE_IFINDEX_CHK(to->ti_docsis_input_dev->ifindex, "dev %p, devname %s, ti_docsis_input_dev %p, ti_docsis_input_dev->name %s", to->dev, to->dev ? to->dev->name : NULL, to->ti_docsis_input_dev, to->ti_docsis_input_dev->name);
+    }
+#endif /* CONFIG_TI_DOCSIS_INPUT_DEV */
+#ifdef CONFIG_INTEL_DOCSIS_ICMP_IIF
+    to->docsis_icmp_iif = from->docsis_icmp_iif;
+#endif /* CONFIG_INTEL_DOCSIS_ICMP_IIF */
+#ifdef CONFIG_TI_L2_SELECTIVE_FORWARDER
+    to->ti_selective_fwd_dev_info = from->ti_selective_fwd_dev_info;
+#endif /* CONFIG_TI_L2_SELECTIVE_FORWARDER */
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    memcpy((void *)SKB_GET_PP_INFO_P(to), (void *)SKB_GET_PP_INFO_P(from), sizeof(*SKB_GET_PP_INFO_P(from)));
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 	skb_copy_secmark(to, from);
 }
 
@@ -715,6 +767,16 @@ slow_path:
 		iph->tot_len = htons(len + hlen);
 
 		ip_send_check(iph);
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+        if (left > 0 )
+        {
+#ifdef PUMA7_OR_NEWER_SOC_TYPE
+            *(Uint32*)(SKB_GET_PP_INFO_P(skb2)->ti_epi_header) &= (~PAL_CPPI4_HOSTDESC_NETINFW0_PTID_FLAG_MASK);
+#else
+            SKB_GET_PP_INFO_P(skb2)->ti_epi_header[4] = 0;
+#endif
+        }
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 
 		err = output(skb2);
 		if (err)
@@ -822,7 +884,11 @@ static int __ip_append_data(struct sock
 			    int getfrag(void *from, char *to, int offset,
 					int len, int odd, struct sk_buff *skb),
 			    void *from, int length, int transhdrlen,
-			    unsigned int flags)
+                unsigned int flags
+#ifdef CONFIG_TI_META_DATA
+,unsigned int ti_meta_info
+#endif
+)
 {
 	struct inet_sock *inet = inet_sk(sk);
 	struct sk_buff *skb;
@@ -960,6 +1026,9 @@ alloc_new_skb:
 			skb_reserve(skb, hh_len);
 			skb_shinfo(skb)->tx_flags = cork->tx_flags;
 
+#ifdef CONFIG_TI_META_DATA
+            skb->ti_meta_info = ti_meta_info;
+#endif /* CONFIG_TI_META_DATA */
 			/*
 			 *	Find where to start putting bytes.
 			 */
@@ -1129,7 +1198,11 @@ int ip_append_data(struct sock *sk, stru
 
 	return __ip_append_data(sk, fl4, &sk->sk_write_queue, &inet->cork.base,
 				sk_page_frag(sk), getfrag,
-				from, length, transhdrlen, flags);
+                from, length, transhdrlen, flags
+#ifdef CONFIG_TI_META_DATA
+                ,ipc->ti_meta_info
+#endif
+    );
 }
 
 ssize_t	ip_append_page(struct sock *sk, struct flowi4 *fl4, struct page *page,
@@ -1452,7 +1525,11 @@ struct sk_buff *ip_make_skb(struct sock
 
 	err = __ip_append_data(sk, fl4, &queue, &cork,
 			       &current->task_frag, getfrag,
-			       from, length, transhdrlen, flags);
+                   from, length, transhdrlen, flags
+#ifdef CONFIG_TI_META_DATA
+                ,ipc->ti_meta_info
+#endif
+    );
 	if (err) {
 		__ip_flush_pending_frames(sk, &queue, &cork);
 		return ERR_PTR(err);
--- a/net/ipv4/ip_sockglue.c
+++ b/net/ipv4/ip_sockglue.c
@@ -53,9 +53,28 @@
 #define IP_CMSG_PASSSEC		32
 #define IP_CMSG_ORIGDSTADDR     64
 
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+#define TI_IP_CMSG_PKTINFO		128
+#endif
 /*
  *	SOL_IP control messages.
  */
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+static void ip_cmsg_recv_ti_pktinfo(struct msghdr *msg, struct sk_buff *skb)
+{
+    struct ti_pktinfo info;
+    struct ethhdr *ehdr;
+#ifdef CONFIG_TI_META_DATA
+    info.ifcpe_side = skb->ti_meta_info;
+#endif
+    ehdr = eth_hdr(skb);
+    memcpy( info.mac_addr, ehdr->h_source, sizeof(info.mac_addr));
+#ifdef CONFIG_TI_META_DATA
+    skb->ti_meta_info=0;
+#endif
+    put_cmsg(msg, SOL_IP, TI_IP_PKTINFO, sizeof(info), &info);
+}
+#endif
 #define PKTINFO_SKB_CB(__skb) ((struct in_pktinfo *)((__skb)->cb))
 
 static void ip_cmsg_recv_pktinfo(struct msghdr *msg, struct sk_buff *skb)
@@ -184,6 +203,12 @@ void ip_cmsg_recv(struct msghdr *msg, st
 	if (flags & 1)
 		ip_cmsg_recv_dstaddr(msg, skb);
 
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+    if ((flags>>=1) == 0)
+		return;
+	if (flags & 1)
+		ip_cmsg_recv_ti_pktinfo(msg, skb);
+#endif
 }
 EXPORT_SYMBOL(ip_cmsg_recv);
 
@@ -217,6 +242,27 @@ int ip_cmsg_send(struct net *net, struct
 			ipc->addr = info->ipi_spec_dst.s_addr;
 			break;
 		}
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+		case TI_IP_PKTINFO:
+                {
+			printk("TI_IP_PKTINFO option is off\n");
+ 			return -EINVAL;
+                }
+#endif
+#ifdef CONFIG_TI_META_DATA
+        case TI_IP_META_DATA:
+        {
+            unsigned int* ptr_meta_info;
+			if (cmsg->cmsg_len != CMSG_LEN(sizeof(unsigned int)))
+				return -EINVAL;
+            ptr_meta_info = (unsigned int *)CMSG_DATA(cmsg);
+            ipc->ti_meta_info = *ptr_meta_info;
+#ifdef CONFIG_TI_META_DATA_CONSOLE_DUMP
+            printk ("Received Meta-Data:0x%x\n", ipc->ti_meta_info);
+#endif /* CONFIG_TI_META_DATA_CONSOLE_DUMP */
+            break;
+        }
+#endif /* CONFIG_TI_META_DATA */
 		default:
 			return -EINVAL;
 		}
@@ -478,6 +524,9 @@ static int do_ip_setsockopt(struct sock
 	case IP_MULTICAST_ALL:
 	case IP_MULTICAST_LOOP:
 	case IP_RECVORIGDSTADDR:
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+	case TI_IP_PKTINFO:
+#endif
 		if (optlen >= sizeof(int)) {
 			if (get_user(val, (int __user *) optval))
 				return -EFAULT;
@@ -539,6 +588,14 @@ static int do_ip_setsockopt(struct sock
 		else
 			inet->cmsg_flags &= ~IP_CMSG_PKTINFO;
 		break;
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+	case TI_IP_PKTINFO:
+		if (val)
+			inet->cmsg_flags |= TI_IP_CMSG_PKTINFO;
+		else
+			inet->cmsg_flags &= ~TI_IP_CMSG_PKTINFO;
+		break;
+#endif
 	case IP_RECVTTL:
 		if (val)
 			inet->cmsg_flags |=  IP_CMSG_TTL;
@@ -1158,6 +1215,11 @@ static int do_ip_getsockopt(struct sock
 	case IP_PKTINFO:
 		val = (inet->cmsg_flags & IP_CMSG_PKTINFO) != 0;
 		break;
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+	case TI_IP_PKTINFO:
+		val = (inet->cmsg_flags & TI_IP_CMSG_PKTINFO) != 0;
+		break;
+#endif
 	case IP_RECVTTL:
 		val = (inet->cmsg_flags & IP_CMSG_TTL) != 0;
 		break;
@@ -1294,6 +1356,12 @@ static int do_ip_getsockopt(struct sock
 			info.ipi_ifindex = inet->mc_index;
 			put_cmsg(&msg, SOL_IP, IP_PKTINFO, sizeof(info), &info);
 		}
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+		if (inet->cmsg_flags & TI_IP_CMSG_PKTINFO) {
+			printk("TI_IP_PKTINFO option is close in this mode\n");
+			return -ENOPROTOOPT;
+		}
+#endif
 		if (inet->cmsg_flags & IP_CMSG_TTL) {
 			int hlim = inet->mc_ttl;
 			put_cmsg(&msg, SOL_IP, IP_TTL, sizeof(hlim), &hlim);
--- a/net/ipv4/ipmr.c
+++ b/net/ipv4/ipmr.c
@@ -64,6 +64,7 @@
 #include <net/ip_tunnels.h>
 #include <net/checksum.h>
 #include <net/netlink.h>
+#include <linux/ti_hil.h>
 #include <net/fib_rules.h>
 #include <linux/netconf.h>
 
@@ -1112,6 +1113,9 @@ static int ipmr_mfc_delete(struct mr_tab
 		    c->mfc_mcastgrp == mfc->mfcc_mcastgrp.s_addr &&
 		    (parent == -1 || parent == c->mfc_parent)) {
 			list_del_rcu(&c->list);
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+            ti_hil_pp_event (TI_MC_SESSION_DELETED,(void *)c);
+#endif// CONFIG_TI_PACKET_PROCESSOR
 			mroute_netlink_event(mrt, c, RTM_DELROUTE);
 			ipmr_cache_free(c);
 			return 0;
@@ -1168,7 +1172,13 @@ static int ipmr_mfc_add(struct net *net,
 		c->mfc_flags |= MFC_STATIC;
 
 	list_add_rcu(&c->list, &mrt->mfc_cache_array[line]);
-
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    {
+        struct pp_mr_param pp_mr;
+        pp_mr.cache = c;
+        pp_mr.vif_table = &mrt->vif_table;
+    }
+#endif// CONFIG_TI_PACKET_PROCESSOR
 	/*
 	 *	Check to see if we resolved a queued list. If so we
 	 *	need to send on the frames and tidy up.
@@ -1868,6 +1878,10 @@ forward:
 	/*
 	 *	Forward the frame
 	 */
+    if ((cache->mfc_un.res.maxvif - cache->mfc_un.res.minvif) > 1)
+    {
+        SKB_GET_PP_INFO_P(skb)->flags |= TI_HIL_PACKET_FLAG_PP_SESSION_BYPASS;
+    }
 	if (cache->mfc_origin == htonl(INADDR_ANY) &&
 	    cache->mfc_mcastgrp == htonl(INADDR_ANY)) {
 		if (true_vifi >= 0 &&
--- a/net/ipv4/netfilter/ip_tables.c
+++ b/net/ipv4/netfilter/ip_tables.c
@@ -28,6 +28,7 @@
 #include <linux/ti_hil.h>
 #include <linux/netfilter/x_tables.h>
 #include <linux/netfilter_ipv4/ip_tables.h>
+#include <linux/ti_hil.h>
 #include <net/netfilter/nf_log.h>
 #include "../../netfilter/xt_repldata.h"
 
@@ -1304,7 +1305,7 @@ __do_replace(struct net *net, const char
 	}
 	vfree(counters);
 	xt_table_unlock(t);
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR
         ti_hil_pp_event (TI_CT_NETFILTER_TABLE_UPDATE, (void *)t);
 #endif
 
--- a/net/ipv4/raw.c
+++ b/net/ipv4/raw.c
@@ -521,6 +521,9 @@ static int raw_sendmsg(struct kiocb *ioc
 	ipc.tx_flags = 0;
 	ipc.oif = sk->sk_bound_dev_if;
 
+#ifdef CONFIG_TI_META_DATA
+    ipc.ti_meta_info = 0;
+#endif
 	if (msg->msg_controllen) {
 		err = ip_cmsg_send(sock_net(sk), msg, &ipc);
 		if (unlikely(err)) {
--- a/net/ipv4/udp.c
+++ b/net/ipv4/udp.c
@@ -903,7 +903,9 @@ int udp_sendmsg(struct kiocb *iocb, stru
 		connected = 1;
 	}
 	ipc.addr = inet->inet_saddr;
-
+#ifdef CONFIG_TI_META_DATA
+    ipc.ti_meta_info = 0;
+#endif
 	ipc.oif = sk->sk_bound_dev_if;
 
 	sock_tx_timestamp(sk, &ipc.tx_flags);
--- a/net/ipv6/datagram.c
+++ b/net/ipv6/datagram.c
@@ -499,7 +499,20 @@ int ip6_datagram_recv_ctl(struct sock *s
 		src_info.ipi6_addr = ipv6_hdr(skb)->daddr;
 		put_cmsg(msg, SOL_IPV6, IPV6_PKTINFO, sizeof(src_info), &src_info);
 	}
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+    if (np->rxopt.bits.ti_rxinfo) {
+		struct ti_pktinfo info;
+        struct ethhdr *ehdr;
+#ifdef CONFIG_TI_META_DATA
+		info.ifcpe_side = skb->ti_meta_info;
+        skb->ti_meta_info=0;
+#endif
+        ehdr = eth_hdr(skb);
+        memcpy( info.mac_addr, ehdr->h_source, sizeof(info.mac_addr));
 
+		put_cmsg(msg, SOL_IPV6, TI_IPV6_PKTINFO, sizeof(info), &info);
+	}
+#endif
 	if (np->rxopt.bits.rxhlim) {
 		int hlim = ipv6_hdr(skb)->hop_limit;
 		put_cmsg(msg, SOL_IPV6, IPV6_HOPLIMIT, sizeof(hlim), &hlim);
--- a/net/ipv6/ip6_input.c
+++ b/net/ipv6/ip6_input.c
@@ -46,6 +46,7 @@
 #include <net/xfrm.h>
 #include <net/inet_ecn.h>
 
+extern int intel_ns_handler (struct net_device *dev,struct in6_addr* dst_addr,unsigned char banned_flags);
 
 int ip6_rcv_finish(struct sk_buff *skb)
 {
@@ -178,6 +179,18 @@ int ipv6_rcv(struct sk_buff *skb, struct
 		}
 	}
 
+#ifdef CONFIG_INTEL_NS_DEVICE_FILTER
+    if (hdr->nexthdr == IPPROTO_ICMPV6)
+    {
+        struct icmp6hdr *icmpv6_hdr;
+        icmpv6_hdr = icmp6_hdr(skb);
+        if (icmpv6_hdr->icmp6_type == NDISC_NEIGHBOUR_SOLICITATION)
+        {
+			if (intel_ns_handler (skb->dev,&(hdr->daddr),IFA_F_TENTATIVE) == 0)
+				goto drop; 	 
+        }
+    }
+#endif
 	rcu_read_unlock();
 
 	/* Must drop socket now because of tproxy. */
--- a/net/ipv6/ip6_output.c
+++ b/net/ipv6/ip6_output.c
@@ -107,6 +107,15 @@ static int ip6_finish_output2(struct sk_
 			return 0;
 		}
 	}
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+    const struct nf_conn *ct = (struct nf_conn *)skb->nfct;
+    if (ct != NULL)
+    {
+        ti_hil_pp_event( TI_CT_NETFILTER_CANCEL_DISCARD_ACCELERATION, (void *)ct );
+    }
+#endif
+#endif
 
 #if defined(CONFIG_LTQ_PPA_API) || defined(CONFIG_LTQ_PPA_API_MODULE)
 	if ( ppa_hook_session_add_fn != NULL )
--- a/net/ipv6/ipv6_sockglue.c
+++ b/net/ipv6/ipv6_sockglue.c
@@ -258,6 +258,12 @@ static int do_ipv6_setsockopt(struct soc
 		retv = 0;
 		break;
 
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+    case TI_IPV6_PKTINFO:
+		np->rxopt.bits.ti_rxinfo = valbool;
+		retv = 0;
+		break;
+#endif
 	case IPV6_RECVHOPLIMIT:
 		if (optlen < sizeof(int))
 			goto e_inval;
@@ -1071,6 +1077,11 @@ static int do_ipv6_getsockopt(struct soc
 		val = np->rxopt.bits.rxinfo;
 		break;
 
+#ifdef CONFIG_TI_IP_PKTINFO_SOCKOPT
+    case TI_IPV6_PKTINFO:
+		val = np->rxopt.bits.ti_rxinfo;
+		break;
+#endif
 	case IPV6_2292PKTINFO:
 		val = np->rxopt.bits.rxoinfo;
 		break;
--- a/net/ipv6/route.c
+++ b/net/ipv6/route.c
@@ -65,6 +65,9 @@
 #include <linux/sysctl.h>
 #endif
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#include <linux/ti_hil.h>
+#endif
 enum rt6_nud_state {
 	RT6_NUD_FAIL_HARD = -2,
 	RT6_NUD_FAIL_SOFT = -1,
@@ -2160,7 +2163,12 @@ static int ip6_pkt_drop(struct sk_buff *
 
 static int ip6_pkt_discard(struct sk_buff *skb)
 {
-	return ip6_pkt_drop(skb, ICMPV6_NOROUTE, IPSTATS_MIB_INNOROUTES);
+    int ret;
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event (TI_IP_DISCARD_PKT_IPV6, (void *)skb);
+#endif //CONFIG_TI_PACKET_PROCESSOR
+	ret = ip6_pkt_drop(skb, ICMPV6_NOROUTE, IPSTATS_MIB_INNOROUTES);
+    return ret;
 }
 
 static int ip6_pkt_discard_out(struct sk_buff *skb)
--- a/net/netfilter/core.c
+++ b/net/netfilter/core.c
@@ -23,7 +23,7 @@
 #include <linux/slab.h>
 #include <net/net_namespace.h>
 #include <net/sock.h>
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR
 #include <linux/ti_hil.h>
 #endif /* CONFIG_APPCPU_GW_PP_HANDLE */
 #include "nf_internals.h"
@@ -195,7 +195,7 @@ next_hook:
 		ret = 1;
 	} else if ((verdict & NF_VERDICT_MASK) == NF_DROP) {
 
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR
 #define MAC_ISMULTICAST( pa, hw )    ( ((pa)->hw[0] & 0x01)  )
 #define MAC_ISBROADCAST( pa, hw ) ( ~0xFF ==( (~(pa)->hw[0]) | \
                                               (~(pa)->hw[1]) | \
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -60,6 +60,7 @@
   static atomic_t g_ppa_force_timeout = {0};
 #endif
 
+#include <linux/ti_hil.h>
 #define NF_CONNTRACK_VERSION	"0.5.0"
 /*Some random value to indicate that the delete is due to CT timeout.
  *this is required to differentiate conntrack_flush related delete.
@@ -404,7 +405,11 @@ delete_record:
         }
     }
 #endif
-
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event (TI_CT_DEATH_BY_TIMEOUT, (void *)ct);
+    if ((ct->ti_pp_status_flag & TI_PP_KILL_CONNTRACK) == 0)
+        return;  /* HIL Profile took over... */
+#endif
 	/*go ahead and clear the ct record */
 	tstamp = nf_conn_tstamp_find(ct);
 	if (tstamp && tstamp->stop == 0)
@@ -885,6 +890,13 @@ __nf_conntrack_alloc(struct net *net, u1
 		nf_ct_zone->id = zone;
 	}
 #endif
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle = TI_PP_SESSION_CT_IDLE;
+    ct->tuplehash[IP_CT_DIR_REPLY   ].ti_pp_session_handle = TI_PP_SESSION_CT_IDLE;
+    ct->ti_pp_status_flag = 0;
+    ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_sessions_count = 0;
+    ct->tuplehash[IP_CT_DIR_REPLY   ].ti_pp_sessions_count = 0;
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 	/* Because we use RCU lookups, we set ct_general.use to zero before
 	 * this is inserted in any list.
 	 */
@@ -1025,7 +1037,9 @@ init_conntrack(struct net *net, struct n
 			exp->expectfn(ct, exp);
 		nf_ct_expect_put(exp);
 	}
-
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    ti_hil_pp_event(TI_CT_ENTRY_CREATED, (void *)ct);
+#endif //CONFIG_TI_PACKET_PROCESSOR
 	return &ct->tuplehash[IP_CT_DIR_ORIGINAL];
 }
 
@@ -1163,6 +1177,12 @@ nf_conntrack_in(struct net *net, u_int8_
 		goto out;
 	}
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    if (ct->ti_pp_status_flag & TI_PP_BYPASS)
+    {
+        SKB_GET_PP_INFO_P(skb)->flags |= TI_HIL_PACKET_FLAG_PP_SESSION_BYPASS;
+    }
+#endif
 	NF_CT_ASSERT(skb->nfct);
 
 	/* Decide what timeout policy we want to apply to this flow. */
--- a/net/netfilter/nf_conntrack_proto_tcp.c
+++ b/net/netfilter/nf_conntrack_proto_tcp.c
@@ -7,6 +7,10 @@
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
  */
+/*
+Includes Intel Corporation's changes/modifications dated: 2014.
+Changed/modified portions - Copyright  2014, Intel Corporation.
+*/
 
 #include <linux/types.h>
 #include <linux/timer.h>
@@ -864,6 +868,33 @@ static int tcp_packet(struct nf_conn *ct
 		     & IP_CT_TCP_FLAG_CLOSE_INIT)
 		    || (ct->proto.tcp.last_dir == dir
 		        && ct->proto.tcp.last_index == TCP_RST_SET)) {
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+                /* Check if the ORIGINAL Tuple is being accelerated? */
+                if ((!IS_TI_PP_SESSION_CT_INVALID(ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle)) &&
+                    (1 == ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_sessions_count))
+                {
+                    /* YES. There is no point in accelerating this; since the session will be deleted. */
+#ifdef CONFIG_MACH_PUMA5
+                    if (ti_ppm_delete_session (ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle, NULL) < 0)
+                        printk ("ERROR: Unable to delete the ORIGINAL session\n");
+#else
+                    ti_hil_pp_event(TI_CT_NETFILTER_DELETE_SESSION, (void *)ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle);
+#endif
+                }
+
+                /* Check if the REPLY Tuple is being accelerated? */
+                if ((!IS_TI_PP_SESSION_CT_INVALID(ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_session_handle)) &&
+                    (1 == ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_sessions_count))
+                {
+                    /* YES. There is no point in accelerating this; since the session will be deleted. */
+#ifdef CONFIG_MACH_PUMA5
+                    if (ti_ppm_delete_session (ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_session_handle, NULL) < 0)
+                        printk ("ERROR: Unable to delete the REPLY session\n");
+#else
+                    ti_hil_pp_event(TI_CT_NETFILTER_DELETE_SESSION, (void *)ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_session_handle);
+#endif
+                }
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 			/* Attempt to reopen a closed/aborted connection.
 			 * Delete this connection and look up again. */
 			spin_unlock_bh(&ct->lock);
@@ -1010,11 +1041,33 @@ static int tcp_packet(struct nf_conn *ct
 		break;
 	}
 
-	if (!tcp_in_window(ct, &ct->proto.tcp, dir, index,
-			   skb, dataoff, th, pf)) {
-		spin_unlock_bh(&ct->lock);
-		return -NF_ACCEPT;
-	}
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    /* TCP Window tracking does not make sense if the sessions are being accelerated. Thus
+     * we added this check... Maybe a better way is to make the window tracking more resilient. 
+     * Check here to see if both of the sessions are not accelerated and if so be the case do the 
+     * window checking else skip it! */
+
+    if (IS_TI_PP_SESSION_CT_IDLE(ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle) &&
+        IS_TI_PP_SESSION_CT_IDLE(ct->tuplehash[IP_CT_DIR_REPLY   ].ti_pp_session_handle))
+#endif
+	{
+		if (!tcp_in_window(ct, &ct->proto.tcp, dir, index,
+				   skb, dataoff, th, pf)) {
+			spin_unlock_bh(&ct->lock);
+			return -NF_ACCEPT;
+		}
+    }
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    else
+    {
+        if (ct->tuplehash[dir].ti_pp_session_handle == TI_PP_SESSION_CT_TCP_UPDATE)
+        {
+            ct->proto.tcp.seen[dir].td_end = 0;   
+            ct->tuplehash[dir].ti_pp_session_handle = TI_PP_SESSION_CT_IDLE;
+            tcp_in_window(ct, &ct->proto.tcp, dir, index,skb, dataoff, th, pf);
+        }
+    }
+#endif
      in_window:
 	/* From now on we have got in-window packets */
 	ct->proto.tcp.last_index = index;
--- a/net/netfilter/nf_conntrack_standalone.c
+++ b/net/netfilter/nf_conntrack_standalone.c
@@ -246,6 +246,28 @@ static int ct_seq_show(struct seq_file *
 		return -ENOSPC;
 #endif
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    if (ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle == 0xFFFF)
+    {
+    	if (seq_printf(s, "[ORG XXX] "))
+	    	goto release;
+    }
+    else
+    {
+    	if (seq_printf(s, "ORG %d ", ct->tuplehash[IP_CT_DIR_ORIGINAL].ti_pp_session_handle))
+	    	goto release;
+    }
+    if (ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_session_handle == 0xFFFF)
+    {
+    	if (seq_printf(s, "[REPLY XXX] "))
+	    	goto release;
+    }
+    else
+    {
+    	if (seq_printf(s, "REPLY %d ", ct->tuplehash[IP_CT_DIR_REPLY].ti_pp_session_handle))
+	    	goto release;
+    }
+#endif /* CONFIG_TI_PACKET_PROCESSOR */
 	if (seq_printf(s, "use=%u\n", atomic_read(&ct->ct_general.use)))
 		goto release;
 
--- a/net/netfilter/nf_nat_core.c
+++ b/net/netfilter/nf_nat_core.c
@@ -16,6 +16,9 @@
 #include <net/xfrm.h>
 #include <linux/jhash.h>
 #include <linux/rtnetlink.h>
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+#include <linux/ti_hil.h>
+#endif
 
 #include <net/netfilter/nf_conntrack.h>
 #include <net/netfilter/nf_conntrack_core.h>
--- a/net/netfilter/nf_queue.c
+++ b/net/netfilter/nf_queue.c
@@ -15,7 +15,7 @@
 #include <net/protocol.h>
 #include <net/netfilter/nf_queue.h>
 #include <net/dst.h>
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR
 #include <linux/ti_hil.h>
 #endif /* CONFIG_APPCPU_GW_PP_HANDLE */
 #include "nf_internals.h"
@@ -222,7 +222,7 @@ void nf_reinject(struct nf_queue_entry *
 	case NF_STOLEN:
 		break;
 	default:
-#ifdef CONFIG_APPCPU_GW_PP_HANDLE
+#ifdef CONFIG_TI_PACKET_PROCESSOR
                 {
 			int skip_pp_discard=0;
 			struct ethhdr* ptr_ethhdr = NULL;
--- a/net/netfilter/nfnetlink_queue_core.c
+++ b/net/netfilter/nfnetlink_queue_core.c
@@ -1028,6 +1028,12 @@ nfqnl_recv_verdict(struct sock *ctnl, st
 	if (nfqa[NFQA_MARK])
 		entry->skb->mark = ntohl(nla_get_be32(nfqa[NFQA_MARK]));
 
+#ifdef CONFIG_TI_PACKET_PROCESSOR
+    if (verdict & NF_VERDICT_FLAG_PP_BYPASS) {
+        SKB_GET_PP_INFO_P(entry->skb)->flags |= TI_HIL_PACKET_FLAG_PP_SESSION_BYPASS;
+        verdict &= ~(NF_VERDICT_FLAG_PP_BYPASS);
+    }
+#endif  /* CONFIG_TI_PACKET_PROCESSOR */
 	nf_reinject(entry, verdict);
 	return 0;
 }
--- /dev/null
+++ b/net/ti.Kconfig
@@ -0,0 +1,311 @@
+#----------------------------------------------------------------
+# Copyright 2006-2007, Texas Instruments Incorporated
+#
+#   Kconfig file which defines and control all of the TI
+#   extensions to the networking stack.
+#
+# THIS MODIFIED SOFTWARE AND DOCUMENTATION ARE PROVIDED
+# "AS IS," AND TEXAS INSTRUMENTS MAKES NO REPRESENTATIONS 
+# OR WARRENTIES, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED 
+# TO, WARRANTIES OF MERCHANTABILITY OR FITNESS FOR ANY 
+# PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE OR 
+# DOCUMENTATION WILL NOT INFRINGE ANY THIRD PARTY PATENTS, 
+# COPYRIGHTS, TRADEMARKS OR OTHER RIGHTS. 
+#----------------------------------------------------------------
+# TI Specific configurations
+
+menu "Texas Instruments Kernel Extensions"
+config TI_DEVICE_PROTOCOL_HANDLING
+	bool "TI Device Specific Protocol Handling"
+	default y
+	help
+     This feature allows specific protocol handlers to be installed on a 
+     per device basis to do custom protocol specific handling. These handler
+     have higher precedence then the NET & Bridge stacks and allows the
+     custom protocol handler to be able to capture the packets and bypass 
+     the Networking stacks.
+
+config TI_UNMANAGED_BRIDGE
+	bool "TI Unmanaged Bridge"
+    depends on TI_DEVICE_PROTOCOL_HANDLING
+    default n
+	help
+        This feature enables the bridged interfaces to be unmanaged i.e. there is no
+        connectivity from a bridged interface to the local stack. 
+config INTEL_KERNEL_DOCSIS_SUPPORT
+	bool "INTEL DOCSIS support in kernel"
+        default n
+	help
+	This feature is available for DOCSIS support in kernel. 
+config INTEL_KERNEL_BBU_SUPPORT
+	bool "INTEL BBU support in kernel"
+        default n
+	help
+	This feature is available for BBU support in kernel. 
+config TI_META_DATA
+	bool "TI Meta Data"
+    default y
+	help
+        This feature is available for applications to add meta data while send out packets
+        The meta data is transferred from the socket layer into the networking packet and 
+        is available for all networking layers. The feature does not define the format of 
+        meta data but 4 bytes are available for storing information.
+         
+config INTEL_NF_TRIGGER_SUPPORT
+	bool "Intel Netfilter Port Trigger"
+    default y
+	help
+        This feature allows to use Port Trigger module of iptables/Netfilter 
+
+config INTEL_NF_GWMETA_SUPPORT
+	bool "Intel Gateway Packet Meta Data"
+    default y
+	help
+        This feature allows to label skb data of ip packets (GWMETA module of iptables/Netfilter )
+config INTEL_NF_WEBSTR_SUPPORT
+         bool "WEBSTR match support"
+    default y
+	help
+        This option allows to match string in http web header
+
+config TI_IP_PKTINFO_SOCKOPT
+	bool "TI IP level socket options <TI_IP_PKTINFO>/<TI_IPV6_PKTINFO>"
+    default y
+	help
+        The socket option level for IP is SOL_IP. A boolean integer flag is zero when it 
+        is false, otherwise true. Pass an TI_IP_PKTINFO ancillary message that contains 
+        a ti_pktinfo structure that supplies some information about the incoming packet. 
+        This only works for datagram oriented sockets. The argument is a flag that tells 
+        the socket whether the TI_IP_PKTINFO/TI_IPV6_PKTINFO message should be passed or
+        not. The message itself can only be sent/retrieved as control message with a 
+        packet using recvmsg(2) or sendmsg(2).  
+
+config TI_META_DATA_CONSOLE_DUMP
+	bool "TI Meta Data Console Dump"
+    default n
+    depends on TI_META_DATA
+	help
+        This feature dumps the meta-information output at various stages in the networking
+        layer to showcase that the meta-information is valid and available at various layers.
+        This feature is only available for DEBUG and should be turned OFF on production releases
+        Make sure that the kernel conosle error level is set to debug to see the messages on the
+        console. 
+
+config TI_DOCSIS_INPUT_DEV
+	bool "TI Docsis Input Device"
+    default n
+	help
+        This feature is an extension to SKB to support docsis specific requirement.
+
+config INTEL_DOCSIS_ICMP_IIF
+	bool "Intel  Docsis ICMP Interface Index"
+    default n
+	help
+        This feature is an extension to ICMP to support docsis specific requirement
+	We use the docsis_icmp_iif to support ICMP when wan0, mta0 or erouter0 are on the same subnet
+
+config TI_L2_SELECTIVE_FORWARDER
+	bool "TI Layer2 Selective Forwarder"
+    default y
+    select TI_DEVICE_INDEX_REUSE
+    select TI_L2_SELECTIVE_PACKET_HANDLING
+	help
+        This feature is an extension to the Layer 2 bridge to selectively forward multicast 
+        and broadcast packets.
+
+config TI_L2_SELECTIVE_FORWARDER_TEST
+	bool "Test TI Layer2 Selective Forwarder"
+    default n
+    depends on TI_L2_SELECTIVE_FORWARDER
+	help
+        This feature tests the Layer 2 Selective Forwarder feature. This feature is for debug and 
+        testing purposes only and SHOULD be turned OFF in production version
+
+config INTEL_L2VPN_L2CP_FORWARD
+        bool "Intel L2VPN L2 Control Protocol Forward"
+        default y
+        help
+        This feature enables L2VPN L2 Control Protocol handling according to L2VPN specification
+
+
+config TI_DEVICE_INDEX_REUSE
+	bool "TI Device Index Reuse"
+    default y
+	help
+        This feature allows the device indexes to be reused when freed instead of infinetely incrementing it.
+        The maximum device index limit is set to 32.
+
+config TI_L2_SELECTIVE_PACKET_HANDLING
+	bool "TI Layer2 Selective Packet Handling Framework"
+    default y
+	help
+     This feature allows multiple packet handlers to be installed on a bridge to do 
+     custom packet handling. The handlers are called in the order of priority with which 
+     they are installed. Handlers installed with lower priority number are called before 
+     a handler installed with a higher priority number
+
+config TI_DOCSIS_EGRESS_HOOK
+	bool "TI DOCSIS Egress Hook"
+	default n
+	help
+        This feature allows dicsis bridge specified hooks to be installed on a per device
+        basis. The hooks are installed just before the packet is passed to the 
+	driver for transmission.
+
+config TI_GW_EGRESS_HOOK
+	bool "TI GW Egress Hook"
+	default n
+	help
+        This feature inteand for GW it allows user specified hooks to be installed 
+	on a per device basis. The hooks are installed just before the packet is passed 
+	to the driver for transmission.
+
+config TI_EGRESS_HOOK
+	bool "TI Egress Hook"
+	default y
+	help
+        This feature allows user specified hooks to be installed on a per device
+        basis. The hooks are installed just before the packet is passed to the 
+        driver for transmission. The hook is the "Egress" counterpoint for the 
+        Device protocol handling.
+
+config TI_ICMP_ECHO_REPLY_NETFILTER_BYPASS
+	bool "TI ICMP echo reply netfilter bypass"
+	default n
+	help
+		Hack to bypass the Netfilter logic for ICMP echo reply. This bypass may be 
+		necessary when the Netfilter logic change the ICMP echo reply source MAC addres.
+
+config INTEL_NS_DEVICE_FILTER
+	bool "INTEL neighbour solicit device filter"
+	default y
+	help
+		This feature allows a neighbour solicit handler to be installed on a 
+		per device basis to do neighbour solicit filtering to neighbour solicit packets not destined
+		to the device.
+
+menu "TI Packet Processor Subsystem"
+
+config TI_PACKET_PROCESSOR
+	bool "TI Packet Processor"
+    default y
+	help
+        The TI packet processor is a hardware acclerator which can be used to acclerate
+        sessions and can improve the throughput of the system. 
+
+config TI_PACKET_PROCESSOR_STATS
+	bool "TI Packet Processor statistics"
+    	default y
+    	depends on TI_PACKET_PROCESSOR
+	help
+        Enable TI packet processor statistics mechanism. 
+
+config TI_PACKET_PROCESSOR_EXT_SWITCH
+    bool "TI Packet Processor external switch support"
+    default n
+    depends on TI_PACKET_PROCESSOR
+    help
+        This feature allows special tagging of outgoing ethernet packets for further
+        prioritization by the external ethernet switch hardware. The VLAN tagging technique
+        might be used.
+    
+config TI_HIL_DEBUG
+	bool "Enable HIL Debug"
+    default n
+    depends on TI_PACKET_PROCESSOR
+	help
+        Enable this to see debug output from the HIL profiles.
+
+choice
+    prompt "HIL Profile selection"
+    default TI_HIL_PROFILE_INTRUSIVE_P7
+    depends on TI_PACKET_PROCESSOR
+
+config TI_HIL_PROFILE_INTRUSIVE
+	bool "HIL Intrusive Profile"
+    select TI_EGRESS_HOOK
+    select TI_DEVICE_PROTOCOL_HANDLING
+	help
+      The HIL Intrusive mode profile hooks into the data path to capture necessary 
+      information for session creation. 
+
+config TI_HIL_PROFILE_STATIC
+	bool "HIL Static Profile"
+	help
+      The HIL static profile demonstrates the creation of the PP session data 
+      structure, i.e LUT and modification record based on user input from the console.
+
+config TI_HIL_PROFILE_INTRUSIVE_PP2K
+	bool "HIL Intrusive Profile PP2K"
+    select TI_EGRESS_HOOK
+    select TI_DEVICE_PROTOCOL_HANDLING
+	help
+      The HIL Intrusive mode profile hooks into the data path to capture necessary 
+      information for session creation. 
+
+config TI_HIL_PROFILE_INTRUSIVE_P7
+	bool "HIL Intrusive Profile Puma7"
+    select TI_EGRESS_HOOK
+    select TI_DEVICE_PROTOCOL_HANDLING
+	help
+      The HIL Intrusive mode profile hooks into the data path to capture necessary 
+      information for session creation. 
+endchoice
+
+config INTEL_PP_TUNNEL_SUPPORT
+	bool "L2TPv3 and GRE-MPLS Tunnels"
+        default n
+        depends on TI_PACKET_PROCESSOR
+	help
+      Enable this to support L2TPv3 and GRE-MPLS tunnels by PP.
+      This tunnels should be configured statically and regular session will not be created by PP.
+
+      
+endmenu
+config INTEL_IRQ_THREAD_CHANGE_PRIORITY
+	bool "Change scheduler policy and priority "
+        default y
+        depends on IRQ_FORCED_THREADING
+	help
+      Enable to change scheduler policy and priority
+
+config INTEL_DEFAULT_IPV6_AUTOCONF_DISABLES_IPV6_AUTOCONF
+	bool "Disable IPv6 Autoconf if the default Autoconf is False"
+        default y
+	help
+      Enable to allow the default Autoconf (set to False) to disable IPv6 Autoconf for newly created interfaces
+
+config INTEL_MAX_BRIDGE_MACS_LIMIT
+	bool "Enable limitation upon max briged CPE macs"
+	default y
+	help
+       Enable limitaion upon maximun number of CPE MAC addresses that can be saved in bridge DB. this is to eliminate memory leak
+
+config INTEL_MAX_BRIDGE_MACS
+        int "INTEL maximum bridge macs"
+	depends on INTEL_MAX_BRIDGE_MACS_LIMIT
+        default 1024
+        range 1 65536
+        help
+       Maximun number of CEPs MACs connected to bridge.
+
+config INTEL_KERNEL_VOICE_SUPPORT
+	bool "INTEL VOICE support in kernel"
+        default n
+	help
+	This feature is available for VOICE support in kernel. 
+
+
+config INTEL_KERNEL_FORCE_IPV6_DOWN_WHEN_NO_ADDRES
+	bool "INTEL force ipv6 down on network interface"
+        default y
+	help
+	force ipv6 down on network interface when it has no ipv6 address.  
+endmenu
+
+config INTEL_KERNEL_PP_DRIVER_ON_ATOM
+	bool "Packet Processor driver on application CPU support in kernel"
+        default n
+	help
+	  Support for running the Packet Processor on the application instead of the network processor CPU. 
+	  Cannot coexist with gateway support. 
--- a/net/ti/pp/Makefile
+++ b/net/ti/pp/Makefile
@@ -23,4 +23,6 @@
 #    Santa Clara, CA  97052
 ifdef CONFIG_APPCPU_GW_PP_HANDLE
 obj-y +=  ti_hil_core_gw.o
+else 
+obj-y +=  ti_hil_core.o
 endif
--- /dev/null
+++ b/net/ti/pp/ti_hil_core.c
@@ -0,0 +1,491 @@
+/*
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2008-2016 Intel Corporation.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  You should have received a copy of the GNU General Public License
+  along with this program; if not, write to the Free Software
+  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+  The full GNU General Public License is included in this distribution
+  in the file called LICENSE.GPL.
+
+  Contact Information:
+    Intel Corporation
+    2200 Mission College Blvd.
+    Santa Clara, CA  97052
+*/
+
+/**************************************************************************
+ *************************** Include Files ********************************
+ **************************************************************************/
+
+#include <linux/types.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/netdevice.h>
+#include <linux/inetdevice.h>
+#include <linux/rtnetlink.h>
+#include <linux/ti_hil.h>
+#include <linux/notifier.h>
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+#include "synopsys_gbe_interface.h"
+#else
+#include <linux/avalanche/puma7/synopsys_gbe_interface.h>
+#include <linux/avalanche/puma7/puma7_defs.h>
+#endif
+#endif
+
+/**************************************************************************
+ ***************************** Static Declarations  ***********************
+ **************************************************************************/
+
+/* HIL Core Event Handler for all networking events. */
+static int ti_hil_net_event_handler(struct notifier_block *chain, unsigned long event, void *ptr);
+
+/* Dev Notifier Block for the HIL; this will get notifications for all the dev related events. */
+static struct notifier_block hil_dev_notifier_block =
+{
+    .notifier_call = ti_hil_net_event_handler,
+};
+
+/* INET Addr Notifier Block for the PPM; this will get notifications for all the INET related events. */
+static struct notifier_block hil_inetaddr_notifier_block =
+{
+    .notifier_call = ti_hil_net_event_handler,
+};
+
+/* PP Notifier Block for the PP; this will get notifications for all the PP related events. */
+static struct notifier_block hil_pp_notifier_block =
+{
+    .notifier_call = ti_hil_net_event_handler,
+};
+
+/**************************************************************************
+ * STRUCTURE NAME : TI_HIL_MCB
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The structure describes the HIL Master control block which is used
+ *  to keep track of the HIL profiles which are active.
+ **************************************************************************/
+typedef struct TI_HIL_MCB
+{
+    /* HIL Status   */
+    int              initialized;
+
+    /* Active HIL Profile. */
+    TI_HIL_PROFILE*  active_profile;
+}TI_HIL_MCB;
+
+/**************************************************************************
+ ********************************* Globals ********************************
+ **************************************************************************/
+
+/* HIL Master Control Block. */
+TI_HIL_MCB             hil_mcb;
+
+/* Packet Processor Notifier Chain */
+ATOMIC_NOTIFIER_HEAD(pp_chain);
+
+#ifdef CONFIG_TI_PACKET_PROCESSOR_STATS
+/* DOCSIS Packet processor start session notification Callback */
+TI_HIL_START_SESSION ti_hil_start_session_notification_cb = NULL;
+EXPORT_SYMBOL(ti_hil_start_session_notification_cb);
+/* DOCSIS Packet processor delete session notification Callback */
+TI_HIL_DELETE_SESSION ti_hil_delete_session_notification_cb = NULL;
+EXPORT_SYMBOL(ti_hil_delete_session_notification_cb);
+#endif /* CONFIG_TI_PACKET_PROCESSOR_STATS */
+
+/**************************************************************************
+ ******************************* Functions  *******************************
+ **************************************************************************/
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_net_event_handler
+ **************************************************************************
+ * DESCRIPTION   :
+ *  HIL Core registered event handler. This function receives event from all
+ *  over the networking subsystem.
+ *
+ * RETURNS       :
+ *  Always returns NOTIFY_DONE
+ **************************************************************************/
+static int ti_hil_net_event_handler(struct notifier_block *chain, unsigned long event, void *ptr)
+{
+    unsigned int    module;
+
+    /* Check if there exists an active profile. */
+    if (hil_mcb.active_profile)
+    {
+        /* Use the chain to identify the module */
+        if (chain == &hil_dev_notifier_block)
+        {
+            /* Device Interface Management Module. */
+            module = TI_DEVICE;
+        }
+        else if (chain == &hil_inetaddr_notifier_block)
+        {
+            /* Inet address Management Module. */
+            module = TI_INET;
+        }
+        else if (chain == &hil_pp_notifier_block)
+        {
+            /* PP Chain Management Module. */
+            module = TI_PP;
+        }
+        else
+        {
+            /* Unrecognized chain: This is a FATAL Error and should not happen. */
+            printk ("FATAL HIL Core Error: Received event from unknown chain 0x%p\n", chain);
+            return NOTIFY_DONE;
+        }
+
+        /* Pass the event to the profile handler. */
+        hil_mcb.active_profile->profile_handler (module, event, ptr);
+    }
+
+    /* Work is succesfully completed. */
+    return NOTIFY_DONE;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_load_profile
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is used to load the specific HIL Profile.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+static int ti_hil_load_profile (TI_HIL_PROFILE* ptr_profile)
+{
+    /* Unload and deinitialize the profile. */
+    if (ptr_profile->profile_init() < 0)
+    {
+        printk ("HIL Core: Unable to load profile %s\n", ptr_profile->name);
+        return -1;
+    }
+
+    /* Profile has been succesfully loaded. */
+    printk ("HIL Core: Profile %s has been Loaded.\n", ptr_profile->name);
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_unload_profile
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is used to unload the specific HIL Profile.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+static int ti_hil_unload_profile (TI_HIL_PROFILE* ptr_profile)
+{
+    /* Unload and deinitialize the profile. */
+    if (ptr_profile->profile_deinit() < 0)
+    {
+        printk ("HIL Core: Unable to unload profile %s\n", ptr_profile->name);
+        return -1;
+    }
+
+    /* Profile has been succesfully unloaded. */
+    printk ("HIL Core: Profile %s has been unloaded.\n", ptr_profile->name);
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_register_profile
+ **************************************************************************
+ * DESCRIPTION   :
+ *  The function is used to register the HIL Profile.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_register_profile (TI_HIL_PROFILE* ptr_profile)
+{
+    /* Ensure that the HIL has been initialized before proceeding. */
+    if (hil_mcb.initialized == 0)
+        return -1;
+
+    /* Validate the arguments. */
+    if (ptr_profile == NULL)
+        return -1;
+
+    /* Check if a profile already exists? */
+    if (hil_mcb.active_profile != NULL)
+    {
+        /* Profile already exists. We need to unload the profile and load the
+         * new one instead. */
+        ti_hil_unload_profile (hil_mcb.active_profile);
+
+        /* Cleanup the memory associated with the active profile. */
+        kfree (hil_mcb.active_profile);
+    }
+
+    /* Allocate memory for the HIL Profile. */
+    hil_mcb.active_profile = (TI_HIL_PROFILE *)kmalloc(sizeof(TI_HIL_PROFILE), GFP_KERNEL);
+    if (hil_mcb.active_profile == NULL)
+    {
+        /* Memory Allocation Failed. */
+        printk ("HIL Core: Unable to allocate memory for the HIL Profile %s\n", ptr_profile->name);
+        return -1;
+    }
+
+    /* Copy the profile into the active profile. */
+    memcpy ((void *)hil_mcb.active_profile, (void *)ptr_profile, sizeof(TI_HIL_PROFILE));
+
+    /* Initialize the profile. */
+    if (ti_hil_load_profile (hil_mcb.active_profile) == 0)
+        return 0;
+
+    /* Error: Unable to initialize the profile. */
+    printk ("HIL Core: HIL Profile %s failed to initialize.\n", hil_mcb.active_profile->name);
+    return -1;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_initialize
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Initialize the HIL Core Layer.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_initialize (void)
+{
+    /* Initialize the HIL Master Control Block */
+    memset ((void *)&hil_mcb, 0, sizeof(TI_HIL_MCB));
+
+    /* Register the HIL core to receive netdevice events */
+    register_netdevice_notifier(&hil_dev_notifier_block);
+
+    /* Register the HIL core to receive inet events */
+    register_inetaddr_notifier(&hil_inetaddr_notifier_block);
+
+    /* Register the HIL core to receive events */
+    atomic_notifier_chain_register(&pp_chain, &hil_pp_notifier_block);
+
+    /* The HIL core is operational now. */
+    hil_mcb.initialized = 1;
+    return 0;
+}
+
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_pp_event
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Notify the HIL of a PP event.
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_pp_event(unsigned long val, void *v)
+{
+    return atomic_notifier_call_chain(&pp_chain, val, v);
+}
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_is_gbe_device
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Return true if this is a gbe device
+ *
+ * RETURNS       :
+ *  None
+ **************************************************************************/
+int ti_hil_is_gbe_device(struct net_device *origDev)
+{
+    if (0 == strcmp(origDev->name, NSGMII0_NAME))
+    {
+        return 1;
+    }
+
+    if (0 == strcmp(origDev->name, NSGMII1_NAME))
+    {
+        return 1;
+    }
+
+    if (0 == strcmp(origDev->name, NRGMII2_NAME))
+    {
+        return 1;
+    }
+
+    if (0 == strcmp(origDev->name, NRGMII3_NAME))
+    {
+        return 1;
+    }
+
+    if (0 == strcmp(origDev->name, NGMII_TO_ATOM_NAME))
+    {
+        return 1;
+    }
+
+    return 0;
+}
+#endif
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_clone_netdev_pp_info
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Copies all the relevant PP PID information from one network device to another
+ *
+ * RETURNS       :
+ *  None
+ **************************************************************************/
+void ti_hil_clone_netdev_pp_info(struct net_device *newDev, struct net_device *origDev)
+{
+    newDev->pid_handle              = origDev->pid_handle;
+    memcpy((void *)&newDev->vpid_block, (void *)&origDev->vpid_block, sizeof(origDev->vpid_block));
+    newDev->qos_setup_hook          = origDev->qos_setup_hook;
+    newDev->qos_shutdown_hook       = origDev->qos_shutdown_hook;
+    newDev->qos_select_hook         = origDev->qos_select_hook;
+    newDev->qos_virtual_scheme_idx  = origDev->qos_virtual_scheme_idx;
+    newDev->devInstance             = origDev->devInstance;
+
+#if PUMA7_OR_NEWER_SOC_TYPE
+#ifdef CONFIG_ARM_AVALANCHE_SOC
+    if (ti_hil_is_gbe_device(origDev))
+#endif
+    {
+        if (origDev->netdev_copy_priv_hook)
+        {
+            origDev->netdev_copy_priv_hook(newDev, origDev);
+        }
+    }
+#endif
+}
+
+#ifdef CONFIG_TI_PACKET_PROCESSOR_STATS
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_register_start_session_notification
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Register the DOCSIS Packet Processor start session notification
+ *  callback function
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_register_start_session_notification(TI_HIL_START_SESSION ti_hil_start_session_notification)
+{
+    if (ti_hil_start_session_notification_cb != NULL)
+    {
+        printk ("Error: DOCSIS Packet Processor start session notification callback already exist\n");
+        return -1;
+    }
+
+    ti_hil_start_session_notification_cb = ti_hil_start_session_notification;
+
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_unregister_start_session_notification
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Un-Register the DOCSIS Packet Processor start session notification
+ *  callback function
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_unregister_start_session_notification(void)
+{
+    if (ti_hil_start_session_notification_cb == NULL)
+    {
+        printk ("Error: DOCSIS Packet Processor start session notification callback empty\n");
+        return -1;
+    }
+
+    ti_hil_start_session_notification_cb = NULL;
+
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_register_delete_session_notification
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Register the DOCSIS Packet processor delete session notification
+ *  callback function
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_register_delete_session_notification(TI_HIL_DELETE_SESSION ti_hil_delete_session_notification)
+{
+    if (ti_hil_delete_session_notification_cb != NULL)
+    {
+        printk ("Error: DOCSIS Packet Processor delete session notification callback already exist\n");
+        return -1;
+    }
+
+    ti_hil_delete_session_notification_cb = ti_hil_delete_session_notification;
+
+    return 0;
+}
+
+/**************************************************************************
+ * FUNCTION NAME : ti_hil_unregister_delete_session_notification
+ **************************************************************************
+ * DESCRIPTION   :
+ *  Un-Register the DOCSIS Packet processor delete session notification
+ *  callback function
+ *
+ * RETURNS       :
+ *  0   -   Success
+ *  <0  -   Error
+ **************************************************************************/
+int ti_hil_unregister_delete_session_notification(void)
+{
+    if (ti_hil_delete_session_notification_cb == NULL)
+    {
+        printk ("Error: DOCSIS Packet Processor delete session notification callback empty\n");
+        return -1;
+    }
+
+    ti_hil_delete_session_notification_cb = NULL;
+
+    return 0;
+}
+#endif /* CONFIG_TI_PACKET_PROCESSOR_STATS */
+
+/* Export all the Symbols for Linux; so that these can be called from modules. */
+EXPORT_SYMBOL(ti_hil_initialize);
+EXPORT_SYMBOL(ti_hil_register_profile);
+EXPORT_SYMBOL(ti_hil_pp_event);
+#ifdef CONFIG_TI_PACKET_PROCESSOR_STATS
+/* DOCSIS Packet processor start/delete session notification API */
+EXPORT_SYMBOL(ti_hil_register_start_session_notification);
+EXPORT_SYMBOL(ti_hil_unregister_start_session_notification);
+EXPORT_SYMBOL(ti_hil_register_delete_session_notification);
+EXPORT_SYMBOL(ti_hil_unregister_delete_session_notification);
+#endif /* CONFIG_TI_PACKET_PROCESSOR_STATS */
+
