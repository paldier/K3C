From 4256e78932db7f0d26c332684b07c89f47ffe528 Mon Sep 17 00:00:00 2001
From: Pawan Gupta <pawan.kumarx.gupta@intel.com>
Date: Fri, 17 Jun 2016 13:18:35 -0700
Subject: [PATCH 424/441] mmc: Merge Puma6 and Puma7

puma7 source is conditionally compiled ifdef CONFIG_X86_PUMA7
Signed-off-by: Pawan Gupta <pawan.kumarx.gupta@intel.com>

mmc: puma6 specific src moved under ifdef

puma6 specific src moved under ifdef CONFIG_X86_PUMA6

Signed-off-by: Pawan Gupta <pawan.kumarx.gupta@intel.com>
---
 drivers/mmc/card/block.c      | 797 +++++++++++++++++++++++++++++++++++++++++-
 drivers/mmc/card/queue.c      | 183 +++++++++-
 drivers/mmc/card/queue.h      |  15 +
 drivers/mmc/core/bus.c        |  44 +++
 drivers/mmc/core/core.c       | 557 ++++++++++++++++++++++++++++-
 drivers/mmc/core/core.h       |  12 +
 drivers/mmc/core/debugfs.c    |   5 +
 drivers/mmc/core/host.c       |  12 +
 drivers/mmc/core/mmc.c        | 598 ++++++++++++++++++++++++++++++-
 drivers/mmc/core/mmc_ops.c    |  51 ++-
 drivers/mmc/core/sd.c         | 134 ++++++-
 drivers/mmc/core/sd.h         |   1 +
 drivers/mmc/core/sdio.c       | 198 ++++++++++-
 drivers/mmc/core/sdio_bus.c   |  36 ++
 drivers/mmc/core/sdio_io.c    |   0
 drivers/mmc/core/sdio_irq.c   |   2 +
 drivers/mmc/core/sdio_ops.c   |   9 +
 drivers/mmc/host/Kconfig      |   1 -
 drivers/mmc/host/sdhci-acpi.c |  94 +++--
 drivers/mmc/host/sdhci-pci.c  | 310 +++++++++++++---
 drivers/mmc/host/sdhci-pci.h  |   3 +
 drivers/mmc/host/sdhci.c      | 415 +++++++++++++++++++++-
 drivers/mmc/host/sdhci.h      |  13 +
 include/linux/mmc/bp.h        |  91 +++++
 include/linux/mmc/card.h      |  39 +++
 include/linux/mmc/core.h      |  28 +-
 include/linux/mmc/host.h      |  33 ++
 include/linux/mmc/mmc.h       |  33 ++
 include/linux/mmc/pm.h        |   2 +
 include/linux/mmc/sdhci.h     |  70 +++-
 30 files changed, 3657 insertions(+), 129 deletions(-)
 mode change 100755 => 100644 drivers/mmc/core/sdio_io.c
 mode change 100755 => 100644 drivers/mmc/host/Kconfig
 create mode 100644 include/linux/mmc/bp.h
 mode change 100755 => 100644 include/linux/mmc/host.h
 mode change 100755 => 100644 include/linux/mmc/sdhci.h

--- a/drivers/mmc/card/block.c
+++ b/drivers/mmc/card/block.c
@@ -36,9 +36,11 @@
 #include <linux/compat.h>
 #include <linux/pm_runtime.h>
 
+#ifdef CONFIG_X86_PUMA7
 #define CREATE_TRACE_POINTS
 #include <trace/events/mmc.h>
 
+#endif
 #include <linux/mmc/ioctl.h>
 #include <linux/mmc/card.h>
 #include <linux/mmc/host.h>
@@ -49,6 +51,9 @@
 
 #include "queue.h"
 
+#include <linux/mmc/bp.h>
+#include "../core/mmc_ops.h"
+
 MODULE_ALIAS("mmc:block");
 #ifdef MODULE_PARAM_PREFIX
 #undef MODULE_PARAM_PREFIX
@@ -111,7 +116,9 @@ struct mmc_blk_data {
 #define MMC_BLK_WRITE		BIT(1)
 #define MMC_BLK_DISCARD		BIT(2)
 #define MMC_BLK_SECDISCARD	BIT(3)
+#ifdef CONFIG_X86_PUMA7
 #define MMC_BLK_CMDQ		BIT(4)
+#endif
 
 	/*
 	 * Only set in main mmc_blk_data associated
@@ -140,10 +147,12 @@ static inline int mmc_blk_part_switch_to
 static inline int mmc_blk_part_switch(struct mmc_card *card,
 				      struct mmc_blk_data *md);
 static int get_card_status(struct mmc_card *card, u32 *status, int retries);
+#ifdef CONFIG_X86_PUMA7
 static int mmc_blk_issue_rw_rq(struct mmc_queue *mq,
 		struct request *rqc, bool urgent);
 static int mmc_blk_queue_cmdq_req(struct mmc_queue *mq,
 		struct mmc_queue_req *mqrq, unsigned long *);
+#endif
 
 static inline void mmc_blk_clear_packed(struct mmc_queue_req *mqrq)
 {
@@ -175,7 +184,15 @@ static struct mmc_blk_data *mmc_blk_get(
 
 static inline int mmc_get_devidx(struct gendisk *disk)
 {
+#ifndef CONFIG_X86_PUMA7
+	int devmaj = MAJOR(disk_devt(disk));
+	int devidx = MINOR(disk_devt(disk)) / perdev_minors;
+
+	if (!devmaj)
+		devidx = disk->first_minor / perdev_minors;
+#else
 	int devidx = disk->first_minor / perdev_minors;
+#endif
 	return devidx;
 }
 
@@ -435,9 +452,11 @@ static int ioctl_do_sanitize(struct mmc_
 		mmc_hostname(card->host), __func__);
 
 	trace_mmc_blk_erase_start(EXT_CSD_SANITIZE_START, 0, 0);
+
 	err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 					EXT_CSD_SANITIZE_START, 1,
 					MMC_SANITIZE_REQ_TIMEOUT);
+
 	trace_mmc_blk_erase_end(EXT_CSD_SANITIZE_START, 0, 0);
 
 	if (err)
@@ -622,10 +641,580 @@ cmd_err:
 	return err;
 }
 
-static int mmc_blk_ioctl(struct block_device *bdev, fmode_t mode,
-	unsigned int cmd, unsigned long arg)
+static int mmc_blk_bp_getinfo(struct mmc_blk_data *md, unsigned long arg)
+{
+	struct mmc_card *card;
+	struct mmc_bp_info bp;
+	int boot;
+
+	if(!md)
+		return -ENXIO;
+
+	card = md->queue.card;
+
+	if(!card)
+		return -ENXIO;
+
+	memset(&bp, 0, sizeof(struct mmc_bp_info));
+	bp.sectors = card->ext_csd.boot_size_mult * (MMC_BP_UNIT_SIZE/MMC_SECTOR_SIZE);
+
+	boot = (card->ext_csd.boot_config >> 3) & 0x07;
+	switch (boot) {
+	case 0:
+		bp.booten = MMC_BOOT_EN_NONE;
+		break;
+	case 1:
+		bp.booten = MMC_BOOT_EN_BP0;
+		break;
+	case 2:
+		bp.booten = MMC_BOOT_EN_BP1;
+		break;
+	case 7:
+		bp.booten = MMC_BOOT_EN_USER;
+		break;
+	default:
+		bp.booten = MMC_BOOT_EN_RESV;
+	}
+
+
+	if(copy_to_user((void __user *) arg, &bp, sizeof(struct mmc_bp_info)))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int mmc_blk_gp_getinfo(struct mmc_blk_data *md, unsigned long arg)
+{
+	struct mmc_card *card;
+	struct mmc_gp_info gp;
+	int i;
+
+	if(!md)
+		return -ENXIO;
+
+	card = md->queue.card;
+
+	if(!card)
+		return -ENXIO;
+
+	memset(&gp, 0, sizeof(struct mmc_gp_info));
+	for (i=0; i < 4; i++)
+		gp.sectors[i] = card->ext_csd.gp_size[i];
+
+	if(copy_to_user((void __user *) arg, &gp, sizeof(struct mmc_gp_info)))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int mmc_blk_card_getinfo(struct mmc_blk_data *md, unsigned long arg)
+{
+	struct mmc_card *card;
+	struct mmc_card_info info;
+
+	if(!md)
+		return -ENXIO;
+
+	card = md->queue.card;
+
+	if(!card)
+		return -ENXIO;
+
+	memset(&info, 0, sizeof(struct mmc_card_info));
+	info.rca = card->rca;
+
+	if(copy_to_user((void __user *) arg, &info, sizeof(struct mmc_card_info)))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int mmc_blk_bp_set_acc(struct mmc_card *card, unsigned char mode)
+{
+	unsigned char val;
+
+	val = (card->ext_csd.boot_config & 0xF8) | mode;
+	return mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_BOOT_CONFIG, val, 0);
+}
+
+static int mmc_blk_set_erase_grp_def(struct mmc_card *card, unsigned char mode)
+{
+	return mmc_switch(card, EXT_CSD_CMD_SET_NORMAL, EXT_CSD_ERASE_GROUP_DEF, mode, 0);
+}
+
+static int mmc_blk_bp_rw(struct mmc_blk_data *md, unsigned long arg, int part_type)
+{
+	struct mmc_queue *mq;
+	struct mmc_card *card;
+	struct mmc_blk_request brq;
+	struct mmc_bp_rw bprw;
+	int retval = 0;
+	unsigned char dest_part = 0;
+
+	if(!md)
+		return -ENXIO;
+
+
+	mq = &md->queue;
+	if(!mq)
+		return -ENXIO;
+
+	if(!mq->mqrq_cur)
+		return -ENXIO;
+
+	card = md->queue.card;
+	if(!card)
+		return -ENXIO;
+
+	if((part_type == 1) && (!(card->ext_csd.boot_size_mult))) {
+		printk("No boot partition in the card\n");
+		return -ENODEV;
+	}
+
+	if((!mq->mqrq_cur->bp_sg) || (!mq->mqrq_cur->bp_buf))
+		return -ENOMEM;
+
+	memset(&bprw, 0, sizeof(struct mmc_bp_rw));
+
+	if(copy_from_user(&bprw, (void __user *) arg, sizeof(struct mmc_bp_rw)))
+		return -EFAULT;
+
+	if((part_type == 1) && (bprw.which > MAX_NUM_OF_BOOT_PARTITIONS)) {
+		printk("Invalid boot partition number\n");
+		return -EINVAL;
+	}
+
+	if((part_type == 2) && (bprw.which > 3)) {
+		printk("Invalid gp partition number\n");
+		return -EINVAL;
+	}
+
+	if((part_type == 2) && (!(card->ext_csd.gp_size[bprw.which]))) {
+		printk("Gp %d doesn't exist\n", bprw.which);
+		return -ENODEV;
+	}
+
+	if((bprw.dir != BP_DIR_READ) && (bprw.dir != BP_DIR_WRITE)) {
+		printk("Invalid access direction\n");
+		return -EINVAL;
+	}
+
+	if(bprw.nr_sectors > MAX_NUM_OF_SECTORS_TRANSFERD) {
+		printk("Too many sectors to be tranferred\n");
+		return -EINVAL;
+	}
+
+	if((part_type == 1) && ((bprw.st_sector + bprw.nr_sectors) > (card->ext_csd.boot_size_mult * (MMC_BP_UNIT_SIZE/MMC_SECTOR_SIZE)))) {
+		printk("Access beyond bp size limit\n");
+		return -EINVAL;
+	}
+
+	if((part_type == 2) && ((bprw.st_sector + bprw.nr_sectors) > (card->ext_csd.gp_size[bprw.which]))) {
+		printk("Access beyond gp size limit\n");
+		return -EINVAL;
+	}
+
+	mmc_claim_host(card->host);
+
+	if(bprw.dir == BP_DIR_WRITE) {
+		if(copy_from_user(mq->mqrq_cur->bp_buf, (void __user *) bprw.buf, bprw.nr_sectors * MMC_SECTOR_SIZE)) {
+
+			mmc_blk_part_switch_to_up(card);
+			mmc_release_host(card->host);
+			return -EFAULT;
+		}
+	}
+
+	if(part_type == 2) {
+		if(mmc_blk_set_erase_grp_def(card, 1)) {
+			printk("Error setting erase group def\n");
+
+			mmc_blk_part_switch_to_up(card);
+			mmc_release_host(card->host);
+			return -EFAULT;
+		}
+	}
+
+	if(part_type == 1)
+		dest_part = bprw.which + 1;
+	else if(part_type == 2)
+		dest_part = bprw.which + 4;
+
+	if(mmc_blk_bp_set_acc(card, dest_part)) {
+		printk("Error switching partition access\n");
+
+		mmc_blk_part_switch_to_up(card);
+		mmc_release_host(card->host);
+		return -EFAULT;
+	}
+
+	do {
+		struct mmc_command cmd;
+		u32 readcmd, writecmd;
+
+		memset(&brq, 0, sizeof(struct mmc_blk_request));
+		brq.mrq.cmd = &brq.cmd;
+		brq.mrq.data = &brq.data;
+
+		brq.cmd.arg = bprw.st_sector;
+		if (!mmc_card_blockaddr(card))
+			brq.cmd.arg <<= 9;
+		brq.cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_ADTC;
+		brq.data.blksz = MMC_SECTOR_SIZE;
+		brq.stop.opcode = MMC_STOP_TRANSMISSION;
+		brq.stop.arg = 0;
+		brq.stop.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
+		brq.data.blocks = bprw.nr_sectors;
+
+		if (brq.data.blocks > 1) {
+			/* SPI multiblock writes terminate using a special
+			 * token, not a STOP_TRANSMISSION request.
+			 */
+			if (!mmc_host_is_spi(card->host)
+					|| bprw.dir == BP_DIR_READ)
+				brq.mrq.stop = &brq.stop;
+			readcmd = MMC_READ_MULTIPLE_BLOCK;
+			writecmd = MMC_WRITE_MULTIPLE_BLOCK;
+		} else {
+			brq.mrq.stop = NULL;
+			readcmd = MMC_READ_SINGLE_BLOCK;
+			writecmd = MMC_WRITE_BLOCK;
+		}
+
+		if (bprw.dir == BP_DIR_READ) {
+			brq.cmd.opcode = readcmd;
+			brq.data.flags |= MMC_DATA_READ;
+		} else {
+			brq.cmd.opcode = writecmd;
+			brq.data.flags |= MMC_DATA_WRITE;
+		}
+
+		mmc_set_data_timeout(&brq.data, card);
+
+		brq.data.sg = mq->mqrq_cur->bp_sg;
+		sg_init_one(mq->mqrq_cur->bp_sg, mq->mqrq_cur->bp_buf, bprw.nr_sectors * MMC_SECTOR_SIZE);
+		brq.data.sg_len = 1;
+
+		mmc_wait_for_req(card->host, &brq.mrq);
+
+		/*
+		 * Check for errors here, but don't jump to cmd_err
+		 * until later as we need to wait for the card to leave
+		 * programming mode even when things go wrong.
+		 */
+		if (brq.cmd.error)
+			printk("Error sending read/write command\n");
+
+		if (brq.data.error)
+			printk("Error transferring data\n");
+
+		if (brq.stop.error)
+			printk("Error sending stop command\n");
+
+		if (!mmc_host_is_spi(card->host) && bprw.dir != BP_DIR_READ) {
+			do {
+				int err;
+
+				cmd.opcode = MMC_SEND_STATUS;
+				cmd.arg = card->rca << 16;
+				cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+				err = mmc_wait_for_cmd(card->host, &cmd, 5);
+				if (err) {
+					printk("Error requesting status\n");
+					goto cmd_err;
+				}
+				/*
+				 * Some cards mishandle the status bits,
+				 * so make sure to check both the busy
+				 * indication and the card state.
+				 */
+			} while (!(cmd.resp[0] & R1_READY_FOR_DATA) ||
+				(R1_CURRENT_STATE(cmd.resp[0]) == 7));
+		}
+
+		if (brq.cmd.error || brq.data.error || brq.stop.error)
+			goto cmd_err;
+
+	} while (0);
+
+	if(bprw.dir == BP_DIR_READ) {
+		if(copy_to_user((void __user *) bprw.buf, mq->mqrq_cur->bp_buf, bprw.nr_sectors * MMC_SECTOR_SIZE))
+			retval = -EFAULT;
+	}
+
+	if(mmc_blk_bp_set_acc(card, 0)) {
+		printk("Error setting back to user partition access\n");
+		retval =  -EFAULT;
+	}
+
+	if(part_type == 2) {
+		if(mmc_blk_set_erase_grp_def(card, card->ext_csd.erase_group_def & 0x1)) {
+			printk("Error setting erase group def\n");
+			retval = -EFAULT;
+		}
+	}
+
+	mmc_blk_part_switch_to_up(card);
+	mmc_release_host(card->host);
+
+	return retval;
+
+ cmd_err:
+	if(mmc_blk_bp_set_acc(card, 0))
+		printk("Error setting back to user partition access\n");
+
+	if(part_type == 2) {
+		if(mmc_blk_set_erase_grp_def(card, card->ext_csd.erase_group_def & 0x1))
+			printk("Error setting erase group def\n");
+	}
+
+	mmc_blk_part_switch_to_up(card);
+	mmc_release_host(card->host);
+
+	return -ENXIO;
+}
+
+static int mmc_blk_cmd_nodata(struct mmc_card *card, struct mmc_arb_cmd *parbcmd)
+{
+	struct mmc_command cmd;
+	int err;
+
+	if(!parbcmd->resp) {
+		printk("Response buffer is NULL\n");
+		return -EINVAL;
+	}
+
+	memset(&cmd, 0, sizeof(struct mmc_command));
+
+	cmd.opcode = parbcmd->opcode;
+	cmd.arg = parbcmd->arg;
+	cmd.flags = parbcmd->cmdflags;
+
+	mmc_claim_host(card->host);
+
+	err = mmc_wait_for_cmd(card->host, &cmd, 0);
+	if (err) {
+		printk("Command fail, opcode is %d, error is %d\n", cmd.opcode, err);
+
+		mmc_blk_part_switch_to_up(card);
+		mmc_release_host(card->host);
+		return err;
+	}
+
+	if(copy_to_user((void __user *) parbcmd->resp, cmd.resp, sizeof(u32) * 4)) {
+		mmc_blk_part_switch_to_up(card);
+		mmc_release_host(card->host);
+		return -EFAULT;
+	}
+
+	mmc_blk_part_switch_to_up(card);
+	mmc_release_host(card->host);
+
+	return 0;
+}
+
+static int mmc_blk_cmd_data(struct mmc_blk_data *md, struct mmc_arb_cmd *parbcmd)
+{
+	struct mmc_queue *mq;
+	struct mmc_card *card;
+	struct mmc_blk_request brq;
+	int retval = 0;
+
+	mq = &md->queue;
+
+	card = md->queue.card;
+
+	if(!mq->mqrq_cur)
+		return -ENXIO;
+
+	if((!mq->mqrq_cur->bp_sg) || (!mq->mqrq_cur->bp_buf))
+		return -ENOMEM;
+
+	if(!parbcmd->resp) {
+		printk("Response buffer is NULL\n");
+		return -EINVAL;
+	}
+
+	if(parbcmd->datalen > (MAX_NUM_OF_SECTORS_TRANSFERD * MMC_SECTOR_SIZE)) {
+		printk("Too many data to be tranferred\n");
+		return -EINVAL;
+	}
+
+	if(parbcmd->datalen % 512) {
+		printk("Data length is not multiples of 512\n");
+		return -EINVAL;
+	}
+
+	mmc_claim_host(card->host);
+
+	if(parbcmd->datadir) {
+		if(copy_from_user(mq->mqrq_cur->bp_buf, (void __user *) parbcmd->databuf, parbcmd->datalen)) {
+			mmc_blk_part_switch_to_up(card);
+			mmc_release_host(card->host);
+			return -EFAULT;
+		}
+	}
+
+	do {
+		struct mmc_command cmd;
+
+		memset(&brq, 0, sizeof(struct mmc_blk_request));
+		brq.mrq.cmd = &brq.cmd;
+		brq.mrq.data = &brq.data;
+
+		brq.cmd.arg = parbcmd->arg;
+		brq.cmd.flags = parbcmd->cmdflags;
+		brq.data.blksz = MMC_SECTOR_SIZE;
+		brq.stop.opcode = MMC_STOP_TRANSMISSION;
+		brq.stop.arg = 0;
+		brq.stop.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
+		brq.data.blocks = parbcmd->datalen / 512;
+
+		if(parbcmd->stop)
+			brq.mrq.stop = &brq.stop;
+		else
+			brq.mrq.stop = NULL;
+
+		brq.cmd.opcode = parbcmd->opcode;
+		brq.data.flags = parbcmd->dataflags;
+
+		mmc_set_data_timeout(&brq.data, card);
+
+		brq.data.sg = mq->mqrq_cur->bp_sg;
+		sg_init_one(mq->mqrq_cur->bp_sg, mq->mqrq_cur->bp_buf, parbcmd->datalen);
+		brq.data.sg_len = 1;
+
+		mmc_wait_for_req(card->host, &brq.mrq);
+
+		/*
+		 * Check for errors here, but don't jump to cmd_err
+		 * until later as we need to wait for the card to leave
+		 * programming mode even when things go wrong.
+		 */
+		if (brq.cmd.error)
+			printk("Error sending read/write command\n");
+
+		if (brq.data.error)
+			printk("Error transferring data\n");
+
+		if (brq.stop.error)
+			printk("Error sending stop command\n");
+
+		if (parbcmd->dataready) {
+			do {
+				int err;
+
+				cmd.opcode = MMC_SEND_STATUS;
+				cmd.arg = card->rca << 16;
+				cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+				err = mmc_wait_for_cmd(card->host, &cmd, 5);
+				if (err) {
+					printk("Error requesting status\n");
+					goto cmd_err;
+				}
+				/*
+				 * Some cards mishandle the status bits,
+				 * so make sure to check both the busy
+				 * indication and the card state.
+				 */
+			} while (!(cmd.resp[0] & R1_READY_FOR_DATA) ||
+				(R1_CURRENT_STATE(cmd.resp[0]) == 7));
+		}
+
+		if (brq.cmd.error || brq.data.error || brq.stop.error)
+			goto cmd_err;
+
+	} while (0);
+
+	if(!parbcmd->datadir) {
+		if(copy_to_user((void __user *) parbcmd->databuf, mq->mqrq_cur->bp_buf, parbcmd->datalen))
+				retval = -EFAULT;
+	}
+
+	if(copy_to_user((void __user *) parbcmd->resp, brq.cmd.resp, sizeof(u32) * 4))
+			retval = -EFAULT;
+
+	mmc_blk_part_switch_to_up(card);
+	mmc_release_host(card->host);
+
+	return retval;
+
+ cmd_err:
+	mmc_blk_part_switch_to_up(card);
+	mmc_release_host(card->host);
+
+	return -ENXIO;
+}
+
+static int mmc_blk_arb_cmd(struct mmc_blk_data *md, unsigned long arg)
+{
+	struct mmc_queue *mq;
+	struct mmc_card *card;
+	struct mmc_arb_cmd arbcmd;
+
+	if(!md)
+		return -ENXIO;
+
+	mq = &md->queue;
+	if(!mq)
+		return -ENXIO;
+
+	card = md->queue.card;
+	if(!card)
+		return -ENXIO;
+
+	memset(&arbcmd, 0, sizeof(struct mmc_arb_cmd));
+
+	if(copy_from_user(&arbcmd, (void __user *) arg, sizeof(struct mmc_arb_cmd)))
+		return -EFAULT;
+
+	if(!arbcmd.databuf || !arbcmd.datalen)
+		return mmc_blk_cmd_nodata(card, &arbcmd);
+	else
+		return mmc_blk_cmd_data(md, &arbcmd);
+
+}
+
+DEFINE_MUTEX(mmc_ioctl_mutex);
+int mmc_in_suspend = 0;
+
+static int mmc_blk_ioctl(struct block_device *bdev, fmode_t mode, unsigned int cmd, unsigned long arg)
 {
 	int ret = -EINVAL;
+#ifdef CONFIG_X86_PUMA6
+	mutex_lock(&mmc_ioctl_mutex);
+
+	if (mmc_in_suspend) {
+		mutex_unlock(&mmc_ioctl_mutex);
+		return -ENODEV;
+	}
+
+	switch (cmd) {
+	case MMC_BLK_IOCTL_BP_GETINFO:
+		ret = mmc_blk_bp_getinfo(bdev->bd_disk->private_data, arg);
+		break;
+	case MMC_BLK_IOCTL_GP_GETINFO:
+		ret = mmc_blk_gp_getinfo(bdev->bd_disk->private_data, arg);
+		break;
+	case MMC_BLK_IOCTL_BP_RDWR:
+		ret = mmc_blk_bp_rw(bdev->bd_disk->private_data, arg, 1);
+		break;
+	case MMC_BLK_IOCTL_GP_RDWR:
+		ret = mmc_blk_bp_rw(bdev->bd_disk->private_data, arg, 2);
+		break;
+	case MMC_BLK_IOCTL_ARB_CMD:
+		ret = mmc_blk_arb_cmd(bdev->bd_disk->private_data, arg);
+		break;
+	case MMC_BLK_IOCTL_CARD_INFO:
+		ret = mmc_blk_card_getinfo(bdev->bd_disk->private_data, arg);
+		break;
+	default:
+		ret = -ENOTTY;
+	}
+
+	mutex_unlock(&mmc_ioctl_mutex);
+#endif
+
 	if (cmd == MMC_IOC_CMD)
 		ret = mmc_blk_ioctl_cmd(bdev, (struct mmc_ioc_cmd __user *)arg);
 	return ret;
@@ -650,6 +1239,7 @@ static const struct block_device_operati
 #endif
 };
 
+#ifdef CONFIG_X86_PUMA7
 static inline int mmc_blk_part_switch_to_up(struct mmc_card *card)
 {
 	struct mmc_blk_data *main_md = mmc_get_drvdata(card);
@@ -658,6 +1248,7 @@ static inline int mmc_blk_part_switch_to
 	WARN_ON(main_md->part_type != EXT_CSD_PART_CONFIG_USER);
 	return mmc_blk_part_switch(card, main_md);
 }
+#endif
 
 static inline int mmc_blk_part_switch(struct mmc_card *card,
 				      struct mmc_blk_data *md)
@@ -670,6 +1261,7 @@ static inline int mmc_blk_part_switch(st
 
 	if (mmc_card_mmc(card)) {
 		u8 part_config = card->ext_csd.part_config;
+#ifdef CONFIG_X86_PUMA7
 		struct mmc_host *host = card->host;
 
 		/*
@@ -719,6 +1311,7 @@ static inline int mmc_blk_part_switch(st
 				card->ext_csd.cmdq_en)
 			pm_suspend_ignore_children(&card->host->class_dev,
 					false);
+#endif
 
 		part_config &= ~EXT_CSD_PART_CONFIG_ACC_MASK;
 		part_config |= md->part_type;
@@ -733,10 +1326,39 @@ static inline int mmc_blk_part_switch(st
 	}
 
 	main_md->part_curr = md->part_type;
+#ifdef CONFIG_X86_PUMA7
 	main_md->mq_curr = &md->queue;
+#endif
 	return 0;
 }
 
+#ifdef CONFIG_X86_PUMA6
+static inline int mmc_blk_part_switch_to_up(struct mmc_card *card)
+{
+        int ret;
+        struct mmc_blk_data *main_md = mmc_get_drvdata(card);
+        if (main_md->part_curr == 0)
+                return 0;
+        if (mmc_card_mmc(card)) {
+                u8 part_config = card->ext_csd.part_config;
+
+                part_config &= ~EXT_CSD_PART_CONFIG_ACC_MASK;
+                part_config |= 0;
+
+                ret = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+                                 EXT_CSD_PART_CONFIG, part_config,
+                                 card->ext_csd.part_time);
+                if (ret)
+                        return ret;
+
+                card->ext_csd.part_config = part_config;
+        }
+
+        main_md->part_curr = 0;
+        return 0;
+}
+#endif
+
 static u32 mmc_sd_num_wr_blocks(struct mmc_card *card)
 {
 	int err;
@@ -963,9 +1585,14 @@ static int mmc_blk_cmd_recovery(struct m
 	}
 
 	/* Check for set block count errors */
+#ifndef CONFIG_X86_PUMA7
+	if (brq->sbc.error)
+		return mmc_blk_cmd_error(req, "SET_BLOCK_COUNT", brq->sbc.error,
+#else
 	if (brq->precmd.error)
 		return mmc_blk_cmd_error(req, "SET_BLOCK_COUNT",
 				brq->precmd.error,
+#endif
 				prev_cmd_status_valid, status);
 
 	/* Check for r/w command errors */
@@ -1138,8 +1765,7 @@ retry:
 			goto out;
 	}
 
-
-
+#ifdef CONFIG_X86_PUMA7
 	if (mmc_can_sanitize(card)) {
 		err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 				 EXT_CSD_SANITIZE_START, 1, 0, false, false);
@@ -1147,6 +1773,7 @@ retry:
 		if (!err)
 			err = mmc_busy_wait(card->host);
 	}
+#endif
 
 out_retry:
 	if (err && !mmc_blk_reset(md, card->host, type))
@@ -1224,7 +1851,11 @@ static int mmc_blk_err_check(struct mmc_
 	 * stop.error indicates a problem with the stop command.  Data
 	 * may have been transferred, or may still be transferring.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (brq->sbc.error || brq->cmd.error || brq->stop.error ||
+#else
 	if (brq->precmd.error || brq->cmd.error || brq->stop.error ||
+#endif
 	    brq->data.error) {
 		switch (mmc_blk_cmd_recovery(card, req, brq, &ecc_err, &gen_err)) {
 		case ERR_RETRY:
@@ -1412,13 +2043,19 @@ static void mmc_blk_rw_rq_prep(struct mm
 
 	/*
 	 * Reliable writes are used to implement Forced Unit Access and
-	 * are supported only on MMCs.
+	 * REQ_META accesses, and are supported only on MMCs.
+	 *
+	 * XXX: this really needs a good explanation of why REQ_META
+	 * is treated special.
 	 */
-	bool do_rel_wr = (req->cmd_flags & REQ_FUA) &&
+	bool do_rel_wr = ((req->cmd_flags & REQ_FUA) ||
+			  (req->cmd_flags & REQ_META)) &&
 		(rq_data_dir(req) == WRITE) &&
 		(md->flags & MMC_BLK_REL_WR);
+#ifdef CONFIG_X86_PUMA7
 	bool cmdq_en  = card->ext_csd.cmdq_en ? true : false;
 	bool read = (rq_data_dir(req) == READ) ? true : false;
+#endif
 
 	memset(brq, 0, sizeof(struct mmc_blk_request));
 	brq->mrq.cmd = &brq->cmd;
@@ -1427,15 +2064,22 @@ static void mmc_blk_rw_rq_prep(struct mm
 	brq->cmd.arg = blk_rq_pos(req);
 	if (!mmc_card_blockaddr(card))
 		brq->cmd.arg <<= 9;
+#ifndef CONFIG_X86_PUMA7
+	brq->cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_ADTC;
+	brq->data.blksz = 512;
+#else
 	if (!cmdq_en)
 		brq->cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_ADTC;
 	else
 		brq->cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+#endif
 	brq->stop.opcode = MMC_STOP_TRANSMISSION;
 	brq->stop.arg = 0;
 	brq->stop.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
 	brq->data.blocks = blk_rq_sectors(req);
+#ifdef CONFIG_X86_PUMA7
 	brq->data.blksz = 512;
+#endif
 
 	/*
 	 * The block layer doesn't support all sector count
@@ -1455,19 +2099,33 @@ static void mmc_blk_rw_rq_prep(struct mm
 			brq->data.blocks = 1;
 
 		/* Some controllers can't do multiblock reads due to hw bugs */
+#ifndef CONFIG_X86_PUMA7
+		if (card->host->caps2 & MMC_CAP2_NO_MULTI_READ &&
+		    rq_data_dir(req) == READ)
+#else
 		if (card->host->caps2 & MMC_CAP2_NO_MULTI_READ && read)
+#endif
 			brq->data.blocks = 1;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	if (brq->data.blocks > 1 || do_rel_wr) {
+#else
 	/* CMDQ doesn't require stop cmd, and use CMD45 for mrq.cmd */
 	if (cmdq_en) {
 		brq->mrq.stop = NULL;
 		readcmd = writecmd = MMC_QUE_TASK_ADDR;
 	} else if (brq->data.blocks > 1 || do_rel_wr) {
+#endif
 		/* SPI multiblock writes terminate using a special
 		 * token, not a STOP_TRANSMISSION request.
 		 */
+#ifndef CONFIG_X86_PUMA7
+		if (!mmc_host_is_spi(card->host) ||
+		    rq_data_dir(req) == READ)
+#else
 		if (!mmc_host_is_spi(card->host) || read)
+#endif
 			brq->mrq.stop = &brq->stop;
 		readcmd = MMC_READ_MULTIPLE_BLOCK;
 		writecmd = MMC_WRITE_MULTIPLE_BLOCK;
@@ -1476,8 +2134,12 @@ static void mmc_blk_rw_rq_prep(struct mm
 		readcmd = MMC_READ_SINGLE_BLOCK;
 		writecmd = MMC_WRITE_BLOCK;
 	}
+#ifndef CONFIG_X86_PUMA7
+	if (rq_data_dir(req) == READ) {
+#else
 
 	if (read) {
+#endif
 		brq->cmd.opcode = readcmd;
 		brq->data.flags |= MMC_DATA_READ;
 	} else {
@@ -1507,7 +2169,7 @@ static void mmc_blk_rw_rq_prep(struct mm
 	 * with Auto-CMD23 enhancements provided by some
 	 * hosts, means that the complexity of dealing
 	 * with this is best left to the host. If CMD23 is
-	 * supported by card and host, we'll fill precmd in and let
+	 * supported by card and host, we'll fill sbc in and let
 	 * the host deal with handling it correctly. This means
 	 * that for hosts that don't expose MMC_CAP_CMD23, no
 	 * change of behavior will be observed.
@@ -1515,10 +2177,10 @@ static void mmc_blk_rw_rq_prep(struct mm
 	 * N.B: Some MMC cards experience perf degradation.
 	 * We'll avoid using CMD23-bounded multiblock writes for
 	 * these, while retaining features like reliable writes.
-	 *
-	 * If CMDQ is enabled, then we use CMD44 for precmd, and
-	 * CMD46/47 for postcmd
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if ((md->flags & MMC_BLK_CMD23) && mmc_op_multi(brq->cmd.opcode) &&
+#else
 	if (cmdq_en) {
 		brq->precmd.opcode = MMC_QUE_TASK_PARAMS;
 		brq->precmd.arg = brq->data.blocks |
@@ -1544,14 +2206,25 @@ static void mmc_blk_rw_rq_prep(struct mm
 		brq->mrq.cmd2 = &brq->cmd2;
 	} else if ((md->flags & MMC_BLK_CMD23) &&
 			mmc_op_multi(brq->cmd.opcode) &&
+#endif
 	    (do_rel_wr || !(card->quirks & MMC_QUIRK_BLK_NO_CMD23) ||
 	     do_data_tag)) {
+#ifndef CONFIG_X86_PUMA7
+		brq->sbc.opcode = MMC_SET_BLOCK_COUNT;
+		brq->sbc.arg = brq->data.blocks |
+#else
 		brq->precmd.opcode = MMC_SET_BLOCK_COUNT;
 		brq->precmd.arg = brq->data.blocks |
+#endif
 			(do_rel_wr ? (1 << 31) : 0) |
 			(do_data_tag ? (1 << 29) : 0);
+#ifndef CONFIG_X86_PUMA7
+		brq->sbc.flags = MMC_RSP_R1 | MMC_CMD_AC;
+		brq->mrq.sbc = &brq->sbc;
+#else
 		brq->precmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
 		brq->mrq.precmd = &brq->precmd;
+#endif
 	}
 
 	mmc_set_data_timeout(&brq->data, card);
@@ -1580,6 +2253,7 @@ static void mmc_blk_rw_rq_prep(struct mm
 
 	mqrq->mmc_active.mrq = &brq->mrq;
 	mqrq->mmc_active.err_check = mmc_blk_err_check;
+
 	mmc_queue_bounce_pre(mqrq);
 }
 
@@ -1759,12 +2433,22 @@ static void mmc_blk_packed_hdr_wrq_prep(
 	memset(brq, 0, sizeof(struct mmc_blk_request));
 	brq->mrq.cmd = &brq->cmd;
 	brq->mrq.data = &brq->data;
+#ifndef CONFIG_X86_PUMA7
+	brq->mrq.sbc = &brq->sbc;
+#else
 	brq->mrq.precmd = &brq->precmd;
+#endif
 	brq->mrq.stop = &brq->stop;
 
+#ifndef CONFIG_X86_PUMA7
+	brq->sbc.opcode = MMC_SET_BLOCK_COUNT;
+	brq->sbc.arg = MMC_CMD23_ARG_PACKED | (packed->blocks + hdr_blocks);
+	brq->sbc.flags = MMC_RSP_R1 | MMC_CMD_AC;
+#else
 	brq->precmd.opcode = MMC_SET_BLOCK_COUNT;
 	brq->precmd.arg = MMC_CMD23_ARG_PACKED | (packed->blocks + hdr_blocks);
 	brq->precmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+#endif
 
 	brq->cmd.opcode = MMC_WRITE_MULTIPLE_BLOCK;
 	brq->cmd.arg = blk_rq_pos(req);
@@ -1892,7 +2576,11 @@ static void mmc_blk_revert_packed_req(st
 	mmc_blk_clear_packed(mq_rq);
 }
 
+#ifndef CONFIG_X86_PUMA7
+static int mmc_blk_issue_rw_rq(struct mmc_queue *mq, struct request *rqc)
+#else
 static int mmc_blk_issue_normal_rw_rq(struct mmc_queue *mq, struct request *rqc)
+#endif
 {
 	struct mmc_blk_data *md = mq->data;
 	struct mmc_card *card = md->queue.card;
@@ -1905,13 +2593,23 @@ static int mmc_blk_issue_normal_rw_rq(st
 	const u8 packed_nr = 2;
 	u8 reqs = 0;
 
+#ifndef CONFIG_X86_PUMA7
+	if (!rqc && !mq->mqrq_prev->req)
+#else
 	if (!rqc && !atomic_read(&mq->active_slots))
+#endif
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	if (rqc)
+#else
 	if (rqc) {
+#endif
 		reqs = mmc_blk_prep_packed_list(mq, rqc);
+#ifdef CONFIG_X86_PUMA7
 		atomic_inc(&mq->active_slots);
 	}
+#endif
 
 	do {
 		if (rqc) {
@@ -1936,8 +2634,17 @@ static int mmc_blk_issue_normal_rw_rq(st
 		} else
 			areq = NULL;
 		areq = mmc_start_req(card->host, areq, (int *) &status);
+#ifndef CONFIG_X86_PUMA7
+		if (!areq) {
+			if (status == MMC_BLK_NEW_REQUEST)
+				mq->flags |= MMC_QUEUE_NEW_REQUEST;
+#else
 		if (!areq)
+#endif
 			return 0;
+#ifndef CONFIG_X86_PUMA7
+		}
+#endif
 
 		mq_rq = container_of(areq, struct mmc_queue_req, mmc_active);
 		brq = &mq_rq->brq;
@@ -2047,8 +2754,10 @@ static int mmc_blk_issue_normal_rw_rq(st
 		}
 	} while (ret);
 
+#ifdef CONFIG_X86_PUMA7
 	clear_bit_unlock(mq_rq->task_id, &mq->cmdqslot);
 	atomic_dec(&mq->active_slots);
+#endif
 
 	return 1;
 
@@ -2062,15 +2771,20 @@ static int mmc_blk_issue_normal_rw_rq(st
 			ret = blk_end_request(req, -EIO,
 					blk_rq_cur_bytes(req));
 	}
+
  start_new_req:
+#ifdef CONFIG_X86_PUMA7
 	clear_bit_unlock(mq_rq->task_id, &mq->cmdqslot);
 	atomic_dec(&mq->active_slots);
+#endif
 	if (rqc) {
 		if (mmc_card_removed(card)) {
 			rqc->cmd_flags |= REQ_QUIET;
 			blk_end_request_all(rqc, -EIO);
+#ifdef CONFIG_X86_PUMA7
 			clear_bit_unlock(mq->mqrq_cur->task_id, &mq->cmdqslot);
 			atomic_dec(&mq->active_slots);
+#endif
 		} else {
 			/*
 			 * If current request is packed, it needs to put back.
@@ -2441,6 +3155,7 @@ requeue:
 	return 0;
 }
 
+#ifdef CONFIG_X86_PUMA7
 static int mmc_blk_issue_rw_rq(struct mmc_queue *mq,
 		struct request *rqc, bool urgent)
 {
@@ -2452,9 +3167,14 @@ static int mmc_blk_issue_rw_rq(struct mm
 	else
 		return mmc_blk_issue_cmdq_rw_rq(mq, rqc, urgent);
 }
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+static int mmc_blk_issue_rq(struct mmc_queue *mq, struct request *req)
+#else
 static int mmc_blk_issue_rq(struct mmc_queue *mq,
 		struct request *req, bool urgent)
+#endif
 {
 	int ret;
 	struct mmc_blk_data *md = mq->data;
@@ -2463,11 +3183,15 @@ static int mmc_blk_issue_rq(struct mmc_q
 	unsigned long flags;
 	unsigned int cmd_flags = req ? req->cmd_flags : 0;
 
+#ifndef CONFIG_X86_PUMA7
+	if (req && !mq->mqrq_prev->req)
+#else
 #ifdef CONFIG_MMC_BLOCK_DEFERRED_RESUME
 	if (mmc_bus_needs_resume(card->host))
 		mmc_resume_bus(card->host);
 #endif
 	if (!atomic_read(&mq->active_slots))
+#endif
 		/* claim host only for the first request */
 		mmc_get_card(card);
 
@@ -2480,10 +3204,18 @@ static int mmc_blk_issue_rq(struct mmc_q
 		goto out;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	mq->flags &= ~MMC_QUEUE_NEW_REQUEST;
+#endif
 	if (cmd_flags & REQ_DISCARD) {
 		/* complete ongoing async transfer before issuing discard */
+#ifndef CONFIG_X86_PUMA7
+		if (card->host->areq)
+			mmc_blk_issue_rw_rq(mq, NULL);
+#else
 		if (atomic_read(&mq->active_slots))
 			mmc_blk_issue_rw_rq(mq, NULL, urgent);
+#endif
 		if (req->cmd_flags & REQ_SECURE &&
 			!(card->quirks & MMC_QUIRK_SEC_ERASE_TRIM_BROKEN))
 			ret = mmc_blk_issue_secdiscard_rq(mq, req);
@@ -2491,29 +3223,52 @@ static int mmc_blk_issue_rq(struct mmc_q
 			ret = mmc_blk_issue_discard_rq(mq, req);
 	} else if (cmd_flags & REQ_FLUSH) {
 		/* complete ongoing async transfer before issuing flush */
+#ifndef CONFIG_X86_PUMA7
+		if (card->host->areq)
+			mmc_blk_issue_rw_rq(mq, NULL);
+#else
 		if (atomic_read(&mq->active_slots))
 			mmc_blk_issue_rw_rq(mq, NULL, urgent);
+#endif
 		ret = mmc_blk_issue_flush(mq, req);
 	} else {
+#ifndef CONFIG_X86_PUMA7
+		if (!req && host->areq) {
+#else
 		if (!req && (atomic_read(&mq->active_slots) == 1)) {
+#endif
 			spin_lock_irqsave(&host->context_info.lock, flags);
 			host->context_info.is_waiting_last_req = true;
 			spin_unlock_irqrestore(&host->context_info.lock, flags);
 		}
+#ifndef CONFIG_X86_PUMA7
+		ret = mmc_blk_issue_rw_rq(mq, req);
+#else
 		ret = mmc_blk_issue_rw_rq(mq, req, urgent);
+#endif
 	}
 
 out:
+#ifndef CONFIG_X86_PUMA7
+	if ((!req && !(mq->flags & MMC_QUEUE_NEW_REQUEST)) ||
+	     (cmd_flags & MMC_REQ_SPECIAL_MASK))
+#else
 	mmc_blk_part_switch_to_up(card);
 
 	if (!atomic_read(&mq->active_slots))
+#endif
 		/*
 		 * Release host when there are no more requests
 		 * and after special request(discard, flush) is done.
 		 * In case sepecial request, there is no reentry to
-		 * the 'mmc_blk_issue_rq'.
+		 * the 'mmc_blk_issue_rq' with 'mqrq_prev->req'.
 		 */
+	{
+#ifdef CONFIG_X86_PUMA6
+		mmc_blk_part_switch_to_up(card);
+#endif
 		mmc_put_card(card);
+	}
 	return ret;
 }
 
@@ -2589,7 +3344,9 @@ static struct mmc_blk_data *mmc_blk_allo
 	md->disk->queue = md->queue.queue;
 	md->disk->driverfs_dev = parent;
 	set_disk_ro(md->disk, md->read_only || default_ro);
+#ifdef CONFIG_X86_PUMA7
 	md->disk->flags = GENHD_FL_EXT_DEVT;
+#endif
 	if (area_type & MMC_BLK_DATA_AREA_RPMB)
 		md->disk->flags |= GENHD_FL_NO_PART_SCAN;
 
@@ -2670,7 +3427,9 @@ static struct mmc_blk_data *mmc_blk_allo
 
 	md = mmc_blk_alloc_req(card, &card->dev, size, false, NULL,
 					MMC_BLK_DATA_AREA_MAIN);
+#ifdef CONFIG_X86_PUMA7
 	md->mq_curr = &md->queue;
+#endif
 
 	return md;
 }
@@ -2850,7 +3609,8 @@ static const struct mmc_fixup blk_fixups
 		  MMC_QUIRK_BLK_NO_CMD23),
 
 	/*
-	 * Some MMC cards need longer data read timeout than indicated in CSD.
+	 * Some Micron MMC cards needs longer data read timeout than
+	 * indicated in CSD.
 	 */
 	MMC_FIXUP(CID_NAME_ANY, CID_MANFID_MICRON, 0x200, add_quirk_mmc,
 		  MMC_QUIRK_LONG_READ_TIME),
@@ -2930,10 +3690,12 @@ static int mmc_blk_probe(struct mmc_card
 	if (card->type != MMC_TYPE_SD_COMBO) {
 		pm_runtime_set_active(&card->dev);
 		pm_runtime_enable(&card->dev);
+#ifdef CONFIG_X86_PUMA7
 		if ((card->host->pm_caps & MMC_PM_TUNING_AFTER_RTRESUME) &&
 				card->ext_csd.cmdq_en)
 			pm_suspend_ignore_children(&card->host->class_dev,
 					false);
+#endif
 	}
 
 	return 0;
@@ -2951,7 +3713,11 @@ static void mmc_blk_remove(struct mmc_ca
 	mmc_blk_remove_parts(card, md);
 	pm_runtime_get_sync(&card->dev);
 	mmc_claim_host(card->host);
+#ifndef CONFIG_X86_PUMA7
+	mmc_blk_part_switch(card, md);
+#else
 	mmc_blk_part_switch_to_up(card);
+#endif
 	mmc_release_host(card->host);
 	if (card->type != MMC_TYPE_SD_COMBO)
 		pm_runtime_disable(&card->dev);
@@ -2969,6 +3735,9 @@ static int _mmc_blk_suspend(struct mmc_c
 	struct mmc_blk_data *md = mmc_get_drvdata(card);
 
 	if (md) {
+#ifndef CONFIG_X86_PUMA7
+		pm_runtime_get_sync(&card->dev);
+#endif
 		mmc_queue_suspend(&md->queue);
 		list_for_each_entry(part_md, &md->part, part) {
 			mmc_queue_suspend(&part_md->queue);
@@ -3003,6 +3772,9 @@ static int mmc_blk_resume(struct mmc_car
 		list_for_each_entry(part_md, &md->part, part) {
 			mmc_queue_resume(&part_md->queue);
 		}
+#ifndef CONFIG_X86_PUMA7
+		pm_runtime_put(&card->dev);
+#endif
 	}
 	return 0;
 }
@@ -3057,4 +3829,3 @@ module_exit(mmc_blk_exit);
 
 MODULE_LICENSE("GPL");
 MODULE_DESCRIPTION("Multimedia Card (MMC) block device driver");
-
--- a/drivers/mmc/card/queue.c
+++ b/drivers/mmc/card/queue.c
@@ -9,6 +9,7 @@
  * published by the Free Software Foundation.
  *
  */
+
 #include <linux/slab.h>
 #include <linux/module.h>
 #include <linux/blkdev.h>
@@ -20,6 +21,7 @@
 #include <linux/mmc/card.h>
 #include <linux/mmc/host.h>
 #include "queue.h"
+#include <linux/mmc/bp.h>
 
 #define MMC_QUEUE_BOUNCESZ	65536
 
@@ -46,6 +48,7 @@ static int mmc_prep_request(struct reque
 	return BLKPREP_OK;
 }
 
+#ifdef CONFIG_X86_PUMA7
 static bool mmc_queue_get_free_slot(struct mmc_queue *mq,
 		unsigned long *free_slot)
 {
@@ -66,6 +69,7 @@ static bool mmc_queue_get_free_slot(stru
 	*free_slot = slot;
 	return true;
 }
+#endif
 
 static int mmc_queue_thread(void *d)
 {
@@ -77,13 +81,28 @@ static int mmc_queue_thread(void *d)
 	down(&mq->thread_sem);
 	do {
 		struct request *req = NULL;
+		struct mmc_queue_req *tmp;
+		unsigned int cmd_flags = 0;
 		unsigned long i;
 
 		spin_lock_irq(q->queue_lock);
 		set_current_state(TASK_INTERRUPTIBLE);
 		req = blk_fetch_request(q);
+#ifndef CONFIG_X86_PUMA7
+		mq->mqrq_cur->req = req;
+#endif
 		spin_unlock_irq(q->queue_lock);
 
+#ifndef CONFIG_X86_PUMA7
+		if (req || mq->mqrq_prev->req) {
+			set_current_state(TASK_RUNNING);
+			cmd_flags = req ? req->cmd_flags : 0;
+			mq->issue_fn(mq, req);
+			if (mq->flags & MMC_QUEUE_NEW_REQUEST) {
+				mq->flags &= ~MMC_QUEUE_NEW_REQUEST;
+				continue; /* fetch again */
+			}
+#else
 		/*
 		 * For the request which doesn't have data to transfer,
 		 * we don't need to allocate a mqrq slot for it as it doesn't
@@ -95,10 +114,29 @@ static int mmc_queue_thread(void *d)
 			mq->mqrq_cur = &mq->mqrq[i];
 			mq->mqrq_cur->req = req;
 		}
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+			/*
+			 * Current request becomes previous request
+			 * and vice versa.
+			 * In case of special requests, current request
+			 * has been finished. Do not assign it to previous
+			 * request.
+			 */
+			if (cmd_flags & MMC_REQ_SPECIAL_MASK)
+				mq->mqrq_cur->req = NULL;
+
+			mq->mqrq_prev->brq.mrq.data = NULL;
+			mq->mqrq_prev->req = NULL;
+			tmp = mq->mqrq_prev;
+			mq->mqrq_prev = mq->mqrq_cur;
+			mq->mqrq_cur = tmp;
+#else
 		if (req || atomic_read(&mq->active_slots)) {
 			set_current_state(TASK_RUNNING);
 			mq->issue_fn(mq, req, false);
+#endif
 		} else {
 			if (kthread_should_stop()) {
 				set_current_state(TASK_RUNNING);
@@ -136,7 +174,11 @@ static void mmc_request_fn(struct reques
 	}
 
 	cntx = &mq->card->host->context_info;
+#ifndef CONFIG_X86_PUMA7
+	if (!mq->mqrq_cur->req && mq->mqrq_prev->req) {
+#else
 	if (atomic_read(&mq->active_slots)) {
+#endif
 		/*
 		 * New MMC request arrived when MMC thread may be
 		 * blocked on the previous request to be complete
@@ -148,7 +190,11 @@ static void mmc_request_fn(struct reques
 			wake_up_interruptible(&cntx->wait);
 		}
 		spin_unlock_irqrestore(&cntx->lock, flags);
+#ifndef CONFIG_X86_PUMA7
+	} else if (!mq->mqrq_cur->req && !mq->mqrq_prev->req)
+#else
 	} else
+#endif
 		wake_up_process(mq->thread);
 }
 
@@ -202,17 +248,31 @@ int mmc_init_queue(struct mmc_queue *mq,
 {
 	struct mmc_host *host = card->host;
 	u64 limit = BLK_BOUNCE_HIGH;
+#ifndef CONFIG_X86_PUMA7
+	int ret;
+	struct mmc_queue_req *mqrq_cur = &mq->mqrq[0];
+	struct mmc_queue_req *mqrq_prev = &mq->mqrq[1];
+#else
 	int ret, i = 0;
 	struct mmc_queue_req *mqrq = mq->mqrq;
+#endif
 
 	if (mmc_dev(host)->dma_mask && *mmc_dev(host)->dma_mask)
+#ifndef CONFIG_X86_PUMA7
+		limit = *mmc_dev(host)->dma_mask;
+#else
 		limit = (u64)dma_max_pfn(mmc_dev(host)) << PAGE_SHIFT;
+#endif
 
 	mq->card = card;
 	mq->queue = blk_init_queue(mmc_request_fn, lock);
 	if (!mq->queue)
 		return -ENOMEM;
 
+#ifndef CONFIG_X86_PUMA7
+	mq->mqrq_cur = mqrq_cur;
+	mq->mqrq_prev = mqrq_prev;
+#else
 	if (card->ext_csd.cmdq_en)
 		mq->qdepth = card->ext_csd.cmdq_depth;
 	else
@@ -229,6 +289,7 @@ int mmc_init_queue(struct mmc_queue *mq,
 	for (i = mq->qdepth; i > 0; i--)
 		mqrq[i - 1].task_id = i - 1;
 
+#endif
 	mq->queue->queuedata = mq;
 
 	blk_queue_prep_rq(mq->queue, mmc_prep_request);
@@ -250,25 +311,64 @@ int mmc_init_queue(struct mmc_queue *mq,
 			bouncesz = host->max_blk_count * 512;
 
 		if (bouncesz > 512) {
+#ifndef CONFIG_X86_PUMA7
+			mqrq_cur->bounce_buf = kmalloc(bouncesz, GFP_KERNEL);
+			if (!mqrq_cur->bounce_buf) {
+				pr_warning("%s: unable to "
+					"allocate bounce cur buffer\n",
+					mmc_card_name(card));
+			}
+			mqrq_prev->bounce_buf = kmalloc(bouncesz, GFP_KERNEL);
+			if (!mqrq_prev->bounce_buf) {
+				pr_warning("%s: unable to "
+					"allocate bounce prev buffer\n",
+					mmc_card_name(card));
+				kfree(mqrq_cur->bounce_buf);
+				mqrq_cur->bounce_buf = NULL;
+#else
 			for (i = 0; i < mq->qdepth; i++) {
 				mqrq[i].bounce_buf =
 					kmalloc(bouncesz, GFP_KERNEL);
 				if (!mqrq[i].bounce_buf)
 					break;
+#endif
 			}
 		}
 
+#ifndef CONFIG_X86_PUMA7
+		if (mqrq_cur->bounce_buf && mqrq_prev->bounce_buf) {
+#else
 		if (i != mq->qdepth) {
 			for (; i >= 0; i--) {
 				kfree(mqrq[i].bounce_buf);
 				mqrq[i].bounce_buf = NULL;
 			}
 		} else {
+#endif
 			blk_queue_bounce_limit(mq->queue, BLK_BOUNCE_ANY);
 			blk_queue_max_hw_sectors(mq->queue, bouncesz / 512);
 			blk_queue_max_segments(mq->queue, bouncesz / 512);
 			blk_queue_max_segment_size(mq->queue, bouncesz);
 
+#ifndef CONFIG_X86_PUMA7
+			mqrq_cur->sg = mmc_alloc_sg(1, &ret);
+			if (ret)
+				goto cleanup_queue;
+
+			mqrq_cur->bounce_sg =
+				mmc_alloc_sg(bouncesz / 512, &ret);
+			if (ret)
+				goto cleanup_queue;
+
+			mqrq_prev->sg = mmc_alloc_sg(1, &ret);
+			if (ret)
+				goto cleanup_queue;
+
+			mqrq_prev->bounce_sg =
+				mmc_alloc_sg(bouncesz / 512, &ret);
+			if (ret)
+				goto cleanup_queue;
+#else
 			for (i = 0; i < mq->qdepth; i++) {
 				mqrq[i].sg = mmc_alloc_sg(1, &ret);
 				if (ret)
@@ -278,24 +378,56 @@ int mmc_init_queue(struct mmc_queue *mq,
 				if (ret)
 					goto cleanup_queue;
 			}
+#endif
 		}
 	}
 #endif
 
+#ifndef CONFIG_X86_PUMA7
+	if (!mqrq_cur->bounce_buf && !mqrq_prev->bounce_buf) {
+#else
 	if (i == 0) {
+#endif
 		blk_queue_bounce_limit(mq->queue, limit);
 		blk_queue_max_hw_sectors(mq->queue,
 			min(host->max_blk_count, host->max_req_size / 512));
 		blk_queue_max_segments(mq->queue, host->max_segs);
 		blk_queue_max_segment_size(mq->queue, host->max_seg_size);
 
+#ifndef CONFIG_X86_PUMA7
+		mqrq_cur->sg = mmc_alloc_sg(host->max_segs, &ret);
+		if (ret)
+			goto cleanup_queue;
+
+
+		mqrq_prev->sg = mmc_alloc_sg(host->max_segs, &ret);
+		if (ret)
+			goto cleanup_queue;
+#else
 		for (i = 0; i < mq->qdepth; i++) {
 			mqrq[i].sg = mmc_alloc_sg(host->max_segs, &ret);
 			if (ret)
 				goto cleanup_queue;
 		}
+#endif
+	}
+
+#ifdef CONFIG_X86_PUMA6
+	mq->mqrq_cur->bp_buf = kmalloc(MAX_NUM_OF_SECTORS_TRANSFERD * MMC_SECTOR_SIZE, GFP_KERNEL);
+	if (!mq->mqrq_cur->bp_buf) {
+		printk("unable to alloc boot partition memory buffer\n");
+		ret = -ENOMEM;
+		goto cleanup_queue;
 	}
 
+	mq->mqrq_cur->bp_sg = kmalloc(sizeof(struct scatterlist), GFP_KERNEL);
+	if (!mq->mqrq_cur->bp_sg) {
+		ret = -ENOMEM;
+		goto cleanup_queue;
+	}
+	sg_init_table(mq->mqrq_cur->bp_sg, 1);
+#endif
+
 	sema_init(&mq->thread_sem, 1);
 
 	mq->thread = kthread_run(mmc_queue_thread, mq, "mmcqd/%d%s",
@@ -308,20 +440,42 @@ int mmc_init_queue(struct mmc_queue *mq,
 
 	return 0;
  free_bounce_sg:
+#ifndef CONFIG_X86_PUMA7
+	kfree(mqrq_cur->bounce_sg);
+	mqrq_cur->bounce_sg = NULL;
+	kfree(mqrq_prev->bounce_sg);
+	mqrq_prev->bounce_sg = NULL;
+
+#else
 	for (i = 0; i < mq->qdepth; i++) {
 		kfree(mqrq[i].bounce_sg);
 		mqrq[i].bounce_sg = NULL;
 	}
+#endif
  cleanup_queue:
+#ifndef CONFIG_X86_PUMA7
+	kfree(mqrq_cur->sg);
+	mqrq_cur->sg = NULL;
+	kfree(mqrq_cur->bounce_buf);
+	mqrq_cur->bounce_buf = NULL;
+
+	kfree(mqrq_prev->sg);
+	mqrq_prev->sg = NULL;
+	kfree(mqrq_prev->bounce_buf);
+	mqrq_prev->bounce_buf = NULL;
+#else
 	for (i = 0; i < mq->qdepth; i++) {
 		kfree(mqrq[i].sg);
 		mqrq[i].sg = NULL;
 		kfree(mqrq[i].bounce_buf);
 		mqrq[i].bounce_buf = NULL;
 	}
+#endif
 
+#ifdef CONFIG_X86_PUMA7
 	kfree(mq->mqrq);
 out:
+#endif
 	blk_cleanup_queue(mq->queue);
 	return ret;
 }
@@ -330,7 +484,12 @@ void mmc_cleanup_queue(struct mmc_queue
 {
 	struct request_queue *q = mq->queue;
 	unsigned long flags;
+#ifndef CONFIG_X86_PUMA7
+	struct mmc_queue_req *mqrq_cur = mq->mqrq_cur;
+	struct mmc_queue_req *mqrq_prev = mq->mqrq_prev;
+#else
 	int i;
+#endif
 
 	/* Make sure the queue isn't suspended, as that will deadlock */
 	mmc_queue_resume(mq);
@@ -344,6 +503,25 @@ void mmc_cleanup_queue(struct mmc_queue
 	blk_start_queue(q);
 	spin_unlock_irqrestore(q->queue_lock, flags);
 
+#ifndef CONFIG_X86_PUMA7
+	kfree(mqrq_cur->bounce_sg);
+	mqrq_cur->bounce_sg = NULL;
+
+	kfree(mqrq_cur->sg);
+	mqrq_cur->sg = NULL;
+
+	kfree(mqrq_cur->bounce_buf);
+	mqrq_cur->bounce_buf = NULL;
+
+	kfree(mqrq_prev->bounce_sg);
+	mqrq_prev->bounce_sg = NULL;
+
+	kfree(mqrq_prev->sg);
+	mqrq_prev->sg = NULL;
+
+	kfree(mqrq_prev->bounce_buf);
+	mqrq_prev->bounce_buf = NULL;
+#else
 	for (i = 0; i < mq->qdepth; i++) {
 		kfree(mq->mqrq[i].bounce_sg);
 		mq->mqrq[i].bounce_sg = NULL;
@@ -352,6 +530,7 @@ void mmc_cleanup_queue(struct mmc_queue
 		kfree(mq->mqrq[i].bounce_buf);
 		mq->mqrq[i].bounce_buf = NULL;
 	}
+#endif
 
 	mq->card = NULL;
 }
@@ -363,9 +542,7 @@ int mmc_packed_init(struct mmc_queue *mq
 	struct mmc_queue_req *mqrq_prev = &mq->mqrq[1];
 	int ret = 0;
 
-	/*
-	 * the qdepth for PACK CMD is 2
-	 */
+
 	mqrq_cur->packed = kzalloc(sizeof(struct mmc_packed), GFP_KERNEL);
 	if (!mqrq_cur->packed) {
 		pr_warn("%s: unable to allocate packed cmd for mqrq_cur\n",
--- a/drivers/mmc/card/queue.h
+++ b/drivers/mmc/card/queue.h
@@ -8,6 +8,7 @@ struct task_struct;
 
 struct mmc_blk_request {
 	struct mmc_request	mrq;
+	struct mmc_command	sbc;
 	struct mmc_command	precmd;
 	struct mmc_command	cmd;
 	struct mmc_command	cmd2;
@@ -37,6 +38,8 @@ struct mmc_queue_req {
 	struct request		*req;
 	struct mmc_blk_request	brq;
 	struct scatterlist	*sg;
+	char			*bp_buf;
+	struct scatterlist	*bp_sg;
 	char			*bounce_buf;
 	struct scatterlist	*bounce_sg;
 	unsigned int		bounce_sg_len;
@@ -52,12 +55,24 @@ struct mmc_queue {
 	struct semaphore	thread_sem;
 	unsigned int		flags;
 #define MMC_QUEUE_SUSPENDED	(1 << 0)
-
+#ifndef CONFIG_X86_PUMA7
+#define MMC_QUEUE_NEW_REQUEST	(1 << 1)
+#endif
+
+#ifndef CONFIG_X86_PUMA7
+	int			(*issue_fn)(struct mmc_queue *, struct request *);
+#else
 	int	(*issue_fn)(struct mmc_queue *, struct request *, bool);
+#endif
 	void			*data;
 	struct request_queue	*queue;
+#ifndef CONFIG_X86_PUMA7
+	struct mmc_queue_req	mqrq[2];
+#else
 	struct mmc_queue_req	*mqrq;
+#endif
 	struct mmc_queue_req	*mqrq_cur;
+	struct mmc_queue_req	*mqrq_prev;
 	unsigned long		cmdqslot;
 	unsigned long		qdepth;
 	atomic_t		active_slots;
--- a/drivers/mmc/core/bus.c
+++ b/drivers/mmc/core/bus.c
@@ -25,9 +25,16 @@
 #include "sdio_cis.h"
 #include "bus.h"
 
+#ifdef CONFIG_X86_PUMA6
+extern int scan_thread_done;
+#endif
 #define to_mmc_driver(d)	container_of(d, struct mmc_driver, drv)
 
+#ifndef CONFIG_X86_PUMA7
+static ssize_t mmc_type_show(struct device *dev,
+#else
 static ssize_t type_show(struct device *dev,
+#endif
 	struct device_attribute *attr, char *buf)
 {
 	struct mmc_card *card = mmc_dev_to_card(dev);
@@ -45,13 +52,23 @@ static ssize_t type_show(struct device *
 		return -EFAULT;
 	}
 }
+#ifdef CONFIG_X86_PUMA7
 static DEVICE_ATTR_RO(type);
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+static struct device_attribute mmc_dev_attrs[] = {
+	__ATTR(type, S_IRUGO, mmc_type_show, NULL),
+	__ATTR_NULL,
+#else
 static struct attribute *mmc_dev_attrs[] = {
 	&dev_attr_type.attr,
 	NULL,
+#endif
 };
+#ifdef CONFIG_X86_PUMA7
 ATTRIBUTE_GROUPS(mmc_dev);
+#endif
 
 /*
  * This currently matches any MMC driver to any MMC card - drivers
@@ -235,12 +252,18 @@ static const struct dev_pm_ops mmc_bus_p
 
 static struct bus_type mmc_bus_type = {
 	.name		= "mmc",
+#ifndef CONFIG_X86_PUMA7
+	.dev_attrs	= mmc_dev_attrs,
+#else
 	.dev_groups	= mmc_dev_groups,
+#endif
 	.match		= mmc_bus_match,
 	.uevent		= mmc_bus_uevent,
 	.probe		= mmc_bus_probe,
 	.remove		= mmc_bus_remove,
+#ifndef CONFIG_X86_PUMA6
 	.shutdown	= mmc_bus_shutdown,
+#endif
 	.pm		= &mmc_bus_pm_ops,
 };
 
@@ -357,30 +380,51 @@ int mmc_add_card(struct mmc_card *card)
 		break;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_sd_card_uhs(card) &&
+#else
 	if (mmc_card_uhs(card) &&
+#endif
 		(card->sd_bus_speed < ARRAY_SIZE(uhs_speeds)))
 		uhs_bus_speed_mode = uhs_speeds[card->sd_bus_speed];
 
 	if (mmc_host_is_spi(card->host)) {
 		pr_info("%s: new %s%s%s card on SPI\n",
 			mmc_hostname(card->host),
+#ifndef CONFIG_X86_PUMA7
+			mmc_card_highspeed(card) ? "high speed " : "",
+			mmc_card_ddr_mode(card) ? "DDR " : "",
+#else
 			mmc_card_hs(card) ? "high speed " : "",
 			mmc_card_ddr52(card) ? "DDR " : "",
+#endif
 			type);
 	} else {
 		pr_info("%s: new %s%s%s%s%s card at address %04x\n",
 			mmc_hostname(card->host),
 			mmc_card_uhs(card) ? "ultra high speed " :
+#ifndef CONFIG_X86_PUMA7
+			(mmc_card_highspeed(card) ? "high speed " : ""),
+#else
 			(mmc_card_hs(card) ? "high speed " : ""),
 			mmc_card_hs400(card) ? "HS400 " :
+#endif
 			(mmc_card_hs200(card) ? "HS200 " : ""),
+#ifndef CONFIG_X86_PUMA7
+			mmc_card_ddr_mode(card) ? "DDR " : "",
+#else
 			mmc_card_ddr52(card) ? "DDR " : "",
+#endif
 			uhs_bus_speed_mode, type, card->rca);
 	}
 
 #ifdef CONFIG_DEBUG_FS
 	mmc_add_card_debugfs(card);
 #endif
+#ifdef CONFIG_X86_PUMA6
+    scan_thread_done = 1;
+#endif
+
 	mmc_init_context_info(card->host);
 
 	ret = device_add(&card->dev);
--- a/drivers/mmc/core/core.c
+++ b/drivers/mmc/core/core.c
@@ -32,14 +32,15 @@
 #include <linux/slab.h>
 #include <linux/of.h>
 #include <linux/wakelock.h>
-
 #include <trace/events/mmc.h>
 
 #include <linux/mmc/card.h>
 #include <linux/mmc/host.h>
 #include <linux/mmc/mmc.h>
 #include <linux/mmc/sd.h>
-
+#ifdef CONFIG_X86_PUMA6
+#include <linux/aep.h>
+#endif
 #include "core.h"
 #include "bus.h"
 #include "host.h"
@@ -52,8 +53,15 @@
 #ifdef CONFIG_HW_MUTEXES
 #include <linux/hw_mutex.h>
 #include <linux/mmc/sdhci.h>
+#if defined(CONFIG_CE_MAILBOX)
+#include <linux/ce_mailbox.h>
+#endif
 #endif
 
+#ifdef CONFIG_X86_PUMA6
+extern int scan_thread_done;
+extern int intelce_boot_mode;
+#endif
 /* If the device is not responding */
 #define MMC_CORE_TIMEOUT_MS	(10 * 60 * 1000) /* 10 minute timeout */
 
@@ -98,7 +106,9 @@ MODULE_PARM_DESC(
 static int mmc_schedule_delayed_work(struct delayed_work *work,
 				     unsigned long delay)
 {
+#ifdef CONFIG_X86_PUMA7
 	wake_lock(&mmc_delayed_work_wake_lock);
+#endif
 	return queue_delayed_work(workqueue, work, delay);
 }
 
@@ -216,6 +226,10 @@ void mmc_request_done(struct mmc_host *h
 	} else {
 		mmc_should_fail_request(host, mrq);
 
+#ifndef CONFIG_X86_PUMA7
+		led_trigger_event(host->led, LED_OFF);
+
+#endif
 		pr_debug("%s: req done (CMD%u): %d: %08x %08x %08x %08x\n",
 			mmc_hostname(host), cmd->opcode, err,
 			cmd->resp[0], cmd->resp[1],
@@ -225,7 +239,9 @@ void mmc_request_done(struct mmc_host *h
 			pr_debug("%s:     %d bytes transferred: %d\n",
 				mmc_hostname(host),
 				mrq->data->bytes_xfered, mrq->data->error);
+#ifdef CONFIG_X86_PUMA7
 			trace_mmc_blk_rw_end(cmd->opcode, cmd->arg, mrq->data);
+#endif
 		}
 
 		if (mrq->stop) {
@@ -236,6 +252,7 @@ void mmc_request_done(struct mmc_host *h
 				mrq->stop->resp[2], mrq->stop->resp[3]);
 		}
 
+#ifdef CONFIG_X86_PUMA7
 		if (mmc_op_cmdq_execute_task(cmd->opcode) && !mrq->data) {
 			if (mrq->done)
 				mrq->done(mrq);
@@ -244,6 +261,7 @@ void mmc_request_done(struct mmc_host *h
 
 		led_trigger_event(host->led, LED_OFF);
 
+#endif
 		if (mrq->done)
 			mrq->done(mrq);
 
@@ -276,10 +294,19 @@ mmc_start_request(struct mmc_host *host,
 	struct scatterlist *sg;
 #endif
 
+#ifndef CONFIG_X86_PUMA7
+	if (mrq->sbc) {
+#else
 	if (mrq->precmd) {
+#endif
 		pr_debug("<%s: starting CMD%u arg %08x flags %08x>\n",
+#ifndef CONFIG_X86_PUMA7
+			 mmc_hostname(host), mrq->sbc->opcode,
+			 mrq->sbc->arg, mrq->sbc->flags);
+#else
 			 mmc_hostname(host), mrq->precmd->opcode,
 			 mrq->precmd->arg, mrq->precmd->flags);
+#endif
 	}
 
 	pr_debug("%s: starting CMD%u arg %08x flags %08x\n",
@@ -329,7 +356,9 @@ mmc_start_request(struct mmc_host *host,
 	}
 	mmc_host_clk_hold(host);
 	led_trigger_event(host->led, LED_FULL);
+#ifdef CONFIG_X86_PUMA7
 	mmc_qos_update(host, mrq, CSTATE_EXIT_LATENCY_C2);
+#endif
 	host->ops->request(host, mrq);
 }
 
@@ -378,7 +407,11 @@ void mmc_start_bkops(struct mmc_card *ca
 	}
 
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+#ifndef CONFIG_X86_PUMA7
+			EXT_CSD_BKOPS_START, 1, timeout, use_busy_signal);
+#else
 			EXT_CSD_BKOPS_START, 1, timeout, use_busy_signal, true);
+#endif
 	if (err) {
 		pr_warn("%s: Error %d starting bkops\n",
 			mmc_hostname(card->host), err);
@@ -442,7 +475,9 @@ static int __mmc_start_req(struct mmc_ho
 {
 	init_completion(&mrq->completion);
 	mrq->done = mmc_wait_done;
+#ifdef CONFIG_X86_PUMA7
 	mrq->host = host;
+#endif
 	if (mmc_card_removed(host->card)) {
 		mrq->cmd->error = -ENOMEDIUM;
 		complete(&mrq->completion);
@@ -488,7 +523,9 @@ static int mmc_wait_for_data_req_done(st
 			    mmc_card_removed(host->card)) {
 				err = host->areq->err_check(host->card,
 							    host->areq);
+#ifdef CONFIG_X86_PUMA7
 				mmc_qos_update(host, mrq, PM_QOS_DEFAULT_VALUE);
+#endif
 				break; /* return err */
 			} else {
 				pr_info("%s: req failed (CMD%u): %d, retrying...\n",
@@ -539,8 +576,10 @@ static void mmc_wait_for_req_done(struct
 		}
 		if (!cmd->error || !cmd->retries ||
 		    mmc_card_removed(host->card)) {
+#ifdef CONFIG_X86_PUMA7
 			if (!mmc_op_cmdq_execute_task(cmd->opcode))
 				mmc_qos_update(host, mrq, PM_QOS_DEFAULT_VALUE);
+#endif
 			break;
 		}
 
@@ -641,9 +680,11 @@ struct mmc_async_req *mmc_start_req(stru
 	}
 
 	if (!err && areq) {
+#ifdef CONFIG_X86_PUMA7
 		trace_mmc_blk_rw_start(areq->mrq->cmd->opcode,
 				       areq->mrq->cmd->arg,
 				       areq->mrq->data);
+#endif
 		start_err = __mmc_start_data_req(host, areq->mrq);
 	}
 
@@ -952,11 +993,15 @@ void mmc_set_data_timeout(struct mmc_dat
 	/*
 	 * Some cards require longer data read timeout than indicated in CSD.
 	 * Address this by setting the read timeout to a "reasonably high"
-	 * value. For the cards tested, 600ms has proven enough. If necessary,
+	 * value. For the cards tested, 300ms has proven enough. If necessary,
 	 * this value can be increased if other problematic cards require this.
 	 */
 	if (mmc_card_long_read_time(card) && data->flags & MMC_DATA_READ) {
+#ifndef CONFIG_X86_PUMA7
+		data->timeout_ns = 300000000;
+#else
 		data->timeout_ns = 600000000;
+#endif
 		data->timeout_clks = 0;
 	}
 
@@ -1005,6 +1050,7 @@ unsigned int mmc_align_data_size(struct
 }
 EXPORT_SYMBOL(mmc_align_data_size);
 
+#ifdef CONFIG_X86_PUMA7
 /**
  *	__mmc_claim_host - exclusively claim a host
  *	@host: mmc host to claim
@@ -1097,6 +1143,197 @@ void mmc_release_host(struct mmc_host *h
 	}
 }
 EXPORT_SYMBOL(mmc_release_host);
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+/**
+ *	__mmc_claim_host - exclusively claim a host
+ *	@host: mmc host to claim
+ *	@abort: whether or not the operation should be aborted
+ *
+ *	Claim a host for a set of operations.  If @abort is non null and
+ *	dereference a non-zero value then this will return prematurely with
+ *	that non-zero value without acquiring the lock.  Returns zero
+ *	with the lock held otherwise.
+ */
+int __mmc_claim_host(struct mmc_host *host, atomic_t *abort)
+{
+	DECLARE_WAITQUEUE(wait, current);
+	unsigned long flags;
+	int stop;
+
+	might_sleep();
+
+	add_wait_queue(&host->wq, &wait);
+	spin_lock_irqsave(&host->lock, flags);
+	while (1) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		stop = abort ? atomic_read(abort) : 0;
+		if (stop || !host->claimed || host->claimer == current)
+			break;
+		spin_unlock_irqrestore(&host->lock, flags);
+		schedule();
+		spin_lock_irqsave(&host->lock, flags);
+	}
+	set_current_state(TASK_RUNNING);
+	if (!stop) {
+		host->claimed = 1;
+		host->claimer = current;
+		host->claim_cnt += 1;
+	} else
+		wake_up(&host->wq);
+	spin_unlock_irqrestore(&host->lock, flags);
+	remove_wait_queue(&host->wq, &wait);
+#if defined(CONFIG_HW_MUTEXES)
+	spin_lock_irqsave(&host->lock, flags);
+	/* 
+	 * mmc_claim_host is the start point of a set of MMC operations.
+	 * Lock HW Mutex at the first time when a task owned the controller. 
+	 */
+	if ((host->claimer == current) && (host->claim_cnt == 1)) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		LOCK_EMMC_HW_MUTEX(host);
+	} else
+		spin_unlock_irqrestore(&host->lock, flags);
+
+#endif
+	if (host->ops->enable && !stop && host->claim_cnt == 1)
+		host->ops->enable(host);
+	return stop;
+}
+
+EXPORT_SYMBOL(__mmc_claim_host);
+
+/**
+ *	__mmc_claim_host_no_hwmutex - exclusively claim a host without taking hw mutex
+ */
+int __mmc_claim_host_no_hwmutex(struct mmc_host *host, atomic_t *abort)
+{
+	DECLARE_WAITQUEUE(wait, current);
+	unsigned long flags;
+	int stop;
+
+	might_sleep();
+
+	add_wait_queue(&host->wq, &wait);
+	spin_lock_irqsave(&host->lock, flags);
+	while (1) {
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		stop = abort ? atomic_read(abort) : 0;
+		if (stop || !host->claimed || host->claimer == current)
+			break;
+		spin_unlock_irqrestore(&host->lock, flags);
+		schedule();
+		spin_lock_irqsave(&host->lock, flags);
+	}
+	set_current_state(TASK_RUNNING);
+	if (!stop) {
+		host->claimed = 1;
+		host->claimer = current;
+		host->claim_cnt += 1;
+	} else
+		wake_up(&host->wq);
+	spin_unlock_irqrestore(&host->lock, flags);
+	remove_wait_queue(&host->wq, &wait);
+	//if (!stop)
+        if (host->ops->enable && !stop && host->claim_cnt == 1)
+		host->ops->enable(host);
+	return stop;
+}
+EXPORT_SYMBOL(__mmc_claim_host_no_hwmutex);
+
+/**
+ *	mmc_try_claim_host - try exclusively to claim a host
+ *	@host: mmc host to claim
+ *
+ *	Returns %1 if the host is claimed, %0 otherwise.
+ */
+int mmc_try_claim_host(struct mmc_host *host)
+{
+	int claimed_host = 0;
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	if (!host->claimed || host->claimer == current) {
+		host->claimed = 1;
+		host->claimer = current;
+		host->claim_cnt += 1;
+		claimed_host = 1;
+	}
+	spin_unlock_irqrestore(&host->lock, flags);
+	if (host->ops->enable && claimed_host && host->claim_cnt == 1)
+		host->ops->enable(host);
+
+#if defined(CONFIG_HW_MUTEXES)
+	spin_lock_irqsave(&host->lock, flags);
+	/* Lock HW Mutex at the first time when a task owned the controller. */
+	if ((host->claimer == current) && (host->claim_cnt == 1)) {
+		spin_unlock_irqrestore(&host->lock, flags);
+		LOCK_EMMC_HW_MUTEX(host);
+	} else
+		spin_unlock_irqrestore(&host->lock, flags);
+#endif
+
+	return claimed_host;
+}
+EXPORT_SYMBOL(mmc_try_claim_host);
+
+/**
+ *	mmc_release_host - release a host
+ *	@host: mmc host to release
+ *
+ *	Release a MMC host, allowing others to claim the host
+ *	for their operations.
+ */
+void mmc_release_host(struct mmc_host *host)
+{
+	unsigned long flags;
+
+	WARN_ON(!host->claimed);
+
+	if (host->ops->disable && host->claim_cnt == 1)
+		host->ops->disable(host);
+
+	spin_lock_irqsave(&host->lock, flags);
+	if (--host->claim_cnt) {
+		/* Release for nested claim */
+		spin_unlock_irqrestore(&host->lock, flags);
+	} else {
+		host->claimed = 0;
+		host->claimer = NULL;
+		spin_unlock_irqrestore(&host->lock, flags);
+#if defined(CONFIG_HW_MUTEXES)
+		/* 
+		 * mmc_release_host is the end point of a set of MMC operations.
+		 * Unlock the HW Mutex when a task doesn't own the controller 
+		 */
+		UNLOCK_EMMC_HW_MUTEX(host);
+#endif
+		wake_up(&host->wq);
+	}
+}
+EXPORT_SYMBOL(mmc_release_host);
+
+/**
+ *	mmc_release_host_no_hwmutex - release a claimed host without release hw mutex
+ */
+void mmc_release_host_no_hwmutex(struct mmc_host *host)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&host->lock, flags);
+	if (--host->claim_cnt) {
+		/* Release for nested claim */
+		spin_unlock_irqrestore(&host->lock, flags);
+	} else {
+		host->claimed = 0;
+		host->claimer = NULL;
+		spin_unlock_irqrestore(&host->lock, flags);
+		wake_up(&host->wq);
+	}
+}
+EXPORT_SYMBOL(mmc_release_host_no_hwmutex);
+#endif
 
 /*
  * This is a helper function, which fetches a runtime pm reference for the
@@ -1505,6 +1742,32 @@ EXPORT_SYMBOL_GPL(mmc_regulator_get_supp
  * Mask off any voltages we don't support and select
  * the lowest voltage
  */
+#ifndef CONFIG_X86_PUMA7
+u32 mmc_select_voltage(struct mmc_host *host, u32 ocr)
+{
+	int bit;
+
+	ocr &= host->ocr_avail;
+
+	bit = ffs(ocr);
+	if (bit) {
+		bit -= 1;
+
+		ocr &= 3 << bit;
+
+		mmc_host_clk_hold(host);
+		host->ios.vdd = bit;
+		mmc_set_ios(host);
+		mmc_host_clk_release(host);
+	} else {
+		pr_warning("%s: host doesn't support card's voltages\n",
+				mmc_hostname(host));
+		ocr = 0;
+	}
+
+	return ocr;
+}
+#else
 u32 mmc_select_voltage(struct mmc_host *host, u32 ocr)
 {
 	int bit;
@@ -1538,6 +1801,7 @@ u32 mmc_select_voltage(struct mmc_host *
 
 	return ocr;
 }
+#endif
 
 int __mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage)
 {
@@ -1558,7 +1822,11 @@ int __mmc_set_signal_voltage(struct mmc_
 
 }
 
+#ifndef CONFIG_X86_PUMA7
+int mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage)
+#else
 int mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage, u32 ocr)
+#endif
 {
 	struct mmc_command cmd = {0};
 	int err = 0;
@@ -1640,7 +1908,11 @@ power_cycle:
 	if (err) {
 		pr_debug("%s: Signal voltage switch failed, "
 			"power cycling card\n", mmc_hostname(host));
+#ifndef CONFIG_X86_PUMA7
+		mmc_power_cycle(host);
+#else
 		mmc_power_cycle(host, ocr);
+#endif
 	}
 
 	mmc_host_clk_release(host);
@@ -1681,16 +1953,30 @@ void mmc_set_driver_type(struct mmc_host
  * If a host does all the power sequencing itself, ignore the
  * initial MMC_POWER_UP stage.
  */
+#ifndef CONFIG_X86_PUMA7
+void mmc_power_up(struct mmc_host *host)
+#else
 void mmc_power_up(struct mmc_host *host, u32 ocr)
+#endif
 {
+	int bit;
+
 	if (host->ios.power_mode == MMC_POWER_ON)
-    {
 		return;
-    }
 
 	mmc_host_clk_hold(host);
 
+#ifndef CONFIG_X86_PUMA7
+	/* If ocr is set, we use it */
+	if (host->ocr)
+		bit = ffs(host->ocr) - 1;
+	else
+		bit = fls(host->ocr_avail) - 1;
+
+	host->ios.vdd = bit;
+#else
 	host->ios.vdd = fls(ocr) - 1;
+#endif
 	if (mmc_host_is_spi(host))
 		host->ios.chip_select = MMC_CS_HIGH;
 	else
@@ -1727,15 +2013,21 @@ void mmc_power_up(struct mmc_host *host,
 void mmc_power_off(struct mmc_host *host)
 {
 	if (host->ios.power_mode == MMC_POWER_OFF)
-    {
 		return;
-    }
 
 	mmc_host_clk_hold(host);
 
 	host->ios.clock = 0;
 	host->ios.vdd = 0;
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Reset ocr mask to be the highest possible voltage supported for
+	 * this mmc host. This value will be used at next power up.
+	 */
+	host->ocr = 1 << (fls(host->ocr_avail) - 1);
+#endif
+
 	if (!mmc_host_is_spi(host)) {
 		host->ios.bus_mode = MMC_BUSMODE_OPENDRAIN;
 		host->ios.chip_select = MMC_CS_DONTCARE;
@@ -1755,9 +2047,18 @@ void mmc_power_off(struct mmc_host *host
 	mmc_host_clk_release(host);
 }
 
+#ifndef CONFIG_X86_PUMA7
+void mmc_power_cycle(struct mmc_host *host)
+#else
 void mmc_power_cycle(struct mmc_host *host, u32 ocr)
+#endif
 {
 	mmc_power_off(host);
+#ifndef CONFIG_X86_PUMA7
+	/* Wait at least 1 ms according to SD spec */
+	mmc_delay(1);
+	mmc_power_up(host);
+#else
 	/*
 	 * Wait at least 1 ms according to SD spec
 	 * some of the SD card seems only 1ms is not enough,
@@ -1765,6 +2066,7 @@ void mmc_power_cycle(struct mmc_host *ho
 	 */
 	mmc_delay(10);
 	mmc_power_up(host, ocr);
+#endif
 }
 
 /*
@@ -1852,6 +2154,7 @@ void mmc_detach_bus(struct mmc_host *hos
 	mmc_bus_put(host);
 }
 
+#ifdef CONFIG_X86_PUMA7
 static void _mmc_detect_change(struct mmc_host *host, unsigned long delay,
 				bool cd_irq)
 {
@@ -1874,6 +2177,7 @@ static void _mmc_detect_change(struct mm
 	mmc_schedule_delayed_work(&host->detect, delay);
 }
 
+#endif
 /**
  *	mmc_detect_change - process change of state on a MMC socket
  *	@host: host which changed state.
@@ -1886,8 +2190,20 @@ static void _mmc_detect_change(struct mm
  */
 void mmc_detect_change(struct mmc_host *host, unsigned long delay)
 {
+#ifndef CONFIG_X86_PUMA7
+#ifdef CONFIG_MMC_DEBUG
+	unsigned long flags;
+	spin_lock_irqsave(&host->lock, flags);
+	WARN_ON(host->removed);
+	spin_unlock_irqrestore(&host->lock, flags);
+#endif
+	host->detect_change = 1;
+	mmc_schedule_delayed_work(&host->detect, delay);
+#else
 	_mmc_detect_change(host, delay, true);
+#endif
 }
+
 EXPORT_SYMBOL(mmc_detect_change);
 
 void mmc_init_erase(struct mmc_card *card)
@@ -1919,7 +2235,11 @@ void mmc_init_erase(struct mmc_card *car
 		card->erase_shift = ffs(card->ssr.au) - 1;
 	} else if (card->ext_csd.hc_erase_size) {
 		card->pref_erase = card->ext_csd.hc_erase_size;
+#ifndef CONFIG_X86_PUMA7
+	} else {
+#else
 	} else if (card->erase_size) {
+#endif
 		sz = (card->csd.capacity << (card->csd.read_blkbits - 9)) >> 11;
 		if (sz < 128)
 			card->pref_erase = 512 * 1024 / 512;
@@ -1936,8 +2256,12 @@ void mmc_init_erase(struct mmc_card *car
 			if (sz)
 				card->pref_erase += card->erase_size - sz;
 		}
+#ifndef CONFIG_X86_PUMA7
+	}
+#else
 	} else
 		card->pref_erase = 0;
+#endif
 }
 
 static unsigned int mmc_mmc_erase_timeout(struct mmc_card *card,
@@ -2044,13 +2368,16 @@ static int mmc_do_erase(struct mmc_card
 {
 	struct mmc_command cmd = {0};
 	unsigned int qty = 0;
+	unsigned long timeout;
 	unsigned int fr, nr;
 	int err;
 
+#ifdef CONFIG_X86_PUMA7
 	fr = from;
 	nr = to - from + 1;
 	trace_mmc_blk_erase_start(arg, fr, nr);
 
+#endif
 	/*
 	 * qty is used to calculate the erase timeout which depends on how many
 	 * erase groups (or allocation units in SD terminology) are affected.
@@ -2113,6 +2440,10 @@ static int mmc_do_erase(struct mmc_card
 	memset(&cmd, 0, sizeof(struct mmc_command));
 	cmd.opcode = MMC_ERASE;
 	cmd.arg = arg;
+#ifndef CONFIG_X86_PUMA7
+	cmd.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
+	cmd.cmd_timeout_ms = mmc_erase_timeout(card, arg, qty);
+#else
 	if (card->host->caps2 & MMC_CAP2_POLL_R1B_BUSY) {
 		cmd.flags = MMC_RSP_SPI_R1 | MMC_RSP_R1 | MMC_CMD_AC;
 		if (card->host->max_discard_to)
@@ -2123,6 +2454,7 @@ static int mmc_do_erase(struct mmc_card
 		cmd.flags = MMC_RSP_SPI_R1B | MMC_RSP_R1B | MMC_CMD_AC;
 		cmd.cmd_timeout_ms = mmc_erase_timeout(card, arg, qty);
 	}
+#endif
 	err = mmc_wait_for_cmd(card->host, &cmd, 0);
 	if (err) {
 		pr_err("mmc_erase: erase error %d, status %#x\n",
@@ -2134,10 +2466,41 @@ static int mmc_do_erase(struct mmc_card
 	if (mmc_host_is_spi(card->host))
 		goto out;
 
+#ifndef CONFIG_X86_PUMA7
+	timeout = jiffies + msecs_to_jiffies(MMC_CORE_TIMEOUT_MS);
+	do {
+		memset(&cmd, 0, sizeof(struct mmc_command));
+		cmd.opcode = MMC_SEND_STATUS;
+		cmd.arg = card->rca << 16;
+		cmd.flags = MMC_RSP_R1 | MMC_CMD_AC;
+		/* Do not retry else we can't see errors */
+		err = mmc_wait_for_cmd(card->host, &cmd, 0);
+		if (err || (cmd.resp[0] & 0xFDF92000)) {
+			pr_err("error %d requesting status %#x\n",
+				err, cmd.resp[0]);
+			err = -EIO;
+			goto out;
+		}
+
+		/* Timeout if the device never becomes ready for data and
+		 * never leaves the program state.
+		 */
+		if (time_after(jiffies, timeout)) {
+			pr_err("%s: Card stuck in programming state! %s\n",
+				mmc_hostname(card->host), __func__);
+			err =  -EIO;
+			goto out;
+		}
+
+	} while (!(cmd.resp[0] & R1_READY_FOR_DATA) ||
+		 (R1_CURRENT_STATE(cmd.resp[0]) == R1_STATE_PRG));
+#else
 	err = mmc_busy_wait(card->host);
+#endif
 out:
-
+#ifdef CONFIG_X86_PUMA7
 	trace_mmc_blk_erase_end(arg, fr, nr);
+#endif
 	return err;
 }
 
@@ -2298,6 +2661,10 @@ static unsigned int mmc_do_calc_max_disc
 	if (!qty)
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	if (qty == 1)
+		return 1;
+#else
 	if (arg & MMC_TRIM_ARGS) {
 		if (qty == 1)
 			aligned_qty = 1;
@@ -2305,14 +2672,23 @@ static unsigned int mmc_do_calc_max_disc
 			aligned_qty = qty - 1;
 	} else
 		aligned_qty = qty;
+#endif
 
 	/* Convert qty to sectors */
 	if (card->erase_shift)
+#ifndef CONFIG_X86_PUMA7
+		max_discard = --qty << card->erase_shift;
+#else
 		max_discard = aligned_qty << card->erase_shift;
+#endif
 	else if (mmc_card_sd(card))
 		max_discard = qty;
 	else
+#ifndef CONFIG_X86_PUMA7
+		max_discard = --qty * card->erase_size;
+#else
 		max_discard = aligned_qty * card->erase_size;
+#endif
 
 	return max_discard;
 }
@@ -2325,7 +2701,6 @@ unsigned int mmc_calc_max_discard(struct
 	if (!host->max_discard_to)
 		return UINT_MAX;
 
-
 	/*
 	 * Without erase_group_def set, MMC erase timeout depends on clock
 	 * frequence which can change.  In that case, the best choice is
@@ -2334,8 +2709,10 @@ unsigned int mmc_calc_max_discard(struct
 	if (mmc_card_mmc(card) && !(card->ext_csd.erase_group_def & 1))
 		return card->pref_erase;
 
+#ifdef CONFIG_X86_PUMA7
 	if (host->caps2 & MMC_CAP2_POLL_R1B_BUSY)
 		return UINT_MAX;
+#endif
 
 	max_discard = mmc_do_calc_max_discard(card, MMC_ERASE_ARG);
 	if (mmc_can_trim(card)) {
@@ -2355,7 +2732,11 @@ int mmc_set_blocklen(struct mmc_card *ca
 {
 	struct mmc_command cmd = {0};
 
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_card_blockaddr(card) || mmc_card_ddr_mode(card))
+#else
 	if (mmc_card_blockaddr(card) || mmc_card_ddr52(card))
+#endif
 		return 0;
 
 	cmd.opcode = MMC_SET_BLOCKLEN;
@@ -2419,12 +2800,14 @@ static int mmc_do_hw_reset(struct mmc_ho
 
 	mmc_host_clk_hold(host);
 
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * before HW reset card, cache needs to be flushed. Otherwise
 	 * the data in cache can be lost. But this flush may be failed
 	 * because card may be not in a good state
 	 */
 	mmc_cache_ctrl(host, 0);
+#endif
 
 	mmc_set_clock(host, host->f_init);
 
@@ -2446,6 +2829,9 @@ static int mmc_do_hw_reset(struct mmc_ho
 		}
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	host->card->state &= ~(MMC_STATE_HIGHSPEED | MMC_STATE_HIGHSPEED_DDR);
+#endif
 	if (mmc_host_is_spi(host)) {
 		host->ios.chip_select = MMC_CS_HIGH;
 		host->ios.bus_mode = MMC_BUSMODE_PUSHPULL;
@@ -2477,12 +2863,15 @@ EXPORT_SYMBOL(mmc_hw_reset_check);
 static int mmc_rescan_try_freq(struct mmc_host *host, unsigned freq)
 {
 	host->f_init = freq;
-
 #ifdef CONFIG_MMC_DEBUG
 	pr_info("%s: %s: trying to init card at %u Hz\n",
 		mmc_hostname(host), __func__, host->f_init);
 #endif
+#ifndef CONFIG_X86_PUMA7
+	mmc_power_up(host);
+#else
 	mmc_power_up(host, host->ocr_avail);
+#endif
 
 	/*
 	 * Some eMMCs (with VCCQ always on) may not be reset after power up, so
@@ -2571,7 +2960,11 @@ int mmc_detect_card_removed(struct mmc_h
 			 * rescan handle the card removal.
 			 */
 			cancel_delayed_work(&host->detect);
+#ifndef CONFIG_X86_PUMA7
+			mmc_detect_change(host, 0);
+#else
 			_mmc_detect_change(host, 0, false);
+#endif
 		}
 	}
 
@@ -2579,6 +2972,7 @@ int mmc_detect_card_removed(struct mmc_h
 }
 EXPORT_SYMBOL(mmc_detect_card_removed);
 
+#ifdef CONFIG_X86_PUMA7
 void mmc_rescan(struct work_struct *work)
 {
 	struct mmc_host *host =
@@ -2672,6 +3066,100 @@ void mmc_rescan(struct work_struct *work
 	if (host->caps & MMC_CAP_NEEDS_POLL)
 		mmc_schedule_delayed_work(&host->detect, HZ);
 }
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+void mmc_rescan(struct work_struct *work)
+{
+	struct mmc_host *host =
+		container_of(work, struct mmc_host, detect.work);
+#if defined(CONFIG_HW_MUTEXES)
+	struct sdhci_host *shost = (struct sdhci_host *)host->private;
+#endif
+
+	int i;
+
+	if (host->rescan_disable)
+		return;
+
+	/* If there is a non-removable card registered, only scan once */
+	if ((host->caps & MMC_CAP_NONREMOVABLE) && host->rescan_entered)
+		return;
+	host->rescan_entered = 1;
+
+	mmc_bus_get(host);
+
+	/*
+	 * if there is a _removable_ card registered, check whether it is
+	 * still present
+	 */
+	if (host->bus_ops && host->bus_ops->detect && !host->bus_dead
+	    && !(host->caps & MMC_CAP_NONREMOVABLE))
+		host->bus_ops->detect(host);
+
+	host->detect_change = 0;
+
+	/*
+	 * Let mmc_bus_put() free the bus/bus_ops if we've found that
+	 * the card is no longer present.
+	 */
+	mmc_bus_put(host);
+	mmc_bus_get(host);
+
+	/* if there still is a card present, stop here */
+	if (host->bus_ops != NULL) {
+		mmc_bus_put(host);
+		goto out;
+	}
+
+	/*
+	 * Only we can add a new handler, so it's safe to
+	 * release the lock here.
+	 */
+	mmc_bus_put(host);
+
+	if (host->ops->get_cd && host->ops->get_cd(host) == 0) {
+		mmc_claim_host(host);
+		mmc_power_off(host);
+		mmc_release_host(host);
+		goto out;
+	}
+
+    if (intelce_boot_mode == 1) {
+        mmc_claim_host_no_hwmutex(host);
+    } else {
+        mmc_claim_host(host);
+    }
+
+	for (i = 0; i < ARRAY_SIZE(freqs); i++) {
+		if (!mmc_rescan_try_freq(host, max(freqs[i], host->f_min)))
+			break;
+		if (freqs[i] <= host->f_min)
+			break;
+	}
+
+    if (intelce_boot_mode == 1) {
+	    mmc_release_host_no_hwmutex(host);
+    } else {
+	    mmc_release_host(host);
+    }
+
+#if defined(CONFIG_HW_MUTEXES)
+#if defined(CONFIG_CE_MAILBOX)
+	if (SDHCI_HOST_HAS_HW_MUTEX(shost) && (intelce_boot_mode != 1)) {
+		/* eMMC advanced mode initializatin done, notify ARM */
+		i = npcpu_appcpu_mbx_send_notification(APPCPU_EVENT_EMMC_ADVANCE_EXIT,NULL);
+		if (i)
+			printk(KERN_ERR "can not send advanced mode finish notification to NPCPU \n");
+	}
+#endif
+#endif
+
+ out:
+	if (host->caps & MMC_CAP_NEEDS_POLL)
+		mmc_schedule_delayed_work(&host->detect, HZ);
+}
+#endif
 
 void mmc_start_host(struct mmc_host *host)
 {
@@ -2680,8 +3168,13 @@ void mmc_start_host(struct mmc_host *hos
 	if (host->caps2 & MMC_CAP2_NO_PRESCAN_POWERUP)
 		mmc_power_off(host);
 	else
+#ifndef CONFIG_X86_PUMA7
+		mmc_power_up(host);
+	mmc_detect_change(host, 0);
+#else
 		mmc_power_up(host, host->ocr_avail);
 	_mmc_detect_change(host, 0, false);
+#endif
 }
 
 void mmc_stop_host(struct mmc_host *host)
@@ -2738,10 +3231,12 @@ int mmc_power_save_host(struct mmc_host
 
 	mmc_bus_put(host);
 
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * disable cache before power off device
 	 */
 	mmc_cache_ctrl(host, 0);
+#endif
 
 	mmc_power_off(host);
 
@@ -2764,7 +3259,11 @@ int mmc_power_restore_host(struct mmc_ho
 		return -EINVAL;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_power_up(host);
+#else
 	mmc_power_up(host, host->card->ocr);
+#endif
 	ret = host->bus_ops->power_restore(host);
 
 	mmc_bus_put(host);
@@ -2820,6 +3319,10 @@ int mmc_cache_ctrl(struct mmc_host *host
 
 		if (card->ext_csd.cache_ctrl ^ enable) {
 			timeout = enable ? card->ext_csd.generic_cmd6_time : 0;
+#ifndef CONFIG_X86_PUMA7
+			err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+					EXT_CSD_CACHE_CTRL, enable, timeout);
+#else
 			if (enable)
 				err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 						EXT_CSD_CACHE_CTRL, enable,
@@ -2836,6 +3339,7 @@ int mmc_cache_ctrl(struct mmc_host *host
 				if (!err)
 					err = mmc_busy_wait(host);
 			}
+#endif
 			if (err)
 				pr_err("%s: cache %s error %d\n",
 						mmc_hostname(card->host),
@@ -2874,6 +3378,11 @@ int mmc_resume_host(struct mmc_host *hos
 }
 EXPORT_SYMBOL(mmc_resume_host);
 
+#ifdef CONFIG_X86_PUMA6
+extern struct mutex mmc_ioctl_mutex;
+extern int mmc_in_suspend;
+#endif
+
 /* Do the card removal on suspend if card is assumed removeable
  * Do that in pm notifier while userspace isn't yet frozen, so we will be able
    to sync the card.
@@ -2886,10 +3395,16 @@ int mmc_pm_notify(struct notifier_block
 	unsigned long flags;
 	int err = 0;
 
+#ifdef CONFIG_X86_PUMA6
+	mutex_lock(&mmc_ioctl_mutex);
+#endif
 	switch (mode) {
 	case PM_HIBERNATION_PREPARE:
 	case PM_SUSPEND_PREPARE:
 	case PM_RESTORE_PREPARE:
+#ifdef CONFIG_X86_PUMA6
+		mmc_in_suspend = 1;
+#endif
 		spin_lock_irqsave(&host->lock, flags);
 		host->rescan_disable = 1;
 		spin_unlock_irqrestore(&host->lock, flags);
@@ -2905,11 +3420,15 @@ int mmc_pm_notify(struct notifier_block
 			break;
 
 		/* Calling bus_ops->remove() with a claimed host can deadlock */
+#ifdef CONFIG_X86_PUMA7
 		mmc_cache_ctrl(host, 0);
+#endif
 		host->bus_ops->remove(host);
 		mmc_claim_host(host);
 		mmc_detach_bus(host);
+#ifdef CONFIG_X86_PUMA6		
 		mmc_power_off(host);
+#endif
 		mmc_release_host(host);
 		host->pm_flags = 0;
 		break;
@@ -2917,13 +3436,22 @@ int mmc_pm_notify(struct notifier_block
 	case PM_POST_SUSPEND:
 	case PM_POST_HIBERNATION:
 	case PM_POST_RESTORE:
-
+#ifdef CONFIG_X86_PUMA6
+		mmc_in_suspend = 0;
+#endif
 		spin_lock_irqsave(&host->lock, flags);
 		host->rescan_disable = 0;
 		spin_unlock_irqrestore(&host->lock, flags);
+#ifndef CONFIG_X86_PUMA7
+		mmc_detect_change(host, 0);
+#else
 		_mmc_detect_change(host, 0, false);
+#endif
 
 	}
+#ifdef CONFIG_X86_PUMA6
+	mutex_unlock(&mmc_ioctl_mutex);
+#endif
 
 	return 0;
 }
@@ -2970,9 +3498,10 @@ static int __init mmc_init(void)
 	if (!workqueue)
 		return -ENOMEM;
 
+#ifdef CONFIG_X86_PUMA7
 	wake_lock_init(&mmc_delayed_work_wake_lock, WAKE_LOCK_SUSPEND,
 		       "mmc_delayed_work");
-
+#endif
 	ret = mmc_register_bus();
 	if (ret)
 		goto destroy_workqueue;
@@ -2993,7 +3522,9 @@ unregister_bus:
 	mmc_unregister_bus();
 destroy_workqueue:
 	destroy_workqueue(workqueue);
+#ifdef CONFIG_X86_PUMA7
 	wake_lock_destroy(&mmc_delayed_work_wake_lock);
+#endif
 
 	return ret;
 }
@@ -3004,7 +3535,9 @@ static void __exit mmc_exit(void)
 	mmc_unregister_host_class();
 	mmc_unregister_bus();
 	destroy_workqueue(workqueue);
+#ifdef CONFIG_X86_PUMA7
 	wake_lock_destroy(&mmc_delayed_work_wake_lock);
+#endif
 }
 
 subsys_initcall(mmc_init);
--- a/drivers/mmc/core/core.h
+++ b/drivers/mmc/core/core.h
@@ -42,13 +42,25 @@ void mmc_set_ungated(struct mmc_host *ho
 void mmc_set_bus_mode(struct mmc_host *host, unsigned int mode);
 void mmc_set_bus_width(struct mmc_host *host, unsigned int width);
 u32 mmc_select_voltage(struct mmc_host *host, u32 ocr);
+#ifndef CONFIG_X86_PUMA7
+int mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage);
+#else
 int mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage, u32 ocr);
+#endif
 int __mmc_set_signal_voltage(struct mmc_host *host, int signal_voltage);
 void mmc_set_timing(struct mmc_host *host, unsigned int timing);
 void mmc_set_driver_type(struct mmc_host *host, unsigned int drv_type);
+#ifndef CONFIG_X86_PUMA7
+void mmc_power_up(struct mmc_host *host);
+#else
 void mmc_power_up(struct mmc_host *host, u32 ocr);
+#endif
 void mmc_power_off(struct mmc_host *host);
+#ifndef CONFIG_X86_PUMA7
+void mmc_power_cycle(struct mmc_host *host);
+#else
 void mmc_power_cycle(struct mmc_host *host, u32 ocr);
+#endif
 
 static inline void mmc_delay(unsigned int ms)
 {
--- a/drivers/mmc/core/debugfs.c
+++ b/drivers/mmc/core/debugfs.c
@@ -142,10 +142,14 @@ static int mmc_ios_show(struct seq_file
 		str = "mmc DDR52";
 		break;
 	case MMC_TIMING_MMC_HS200:
+#ifndef CONFIG_X86_PUMA7
+		str = "mmc high-speed SDR200";
+#else
 		str = "mmc HS200";
 		break;
 	case MMC_TIMING_MMC_HS400:
 		str = "mmc HS400";
+#endif
 		break;
 	default:
 		str = "invalid";
@@ -167,6 +171,7 @@ static int mmc_ios_show(struct seq_file
 		str = "invalid";
 		break;
 	}
+
 	seq_printf(s, "signal voltage:\t%u (%s)\n", ios->signal_voltage, str);
 
 	return 0;
--- a/drivers/mmc/core/host.c
+++ b/drivers/mmc/core/host.c
@@ -48,7 +48,9 @@ static const struct dev_pm_ops mmc_host_
 static struct class mmc_host_class = {
 	.name		= "mmc_host",
 	.dev_release	= mmc_host_classdev_release,
+#ifdef CONFIG_X86_PUMA7
 	.pm		= &mmc_host_class_pm_ops,
+#endif
 };
 
 int mmc_register_host_class(void)
@@ -539,15 +541,21 @@ int mmc_add_host(struct mmc_host *host)
 #endif
 	mmc_host_clk_sysfs_init(host);
 
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * ignore the children by default
 	 */
 	pm_suspend_ignore_children(&host->class_dev, true);
 	pm_runtime_enable(&host->class_dev);
+#endif
 
 	mmc_start_host(host);
+#ifndef CONFIG_X86_PUMA7
+	register_pm_notifier(&host->pm_notify);
+#else
 	if (!(host->pm_flags & MMC_PM_IGNORE_PM_NOTIFY))
 		register_pm_notifier(&host->pm_notify);
+#endif
 
 	return 0;
 }
@@ -564,8 +572,12 @@ EXPORT_SYMBOL(mmc_add_host);
  */
 void mmc_remove_host(struct mmc_host *host)
 {
+#ifndef CONFIG_X86_PUMA7
+	unregister_pm_notifier(&host->pm_notify);
+#else
 	if (!(host->pm_flags & MMC_PM_IGNORE_PM_NOTIFY))
 		unregister_pm_notifier(&host->pm_notify);
+#endif
 
 	mmc_stop_host(host);
 
--- a/drivers/mmc/core/mmc.c
+++ b/drivers/mmc/core/mmc.c
@@ -18,11 +18,17 @@
 #include <linux/mmc/host.h>
 #include <linux/mmc/card.h>
 #include <linux/mmc/mmc.h>
+#ifdef CONFIG_X86_PUMA6
+#include <linux/aep.h>
+#endif
 
 #include "core.h"
 #include "bus.h"
 #include "mmc_ops.h"
 #include "sd_ops.h"
+#ifdef CONFIG_X86_PUMA6
+extern int intelce_boot_mode;
+#endif
 
 static const unsigned int tran_exp[] = {
 	10000,		100000,		1000000,	10000000,
@@ -237,6 +243,7 @@ static int mmc_get_ext_csd(struct mmc_ca
 	return err;
 }
 
+#ifdef CONFIG_X86_PUMA7
 static void mmc_select_card_type(struct mmc_card *card)
 {
 	struct mmc_host *host = card->host;
@@ -297,7 +304,37 @@ static void mmc_select_card_type(struct
 	card->ext_csd.hs200_max_dtr = hs200_max_dtr;
 	card->mmc_avail_type = avail_type;
 }
+#else
+static void mmc_select_card_type(struct mmc_card *card)
+{
+	struct mmc_host *host = card->host;
+	u8 card_type = card->ext_csd.raw_card_type & EXT_CSD_CARD_TYPE_MASK;
+	u32 caps = host->caps, caps2 = host->caps2;
+	unsigned int hs_max_dtr = 0;
+
+	if (card_type & EXT_CSD_CARD_TYPE_26)
+		hs_max_dtr = MMC_HIGH_26_MAX_DTR;
+
+	if (caps & MMC_CAP_MMC_HIGHSPEED &&
+			card_type & EXT_CSD_CARD_TYPE_52)
+		hs_max_dtr = MMC_HIGH_52_MAX_DTR;
+
+	if ((caps & MMC_CAP_1_8V_DDR &&
+			card_type & EXT_CSD_CARD_TYPE_DDR_1_8V) ||
+	    (caps & MMC_CAP_1_2V_DDR &&
+			card_type & EXT_CSD_CARD_TYPE_DDR_1_2V))
+		hs_max_dtr = MMC_HIGH_DDR_MAX_DTR;
+
+	if ((caps2 & MMC_CAP2_HS200_1_8V_SDR &&
+			card_type & EXT_CSD_CARD_TYPE_SDR_1_8V) ||
+	    (caps2 & MMC_CAP2_HS200_1_2V_SDR &&
+			card_type & EXT_CSD_CARD_TYPE_SDR_1_2V))
+		hs_max_dtr = MMC_HS200_MAX_DTR;
 
+	card->ext_csd.hs_max_dtr = hs_max_dtr;
+	card->ext_csd.card_type = card_type;
+}
+#endif
 /*
  * Decode extended CSD.
  */
@@ -306,6 +343,7 @@ static int mmc_read_ext_csd(struct mmc_c
 	int err = 0, idx;
 	unsigned int part_size;
 	u8 hc_erase_grp_sz = 0, hc_wp_grp_sz = 0;
+	int i;
 
 	BUG_ON(!card);
 
@@ -329,6 +367,7 @@ static int mmc_read_ext_csd(struct mmc_c
 	 * as CSD_STRUCTURE does not change, all values for EXT_CSD_REV
 	 * are authorized, see JEDEC JESD84-B50 section B.8.
 	 */
+
 	card->ext_csd.rev = ext_csd[EXT_CSD_REV];
 
 	card->ext_csd.raw_sectors[0] = ext_csd[EXT_CSD_SEC_CNT + 0];
@@ -347,6 +386,38 @@ static int mmc_read_ext_csd(struct mmc_c
 			mmc_card_set_blockaddr(card);
 	}
 
+#ifdef CONFIG_X86_PUMA6
+	card->ext_csd.boot_size_mult = ext_csd[EXT_CSD_BOOT_MULT];
+	card->ext_csd.boot_config = ext_csd[EXT_CSD_BOOT_CONFIG];
+
+	if (ext_csd[EXT_CSD_REV] == 5) {
+		for (i = 0; i < 4; i++) {
+			card->ext_csd.gp_size[i] =
+				(ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3] +
+				ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3 + 1] * 256 +
+				ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3 + 2] * 65536) *
+				ext_csd[EXT_CSD_HC_WP_GRP_SIZE] *
+				ext_csd[EXT_CSD_HC_ERASE_GRP_SIZE] * 1024 *
+				(ext_csd[EXT_CSD_PARTITION_SUPPORT] & 0x1);
+		}
+	}
+	else if (ext_csd[EXT_CSD_REV] == 4) {
+		for (i = 0; i < 4; i++) {
+			card->ext_csd.gp_size[i] =
+				(ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3] +
+				ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3 + 1] * 8 +
+				ext_csd[EXT_CSD_GP_SIZE_MULT + i * 3 + 2] * 64) *
+				ext_csd[EXT_CSD_HC_WP_GRP_SIZE] *
+				ext_csd[EXT_CSD_HC_ERASE_GRP_SIZE] * 1024 *
+				(ext_csd[EXT_CSD_PARTITION_SUPPORT] & 0x1);
+		}
+	}
+	else {
+		for (i = 0; i < 4; i++) {
+			card->ext_csd.gp_size[i] = 0;
+		}
+	}
+#endif
 	card->ext_csd.raw_card_type = ext_csd[EXT_CSD_CARD_TYPE];
 	mmc_select_card_type(card);
 
@@ -355,8 +426,10 @@ static int mmc_read_ext_csd(struct mmc_c
 		ext_csd[EXT_CSD_ERASE_TIMEOUT_MULT];
 	card->ext_csd.raw_hc_erase_grp_size =
 		ext_csd[EXT_CSD_HC_ERASE_GRP_SIZE];
+#ifdef CONFIG_X86_PUMA7
 	card->ext_csd.part_set_complete =
 		ext_csd[EXT_CSD_PART_SET_COMPLETE];
+#endif
 	if (card->ext_csd.rev >= 3) {
 		u8 sa_shift = ext_csd[EXT_CSD_S_A_TIMEOUT];
 		card->ext_csd.part_config = ext_csd[EXT_CSD_PART_CONFIG];
@@ -512,8 +585,10 @@ static int mmc_read_ext_csd(struct mmc_c
 			ext_csd[EXT_CSD_PWR_CL_DDR_52_195];
 		card->ext_csd.raw_pwr_cl_ddr_52_360 =
 			ext_csd[EXT_CSD_PWR_CL_DDR_52_360];
+#ifdef CONFIG_X86_PUMA7
 		card->ext_csd.raw_pwr_cl_ddr_200_360 =
 			ext_csd[EXT_CSD_PWR_CL_DDR_200_360];
+#endif
 	}
 
 	if (card->ext_csd.rev >= 5) {
@@ -694,10 +769,14 @@ static int mmc_compare_ext_csds(struct m
 		(card->ext_csd.raw_pwr_cl_ddr_52_195 ==
 			bw_ext_csd[EXT_CSD_PWR_CL_DDR_52_195]) &&
 		(card->ext_csd.raw_pwr_cl_ddr_52_360 ==
+#ifndef CONFIG_X86_PUMA7
+			bw_ext_csd[EXT_CSD_PWR_CL_DDR_52_360]));
+#else
 			bw_ext_csd[EXT_CSD_PWR_CL_DDR_52_360]) &&
 		(card->ext_csd.raw_pwr_cl_ddr_200_360 ==
 			bw_ext_csd[EXT_CSD_PWR_CL_DDR_200_360]));
 
+#endif
 	if (err)
 		err = -EINVAL;
 
@@ -726,7 +805,9 @@ MMC_DEV_ATTR(enhanced_area_size, "%d KBy
 		card->ext_csd.enhanced_area_size);
 MMC_DEV_ATTR(raw_rpmb_size_mult, "%#x\n", card->ext_csd.raw_rpmb_size_mult);
 MMC_DEV_ATTR(rel_sectors, "%#x\n", card->ext_csd.rel_sectors);
+#ifdef CONFIG_X86_PUMA7
 MMC_DEV_ATTR(cmdq_en, "%#x\n", card->ext_csd.cmdq_en);
+#endif
 
 static struct attribute *mmc_std_attrs[] = {
 	&dev_attr_cid.attr,
@@ -745,7 +826,9 @@ static struct attribute *mmc_std_attrs[]
 	&dev_attr_enhanced_area_size.attr,
 	&dev_attr_raw_rpmb_size_mult.attr,
 	&dev_attr_rel_sectors.attr,
+#ifdef CONFIG_X86_PUMA7
 	&dev_attr_cmdq_en.attr,
+#endif
 	NULL,
 };
 
@@ -768,13 +851,26 @@ static struct device_type mmc_type = {
  * extended CSD register, select it by executing the
  * mmc_switch command.
  */
+#ifndef CONFIG_X86_PUMA7
+static int mmc_select_powerclass(struct mmc_card *card,
+		unsigned int bus_width)
+#else
 static int __mmc_select_powerclass(struct mmc_card *card,
 				   unsigned int bus_width)
+#endif
 {
+	int err = 0;
 	struct mmc_host *host = card->host;
 	struct mmc_ext_csd *ext_csd = &card->ext_csd;
 	unsigned int pwrclass_val = 0;
-	int err = 0;
+#ifndef CONFIG_X86_PUMA7
+	struct mmc_host *host;
+
+	BUG_ON(!card);
+
+	host = card->host;
+	BUG_ON(!host);
+#endif
 
 	/* Power class selection is supported for versions >= 4.0 */
 	if (card->csd.mmca_vsn < CSD_SPEC_VER_4)
@@ -786,14 +882,27 @@ static int __mmc_select_powerclass(struc
 
 	switch (1 << host->ios.vdd) {
 	case MMC_VDD_165_195:
+#ifndef CONFIG_X86_PUMA7
+		if (host->ios.clock <= 26000000)
+			pwrclass_val = card->ext_csd.raw_pwr_cl_26_195;
+		else if	(host->ios.clock <= 52000000)
+#else
 		if (host->ios.clock <= MMC_HIGH_26_MAX_DTR)
 			pwrclass_val = ext_csd->raw_pwr_cl_26_195;
 		else if (host->ios.clock <= MMC_HIGH_52_MAX_DTR)
+#endif
 			pwrclass_val = (bus_width <= EXT_CSD_BUS_WIDTH_8) ?
+#ifndef CONFIG_X86_PUMA7
+				card->ext_csd.raw_pwr_cl_52_195 :
+				card->ext_csd.raw_pwr_cl_ddr_52_195;
+		else if (host->ios.clock <= 200000000)
+			pwrclass_val = card->ext_csd.raw_pwr_cl_200_195;
+#else
 				ext_csd->raw_pwr_cl_52_195 :
 				ext_csd->raw_pwr_cl_ddr_52_195;
 		else if (host->ios.clock <= MMC_HS200_MAX_DTR)
 			pwrclass_val = ext_csd->raw_pwr_cl_200_195;
+#endif
 		break;
 	case MMC_VDD_27_28:
 	case MMC_VDD_28_29:
@@ -804,16 +913,29 @@ static int __mmc_select_powerclass(struc
 	case MMC_VDD_33_34:
 	case MMC_VDD_34_35:
 	case MMC_VDD_35_36:
+#ifndef CONFIG_X86_PUMA7
+		if (host->ios.clock <= 26000000)
+			pwrclass_val = card->ext_csd.raw_pwr_cl_26_360;
+		else if	(host->ios.clock <= 52000000)
+#else
 		if (host->ios.clock <= MMC_HIGH_26_MAX_DTR)
 			pwrclass_val = ext_csd->raw_pwr_cl_26_360;
 		else if (host->ios.clock <= MMC_HIGH_52_MAX_DTR)
+#endif
 			pwrclass_val = (bus_width <= EXT_CSD_BUS_WIDTH_8) ?
+#ifndef CONFIG_X86_PUMA7
+				card->ext_csd.raw_pwr_cl_52_360 :
+				card->ext_csd.raw_pwr_cl_ddr_52_360;
+		else if (host->ios.clock <= 200000000)
+			pwrclass_val = card->ext_csd.raw_pwr_cl_200_360;
+#else
 				ext_csd->raw_pwr_cl_52_360 :
 				ext_csd->raw_pwr_cl_ddr_52_360;
 		else if (host->ios.clock <= MMC_HS200_MAX_DTR)
 			pwrclass_val = (bus_width == EXT_CSD_DDR_BUS_WIDTH_8) ?
 				ext_csd->raw_pwr_cl_ddr_200_360 :
 				ext_csd->raw_pwr_cl_200_360;
+#endif
 		break;
 	default:
 		pr_warning("%s: Voltage range not supported "
@@ -839,6 +961,7 @@ static int __mmc_select_powerclass(struc
 	return err;
 }
 
+#ifdef CONFIG_X86_PUMA7
 static int mmc_select_powerclass(struct mmc_card *card)
 {
 	struct mmc_host *host = card->host;
@@ -870,9 +993,14 @@ static int mmc_select_powerclass(struct
 	return err;
 }
 
+#endif
 /*
- * Set the bus speed for the selected speed mode.
+ * Selects the desired buswidth and switch to the HS200 mode
+ * if bus width set without error
  */
+#ifndef CONFIG_X86_PUMA7
+static int mmc_select_hs200(struct mmc_card *card)
+#else
 static void mmc_set_bus_speed(struct mmc_card *card)
 {
 	unsigned int max_dtr = (unsigned int)-1;
@@ -894,24 +1022,63 @@ static void mmc_set_bus_speed(struct mmc
  * Zero is returned instead of error value if the wide width is not supported.
  */
 static int mmc_select_bus_width(struct mmc_card *card)
+#endif
 {
+#ifndef CONFIG_X86_PUMA7
+	int idx, err = -EINVAL;
+	struct mmc_host *host;
+#endif
 	static unsigned ext_csd_bits[] = {
+#ifndef CONFIG_X86_PUMA7
+		EXT_CSD_BUS_WIDTH_4,
+#endif
 		EXT_CSD_BUS_WIDTH_8,
+#ifdef CONFIG_X86_PUMA7
 		EXT_CSD_BUS_WIDTH_4,
+#endif
 	};
 	static unsigned bus_widths[] = {
+#ifndef CONFIG_X86_PUMA7
+		MMC_BUS_WIDTH_4,
+#endif
 		MMC_BUS_WIDTH_8,
+#ifdef CONFIG_X86_PUMA7
 		MMC_BUS_WIDTH_4,
+#endif
 	};
+#ifdef CONFIG_X86_PUMA7
 	struct mmc_host *host = card->host;
 	unsigned idx, bus_width = 0;
 	int err = 0;
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	BUG_ON(!card);
+
+	host = card->host;
+
+	if (card->ext_csd.card_type & EXT_CSD_CARD_TYPE_SDR_1_2V &&
+			host->caps2 & MMC_CAP2_HS200_1_2V_SDR)
+		err = __mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_120);
+
+	if (err && card->ext_csd.card_type & EXT_CSD_CARD_TYPE_SDR_1_8V &&
+			host->caps2 & MMC_CAP2_HS200_1_8V_SDR)
+		err = __mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_180);
+
+	/* If fails try again during next card power cycle */
+	if (err)
+		goto err;
+#else
 	if ((card->csd.mmca_vsn < CSD_SPEC_VER_4) &&
 	    !(host->caps & (MMC_CAP_4_BIT_DATA | MMC_CAP_8_BIT_DATA)))
 		return 0;
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	idx = (host->caps & MMC_CAP_8_BIT_DATA) ? 1 : 0;
+#else
 	idx = (host->caps & MMC_CAP_8_BIT_DATA) ? 0 : 1;
+#endif
 
 	/*
 	 * Unlike SD, MMC cards dont have a configuration register to notify
@@ -919,7 +1086,12 @@ static int mmc_select_bus_width(struct m
 	 * the supported bus width or compare the ext csd values of current
 	 * bus width and ext csd values of 1 bit mode read earlier.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	for (; idx >= 0; idx--) {
+
+#else
 	for (; idx < ARRAY_SIZE(bus_widths); idx++) {
+#endif
 		/*
 		 * Host is capable of 8bit transfer, then switch
 		 * the device to work in 8bit transfer mode. If the
@@ -934,22 +1106,38 @@ static int mmc_select_bus_width(struct m
 		if (err)
 			continue;
 
+#ifndef CONFIG_X86_PUMA7
+		mmc_set_bus_width(card->host, bus_widths[idx]);
+#else
 		bus_width = bus_widths[idx];
 		mmc_set_bus_width(host, bus_width);
+#endif
 
+#ifdef CONFIG_X86_PUMA7
 		/*
 		 * If controller can't handle bus width test,
 		 * compare ext_csd previously read in 1 bit mode
 		 * against ext_csd at new bus width
 		 */
+#endif
 		if (!(host->caps & MMC_CAP_BUS_WIDTH_TEST))
+#ifndef CONFIG_X86_PUMA7
+			err = mmc_compare_ext_csds(card, bus_widths[idx]);
+#else
 			err = mmc_compare_ext_csds(card, bus_width);
+#endif
 		else
+#ifndef CONFIG_X86_PUMA7
+			err = mmc_bus_test(card, bus_widths[idx]);
+		if (!err)
+#else
 			err = mmc_bus_test(card, bus_width);
 
 		if (!err) {
 			err = bus_width;
+#endif
 			break;
+#ifdef CONFIG_X86_PUMA7
 		} else {
 			pr_warn("%s: switch to bus width %d failed\n",
 				mmc_hostname(host), ext_csd_bits[idx]);
@@ -1002,8 +1190,12 @@ static int mmc_select_hs_ddr(struct mmc_
 		pr_warn("%s: switch to bus width %d ddr failed\n",
 			mmc_hostname(host), 1 << bus_width);
 		return err;
+#endif
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	/* switch to HS200 mode if bus width set successfully */
+#else
 	/*
 	 * eMMC cards can support 3.3V to 1.2V i/o (vccq)
 	 * signaling.
@@ -1040,7 +1232,9 @@ static int mmc_select_hs_ddr(struct mmc_
 	if (err)
 		err = __mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_330);
 
+#endif
 	if (!err)
+#ifdef CONFIG_X86_PUMA7
 		mmc_set_timing(host, MMC_TIMING_MMC_DDR52);
 
 	return err;
@@ -1127,15 +1321,22 @@ static int mmc_select_hs200(struct mmc_c
 	 */
 	err = mmc_select_bus_width(card);
 	if (!IS_ERR_VALUE(err)) {
+#endif
 		err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+#ifndef CONFIG_X86_PUMA7
+				 EXT_CSD_HS_TIMING, 2, 0);
+#else
 				 EXT_CSD_HS_TIMING, EXT_CSD_TIMING_HS200, 0);
 		if (!err)
 			mmc_set_timing(host, MMC_TIMING_MMC_HS200);
 	}
+#endif
 err:
 	return err;
 }
 
+
+#ifdef CONFIG_X86_PUMA7
 /*
  * Activate High Speed or HS200 mode if supported.
  */
@@ -1203,6 +1404,7 @@ static int mmc_hs200_tuning(struct mmc_c
 
 	return err;
 }
+#endif
 
 /*
  * Handle the detection and initialisation of a card.
@@ -1214,8 +1416,15 @@ static int mmc_init_card(struct mmc_host
 	struct mmc_card *oldcard)
 {
 	struct mmc_card *card;
+#ifndef CONFIG_X86_PUMA7
+	int err, ddr = 0;
+#else
 	int err;
+#endif
 	u32 cid[4];
+#ifndef CONFIG_X86_PUMA7
+	unsigned int max_dtr;
+#endif
 	u32 rocr;
 	u8 *ext_csd = NULL;
 
@@ -1276,7 +1485,9 @@ static int mmc_init_card(struct mmc_host
 			goto err;
 		}
 
+#ifdef CONFIG_X86_PUMA7
 		card->ocr = ocr;
+#endif
 		card->type = MMC_TYPE_MMC;
 		card->rca = 1;
 		memcpy(card->raw_cid, cid, sizeof(card->raw_cid));
@@ -1346,12 +1557,28 @@ static int mmc_init_card(struct mmc_host
 	 * If enhanced_area_en is TRUE, host needs to enable ERASE_GRP_DEF
 	 * bit.  This bit will be lost every time after a reset or power off.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (card->ext_csd.enhanced_area_en ||
+#else
 	if (card->ext_csd.enhanced_area_en || card->ext_csd.part_set_complete ||
+#endif
 	    (card->ext_csd.rev >= 3 && (host->caps2 & MMC_CAP2_HC_ERASE_SZ))) {
+#ifndef CONFIG_X86_PUMA6
 		err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 				 EXT_CSD_ERASE_GROUP_DEF, 1,
 				 card->ext_csd.generic_cmd6_time);
 
+#else
+                if(!aep_is_active()) {
+                        err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+                                         EXT_CSD_ERASE_GROUP_DEF, 1,
+                                         card->ext_csd.generic_cmd6_time);
+                }
+                else
+                {
+                        err = -EBADMSG;
+                }
+#endif
 		if (err && err != -EBADMSG)
 			goto free_card;
 
@@ -1364,7 +1591,9 @@ static int mmc_init_card(struct mmc_host
 			 */
 			card->ext_csd.enhanced_area_offset = -EINVAL;
 			card->ext_csd.enhanced_area_size = -EINVAL;
+#ifdef CONFIG_X86_PUMA7
 			card->ext_csd.erase_group_def = 0;
+#endif
 		} else {
 			card->ext_csd.erase_group_def = 1;
 			/*
@@ -1408,19 +1637,127 @@ static int mmc_init_card(struct mmc_host
 	}
 
 	/*
-	 * Select timing interface
+	 * Activate high speed (if supported)
+	 */
+#ifndef CONFIG_X86_PUMA7
+	if (card->ext_csd.hs_max_dtr != 0) {
+		err = 0;
+		if (card->ext_csd.hs_max_dtr > 52000000 &&
+		    host->caps2 & MMC_CAP2_HS200)
+			err = mmc_select_hs200(card);
+		else if	(host->caps & MMC_CAP_MMC_HIGHSPEED)
+			err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+					 EXT_CSD_HS_TIMING, 1,
+					 card->ext_csd.generic_cmd6_time);
+
+		if (err && err != -EBADMSG)
+			goto free_card;
+
+		if (err) {
+			pr_warning("%s: switch to highspeed failed\n",
+			       mmc_hostname(card->host));
+			err = 0;
+		} else {
+			if (card->ext_csd.hs_max_dtr > 52000000 &&
+			    host->caps2 & MMC_CAP2_HS200) {
+				mmc_card_set_hs200(card);
+				mmc_set_timing(card->host,
+					       MMC_TIMING_MMC_HS200);
+			} else {
+				mmc_card_set_highspeed(card);
+				mmc_set_timing(card->host, MMC_TIMING_MMC_HS);
+			}
+		}
+	}
+
+	/*
+	 * Compute bus speed.
 	 */
+	max_dtr = (unsigned int)-1;
+
+	if (mmc_card_highspeed(card) || mmc_card_hs200(card)) {
+		if (max_dtr > card->ext_csd.hs_max_dtr)
+			max_dtr = card->ext_csd.hs_max_dtr;
+		if (mmc_card_highspeed(card) && (max_dtr > 52000000))
+			max_dtr = 52000000;
+	} else if (max_dtr > card->csd.max_dtr) {
+		max_dtr = card->csd.max_dtr;
+	}
+
+	mmc_set_clock(host, max_dtr);
+
+	/*
+	 * Indicate DDR mode (if supported).
+	 */
+	if (mmc_card_highspeed(card)) {
+		if ((card->ext_csd.card_type & EXT_CSD_CARD_TYPE_DDR_1_8V)
+			&& ((host->caps & (MMC_CAP_1_8V_DDR |
+			     MMC_CAP_UHS_DDR50))
+				== (MMC_CAP_1_8V_DDR | MMC_CAP_UHS_DDR50)))
+				ddr = MMC_1_8V_DDR_MODE;
+		else if ((card->ext_csd.card_type & EXT_CSD_CARD_TYPE_DDR_1_2V)
+			&& ((host->caps & (MMC_CAP_1_2V_DDR |
+			     MMC_CAP_UHS_DDR50))
+				== (MMC_CAP_1_2V_DDR | MMC_CAP_UHS_DDR50)))
+				ddr = MMC_1_2V_DDR_MODE;
+	}
+#else
 	err = mmc_select_timing(card);
 	if (err)
 		goto free_card;
+#endif
 
+	/*
+	 * Indicate HS200 SDR mode (if supported).
+	 */
 	if (mmc_card_hs200(card)) {
+#ifndef CONFIG_X86_PUMA7
+		u32 ext_csd_bits;
+		u32 bus_width = card->host->ios.bus_width;
+
+		/*
+		 * For devices supporting HS200 mode, the bus width has
+		 * to be set before executing the tuning function. If
+		 * set before tuning, then device will respond with CRC
+		 * errors for responses on CMD line. So for HS200 the
+		 * sequence will be
+		 * 1. set bus width 4bit / 8 bit (1 bit not supported)
+		 * 2. switch to HS200 mode
+		 * 3. set the clock to > 52Mhz <=200MHz and
+		 * 4. execute tuning for HS200
+		 */
+		if ((host->caps2 & MMC_CAP2_HS200) &&
+		    card->host->ops->execute_tuning) {
+			mmc_host_clk_hold(card->host);
+			err = card->host->ops->execute_tuning(card->host,
+				MMC_SEND_TUNING_BLOCK_HS200);
+			mmc_host_clk_release(card->host);
+		}
+		if (err) {
+			pr_warning("%s: tuning execution failed\n",
+				   mmc_hostname(card->host));
+#else
 		err = mmc_hs200_tuning(card);
 		if (err)
+#endif
 			goto err;
+#ifndef CONFIG_X86_PUMA7
+		}
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+		ext_csd_bits = (bus_width == MMC_BUS_WIDTH_8) ?
+				EXT_CSD_BUS_WIDTH_8 : EXT_CSD_BUS_WIDTH_4;
+		err = mmc_select_powerclass(card, ext_csd_bits);
+#else
 		err = mmc_select_hs400(card);
+#endif
 		if (err)
+#ifndef CONFIG_X86_PUMA7
+			pr_warning("%s: power class selection to bus width %d"
+				   " failed\n", mmc_hostname(card->host),
+				   1 << bus_width);
+#else
 			goto err;
 	} else if (mmc_card_hs(card)) {
 		/* Select the desired bus width optionally */
@@ -1430,12 +1767,112 @@ static int mmc_init_card(struct mmc_host
 			if (err)
 				goto err;
 		}
+#endif
 	}
 
 	/*
-	 * Choose the power class with selected bus interface
+	 * Activate wide bus and DDR (if supported).
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!mmc_card_hs200(card) &&
+	    (card->csd.mmca_vsn >= CSD_SPEC_VER_4) &&
+	    (host->caps & (MMC_CAP_4_BIT_DATA | MMC_CAP_8_BIT_DATA))) {
+		static unsigned ext_csd_bits[][2] = {
+			{ EXT_CSD_BUS_WIDTH_8, EXT_CSD_DDR_BUS_WIDTH_8 },
+			{ EXT_CSD_BUS_WIDTH_4, EXT_CSD_DDR_BUS_WIDTH_4 },
+			{ EXT_CSD_BUS_WIDTH_1, EXT_CSD_BUS_WIDTH_1 },
+		};
+		static unsigned bus_widths[] = {
+			MMC_BUS_WIDTH_8,
+			MMC_BUS_WIDTH_4,
+			MMC_BUS_WIDTH_1
+		};
+		unsigned idx, bus_width = 0;
+
+		if (host->caps & MMC_CAP_8_BIT_DATA)
+			idx = 0;
+		else
+			idx = 1;
+		for (; idx < ARRAY_SIZE(bus_widths); idx++) {
+			bus_width = bus_widths[idx];
+			if (bus_width == MMC_BUS_WIDTH_1)
+				ddr = 0; /* no DDR for 1-bit width */
+			err = mmc_select_powerclass(card, ext_csd_bits[idx][0]);
+			if (err)
+				pr_warning("%s: power class selection to "
+					   "bus width %d failed\n",
+					   mmc_hostname(card->host),
+					   1 << bus_width);
+
+			err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+					 EXT_CSD_BUS_WIDTH,
+					 ext_csd_bits[idx][0],
+					 card->ext_csd.generic_cmd6_time);
+			if (!err) {
+				mmc_set_bus_width(card->host, bus_width);
+
+				/*
+				 * If controller can't handle bus width test,
+				 * compare ext_csd previously read in 1 bit mode
+				 * against ext_csd at new bus width
+				 */
+				if (!(host->caps & MMC_CAP_BUS_WIDTH_TEST))
+					err = mmc_compare_ext_csds(card,
+						bus_width);
+				else
+					err = mmc_bus_test(card, bus_width);
+				if (!err)
+					break;
+			}
+		}
+
+		if (!err && ddr) {
+			err = mmc_select_powerclass(card, ext_csd_bits[idx][1]);
+			if (err)
+				pr_warning("%s: power class selection to "
+					   "bus width %d ddr %d failed\n",
+					   mmc_hostname(card->host),
+					   1 << bus_width, ddr);
+
+			err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+					 EXT_CSD_BUS_WIDTH,
+					 ext_csd_bits[idx][1],
+					 card->ext_csd.generic_cmd6_time);
+		}
+		if (err) {
+			pr_warning("%s: switch to bus width %d ddr %d "
+				"failed\n", mmc_hostname(card->host),
+				1 << bus_width, ddr);
+			goto free_card;
+		} else if (ddr) {
+			/*
+			 * eMMC cards can support 3.3V to 1.2V i/o (vccq)
+			 * signaling.
+			 *
+			 * EXT_CSD_CARD_TYPE_DDR_1_8V means 3.3V or 1.8V vccq.
+			 *
+			 * 1.8V vccq at 3.3V core voltage (vcc) is not required
+			 * in the JEDEC spec for DDR.
+			 *
+			 * Do not force change in vccq since we are obviously
+			 * working and no change to vccq is needed.
+			 *
+			 * WARNING: eMMC rules are NOT the same as SD DDR
+			 */
+			if (ddr == MMC_1_2V_DDR_MODE) {
+				err = __mmc_set_signal_voltage(host,
+					MMC_SIGNAL_VOLTAGE_120);
+				if (err)
+					goto err;
+			}
+			mmc_card_set_ddr_mode(card);
+			mmc_set_timing(card->host, MMC_TIMING_UHS_DDR50);
+			mmc_set_bus_width(card->host, bus_width);
+		}
+	}
+#else
 	mmc_select_powerclass(card);
+#endif
 
 	/*
 	 * Enable HPI feature (if supported)
@@ -1480,6 +1917,7 @@ static int mmc_init_card(struct mmc_host
 		}
 	}
 
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * enable Command queue if supported
 	 */
@@ -1500,17 +1938,19 @@ static int mmc_init_card(struct mmc_host
 		} else
 			card->ext_csd.cmdq_en = 1;
 	}
-
+#endif
 	/*
 	 * The mandatory minimum values are defined for packed command.
 	 * read: 5, write: 3
-	 * disable packed CMD feature if CMDQ is enabled
-	 * CMDQ has better performance
 	 */
 	if (card->ext_csd.max_packed_writes >= 3 &&
 	    card->ext_csd.max_packed_reads >= 5 &&
+#ifndef CONFIG_X86_PUMA7
+	    host->caps2 & MMC_CAP2_PACKED_CMD) {
+#else
 	    (host->caps2 & MMC_CAP2_PACKED_CMD) &&
 	    !card->ext_csd.cmdq_en) {
+#endif
 		err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 				EXT_CSD_EXP_EVENTS_CTRL,
 				EXT_CSD_PACKED_EVENT_EN,
@@ -1597,9 +2037,15 @@ static int mmc_poweroff_notify(struct mm
 	if (notify_type == EXT_CSD_POWER_OFF_LONG)
 		timeout = card->ext_csd.power_off_longtime;
 
+#ifndef CONFIG_X86_PUMA7
+	err = mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
+			 EXT_CSD_POWER_OFF_NOTIFICATION,
+			 notify_type, timeout);
+#else
 	err = __mmc_switch(card, EXT_CSD_CMD_SET_NORMAL,
 			EXT_CSD_POWER_OFF_NOTIFICATION,
 			notify_type, timeout, true, false);
+#endif
 	if (err)
 		pr_err("%s: Power Off Notification timed out, %u\n",
 		       mmc_hostname(card->host), timeout);
@@ -1670,9 +2116,11 @@ static int _mmc_suspend(struct mmc_host
 
 	mmc_claim_host(host);
 
+#ifdef CONFIG_X86_PUMA7
 	if (mmc_card_suspended(host->card))
 		goto out;
 
+#endif
 	if (mmc_card_doing_bkops(host->card)) {
 		err = mmc_stop_bkops(host->card);
 		if (err)
@@ -1690,21 +2138,31 @@ static int _mmc_suspend(struct mmc_host
 		err = mmc_sleep(host);
 	else if (!mmc_host_is_spi(host))
 		err = mmc_deselect_cards(host);
+#ifndef CONFIG_X86_PUMA7
+	host->card->state &= ~(MMC_STATE_HIGHSPEED | MMC_STATE_HIGHSPEED_200);
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	if (!err)
+#else
 	if (!err) {
+#endif
 		mmc_power_off(host);
+#ifdef CONFIG_X86_PUMA7
 		mmc_card_set_suspended(host->card);
 	}
+#endif
 out:
 	mmc_release_host(host);
 	return err;
 }
 
 /*
- * Suspend callback
+ * Suspend callback.
  */
 static int mmc_suspend(struct mmc_host *host)
 {
+#ifdef CONFIG_X86_PUMA7
 	int err;
 
 	err = _mmc_suspend(host, true);
@@ -1714,8 +2172,14 @@ static int mmc_suspend(struct mmc_host *
 	}
 
 	return err;
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+	return 0;
+#endif
 }
 
+#ifdef CONFIG_X86_PUMA7
 /*
  * This function tries to determine if the same card is still present
  * and, if so, restore all state to it.
@@ -1740,12 +2204,11 @@ out:
 	mmc_release_host(host);
 	return err;
 }
+#endif
 
-/*
- * Shutdown callback
- */
 static int mmc_shutdown(struct mmc_host *host)
 {
+#ifdef CONFIG_X86_PUMA7
 	int err = 0;
 
 	/*
@@ -1760,6 +2223,11 @@ static int mmc_shutdown(struct mmc_host
 		err = _mmc_suspend(host, false);
 
 	return err;
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+	return _mmc_suspend(host, false);
+#endif
 }
 
 /*
@@ -1767,6 +2235,7 @@ static int mmc_shutdown(struct mmc_host
  */
 static int mmc_resume(struct mmc_host *host)
 {
+#ifdef CONFIG_X86_PUMA7
 	int err = 0;
 
 	if (!(host->caps & MMC_CAP_RUNTIME_RESUME)) {
@@ -1777,6 +2246,11 @@ static int mmc_resume(struct mmc_host *h
 	pm_runtime_enable(&host->card->dev);
 
 	return err;
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+ 	return 0;
+#endif
 }
 
 /*
@@ -1789,11 +2263,27 @@ static int mmc_runtime_suspend(struct mm
 	if (!(host->caps & MMC_CAP_AGGRESSIVE_PM))
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_claim_host(host);
+
+	err = mmc_suspend(host);
+	if (err) {
+#else
 	err = _mmc_suspend(host, true);
 	if (err)
+#endif
 		pr_err("%s: error %d doing aggessive suspend\n",
 			mmc_hostname(host), err);
+#ifndef CONFIG_X86_PUMA7
+		goto out;
+	}
+	mmc_power_off(host);
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+out:
+	mmc_release_host(host);
+#endif
 	return err;
 }
 
@@ -1804,14 +2294,28 @@ static int mmc_runtime_resume(struct mmc
 {
 	int err;
 
+#ifndef CONFIG_X86_PUMA7
+	if (!(host->caps & MMC_CAP_AGGRESSIVE_PM))
+#else
 	if (!(host->caps & (MMC_CAP_AGGRESSIVE_PM | MMC_CAP_RUNTIME_RESUME)))
+#endif
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_claim_host(host);
+
+	mmc_power_up(host);
+	err = mmc_resume(host);
+#else
 	err = _mmc_resume(host);
+#endif
 	if (err)
 		pr_err("%s: error %d doing aggessive resume\n",
 			mmc_hostname(host), err);
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_release_host(host);
+#endif
 	return 0;
 }
 
@@ -1819,8 +2323,15 @@ static int mmc_power_restore(struct mmc_
 {
 	int ret;
 
+#ifndef CONFIG_X86_PUMA7
+	host->card->state &= ~(MMC_STATE_HIGHSPEED | MMC_STATE_HIGHSPEED_200);
+#endif
 	mmc_claim_host(host);
+#ifndef CONFIG_X86_PUMA7
+	ret = mmc_init_card(host, host->ocr, host->card);
+#else
 	ret = mmc_init_card(host, host->card->ocr, host->card);
+#endif
 	mmc_release_host(host);
 
 	return ret;
@@ -1865,7 +2376,11 @@ static void mmc_attach_bus_ops(struct mm
 int mmc_attach_mmc(struct mmc_host *host)
 {
 	int err;
+#ifndef CONFIG_X86_PUMA7
+	u32 ocr;
+#else
 	u32 ocr, rocr;
+#endif
 
 	BUG_ON(!host);
 	WARN_ON(!host->claimed);
@@ -1891,12 +2406,31 @@ int mmc_attach_mmc(struct mmc_host *host
 			goto err;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Sanity check the voltages that the card claims to
+	 * support.
+	 */
+	if (ocr & 0x7F) {
+		pr_warning("%s: card claims to support voltages "
+		       "below the defined range. These will be ignored.\n",
+		       mmc_hostname(host));
+		ocr &= ~0x7F;
+	}
+
+	host->ocr = mmc_select_voltage(host, ocr);
+#else
 	rocr = mmc_select_voltage(host, ocr);
+#endif
 
 	/*
 	 * Can we support the voltage of the card?
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!host->ocr) {
+#else
 	if (!rocr) {
+#endif
 		err = -EINVAL;
 		goto err;
 	}
@@ -1904,22 +2438,62 @@ int mmc_attach_mmc(struct mmc_host *host
 	/*
 	 * Detect and init the card.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	err = mmc_init_card(host, host->ocr, NULL);
+#else
 	err = mmc_init_card(host, rocr, NULL);
+#endif
 	if (err)
 		goto err;
-
+#if defined(CONFIG_X86_PUMA6)
+    if (intelce_boot_mode == 1) {
+	    mmc_release_host_no_hwmutex(host);
+    } else {
+	    mmc_release_host(host);
+    }
+#else
 	mmc_release_host(host);
+#endif
+
 	err = mmc_add_card(host->card);
+
+#if defined(CONFIG_X86_PUMA6)
+    if (intelce_boot_mode == 1) {
+        mmc_claim_host_no_hwmutex(host);
+    } else {
+        mmc_claim_host(host);
+    }
+#else
 	mmc_claim_host(host);
+#endif
+
 	if (err)
 		goto remove_card;
 
 	return 0;
 
 remove_card:
+#if defined(CONFIG_X86_PUMA6)
+    if (intelce_boot_mode == 1) {
+	    mmc_release_host_no_hwmutex(host);
+    } else {
+	    mmc_release_host(host);
+    }
+#else
 	mmc_release_host(host);
+#endif
 	mmc_remove_card(host->card);
+
+#if defined(CONFIG_X86_PUMA6)
+    if (intelce_boot_mode == 1) {
+        mmc_claim_host_no_hwmutex(host);
+    } else {
+        mmc_claim_host(host);
+    }
+#else
 	mmc_claim_host(host);
+#endif
+
 	host->card = NULL;
 err:
 	mmc_detach_bus(host);
--- a/drivers/mmc/core/mmc_ops.c
+++ b/drivers/mmc/core/mmc_ops.c
@@ -23,6 +23,7 @@
 
 #define MMC_OPS_TIMEOUT_MS	(10 * 60 * 1000) /* 10 minute timeout */
 
+#ifdef CONFIG_X86_PUMA7
 static inline int __mmc_send_status(struct mmc_card *card, u32 *status,
 				    bool ignore_crc)
 {
@@ -57,6 +58,7 @@ int mmc_send_status(struct mmc_card *car
 	return __mmc_send_status(card, status, false);
 }
 
+#endif
 static int _mmc_select_card(struct mmc_host *host, struct mmc_card *card)
 {
 	int err;
@@ -404,12 +406,15 @@ int mmc_spi_set_crc(struct mmc_host *hos
  *	@timeout_ms: timeout (ms) for operation performed by register write,
  *                   timeout of zero implies maximum possible timeout
  *	@use_busy_signal: use the busy signal as response type
- *	@send_status: send status cmd to poll for busy
  *
  *	Modifies the EXT_CSD register for selected card.
  */
 int __mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
+#ifndef CONFIG_X86_PUMA7
+	       unsigned int timeout_ms, bool use_busy_signal)
+#else
 		unsigned int timeout_ms, bool use_busy_signal, bool send_status)
+#endif
 {
 	int err;
 	struct mmc_command cmd = {0};
@@ -444,6 +449,9 @@ int __mmc_switch(struct mmc_card *card,
 	if (!use_busy_signal)
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	/* Must check status to be sure of no errors */
+#else
 	/*
 	 * Must check status to be sure of no errors
 	 * If CMD13 is to check the busy completion of the timing change,
@@ -452,19 +460,27 @@ int __mmc_switch(struct mmc_card *card,
 	if (index == EXT_CSD_HS_TIMING &&
 	    !(card->host->caps & MMC_CAP_WAIT_WHILE_BUSY))
 		ignore_crc = true;
+#endif
 
 	timeout = jiffies + msecs_to_jiffies(MMC_OPS_TIMEOUT_MS);
 	do {
+#ifndef CONFIG_X86_PUMA7
+		err = mmc_send_status(card, &status);
+		if (err)
+			return err;
+#else
 		if (send_status) {
 			err = __mmc_send_status(card, &status, ignore_crc);
 			if (err)
 				return err;
 		}
+#endif
 		if (card->host->caps & MMC_CAP_WAIT_WHILE_BUSY)
 			break;
 		if (mmc_host_is_spi(card->host))
 			break;
 
+#ifdef CONFIG_X86_PUMA7
 		/*
 		 * We are not allowed to issue a status command and the host
 		 * does'nt support MMC_CAP_WAIT_WHILE_BUSY, then we can only
@@ -475,6 +491,7 @@ int __mmc_switch(struct mmc_card *card,
 			return 0;
 		}
 
+#endif
 		/* Timeout if the device never leaves the program state. */
 		if (time_after(jiffies, timeout)) {
 			pr_err("%s: Card stuck in programming state! %s\n",
@@ -501,10 +518,42 @@ EXPORT_SYMBOL_GPL(__mmc_switch);
 int mmc_switch(struct mmc_card *card, u8 set, u8 index, u8 value,
 		unsigned int timeout_ms)
 {
+#ifndef CONFIG_X86_PUMA7
+	return __mmc_switch(card, set, index, value, timeout_ms, true);
+#else
 	return __mmc_switch(card, set, index, value, timeout_ms, true, true);
+#endif
 }
 EXPORT_SYMBOL_GPL(mmc_switch);
 
+#ifndef CONFIG_X86_PUMA7
+int mmc_send_status(struct mmc_card *card, u32 *status)
+{
+	int err;
+	struct mmc_command cmd = {0};
+
+	BUG_ON(!card);
+	BUG_ON(!card->host);
+
+	cmd.opcode = MMC_SEND_STATUS;
+	if (!mmc_host_is_spi(card->host))
+		cmd.arg = card->rca << 16;
+	cmd.flags = MMC_RSP_SPI_R2 | MMC_RSP_R1 | MMC_CMD_AC;
+
+	err = mmc_wait_for_cmd(card->host, &cmd, MMC_CMD_RETRIES);
+	if (err)
+		return err;
+
+	/* NOTE: callers are required to understand the difference
+	 * between "native" and SPI format status words!
+	 */
+	if (status)
+		*status = cmd.resp[0];
+
+	return 0;
+}
+#endif
+
 static int
 mmc_send_bus_test(struct mmc_card *card, struct mmc_host *host, u8 opcode,
 		  u8 len)
--- a/drivers/mmc/core/sd.c
+++ b/drivers/mmc/core/sd.c
@@ -782,8 +782,12 @@ try_again:
 	 */
 	if (!mmc_host_is_spi(host) && rocr &&
 	   ((*rocr & 0x41000000) == 0x41000000)) {
+#ifndef CONFIG_X86_PUMA7
+		err = mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_180);
+#else
 		err = mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_180,
 					pocr);
+#endif
 		if (err == -EAGAIN) {
 			retries--;
 			goto try_again;
@@ -871,7 +875,6 @@ int mmc_sd_setup_card(struct mmc_host *h
 #else
 		err = mmc_read_switch(card);
 #endif
-
 		if (err)
 			return err;
 	}
@@ -917,7 +920,11 @@ unsigned mmc_sd_get_max_clock(struct mmc
 {
 	unsigned max_dtr = (unsigned int)-1;
 
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_card_highspeed(card)) {
+#else
 	if (mmc_card_hs(card)) {
+#endif
 		if (max_dtr > card->sw_caps.hs_max_dtr)
 			max_dtr = card->sw_caps.hs_max_dtr;
 	} else if (max_dtr > card->csd.max_dtr) {
@@ -927,6 +934,14 @@ unsigned mmc_sd_get_max_clock(struct mmc
 	return max_dtr;
 }
 
+#ifndef CONFIG_X86_PUMA7
+void mmc_sd_go_highspeed(struct mmc_card *card)
+{
+	mmc_card_set_highspeed(card);
+	mmc_set_timing(card->host, MMC_TIMING_SD_HS);
+}
+#endif
+
 /*
  * Handle the detection and initialisation of a card.
  *
@@ -961,7 +976,9 @@ static int mmc_sd_init_card(struct mmc_h
 		if (IS_ERR(card))
 			return PTR_ERR(card);
 
+#ifdef CONFIG_X86_PUMA7
 		card->ocr = ocr;
+#endif
 		card->type = MMC_TYPE_SD;
 		memcpy(card->raw_cid, cid, sizeof(card->raw_cid));
 	}
@@ -1001,13 +1018,22 @@ static int mmc_sd_init_card(struct mmc_h
 		err = mmc_sd_init_uhs_card(card);
 		if (err)
 			goto free_card;
+
+#ifndef CONFIG_X86_PUMA7
+		/* Card is an ultra-high-speed card */
+		mmc_card_set_uhs(card);
+#endif
 	} else {
 		/*
 		 * Attempt to change to high-speed (if supported)
 		 */
 		err = mmc_sd_switch_hs(card);
 		if (err > 0)
+#ifndef CONFIG_X86_PUMA7
+			mmc_sd_go_highspeed(card);
+#else
 			mmc_set_timing(card->host, MMC_TIMING_SD_HS);
+#endif
 		else if (err)
 			goto free_card;
 
@@ -1107,7 +1133,14 @@ static void mmc_sd_detect(struct mmc_hos
 	}
 }
 
+#ifndef CONFIG_X86_PUMA7
+/*
+ * Suspend callback from host.
+ */
+static int mmc_sd_suspend(struct mmc_host *host)
+#else
 static int _mmc_sd_suspend(struct mmc_host *host)
+#endif
 {
 	int err = 0;
 
@@ -1115,20 +1148,30 @@ static int _mmc_sd_suspend(struct mmc_ho
 	BUG_ON(!host->card);
 
 	mmc_claim_host(host);
+#ifdef CONFIG_X86_PUMA7
 
 	if (mmc_card_suspended(host->card))
 		goto out;
 
+#endif
 	if (!mmc_host_is_spi(host))
 		err = mmc_deselect_cards(host);
+#ifndef CONFIG_X86_PUMA7
+	host->card->state &= ~MMC_STATE_HIGHSPEED;
+	if (!err)
+#else
 
 	if (!err) {
+#endif
 		mmc_power_off(host);
+#ifdef CONFIG_X86_PUMA7
 		mmc_card_set_suspended(host->card);
 	}
 
 out:
+#endif
 	mmc_release_host(host);
+#ifdef CONFIG_X86_PUMA7
 	return err;
 }
 
@@ -1144,25 +1187,41 @@ static int mmc_sd_suspend(struct mmc_hos
 		pm_runtime_disable(&host->card->dev);
 		pm_runtime_set_suspended(&host->card->dev);
 	}
+#endif
 
 	return err;
 }
 
 /*
+ * Resume callback from host.
+ *
  * This function tries to determine if the same card is still present
  * and, if so, restore all state to it.
  */
+#ifndef CONFIG_X86_PUMA7
+static int mmc_sd_resume(struct mmc_host *host)
+#else
 static int _mmc_sd_resume(struct mmc_host *host)
+#endif
 {
+#ifndef CONFIG_X86_PUMA7
+	int err;
+#else
 	int err = 0;
 #ifdef CONFIG_MMC_PARANOID_SD_INIT
 	int retries;
 #endif
+#endif
 
 	BUG_ON(!host);
 	BUG_ON(!host->card);
 
 	mmc_claim_host(host);
+#ifndef CONFIG_X86_PUMA7
+	mmc_power_up(host);
+	mmc_select_voltage(host, host->ocr);
+	err = mmc_sd_init_card(host, host->ocr, host->card);
+#else
 
 	if (!mmc_card_suspended(host->card))
 		goto out;
@@ -1188,7 +1247,9 @@ static int _mmc_sd_resume(struct mmc_hos
 	mmc_card_clr_suspended(host->card);
 
 out:
+#endif
 	mmc_release_host(host);
+#ifdef CONFIG_X86_PUMA7
 	return err;
 }
 
@@ -1205,6 +1266,7 @@ static int mmc_sd_resume(struct mmc_host
 		pm_runtime_mark_last_busy(&host->card->dev);
 	}
 	pm_runtime_enable(&host->card->dev);
+#endif
 
 	return err;
 }
@@ -1219,11 +1281,27 @@ static int mmc_sd_runtime_suspend(struct
 	if (!(host->caps & MMC_CAP_AGGRESSIVE_PM))
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_claim_host(host);
+
+	err = mmc_sd_suspend(host);
+	if (err) {
+#else
 	err = _mmc_sd_suspend(host);
 	if (err)
+#endif
 		pr_err("%s: error %d doing aggessive suspend\n",
 			mmc_hostname(host), err);
+#ifndef CONFIG_X86_PUMA7
+		goto out;
+	}
+	mmc_power_off(host);
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+out:
+	mmc_release_host(host);
+#endif
 	return err;
 }
 
@@ -1234,14 +1312,28 @@ static int mmc_sd_runtime_resume(struct
 {
 	int err;
 
+#ifndef CONFIG_X86_PUMA7
+	if (!(host->caps & MMC_CAP_AGGRESSIVE_PM))
+#else
 	if (!(host->caps & (MMC_CAP_AGGRESSIVE_PM | MMC_CAP_RUNTIME_RESUME)))
+#endif
 		return 0;
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_claim_host(host);
+
+	mmc_power_up(host);
+	err = mmc_sd_resume(host);
+#else
 	err = _mmc_sd_resume(host);
+#endif
 	if (err)
 		pr_err("%s: error %d doing aggessive resume\n",
 			mmc_hostname(host), err);
 
+#ifndef CONFIG_X86_PUMA7
+	mmc_release_host(host);
+#endif
 	return 0;
 }
 
@@ -1249,8 +1341,15 @@ static int mmc_sd_power_restore(struct m
 {
 	int ret;
 
+#ifndef CONFIG_X86_PUMA7
+	host->card->state &= ~MMC_STATE_HIGHSPEED;
+#endif
 	mmc_claim_host(host);
+#ifndef CONFIG_X86_PUMA7
+	ret = mmc_sd_init_card(host, host->ocr, host->card);
+#else
 	ret = mmc_sd_init_card(host, host->card->ocr, host->card);
+#endif
 	mmc_release_host(host);
 
 	return ret;
@@ -1322,12 +1421,39 @@ int mmc_attach_sd(struct mmc_host *host)
 			goto err;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Sanity check the voltages that the card claims to
+	 * support.
+	 */
+	if (ocr & 0x7F) {
+		pr_warning("%s: card claims to support voltages "
+		       "below the defined range. These will be ignored.\n",
+		       mmc_hostname(host));
+		ocr &= ~0x7F;
+	}
+
+	if ((ocr & MMC_VDD_165_195) &&
+	    !(host->ocr_avail_sd & MMC_VDD_165_195)) {
+		pr_warning("%s: SD card claims to support the "
+		       "incompletely defined 'low voltage range'. This "
+		       "will be ignored.\n", mmc_hostname(host));
+		ocr &= ~MMC_VDD_165_195;
+	}
+
+	host->ocr = mmc_select_voltage(host, ocr);
+#else
 	rocr = mmc_select_voltage(host, ocr);
+#endif
 
 	/*
 	 * Can we support the voltage(s) of the card(s)?
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!host->ocr) {
+#else
 	if (!rocr) {
+#endif
 		err = -EINVAL;
 		goto err;
 	}
@@ -1352,10 +1478,14 @@ int mmc_attach_sd(struct mmc_host *host)
 		goto err;
 	}
 #else
+#ifdef CONFIG_X86_PUMA7
 	err = mmc_sd_init_card(host, rocr, NULL);
+#else
+	err = mmc_sd_init_card(host, host->ocr, NULL);
+#endif
+#endif /* CONFIG_MMC_PARANOID_SD_INIT */
 	if (err)
 		goto err;
-#endif
 
 	mmc_release_host(host);
 	err = mmc_add_card(host->card);
--- a/drivers/mmc/core/sd.h
+++ b/drivers/mmc/core/sd.h
@@ -12,5 +12,6 @@ int mmc_sd_setup_card(struct mmc_host *h
 	bool reinit);
 unsigned mmc_sd_get_max_clock(struct mmc_card *card);
 int mmc_sd_switch_hs(struct mmc_card *card);
+void mmc_sd_go_highspeed(struct mmc_card *card);
 
 #endif
--- a/drivers/mmc/core/sdio.c
+++ b/drivers/mmc/core/sdio.c
@@ -368,7 +368,11 @@ static unsigned mmc_sdio_get_max_clock(s
 {
 	unsigned max_dtr;
 
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_card_highspeed(card)) {
+#else
 	if (mmc_card_hs(card)) {
+#endif
 		/*
 		 * The SDIO specification doesn't mention how
 		 * the CIS transfer speed register relates to
@@ -604,22 +608,31 @@ static int mmc_sdio_init_card(struct mmc
 	BUG_ON(!host);
 	WARN_ON(!host->claimed);
 
+#ifdef CONFIG_X86_PUMA7
 	/* to query card if 1.8V signalling is supported */
 	if (mmc_host_uhs(host))
 		ocr |= R4_18V_PRESENT;
+#endif
 
 try_again:
 	if (!retries) {
 		pr_warning("%s: Skipping voltage switch\n",
 				mmc_hostname(host));
 		ocr &= ~R4_18V_PRESENT;
+#ifndef CONFIG_X86_PUMA7
+		host->ocr &= ~R4_18V_PRESENT;
+#endif
 	}
 
 	/*
 	 * Inform the card of the voltage
 	 */
 	if (!powered_resume) {
+#ifndef CONFIG_X86_PUMA7
+		err = mmc_send_io_op_cond(host, host->ocr, &ocr);
+#else
 		err = mmc_send_io_op_cond(host, ocr, &rocr);
+#endif
 		if (err)
 			goto err;
 	}
@@ -642,8 +655,13 @@ try_again:
 		goto err;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	if ((ocr & R4_MEMORY_PRESENT) &&
+	    mmc_sd_get_cid(host, host->ocr & ocr, card->raw_cid, NULL) == 0) {
+#else
 	if ((rocr & R4_MEMORY_PRESENT) &&
 	    mmc_sd_get_cid(host, ocr & rocr, card->raw_cid, NULL) == 0) {
+#endif
 		card->type = MMC_TYPE_SD_COMBO;
 
 		if (oldcard && (oldcard->type != MMC_TYPE_SD_COMBO ||
@@ -673,9 +691,14 @@ try_again:
 	 * systems that claim 1.8v signalling in fact do not support
 	 * it.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!powered_resume && (ocr & R4_18V_PRESENT) && mmc_host_uhs(host)) {
+		err = mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_180);
+#else
 	if (!powered_resume && (rocr & ocr & R4_18V_PRESENT)) {
 		err = mmc_set_signal_voltage(host, MMC_SIGNAL_VOLTAGE_180,
 					ocr);
+#endif
 		if (err == -EAGAIN) {
 			sdio_reset(host);
 			mmc_go_idle(host);
@@ -685,10 +708,16 @@ try_again:
 			goto try_again;
 		} else if (err) {
 			ocr &= ~R4_18V_PRESENT;
+#ifndef CONFIG_X86_PUMA7
+			host->ocr &= ~R4_18V_PRESENT;
+#endif
 		}
 		err = 0;
 	} else {
 		ocr &= ~R4_18V_PRESENT;
+#ifndef CONFIG_X86_PUMA7
+		host->ocr &= ~R4_18V_PRESENT;
+#endif
 	}
 
 	/*
@@ -738,12 +767,23 @@ try_again:
 		mmc_set_clock(host, card->cis.max_dtr);
 
 		if (card->cccr.high_speed) {
+#ifndef CONFIG_X86_PUMA7
+			mmc_card_set_highspeed(card);
+#endif
 			mmc_set_timing(card->host, MMC_TIMING_SD_HS);
 		}
 
 		goto finish;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Read the common registers.
+	 */
+	err = sdio_read_cccr(card, ocr);
+	if (err)
+		goto remove;
+#else
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	if (host->embedded_sdio_data.cccr)
 		memcpy(&card->cccr, host->embedded_sdio_data.cccr, sizeof(struct sdio_cccr));
@@ -758,7 +798,16 @@ try_again:
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	}
 #endif
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Read the common CIS tuples.
+	 */
+	err = sdio_read_common_cis(card);
+	if (err)
+		goto remove;
+#else
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	if (host->embedded_sdio_data.cis)
 		memcpy(&card->cis, host->embedded_sdio_data.cis, sizeof(struct sdio_cis));
@@ -773,6 +822,7 @@ try_again:
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	}
 #endif
+#endif
 
 	if (oldcard) {
 		int same = (card->cis.vendor == oldcard->cis.vendor &&
@@ -783,7 +833,9 @@ try_again:
 
 		card = oldcard;
 	}
+#ifdef CONFIG_X86_PUMA7
 	card->ocr = ocr_card;
+#endif
 	mmc_fixup_device(card, NULL);
 
 	if (card->type == MMC_TYPE_SD_COMBO) {
@@ -812,13 +864,22 @@ try_again:
 		err = mmc_sdio_init_uhs_card(card);
 		if (err)
 			goto remove;
+#ifndef CONFIG_X86_PUMA7
+
+		/* Card is an ultra-high-speed card */
+		mmc_card_set_uhs(card);
+#endif
 	} else {
 		/*
 		 * Switch to high-speed (if supported).
 		 */
 		err = sdio_enable_hs(card);
 		if (err > 0)
+#ifndef CONFIG_X86_PUMA7
+			mmc_sd_go_highspeed(card);
+#else
 			mmc_set_timing(card->host, MMC_TIMING_SD_HS);
+#endif
 		else if (err)
 			goto remove;
 
@@ -960,21 +1021,52 @@ static int mmc_sdio_pre_suspend(struct m
  */
 static int mmc_sdio_suspend(struct mmc_host *host)
 {
+#ifndef CONFIG_X86_PUMA7
+	int i, err = 0;
+
+	for (i = 0; i < host->card->sdio_funcs; i++) {
+		struct sdio_func *func = host->card->sdio_func[i];
+		if (func && sdio_func_present(func) && func->dev.driver) {
+			const struct dev_pm_ops *pmops = func->dev.driver->pm;
+			err = pmops->suspend(&func->dev);
+			if (err)
+				break;
+		}
+	}
+	while (err && --i >= 0) {
+		struct sdio_func *func = host->card->sdio_func[i];
+		if (func && sdio_func_present(func) && func->dev.driver) {
+			const struct dev_pm_ops *pmops = func->dev.driver->pm;
+			pmops->resume(&func->dev);
+		}
+	}
+
+	if (!err && mmc_card_keep_power(host) && mmc_card_wake_sdio_irq(host)) {
+#else
 	if (mmc_card_keep_power(host) && mmc_card_wake_sdio_irq(host)) {
+#endif
 		mmc_claim_host(host);
 		sdio_disable_wide(host->card);
 		mmc_release_host(host);
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	if (!err && !mmc_card_keep_power(host))
+#else
 	if (!mmc_card_keep_power(host))
+#endif
 		mmc_power_off(host);
 
+#ifndef CONFIG_X86_PUMA7
+	return err;
+#else
 	return 0;
+#endif
 }
 
 static int mmc_sdio_resume(struct mmc_host *host)
 {
-	int err = 0;
+	int i, err = 0;
 
 	BUG_ON(!host);
 	BUG_ON(!host->card);
@@ -984,7 +1076,12 @@ static int mmc_sdio_resume(struct mmc_ho
 
 	/* Restore power if needed */
 	if (!mmc_card_keep_power(host)) {
+#ifndef CONFIG_X86_PUMA7
+		mmc_power_up(host);
+		mmc_select_voltage(host, host->ocr);
+#else
 		mmc_power_up(host, host->card->ocr);
+#endif
 		/*
 		 * Tell runtime PM core we just powered up the card,
 		 * since it still believes the card is powered off.
@@ -1002,7 +1099,11 @@ static int mmc_sdio_resume(struct mmc_ho
 	if (mmc_card_is_removable(host) || !mmc_card_keep_power(host)) {
 		sdio_reset(host);
 		mmc_go_idle(host);
+#ifndef CONFIG_X86_PUMA7
+		err = mmc_sdio_init_card(host, host->ocr, host->card,
+#else
 		err = mmc_sdio_init_card(host, host->card->ocr, host->card,
+#endif
 					mmc_card_keep_power(host));
 	} else if (mmc_card_keep_power(host) && mmc_card_wake_sdio_irq(host)) {
 		/* We may have switched to 1-bit mode during suspend */
@@ -1017,6 +1118,26 @@ static int mmc_sdio_resume(struct mmc_ho
 		wake_up_process(host->sdio_irq_thread);
 	mmc_release_host(host);
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * If the card looked to be the same as before suspending, then
+	 * we proceed to resume all card functions.  If one of them returns
+	 * an error then we simply return that error to the core and the
+	 * card will be redetected as new.  It is the responsibility of
+	 * the function driver to perform further tests with the extra
+	 * knowledge it has of the card to confirm the card is indeed the
+	 * same as before suspending (same MAC address for network cards,
+	 * etc.) and return an error otherwise.
+	 */
+	for (i = 0; !err && i < host->card->sdio_funcs; i++) {
+		struct sdio_func *func = host->card->sdio_func[i];
+		if (func && sdio_func_present(func) && func->dev.driver) {
+			const struct dev_pm_ops *pmops = func->dev.driver->pm;
+			err = pmops->resume(&func->dev);
+		}
+	}
+
+#endif
 	host->pm_flags &= ~MMC_PM_KEEP_POWER;
 	return err;
 }
@@ -1024,6 +1145,7 @@ static int mmc_sdio_resume(struct mmc_ho
 static int mmc_sdio_power_restore(struct mmc_host *host)
 {
 	int ret;
+	u32 ocr;
 
 	BUG_ON(!host);
 	BUG_ON(!host->card);
@@ -1045,17 +1167,40 @@ static int mmc_sdio_power_restore(struct
 	 * for OLPC SD8686 (which expects a [CMD5,5,3,7] init sequence), and
 	 * harmless in other situations.
 	 *
+	 * With these steps taken, mmc_select_voltage() is also required to
+	 * restore the correct voltage setting of the card.
 	 */
 
 	sdio_reset(host);
 	mmc_go_idle(host);
 	mmc_send_if_cond(host, host->ocr_avail);
 
+#ifndef CONFIG_X86_PUMA7
+	ret = mmc_send_io_op_cond(host, 0, &ocr);
+#else
 	ret = mmc_send_io_op_cond(host, 0, NULL);
+#endif
 	if (ret)
 		goto out;
 
+#ifndef CONFIG_X86_PUMA7
+	if (host->ocr_avail_sdio)
+		host->ocr_avail = host->ocr_avail_sdio;
+
+	host->ocr = mmc_select_voltage(host, ocr & ~0x7F);
+	if (!host->ocr) {
+		ret = -EINVAL;
+		goto out;
+	}
+
+	if (mmc_host_uhs(host))
+		/* to query card if 1.8V signalling is supported */
+		host->ocr |= R4_18V_PRESENT;
+
+	ret = mmc_sdio_init_card(host, host->ocr, host->card,
+#else
 	ret = mmc_sdio_init_card(host, host->card->ocr, host->card,
+#endif
 				mmc_card_keep_power(host));
 	if (!ret && host->sdio_irqs)
 		mmc_signal_sdio_irq(host);
@@ -1076,7 +1221,11 @@ static int mmc_sdio_runtime_suspend(stru
 static int mmc_sdio_runtime_resume(struct mmc_host *host)
 {
 	/* Restore power and re-initialize. */
+#ifndef CONFIG_X86_PUMA7
+	mmc_power_up(host);
+#else
 	mmc_power_up(host, host->card->ocr);
+#endif
 	return mmc_sdio_power_restore(host);
 }
 
@@ -1113,13 +1262,33 @@ int mmc_attach_sdio(struct mmc_host *hos
 	if (host->ocr_avail_sdio)
 		host->ocr_avail = host->ocr_avail_sdio;
 
+#ifndef CONFIG_X86_PUMA7
+	/*
+	 * Sanity check the voltages that the card claims to
+	 * support.
+	 */
+	if (ocr & 0x7F) {
+		pr_warning("%s: card claims to support voltages "
+		       "below the defined range. These will be ignored.\n",
+		       mmc_hostname(host));
+		ocr &= ~0x7F;
+	}
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	host->ocr = mmc_select_voltage(host, ocr);
+#else
 	rocr = mmc_select_voltage(host, ocr);
+#endif
 
 	/*
 	 * Can we support the voltage(s) of the card(s)?
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!host->ocr) {
+#else
 	if (!rocr) {
+#endif
 		err = -EINVAL;
 		goto err;
 	}
@@ -1127,10 +1296,30 @@ int mmc_attach_sdio(struct mmc_host *hos
 	/*
 	 * Detect and init the card.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_host_uhs(host))
+		/* to query card if 1.8V signalling is supported */
+		host->ocr |= R4_18V_PRESENT;
+#else
 	err = mmc_sdio_init_card(host, rocr, NULL, 0);
 	if (err)
 		goto err;
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	err = mmc_sdio_init_card(host, host->ocr, NULL, 0);
+	if (err) {
+		if (err == -EAGAIN) {
+			/*
+			 * Retry initialization with S18R set to 0.
+			 */
+			host->ocr &= ~R4_18V_PRESENT;
+			err = mmc_sdio_init_card(host, host->ocr, NULL, 0);
+		}
+		if (err)
+			goto err;
+	}
+#endif
 	card = host->card;
 
 	/*
@@ -1166,6 +1355,12 @@ int mmc_attach_sdio(struct mmc_host *hos
 	 * Initialize (but don't add) all present functions.
 	 */
 	for (i = 0; i < funcs; i++, card->sdio_funcs++) {
+#ifndef CONFIG_X86_PUMA7
+		err = sdio_init_func(host->card, i + 1);
+		if (err)
+			goto remove;
+
+#else
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 		if (host->embedded_sdio_data.funcs) {
 			struct sdio_func *tmp;
@@ -1187,6 +1382,7 @@ int mmc_attach_sdio(struct mmc_host *hos
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 		}
 #endif
+#endif
 		/*
 		 * Enable Runtime PM for this func (if supported)
 		 */
--- a/drivers/mmc/core/sdio_bus.c
+++ b/drivers/mmc/core/sdio_bus.c
@@ -52,6 +52,15 @@ static ssize_t modalias_show(struct devi
 	return sprintf(buf, "sdio:c%02Xv%04Xd%04X\n",
 			func->class, func->vendor, func->device);
 }
+#ifndef CONFIG_X86_PUMA7
+
+static struct device_attribute sdio_dev_attrs[] = {
+	__ATTR_RO(class),
+	__ATTR_RO(vendor),
+	__ATTR_RO(device),
+	__ATTR_RO(modalias),
+	__ATTR_NULL,
+#else
 static DEVICE_ATTR_RO(modalias);
 
 static struct attribute *sdio_dev_attrs[] = {
@@ -60,8 +69,11 @@ static struct attribute *sdio_dev_attrs[
 	&dev_attr_device.attr,
 	&dev_attr_modalias.attr,
 	NULL,
+#endif
 };
+#ifdef CONFIG_X86_PUMA7
 ATTRIBUTE_GROUPS(sdio_dev);
+#endif
 
 static const struct sdio_device_id *sdio_match_one(struct sdio_func *func,
 	const struct sdio_device_id *id)
@@ -201,8 +213,24 @@ static int sdio_bus_remove(struct device
 
 #ifdef CONFIG_PM
 
+#ifdef CONFIG_PM_SLEEP
+static int pm_no_operation(struct device *dev)
+{
+	/*
+	 * Prevent the PM core from calling SDIO device drivers' suspend
+	 * callback routines, which it is not supposed to do, by using this
+	 * empty function as the bus type suspend callaback for SDIO.
+	 */
+	return 0;
+}
+#endif
+
 static const struct dev_pm_ops sdio_bus_pm_ops = {
+#ifndef CONFIG_X86_PUMA7
+	SET_SYSTEM_SLEEP_PM_OPS(pm_no_operation, pm_no_operation)
+#else
 	SET_SYSTEM_SLEEP_PM_OPS(pm_generic_suspend, pm_generic_resume)
+#endif
 	SET_RUNTIME_PM_OPS(
 		pm_generic_runtime_suspend,
 		pm_generic_runtime_resume,
@@ -220,7 +248,11 @@ static const struct dev_pm_ops sdio_bus_
 
 static struct bus_type sdio_bus_type = {
 	.name		= "sdio",
+#ifndef CONFIG_X86_PUMA7
+	.dev_attrs	= sdio_dev_attrs,
+#else
 	.dev_groups	= sdio_dev_groups,
+#endif
 	.match		= sdio_bus_match,
 	.uevent		= sdio_bus_uevent,
 	.probe		= sdio_bus_probe,
@@ -265,6 +297,9 @@ static void sdio_release_func(struct dev
 {
 	struct sdio_func *func = dev_to_sdio_func(dev);
 
+#ifndef CONFIG_X86_PUMA7
+	sdio_free_func_cis(func);
+#else
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	/*
 	 * If this device is embedded then we never allocated
@@ -273,6 +308,7 @@ static void sdio_release_func(struct dev
 	if (!func->card->host->embedded_sdio_data.funcs)
 #endif
 		sdio_free_func_cis(func);
+#endif
 
 	kfree(func->info);
 
--- a/drivers/mmc/core/sdio_irq.c
+++ b/drivers/mmc/core/sdio_irq.c
@@ -53,6 +53,7 @@ static int process_sdio_pending_irqs(str
 		return ret;
 	}
 
+#ifdef CONFIG_X86_PUMA7
 	if (pending && mmc_card_broken_irq_polling(card) &&
 	    !(host->caps & MMC_CAP_SDIO_IRQ)) {
 		unsigned char dummy;
@@ -64,6 +65,7 @@ static int process_sdio_pending_irqs(str
 		mmc_io_rw_direct(card, 0, 0, 0xff, 0, &dummy);
 	}
 
+#endif
 	count = 0;
 	for (i = 1; i <= 7; i++) {
 		if (pending & (1 << i)) {
--- a/drivers/mmc/core/sdio_ops.c
+++ b/drivers/mmc/core/sdio_ops.c
@@ -84,13 +84,21 @@ static int mmc_io_rw_direct_host(struct
 	cmd.arg |= (write && out) ? 0x08000000 : 0x00000000;
 	cmd.arg |= addr << 9;
 	cmd.arg |= in;
+#ifndef CONFIG_X86_PUMA7
+	cmd.flags = MMC_RSP_SPI_R5 | MMC_RSP_R5 | MMC_CMD_AC;
+#else
 	if (host->card && (host->card->quirks & MMC_QUIRK_NO_TUNING_IN_SLEEP))
 		cmd.flags = MMC_RSP_SPI_R5 | MMC_RSP_R5 | MMC_CMD_AC |
 			MMC_SKIP_TUNING;
 	else
 		cmd.flags = MMC_RSP_SPI_R5 | MMC_RSP_R5 | MMC_CMD_AC;
+#endif
 
 	err = mmc_wait_for_cmd(host, &cmd, 0);
+#ifndef CONFIG_X86_PUMA7
+	if (err)
+		return err;
+#else
 	if (err) {
 		if (err != -ETIMEDOUT && (cmd.flags & MMC_SKIP_TUNING)) {
 			cmd.error = 0;
@@ -102,6 +110,7 @@ static int mmc_io_rw_direct_host(struct
 		} else
 			return err;
 	}
+#endif
 
 	if (mmc_host_is_spi(host)) {
 		/* host driver already reported errors */
--- a/drivers/mmc/host/Kconfig
+++ b/drivers/mmc/host/Kconfig
@@ -96,7 +96,6 @@ config MMC_SDHCI_ACPI
 
 config MMC_SDHCI_ACPI_FORCE_POWER_ON
 	bool "Force Power On through ACPI methods"
-	depends on X86_PUMA7
 	depends on MMC_SDHCI_ACPI
 	help
 	  This forces the controller and all connected devices to
--- a/drivers/mmc/host/sdhci-acpi.c
+++ b/drivers/mmc/host/sdhci-acpi.c
@@ -143,6 +143,7 @@ static const struct sdhci_ops sdhci_acpi
 	.hw_reset   = sdhci_acpi_int_hw_reset,
 };
 
+#ifdef CONFIG_X86_PUMA7
 static const struct sdhci_ops sdhci_acpi_ops_int_cgm_emmc = {
 	.enable_dma = sdhci_acpi_enable_dma,
 	.hw_reset   = sdhci_acpi_int_hw_reset,
@@ -154,6 +155,7 @@ static const struct sdhci_ops sdhci_acpi
 #endif
 };
 
+#endif
 static const struct sdhci_acpi_chip sdhci_acpi_chip_int = {
 	.ops = &sdhci_acpi_ops_int,
 };
@@ -219,6 +221,11 @@ static int sdhci_acpi_remove_slot(struct
 
 static const struct sdhci_acpi_slot sdhci_acpi_slot_int_emmc = {
 	.chip    = &sdhci_acpi_chip_int,
+#ifndef CONFIG_X86_PUMA7
+	.caps    = MMC_CAP_8_BIT_DATA | MMC_CAP_NONREMOVABLE | MMC_CAP_HW_RESET,
+	.caps2   = MMC_CAP2_HC_ERASE_SZ,
+	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN,
+#else
 	.caps    = MMC_CAP_8_BIT_DATA | MMC_CAP_NONREMOVABLE | MMC_CAP_HW_RESET
 		| MMC_CAP_1_8V_DDR,
 	.caps2   = MMC_CAP2_HC_ERASE_SZ | MMC_CAP2_POLL_R1B_BUSY |
@@ -238,7 +245,9 @@ static const struct sdhci_acpi_slot sdhc
 	.caps2   = MMC_CAP2_HC_ERASE_SZ | MMC_CAP2_POLL_R1B_BUSY |
 		MMC_CAP2_CACHE_CTRL | MMC_CAP2_HS200_1_8V_SDR |
 		MMC_CAP2_CAN_DO_CMDQ,
+#endif
 	.flags   = SDHCI_ACPI_RUNTIME_PM,
+#ifdef CONFIG_X86_PUMA7
 	.quirks2 = SDHCI_QUIRK2_TUNING_POLL | SDHCI_QUIRK2_PRESET_VALUE_BROKEN
 		| SDHCI_QUIRK2_HW_MUTEX,
 	.pm_caps = MMC_PM_TUNING_AFTER_RTRESUME,
@@ -258,25 +267,36 @@ static const struct sdhci_acpi_slot sdhc
 	.pm_caps = MMC_PM_TUNING_AFTER_RTRESUME,
 	.probe_slot = sdhci_acpi_probe_slot,
 	.remove_slot = sdhci_acpi_remove_slot,
+#endif
 };
 
 static const struct sdhci_acpi_slot sdhci_acpi_slot_int_sdio = {
 	.quirks  = SDHCI_QUIRK_BROKEN_CARD_DETECTION,
+#ifndef CONFIG_X86_PUMA7
+	.quirks2 = SDHCI_QUIRK2_HOST_OFF_CARD_ON,
+#else
 	.quirks2 = SDHCI_QUIRK2_HOST_OFF_CARD_ON |
 		   SDHCI_QUIRK2_PRESET_VALUE_BROKEN |
 		   SDHCI_QUIRK2_FAKE_VDD,
+#endif
 	.caps    = MMC_CAP_NONREMOVABLE | MMC_CAP_POWER_OFF_CARD,
 	.flags   = SDHCI_ACPI_RUNTIME_PM,
 	.pm_caps = MMC_PM_KEEP_POWER,
+#ifdef CONFIG_X86_PUMA7
 	.probe_slot = sdhci_acpi_sdio_probe_slot,
 	.remove_slot = sdhci_acpi_remove_slot,
+#endif
 };
 
 static const struct sdhci_acpi_slot sdhci_acpi_slot_int_sd = {
 	.flags   = SDHCI_ACPI_SD_CD | SDHCI_ACPI_RUNTIME_PM,
+#ifndef CONFIG_X86_PUMA7
+	.quirks2 = SDHCI_QUIRK2_CARD_ON_NEEDS_BUS_ON,
+#else
 	.quirks2 = SDHCI_QUIRK2_PRESET_VALUE_BROKEN,
 	.probe_slot = sdhci_acpi_probe_slot,
 	.remove_slot = sdhci_acpi_remove_slot,
+#endif
 };
 
 struct sdhci_acpi_uid_slot {
@@ -286,31 +306,31 @@ struct sdhci_acpi_uid_slot {
 };
 
 static const struct sdhci_acpi_uid_slot sdhci_acpi_uids[] = {
-	{ "80860F14" , "1" , &sdhci_acpi_slot_int_emmc },
-	{ "80860F14" , "3" , &sdhci_acpi_slot_int_sd   },
-	{ "80860F16" , NULL, &sdhci_acpi_slot_int_sd   },
-	{ "80862B94" , "1" , &sdhci_acpi_slot_int_cgm_emmc1 },
-	{ "80862B95" , "1" , &sdhci_acpi_slot_int_cgm_emmc2 },
-	{ "80862B96" , "1" , &sdhci_acpi_slot_int_sd   },
-	{ "INT33BB"  , "2" , &sdhci_acpi_slot_int_sdio },
-	{ "INT33BB"  , "3" , &sdhci_acpi_slot_int_sd   },
-	{ "INT33C6"  , NULL, &sdhci_acpi_slot_int_sdio },
-	{ "INT3436"  , NULL, &sdhci_acpi_slot_int_sdio },
-	{ "INT344D"  , NULL, &sdhci_acpi_slot_int_sdio },
-	{ "PNP0D40"  },
-	{ },
+        { "80860F14" , "1" , &sdhci_acpi_slot_int_emmc },
+        { "80860F14" , "3" , &sdhci_acpi_slot_int_sd   },
+		{ "80860F16" , NULL, &sdhci_acpi_slot_int_sd   },
+        { "80862B94" , "1" , &sdhci_acpi_slot_int_cgm_emmc1 },
+        { "80862B95" , "1" , &sdhci_acpi_slot_int_cgm_emmc2 },
+        { "80862B96" , "1" , &sdhci_acpi_slot_int_sd   },
+        { "INT33BB"  , "2" , &sdhci_acpi_slot_int_sdio },
+        { "INT33BB"  , "3" , &sdhci_acpi_slot_int_sd   },
+        { "INT33C6"  , NULL, &sdhci_acpi_slot_int_sdio },
+        { "INT3436"  , NULL, &sdhci_acpi_slot_int_sdio },
+		{ "INT344D"  , NULL, &sdhci_acpi_slot_int_sdio },
+        { "PNP0D40"  },
+        { },
 };
 
 static const struct acpi_device_id sdhci_acpi_ids[] = {
-	{ "80860F14" },
-	{ "80860F16" },
-	{ "80862B94" },
-	{ "INT33BB"  },
-	{ "INT33C6"  },
-	{ "INT3436"  },
-	{ "INT344D"  },
-	{ "PNP0D40"  },
-	{ },
+        { "80860F14" },
+		{ "80860F16" },
+        { "80862B94" },
+        { "INT33BB"  },
+        { "INT33C6"  },
+        { "INT3436"  },
+		{ "INT344D"  },
+        { "PNP0D40"  },
+        { },
 };
 MODULE_DEVICE_TABLE(acpi, sdhci_acpi_ids);
 
@@ -416,6 +436,7 @@ static int sdhci_acpi_probe(struct platf
 	if (acpi_bus_get_device(handle, &device))
 		return -ENODEV;
 
+#ifdef CONFIG_X86_PUMA7
 	if (IS_ENABLED(CONFIG_MMC_SDHCI_ACPI_FORCE_POWER_ON)) {
 		/* Power on the SDHCI controller and its children */
 		acpi_device_fix_up_power(device);
@@ -423,6 +444,7 @@ static int sdhci_acpi_probe(struct platf
 			acpi_device_fix_up_power(child);
 	}
 
+#endif
 	if (acpi_bus_get_status(device) || !device->status.present)
 		return -ENODEV;
 
@@ -450,7 +472,9 @@ static int sdhci_acpi_probe(struct platf
 	c->slot = sdhci_acpi_get_slot(handle, hid);
 	c->pdev = pdev;
 	c->use_runtime_pm = sdhci_acpi_flag(c, SDHCI_ACPI_RUNTIME_PM);
+#ifdef CONFIG_X86_PUMA7
 	c->autosuspend_delay = 0;
+#endif
 
 	platform_set_drvdata(pdev, c);
 
@@ -475,17 +499,24 @@ static int sdhci_acpi_probe(struct platf
 			dma_mask = DMA_BIT_MASK(32);
 		}
 
+#ifndef CONFIG_X86_PUMA7
+		dev->dma_mask = &dev->coherent_dma_mask;
+		dev->coherent_dma_mask = dma_mask;
+#else
 		err = dma_coerce_mask_and_coherent(dev, dma_mask);
 		if (err)
 			goto err_free;
+#endif
 	}
 
 	if (c->slot) {
+#ifdef CONFIG_X86_PUMA7
 		if (c->slot->probe_slot) {
 			err = c->slot->probe_slot(pdev);
 			if (err)
 				goto err_free;
 		}
+#endif
 		if (c->slot->chip) {
 			host->ops            = c->slot->chip->ops;
 			host->quirks        |= c->slot->chip->quirks;
@@ -502,8 +533,8 @@ static int sdhci_acpi_probe(struct platf
 	}
 
 	host->mmc->caps2 |= MMC_CAP2_NO_PRESCAN_POWERUP;
-	
-#ifdef CONFIG_HW_MUTEXES
+
+#if defined(CONFIG_X86_PUMA7) && defined(CONFIG_HW_MUTEXES)
 	if (SDHCI_HOST_SUPPORTS_HW_MUTEX(host)) {
 		MMC_LOCK_HW_MUTEX(host->mmc);
 
@@ -518,9 +549,13 @@ static int sdhci_acpi_probe(struct platf
 #else 
 	err = sdhci_add_host(host);
 #endif
-	
+
 	if (err)
+#ifndef CONFIG_X86_PUMA7
+		goto err_free;
+#else
 		goto remove_slot;
+#endif
 
 	if (sdhci_acpi_flag(c, SDHCI_ACPI_SD_CD)) {
 		if (sdhci_acpi_add_own_cd(dev, gpio, host->mmc))
@@ -529,19 +564,26 @@ static int sdhci_acpi_probe(struct platf
 
 	if (c->use_runtime_pm) {
 		pm_runtime_set_active(dev);
+#ifndef CONFIG_X86_PUMA7
+		pm_suspend_ignore_children(dev, 1);
+		pm_runtime_set_autosuspend_delay(dev, 50);
+#else
 		if (c->autosuspend_delay)
 			pm_runtime_set_autosuspend_delay(dev, c->autosuspend_delay);
 		else
 			pm_runtime_set_autosuspend_delay(dev, 50);
+#endif
 		pm_runtime_use_autosuspend(dev);
 		pm_runtime_enable(dev);
 	}
 
 	return 0;
 
+#ifdef CONFIG_X86_PUMA7
 remove_slot:
 	if (c->slot && c->slot->remove_slot)
 		c->slot->remove_slot(pdev);
+#endif
 err_free:
 	sdhci_free_host(c->host);
 	return err;
@@ -559,9 +601,11 @@ static int sdhci_acpi_remove(struct plat
 		pm_runtime_put_noidle(dev);
 	}
 
+#ifdef CONFIG_X86_PUMA7
 	if (c->slot && c->slot->remove_slot)
 		c->slot->remove_slot(pdev);
 
+#endif
 	dead = (sdhci_readl(c->host, SDHCI_INT_STATUS) == ~0);
 	sdhci_remove_host(c->host, dead);
 	sdhci_free_host(c->host);
--- a/drivers/mmc/host/sdhci-pci.c
+++ b/drivers/mmc/host/sdhci-pci.c
@@ -19,18 +19,29 @@
 #include <linux/dma-mapping.h>
 #include <linux/slab.h>
 #include <linux/device.h>
+#ifdef CONFIG_X86_PUMA6
+#include <linux/aep.h>
+#endif
 #include <linux/mmc/host.h>
 #include <linux/scatterlist.h>
 #include <linux/io.h>
 #include <linux/gpio.h>
 #include <linux/pm_runtime.h>
 #include <linux/mmc/sdhci-pci-data.h>
-#ifdef CONFIG_HW_MUTEXES
-#include <linux/hw_mutex.h>
-#endif
+
 #include "sdhci.h"
 #include "sdhci-pci.h"
 
+#include <linux/hw_mutex.h>
+#if defined(CONFIG_CE_MAILBOX) && defined(CONFIG_X86_PUMA6)
+#include <linux/ce_mailbox.h>
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+int scan_thread_done = 0;
+extern int intelce_boot_mode;
+#endif
+
 /*****************************************************************************\
  *                                                                           *
  * Hardware specific quirk handling                                          *
@@ -310,11 +321,6 @@ static const struct sdhci_pci_fixes sdhc
 	.own_cd_for_runtime_pm = true,
 };
 
-static const struct sdhci_pci_fixes sdhci_intel_cgm_shared_emmc = {
-	.allow_runtime_pm = true,
-	.probe_slot	= cgm_emmc_probe_shared_slot,
-};
-
 /* Define Host controllers for Intel Merrifield platform */
 #define INTEL_MRFL_EMMC_0	0
 #define INTEL_MRFL_EMMC_1	1
@@ -338,6 +344,11 @@ static const struct sdhci_pci_fixes sdhc
 	.probe_slot	= intel_mrfl_mmc_probe_slot,
 };
 
+static const struct sdhci_pci_fixes sdhci_intel_cgm_shared_emmc = {
+	.allow_runtime_pm = true,
+	.probe_slot	= cgm_emmc_probe_shared_slot,
+};
+
 /* O2Micro extra registers */
 #define O2_SD_LOCK_WP		0xD3
 #define O2_SD_MULTI_VCC3V	0xEE
@@ -951,6 +962,30 @@ static const struct pci_device_id pci_id
 
 	{
 		.vendor		= PCI_VENDOR_ID_INTEL,
+		.device		= PCI_DEVICE_ID_INTEL_CGM_EMMC,
+		.subvendor	= PCI_ANY_ID,
+		.subdevice	= PCI_ANY_ID,
+		.driver_data	= (kernel_ulong_t)&sdhci_intel_cgm_shared_emmc,
+	},
+
+	{
+		.vendor		= PCI_VENDOR_ID_INTEL,
+		.device		= PCI_DEVICE_ID_INTEL_CGM_EMMC2,
+		.subvendor	= PCI_ANY_ID,
+		.subdevice	= PCI_ANY_ID,
+		.driver_data	= (kernel_ulong_t)&sdhci_intel_byt_emmc,
+	},
+
+	{
+		.vendor		= PCI_VENDOR_ID_INTEL,
+		.device		= PCI_DEVICE_ID_INTEL_CGM_SD,
+		.subvendor	= PCI_ANY_ID,
+		.subdevice	= PCI_ANY_ID,
+		.driver_data	= (kernel_ulong_t)&sdhci_intel_byt_sd,
+	},
+
+	{
+		.vendor		= PCI_VENDOR_ID_INTEL,
 		.device		= PCI_DEVICE_ID_INTEL_BSW_EMMC,
 		.subvendor	= PCI_ANY_ID,
 		.subdevice	= PCI_ANY_ID,
@@ -1046,30 +1081,6 @@ static const struct pci_device_id pci_id
 	},
 
 	{
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_CGM_EMMC,
-		.subvendor	= PCI_ANY_ID,
-		.subdevice	= PCI_ANY_ID,
-		.driver_data	= (kernel_ulong_t)&sdhci_intel_cgm_shared_emmc,
-	},
-
-	{
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_CGM_EMMC2,
-		.subvendor	= PCI_ANY_ID,
-		.subdevice	= PCI_ANY_ID,
-		.driver_data	= (kernel_ulong_t)&sdhci_intel_byt_emmc,
-	},
-
-	{
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_CGM_SD,
-		.subvendor	= PCI_ANY_ID,
-		.subdevice	= PCI_ANY_ID,
-		.driver_data	= (kernel_ulong_t)&sdhci_intel_byt_sd,
-	},
-
-	{
 		.vendor		= PCI_VENDOR_ID_O2,
 		.device		= PCI_DEVICE_ID_O2_8120,
 		.subvendor	= PCI_ANY_ID,
@@ -1149,6 +1160,91 @@ static int sdhci_pci_enable_dma(struct s
 	return 0;
 }
 
+#ifdef CONFIG_X86_PUMA6
+/* AEP only supports dword read and write */
+static inline u8 sdhci_puma6_readb(struct sdhci_host *host, int reg)
+{
+	int align_reg;
+	u32 align_val;
+	u8 val;
+	/* Align the register to 32 bit boundary */
+	align_reg = reg & ~0x3;
+	align_val = readl(host->ioaddr + align_reg);
+	val = (align_val >> ((reg % 4) * 8)) & 0xFF;
+
+	return val;
+}
+
+static inline u16 sdhci_puma6_readw(struct sdhci_host *host, int reg)
+{
+	int align_reg;
+	u32 align_val;
+	u16 val;
+	/* Align the register to 32 bit boundary */
+	align_reg = reg & ~0x3;
+  	align_val = readl(host->ioaddr + align_reg);
+  	val = (align_val >> ((reg % 4) * 8)) & 0xFFFF;
+
+	return val;
+}
+
+static inline void sdhci_puma6_writeb(struct sdhci_host *host, u8 val, int reg)
+{
+	int align_reg;
+	u32 align_val;
+
+	/* Align the register to 32 bit boundary */
+	align_reg = reg & ~0x3;
+	align_val = readl(host->ioaddr + align_reg);
+
+	/* Clear wanted byte and set with new value */
+	align_val = align_val &~ (0xFF <<  ((reg % 4) * 8));
+	align_val = align_val | val << ((reg % 4) * 8);
+	writel(align_val, host->ioaddr + align_reg);
+}
+
+static inline void sdhci_puma6_writew(struct sdhci_host *host, u16 val, int reg)
+{
+	int align_reg;
+	u32 align_val;
+	static u32 shadow_value;
+	static u32 shadow_valid = 0;
+	/* In Puma6, we must write to HC Registers within width of 32 bits (4 bytes alingment)
+	 * Solution: Read the 32 bit register, modify the High Word (16 bit), or Low Word, and write back 32 bits
+	 *
+	 * A special case is wiriting to TRANSFER MODE register.
+	 * Writing to TRANSFER MODE Register with Read/modify/write solution (as above), will trigger the
+	 * COMMAND Register, to send a message to eMMC card.
+	 * Solution: write the value of TRANSFER MODE to 'a shadow' register, and next time the user write
+	 * to COMMAND Register, then write the shadow register to TRANSFER MODE register.
+	 *
+	 * Note: According to spec after each writing to TRANSFER MODE register, and user will also write
+	 * to COMMAND Register.
+	 */
+
+	/* Align the register to 32 bit boundary */
+	align_reg = reg & ~0x3;
+
+	/* Save Transfer Mode to a shadow register */
+	if (unlikely(reg == SDHCI_TRANSFER_MODE)) {
+		shadow_value = val;
+		shadow_valid = 1;
+		return;
+	}
+	/* Restore the Transfer Mode from a shadow register */
+	if (unlikely((reg == SDHCI_COMMAND) && (shadow_valid == 1))) {
+		align_val = shadow_value;
+		shadow_valid = 0;
+	} else
+		align_val = readl(host->ioaddr + align_reg);
+	/* Clear wanted word and set with new value */
+	align_val = align_val &~ (0xFFFF <<  ((reg % 4) * 8));
+	align_val = align_val | val << ((reg % 4) * 8);
+
+	writel(align_val, host->ioaddr + align_reg);
+}
+#endif
+
 static int sdhci_pci_bus_width(struct sdhci_host *host, int width)
 {
 	u8 ctrl;
@@ -1197,11 +1293,19 @@ static void sdhci_pci_hw_reset(struct sd
 		slot->hw_reset(host);
 }
 
+#ifdef CONFIG_X86_PUMA6
+static struct sdhci_ops sdhci_pci_ops = {
+	.enable_dma	= sdhci_pci_enable_dma,
+	.platform_bus_width	= sdhci_pci_bus_width,
+	.hw_reset		= sdhci_pci_hw_reset,
+};
+#else
 static const struct sdhci_ops sdhci_pci_ops = {
 	.enable_dma	= sdhci_pci_enable_dma,
 	.platform_bus_width	= sdhci_pci_bus_width,
 	.hw_reset		= sdhci_pci_hw_reset,
 };
+#endif
 
 /*****************************************************************************\
  *                                                                           *
@@ -1224,6 +1328,10 @@ static int sdhci_pci_suspend(struct devi
 	if (!chip)
 		return 0;
 
+#ifdef CONFIG_X86_PUMA6
+	if (chip->quirks2 & SDHCI_QUIRK2_NO_SUSPEND)
+		return 0;
+#endif
 	for (i = 0; i < chip->num_slots; i++) {
 		slot = chip->slots[i];
 		if (!slot)
@@ -1279,6 +1387,10 @@ static int sdhci_pci_resume(struct devic
 	if (!chip)
 		return 0;
 
+#ifdef CONFIG_X86_PUMA6
+	if (chip->quirks2 & SDHCI_QUIRK2_NO_SUSPEND)
+		return 0;
+#endif
 	pci_set_power_state(pdev, PCI_D0);
 	pci_restore_state(pdev);
 	ret = pci_enable_device(pdev);
@@ -1413,6 +1525,13 @@ static struct sdhci_pci_slot *sdhci_pci_
 	struct sdhci_pci_slot *slot;
 	struct sdhci_host *host;
 	int ret, bar = first_bar + slotno;
+#ifdef CONFIG_X86_PUMA6
+	int tmp;
+	int id;
+	int aep_region = 0;
+	struct pci_dev *tmp_dev = NULL;
+	struct pci_dev *aep_pdev = NULL;
+#endif
 
 	if (!(pci_resource_flags(pdev, bar) & IORESOURCE_MEM)) {
 		dev_err(&pdev->dev, "BAR %d is not iomem. Aborting.\n", bar);
@@ -1471,6 +1590,43 @@ static struct sdhci_pci_slot *sdhci_pci_
 
 	host->irq = pdev->irq;
 
+#ifdef CONFIG_X86_PUMA6
+	/* Should not fail SDHCI probe, even if AEP is not supported */
+	aep_pdev = pci_get_device(PCI_VENDOR_ID_INTEL, 0x0956, NULL);
+	if (!aep_pdev)
+		dev_info(&pdev->dev, "AEP device is not found\n");
+	else {
+		ret = pci_request_region(aep_pdev, bar, mmc_hostname(host->mmc));
+		if (ret)
+			dev_info(&pdev->dev, "cannot request AEP region\n");
+		else {
+			aep_region = 1;
+			host->aep_base = pci_ioremap_bar(aep_pdev, bar);
+			if (!host->aep_base) {
+				dev_info(&pdev->dev, "failed to remap AEP registers\n");
+				pci_release_region(aep_pdev, bar);
+				aep_region = 0;
+			}
+			else {
+				if (readl(host->aep_base + PV_CONTROL) & PV_CNTL_AEP_EN)
+					host->aep_enabled = true;
+				else
+					host->aep_enabled = false;
+			}
+		}
+		pci_dev_put(aep_pdev);
+	}
+	/* Virtual emmc controller locates at offset 0x1000 of AEP base */
+	if (host->aep_enabled) {
+		host->ioaddr = host->aep_base + 0x1000;
+		/* AEP only supports DWORD register access */
+		sdhci_pci_ops.read_b = sdhci_puma6_readb;
+		sdhci_pci_ops.read_w = sdhci_puma6_readw;
+		sdhci_pci_ops.write_b = sdhci_puma6_writeb;
+		sdhci_pci_ops.write_w = sdhci_puma6_writew;
+	} else {
+#endif
+
 	ret = pci_request_region(pdev, bar, mmc_hostname(host->mmc));
 	if (ret) {
 		dev_err(&pdev->dev, "cannot request region\n");
@@ -1483,6 +1639,9 @@ static struct sdhci_pci_slot *sdhci_pci_
 		ret = -ENOMEM;
 		goto release;
 	}
+#ifdef CONFIG_X86_PUMA6
+	}
+#endif
 
 	if (chip->fixes && chip->fixes->probe_slot) {
 		ret = chip->fixes->probe_slot(slot);
@@ -1505,22 +1664,77 @@ static struct sdhci_pci_slot *sdhci_pci_
 	host->mmc->slotno = slotno;
 	host->mmc->caps2 |= MMC_CAP2_NO_PRESCAN_POWERUP;
 
-#ifdef CONFIG_HW_MUTEXES
+#ifdef CONFIG_X86_PUMA6
+	intelce_get_soc_info(&id, NULL);
+	if (id != CE2600_SOC_DEVICE_ID)
+    {
+		if(pdev->revision >= 0x2)
+			host->flags |= SDHCI_SUPPORT_DDR;
+	}
+#endif
+
+#if defined(CONFIG_X86_PUMA6) && defined(CONFIG_HW_MUTEXES)
+	/* If there's HW Mutex controller exist, then we'll need to use HW Mutex to make sure exclusive controller access from different processors */
+	tmp_dev = pci_get_device(0x8086, HW_MUTEX_DEV_ID,NULL);
+	if (tmp_dev)
+	{
+		host->flags |= SDHCI_SUPPORT_HW_MUTEX;
+		pci_dev_put(tmp_dev);
+	}
+
+#if defined(CONFIG_CE_MAILBOX)
+	if (SDHCI_HOST_HAS_HW_MUTEX(host) && (intelce_boot_mode == 0)) {
+		/* Wait till ARM doesn't use eMMC in legacy mode */
+		printk(KERN_INFO "waiting for eMMC legacy mode exit notification from NPCPU ... ...\n");
+		for (;;) {
+			tmp = npcpu_appcpu_mbx_receive_event_notification(NPCPU_EVENT_EMMC_INIT_EXIT,NULL);
+			if (tmp) {
+				dev_err(&pdev->dev, "can not receive legacy mode exit notification from NPCPU, retrying ... \n");
+			}
+			else
+				break;
+		}
+		tmp = npcpu_appcpu_mbx_send_ack(NPCPU_EVENT_EMMC_INIT_EXIT);
+		if (tmp) {
+			dev_err(&pdev->dev, "can not send NPCPU_EVENT_EMMC_INIT_EXIT ACK message to NPCPU \n");
+		}
+	}
+#endif /*CONFIG_CE_MAILBOX */
+	LOCK_EMMC_HW_MUTEX(host->mmc);
+
+	ret = sdhci_add_host(host);
+	if (intelce_boot_mode == 1) {
+		while (!scan_thread_done) {
+			schedule_timeout(10);
+		}
+	}
+
+	UNLOCK_EMMC_HW_MUTEX(host->mmc);
+#if defined(CONFIG_CE_MAILBOX)
+	if (SDHCI_HOST_HAS_HW_MUTEX(host) && (intelce_boot_mode == 0)) {
+		if (!ret) {
+			for (;;) {
+				printk(KERN_INFO "waiting for eMMC advanced mode exit notification from NPCPU ... ...\n");
+				tmp = npcpu_appcpu_mbx_receive_event_notification(NPCPU_EVENT_EMMC_ADVANCE_INIT_EXIT,NULL);
+				if (tmp) {
+					dev_err(&pdev->dev, "can not receive advanced mode exit notification from NPCPU, retrying ... \n");
+				}
+				else
+					break;
+			}
+		}
+	}
+#endif /*CONFIG_CE_MAILBOX */
+
+#elif defined(CONFIG_X86_PUMA7) && defined(CONFIG_HW_MUTEXES)
 	/* If there's a HW Mutex controller that exists, then we'll need to use a HW Mutex
 	 * to make sure and use exclusive controller access from different processors */
-
 	//Lock the HW Mutex (Gain Control)
 	MMC_LOCK_HW_MUTEX(host->mmc);
-
 	ret = sdhci_add_host(host);
-
-	//Unlock the HW Mutex (Release Control)
 	MMC_UNLOCK_HW_MUTEX(host->mmc);
-
 #else
-
 	ret = sdhci_add_host(host);
-
 #endif
 
 	if (ret)
@@ -1557,6 +1771,12 @@ cleanup:
 		slot->data->cleanup(slot->data);
 
 free:
+#ifdef CONFIG_X86_PUMA6
+	if (host->aep_base)
+		iounmap(host->aep_base);
+	if (aep_region)
+		pci_release_region(aep_pdev, bar);
+#endif
 	sdhci_free_host(host);
 
 	return ERR_PTR(ret);
@@ -1614,6 +1834,10 @@ static int sdhci_pci_probe(struct pci_de
 	u8 slots, first_bar;
 	int ret, i;
 
+#ifdef CONFIG_X86_PUMA6
+	unsigned int id;
+	intelce_get_soc_info(&id, NULL);
+#endif
 	BUG_ON(pdev == NULL);
 	BUG_ON(ent == NULL);
 
@@ -1661,6 +1885,12 @@ static int sdhci_pci_probe(struct pci_de
 	}
 	chip->num_slots = slots;
 
+#ifdef CONFIG_X86_PUMA6
+	if (CE2600_SOC_DEVICE_ID == id)
+    {
+		chip->quirks2 |= SDHCI_QUIRK2_NO_SUSPEND;
+    }
+#endif
 	pci_set_drvdata(pdev, chip);
 
 	if (chip->fixes && chip->fixes->probe) {
--- a/drivers/mmc/host/sdhci-pci.h
+++ b/drivers/mmc/host/sdhci-pci.h
@@ -24,6 +24,9 @@
 #define PCI_DEVICE_ID_INTEL_SPT_EMMC	0x9d2b
 #define PCI_DEVICE_ID_INTEL_SPT_SDIO	0x9d2c
 #define PCI_DEVICE_ID_INTEL_SPT_SD	0x9d2d
+#define PCI_DEVICE_ID_INTEL_CGM_EMMC	0x2B94
+#define PCI_DEVICE_ID_INTEL_CGM_EMMC2	0x2B95
+#define PCI_DEVICE_ID_INTEL_CGM_SD	    0x2B96
 
 /*
  * PCI registers
--- a/drivers/mmc/host/sdhci.c
+++ b/drivers/mmc/host/sdhci.c
@@ -28,9 +28,9 @@
 #include <linux/mmc/mmc.h>
 #include <linux/mmc/host.h>
 #include <linux/mmc/card.h>
-#include <linux/mmc/sdio.h>
 #include <linux/mmc/slot-gpio.h>
-#ifdef CONFIG_HW_MUTEXES
+
+#if defined(CONFIG_HW_MUTEXES)
 #include <linux/hw_mutex.h>
 #endif
 #include "sdhci.h"
@@ -51,7 +51,6 @@ static unsigned int debug_quirks = 0;
 static unsigned int debug_quirks2;
 
 static void sdhci_finish_data(struct sdhci_host *);
-
 static void sdhci_finish_command(struct sdhci_host *);
 static int sdhci_execute_tuning(struct mmc_host *mmc, u32 opcode);
 static void sdhci_tuning_timer(unsigned long data);
@@ -209,8 +208,12 @@ static void sdhci_reset(struct sdhci_hos
 			sdhci_runtime_pm_bus_off(host);
 	}
 
+#ifndef CONFIG_X86_PUMA7
 	/* Wait max 100 ms */
+	timeout = 100;
+#else
 	timeout = 10000;
+#endif
 
 	/* hw clears the bit when it's done */
 	while (sdhci_readb(host, SDHCI_SOFTWARE_RESET) & mask) {
@@ -221,7 +224,11 @@ static void sdhci_reset(struct sdhci_hos
 			return;
 		}
 		timeout--;
+#ifndef CONFIG_X86_PUMA7
+		mdelay(1);
+#else
 		udelay(10);
+#endif
 	}
 
 	if (host->ops->platform_reset_exit)
@@ -240,6 +247,8 @@ static void sdhci_set_ios(struct mmc_hos
 
 static void sdhci_init(struct sdhci_host *host, int soft)
 {
+	u32 aep_int;
+
 	if (soft)
 		sdhci_reset(host, SDHCI_RESET_CMD|SDHCI_RESET_DATA);
 	else
@@ -251,6 +260,14 @@ static void sdhci_init(struct sdhci_host
 		SDHCI_INT_END_BIT | SDHCI_INT_CRC | SDHCI_INT_TIMEOUT |
 		SDHCI_INT_DATA_END | SDHCI_INT_RESPONSE);
 
+#ifdef CONFIG_X86_PUMA6
+	if (host->aep_enabled) {
+		/* Enable AEP to Atom interrupt*/
+		aep_int = sdhci_readl(host, PV2ATOM_SW_INT);
+		aep_int |= EMMC_SW_INT | EMMC_SW_INT_EN | ATOM_DRBL_INT_EN;
+		sdhci_writel(host, aep_int, PV2ATOM_SW_INT);
+	}
+#endif
 	if (soft) {
 		/* force clock reconfiguration */
 		host->clock = 0;
@@ -677,6 +694,10 @@ static u8 sdhci_calc_timeout(struct sdhc
 	if (host->quirks & SDHCI_QUIRK_BROKEN_TIMEOUT_VAL)
 		return 0xE;
 
+#ifdef CONFIG_X86_PUMA6
+	if (!data)
+		return 0xE;
+#endif
 	/* Unspecified timeout, assume max */
 	if (!data && !cmd->cmd_timeout_ms)
 		return 0xE;
@@ -736,16 +757,21 @@ static void sdhci_prepare_data(struct sd
 	struct mmc_data *data = cmd->data;
 	int ret;
 
+	WARN_ON(host->data);
+
 	if (data || (cmd->flags & MMC_RSP_BUSY)) {
 		count = sdhci_calc_timeout(host, cmd);
+#ifdef CONFIG_X86_PUMA6
+		if (host->aep_enabled) {
+			count *= 2;
+        }
+#endif
 		sdhci_writeb(host, count, SDHCI_TIMEOUT_CONTROL);
 	}
 
 	if (!data)
 		return;
 
-	WARN_ON(host->data);
-
 	/* Sanity checks */
 	BUG_ON(data->blksz * data->blocks > 524288);
 	BUG_ON(data->blksz > host->mmc->max_blk_size);
@@ -889,10 +915,20 @@ static void sdhci_prepare_data(struct sd
 
 	sdhci_set_transfer_irqs(host);
 
+#ifdef CONFIG_X86_PUMA6
+	if (host->aep_enabled) {
+		sdhci_writel(host, (data->blocks << 16) |
+			SDHCI_MAKE_BLKSZ(7, data->blksz), SDHCI_BLOCK_SIZE);
+    }
+    else {
+#endif
 	/* Set the DMA boundary value and block size */
 	sdhci_writew(host, SDHCI_MAKE_BLKSZ(SDHCI_DEFAULT_BOUNDARY_ARG,
 		data->blksz), SDHCI_BLOCK_SIZE);
 	sdhci_writew(host, data->blocks, SDHCI_BLOCK_COUNT);
+#ifdef CONFIG_X86_PUMA6
+	}
+#endif
 }
 
 static void sdhci_set_transfer_mode(struct sdhci_host *host,
@@ -902,31 +938,49 @@ static void sdhci_set_transfer_mode(stru
 	struct mmc_data *data = cmd->data;
 
 	if (data == NULL) {
+#ifdef CONFIG_X86_PUMA7
 		/* clear Auto CMD settings for no data CMDs */
 		mode = sdhci_readw(host, SDHCI_TRANSFER_MODE);
 		sdhci_writew(host, mode & ~(SDHCI_TRNS_AUTO_CMD12 |
 				SDHCI_TRNS_AUTO_CMD23), SDHCI_TRANSFER_MODE);
+#endif
 		return;
 	}
 
 	WARN_ON(!host->data);
 
 	mode = SDHCI_TRNS_BLK_CNT_EN;
+#ifndef CONFIG_X86_PUMA7
+	if (mmc_op_multi(cmd->opcode) || data->blocks > 1) {
+#else
 	if (mmc_op_cmdq_execute_task(cmd->opcode) && (data->blocks > 1))
 		mode |= SDHCI_TRNS_MULTI;
 	else if (mmc_op_multi(cmd->opcode) || (data->blocks > 1)) {
+#endif
 		mode |= SDHCI_TRNS_MULTI;
 		/*
 		 * If we are sending CMD23, CMD12 never gets sent
 		 * on successful completion (so no Auto-CMD12).
 		 */
+#ifndef CONFIG_X86_PUMA7
+		if (!host->mrq->sbc && (host->flags & SDHCI_AUTO_CMD12))
+#else
 		if (!host->mrq->precmd && (host->flags & SDHCI_AUTO_CMD12))
+#endif
 			mode |= SDHCI_TRNS_AUTO_CMD12;
+#ifndef CONFIG_X86_PUMA7
+		else if (host->mrq->sbc && (host->flags & SDHCI_AUTO_CMD23)) {
+#else
 		else if (host->mrq->precmd && (host->flags &
 					SDHCI_AUTO_CMD23)) {
+#endif
 			mode |= SDHCI_TRNS_AUTO_CMD23;
+#ifndef CONFIG_X86_PUMA7
+			sdhci_writel(host, host->mrq->sbc->arg, SDHCI_ARGUMENT2);
+#else
 			sdhci_writel(host, host->mrq->precmd->arg,
 					SDHCI_ARGUMENT2);
+#endif
 		}
 	}
 
@@ -976,7 +1030,11 @@ static void sdhci_finish_data(struct sdh
 	 */
 	if (data->stop &&
 	    (data->error ||
+#ifndef CONFIG_X86_PUMA7
+	     !host->mrq->sbc)) {
+#else
 	     !host->mrq->precmd)) {
+#endif
 
 		/*
 		 * The controller needs a reset of internal state machines
@@ -988,12 +1046,17 @@ static void sdhci_finish_data(struct sdh
 		}
 
 		sdhci_send_command(host, data->stop);
+#ifndef CONFIG_X86_PUMA7
+	} else
+		tasklet_schedule(&host->finish_tasklet);
+#else
 	} else {
 		if (host->mmc->context_info.is_cmdq_busy)
 			tasklet_schedule(&host->finish_async_data_tasklet);
 		else
 			tasklet_schedule(&host->finish_tasklet);
 	}
+#endif
 }
 
 void sdhci_send_command(struct sdhci_host *host, struct mmc_command *cmd)
@@ -1005,7 +1068,17 @@ void sdhci_send_command(struct sdhci_hos
 	WARN_ON(host->cmd);
 
 	/* Wait max 10 ms */
+#ifdef CONFIG_X86_PUMA6
+	if (host->aep_enabled) {
+	/* Wait max 50 ms */
+		timeout = 50;
+    }
+	else
+#elif defined(CONFIG_X86_PUMA7)
 	timeout = 1000;
+#else
+	timeout = 10;
+#endif
 
 	mask = SDHCI_CMD_INHIBIT;
 	if ((cmd->data != NULL) || (cmd->flags & MMC_RSP_BUSY))
@@ -1026,18 +1099,28 @@ void sdhci_send_command(struct sdhci_hos
 			return;
 		}
 		timeout--;
+#ifndef CONFIG_X86_PUMA7
+		mdelay(1);
+#else
 		udelay(10);
+#endif
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	mod_timer(&host->timer, jiffies + 10 * HZ);
+#else
 	timeout = jiffies;
 	if (!cmd->data && cmd->cmd_timeout_ms > 9000)
 		timeout += DIV_ROUND_UP(cmd->cmd_timeout_ms, 1000) * HZ + HZ;
 	else
 		timeout += 10 * HZ;
 	mod_timer(&host->timer, timeout);
+#endif
 
 	host->cmd = cmd;
+#ifdef CONFIG_X86_PUMA7
 	host->busy_handle = 0;
+#endif
 
 	sdhci_prepare_data(host, cmd);
 
@@ -1072,11 +1155,13 @@ void sdhci_send_command(struct sdhci_hos
 	    cmd->opcode == MMC_SEND_TUNING_BLOCK_HS200)
 		flags |= SDHCI_CMD_DATA;
 
+#ifdef CONFIG_X86_PUMA7
 	/* CMD46/47 doesn't wait for data */
 	if (mmc_op_cmdq_execute_task(cmd->opcode)) {
 		cmd->data = NULL;
 		host->mrq->data = NULL;
 	}
+#endif
 
 	sdhci_writew(host, SDHCI_MAKE_CMD(cmd->opcode, flags), SDHCI_COMMAND);
 }
@@ -1107,12 +1192,18 @@ static void sdhci_finish_command(struct
 	host->cmd->error = 0;
 
 	/* Finished CMD23, now send actual command. */
+#ifndef CONFIG_X86_PUMA7
+	if (host->cmd == host->mrq->sbc) {
+#else
 	if (host->cmd == host->mrq->precmd) {
+#endif
 		host->cmd = NULL;
 		sdhci_send_command(host, host->mrq->cmd);
+#ifdef CONFIG_X86_PUMA7
 	} else if ((host->cmd == host->mrq->cmd) && host->mrq->cmd2) {
 		host->cmd = NULL;
 		sdhci_send_command(host, host->mrq->cmd2);
+#endif
 	} else {
 
 		/* Processed actual command. */
@@ -1255,8 +1346,15 @@ clock_set:
 	clk |= SDHCI_CLOCK_INT_EN;
 	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
 
+#ifdef CONFIG_X86_PUMA6
+	if (!host->aep_enabled) {
+#endif
+#ifndef CONFIG_X86_PUMA7
 	/* Wait max 20 ms */
+	timeout = 20;
+#else
 	timeout = 2000;
+#endif
 	while (!((clk = sdhci_readw(host, SDHCI_CLOCK_CONTROL))
 		& SDHCI_CLOCK_INT_STABLE)) {
 		if (timeout == 0) {
@@ -1266,8 +1364,15 @@ clock_set:
 			return;
 		}
 		timeout--;
+#ifndef CONFIG_X86_PUMA7
+		mdelay(1);
+#else
 		udelay(10);
+#endif
+	}
+#ifdef CONFIG_X86_PUMA6
 	}
+#endif
 
 	clk |= SDHCI_CLOCK_CARD_EN;
 	sdhci_writew(host, clk, SDHCI_CLOCK_CONTROL);
@@ -1367,12 +1472,14 @@ static void sdhci_request(struct mmc_hos
 
 	sdhci_runtime_pm_get(host);
 
+#ifdef CONFIG_X86_PUMA7
 	if (host->mmc->caps & MMC_CAP_NONREMOVABLE)
 		present = 1;
 	else
 		present = mmc_gpio_get_cd(host->mmc);
-
-
+#else
+	present = mmc_gpio_get_cd(host->mmc);
+#endif
 	spin_lock_irqsave(&host->lock, flags);
 
 	WARN_ON(host->mrq != NULL);
@@ -1385,7 +1492,11 @@ static void sdhci_request(struct mmc_hos
 	 * Ensure we don't send the STOP for non-SET_BLOCK_COUNTED
 	 * requests if Auto-CMD12 is enabled.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!mrq->sbc && (host->flags & SDHCI_AUTO_CMD12)) {
+#else
 	if (!mrq->precmd && (host->flags & SDHCI_AUTO_CMD12)) {
+#endif
 		if (mrq->stop) {
 			mrq->data->stop = NULL;
 			mrq->stop = NULL;
@@ -1423,9 +1534,14 @@ static void sdhci_request(struct mmc_hos
 		 * tuning procedure before sending command.
 		 */
 		if ((host->flags & SDHCI_NEEDS_RETUNING) &&
+#ifndef CONFIG_X86_PUMA7
+		    !(present_state & (SDHCI_DOING_WRITE | SDHCI_DOING_READ))) {
+#else
 		    !(present_state & (SDHCI_DOING_WRITE | SDHCI_DOING_READ)) &&
 		    (present_state & SDHCI_DATA_0_LVL_MASK)) {
+#endif
 			if (mmc->card) {
+#ifdef CONFIG_X86_PUMA7
 				if (mrq->cmd->flags & MMC_SKIP_TUNING)
 					goto end_tuning;
 				if ((mmc->card->ext_csd.part_config & 0x07) ==
@@ -1434,18 +1550,19 @@ static void sdhci_request(struct mmc_hos
 				/* don't do tuning when cmdq is not empty */
 				if (mmc->context_info.is_cmdq_busy)
 					goto end_tuning;
+#endif
 				/* eMMC uses cmd21 but sd and sdio use cmd19 */
 				tuning_opcode =
 					mmc->card->type == MMC_TYPE_MMC ?
 					MMC_SEND_TUNING_BLOCK_HS200 :
 					MMC_SEND_TUNING_BLOCK;
-
+#ifdef CONFIG_X86_PUMA7
 				/* Here we need to set the host->mrq to NULL,
 				 * in case the pending finish_tasklet
 				 * finishes it incorrectly.
 				 */
 				host->mrq = NULL;
-
+#endif
 				spin_unlock_irqrestore(&host->lock, flags);
 				sdhci_execute_tuning(mmc, tuning_opcode);
 				spin_lock_irqsave(&host->lock, flags);
@@ -1455,6 +1572,11 @@ static void sdhci_request(struct mmc_hos
 			}
 		}
 
+#ifndef CONFIG_X86_PUMA7
+		if (mrq->sbc && !(host->flags & SDHCI_AUTO_CMD23))
+			sdhci_send_command(host, mrq->sbc);
+		else
+#else
 end_tuning:
 		if (!(sdhci_readw(host, SDHCI_CLOCK_CONTROL) &
 					SDHCI_CLOCK_CARD_EN)) {
@@ -1482,10 +1604,13 @@ end_tuning:
 			} else
 				sdhci_send_command(host, mrq->precmd);
 		} else
+#endif
 			sdhci_send_command(host, mrq->cmd);
 	}
 
+#ifdef CONFIG_X86_PUMA7
 out:
+#endif
 	mmiowb();
 	spin_unlock_irqrestore(&host->lock, flags);
 }
@@ -1515,8 +1640,12 @@ static void sdhci_do_set_ios(struct sdhc
 	}
 
 	if (host->version >= SDHCI_SPEC_300 &&
+#ifndef CONFIG_X86_PUMA7
+		(ios->power_mode == MMC_POWER_UP))
+#else
 		(ios->power_mode == MMC_POWER_UP) &&
 		!(host->quirks2 & SDHCI_QUIRK2_PRESET_VALUE_BROKEN))
+#endif
 		sdhci_enable_preset_value(host, false);
 
 	sdhci_set_clock(host, ios->clock);
@@ -1526,6 +1655,7 @@ static void sdhci_do_set_ios(struct sdhc
 	else
 		vdd_bit = sdhci_set_power(host, ios->vdd);
 
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * some controller is not able to set the power control register
 	 * after resuming from low power mode, and need some cycles to
@@ -1556,6 +1686,7 @@ static void sdhci_do_set_ios(struct sdhc
 						mmc_hostname(host->mmc));
 		}
 	}
+#endif
 
 	if (host->vmmc && vdd_bit != -1) {
 		spin_unlock_irqrestore(&host->lock, flags);
@@ -1603,9 +1734,13 @@ static void sdhci_do_set_ios(struct sdhc
 		u16 clk, ctrl_2;
 
 		/* In case of UHS-I modes, set High Speed Enable */
+#ifndef CONFIG_X86_PUMA7
+		if ((ios->timing == MMC_TIMING_MMC_HS200) ||
+#else
 		if ((ios->timing == MMC_TIMING_MMC_HS400) ||
 		    (ios->timing == MMC_TIMING_MMC_HS200) ||
 		    (ios->timing == MMC_TIMING_MMC_DDR52) ||
+#endif
 		    (ios->timing == MMC_TIMING_UHS_SDR50) ||
 		    (ios->timing == MMC_TIMING_UHS_SDR104) ||
 		    (ios->timing == MMC_TIMING_UHS_DDR50) ||
@@ -1657,9 +1792,13 @@ static void sdhci_do_set_ios(struct sdhc
 			ctrl_2 = sdhci_readw(host, SDHCI_HOST_CONTROL2);
 			/* Select Bus Speed Mode for host */
 			ctrl_2 &= ~SDHCI_CTRL_UHS_MASK;
+#ifndef CONFIG_X86_PUMA7
+			if ((ios->timing == MMC_TIMING_MMC_HS200) ||
+#else
 			if (ios->timing == MMC_TIMING_MMC_HS400)
 				ctrl_2 |= SDHCI_CTRL_MMC_HS400;
 			else if ((ios->timing == MMC_TIMING_MMC_HS200) ||
+#endif
 			    (ios->timing == MMC_TIMING_UHS_SDR104))
 				ctrl_2 |= SDHCI_CTRL_UHS_SDR104;
 			else if (ios->timing == MMC_TIMING_UHS_SDR12)
@@ -1668,8 +1807,12 @@ static void sdhci_do_set_ios(struct sdhc
 				ctrl_2 |= SDHCI_CTRL_UHS_SDR25;
 			else if (ios->timing == MMC_TIMING_UHS_SDR50)
 				ctrl_2 |= SDHCI_CTRL_UHS_SDR50;
+#ifndef CONFIG_X86_PUMA7
+			else if (ios->timing == MMC_TIMING_UHS_DDR50)
+#else
 			else if ((ios->timing == MMC_TIMING_UHS_DDR50) ||
 				 (ios->timing == MMC_TIMING_MMC_DDR52))
+#endif
 				ctrl_2 |= SDHCI_CTRL_UHS_DDR50;
 			sdhci_writew(host, ctrl_2, SDHCI_HOST_CONTROL2);
 		}
@@ -1737,11 +1880,15 @@ void sdhci_wait_for_card_stable(struct s
 
 static int sdhci_do_get_cd(struct sdhci_host *host)
 {
+#ifndef CONFIG_X86_PUMA7
+	int gpio_cd = mmc_gpio_get_cd(host->mmc);
+#else
 	int gpio_cd;
 
 	sdhci_wait_for_card_stable(host);
 
 	gpio_cd = mmc_gpio_get_cd(host->mmc);
+#endif
 
 	if (host->flags & SDHCI_DEVICE_DEAD)
 		return 0;
@@ -1885,7 +2032,11 @@ static int sdhci_do_start_signal_voltage
 		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
 
 		if (host->vqmmc) {
+#ifndef CONFIG_X86_PUMA7
+			ret = regulator_set_voltage(host->vqmmc, 2700000, 3600000);
+#else
 			ret = regulator_set_voltage(host->vqmmc, 3300000, 3600000);
+#endif
 			if (ret) {
 				pr_warning("%s: Switching to 3.3V signalling voltage "
 						" failed\n", mmc_hostname(host->mmc));
@@ -1907,7 +2058,11 @@ static int sdhci_do_start_signal_voltage
 	case MMC_SIGNAL_VOLTAGE_180:
 		if (host->vqmmc) {
 			ret = regulator_set_voltage(host->vqmmc,
+#ifndef CONFIG_X86_PUMA7
+					1700000, 1950000);
+#else
 					1800000, 1950000);
+#endif
 			if (ret) {
 				pr_warning("%s: Switching to 1.8V signalling voltage "
 						" failed\n", mmc_hostname(host->mmc));
@@ -1983,6 +2138,7 @@ static int sdhci_execute_tuning(struct m
 	u16 ctrl;
 	u32 ier;
 	int tuning_loop_counter = MAX_TUNING_LOOP;
+	unsigned long timeout;
 	int err = 0;
 	bool requires_tuning_nonuhs = false;
 	unsigned long flags;
@@ -1990,7 +2146,12 @@ static int sdhci_execute_tuning(struct m
 	host = mmc_priv(mmc);
 
 	sdhci_runtime_pm_get(host);
+#ifndef CONFIG_X86_PUMA7
+	disable_irq(host->irq);
+	spin_lock(&host->lock);
+#else
 	spin_lock_irqsave(&host->lock, flags);
+#endif
 
 	ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
 
@@ -2001,6 +2162,11 @@ static int sdhci_execute_tuning(struct m
 	 * If the Host Controller supports the HS200 mode then the
 	 * tuning function has to be executed.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (((ctrl & SDHCI_CTRL_UHS_MASK) == SDHCI_CTRL_UHS_SDR50) &&
+	    (host->flags & SDHCI_SDR50_NEEDS_TUNING ||
+	     host->flags & SDHCI_SDR104_NEEDS_TUNING))
+#else
 	if ((((ctrl & SDHCI_CTRL_UHS_MASK) == SDHCI_CTRL_UHS_SDR50) &&
 	    (host->flags & SDHCI_SDR50_NEEDS_TUNING) &&
 	    (mmc->ios.timing == MMC_TIMING_UHS_SDR50)) ||
@@ -2008,17 +2174,24 @@ static int sdhci_execute_tuning(struct m
 	      ((mmc->ios.timing == MMC_TIMING_MMC_HS200) ||
 	      (mmc->ios.timing == MMC_TIMING_MMC_HS400))) ||
 	       mmc->ios.timing == MMC_TIMING_UHS_SDR104)
+#endif
 		requires_tuning_nonuhs = true;
 
 	if (((ctrl & SDHCI_CTRL_UHS_MASK) == SDHCI_CTRL_UHS_SDR104) ||
 	    requires_tuning_nonuhs)
 		ctrl |= SDHCI_CTRL_EXEC_TUNING;
 	else {
+#ifndef CONFIG_X86_PUMA7
+		spin_unlock(&host->lock);
+		enable_irq(host->irq);
+#else
 		spin_unlock_irqrestore(&host->lock, flags);
+#endif
 		sdhci_runtime_pm_put(host);
 		return 0;
 	}
 
+#ifdef CONFIG_X86_PUMA7
 	if (host->ops->platform_execute_tuning) {
 		spin_unlock_irqrestore(&host->lock, flags);
 		err = host->ops->platform_execute_tuning(host, opcode);
@@ -2026,6 +2199,7 @@ static int sdhci_execute_tuning(struct m
 		return err;
 	}
 
+#endif
 	sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
 
 	/*
@@ -2045,10 +2219,18 @@ static int sdhci_execute_tuning(struct m
 	 * Issue CMD19 repeatedly till Execute Tuning is set to 0 or the number
 	 * of loops reaches 40 times or a timeout of 150ms occurs.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	timeout = 150;
+#endif
 	do {
 		struct mmc_command cmd = {0};
 		struct mmc_request mrq = {NULL};
 
+#ifndef CONFIG_X86_PUMA7
+		if (!tuning_loop_counter && !timeout)
+			break;
+
+#endif
 		cmd.opcode = opcode;
 		cmd.arg = 0;
 		cmd.flags = MMC_RSP_R1 | MMC_CMD_ADTC;
@@ -2056,9 +2238,11 @@ static int sdhci_execute_tuning(struct m
 		cmd.data = NULL;
 		cmd.error = 0;
 
+#ifdef CONFIG_X86_PUMA7
 		if (tuning_loop_counter-- == 0)
 			break;
 
+#endif
 		mrq.cmd = &cmd;
 		host->mrq = &mrq;
 
@@ -2092,6 +2276,17 @@ static int sdhci_execute_tuning(struct m
 		host->cmd = NULL;
 		host->mrq = NULL;
 
+#ifndef CONFIG_X86_PUMA7
+		spin_unlock(&host->lock);
+		enable_irq(host->irq);
+
+		/* Wait for Buffer Read Ready interrupt */
+		wait_event_interruptible_timeout(host->buf_ready_int,
+					(host->tuning_done == 1),
+					msecs_to_jiffies(50));
+		disable_irq(host->irq);
+		spin_lock(&host->lock);
+#else
 		if (unlikely(host->quirks2 & SDHCI_QUIRK2_TUNING_POLL)) {
 			unsigned long timeout = jiffies + msecs_to_jiffies(150);
 			do {
@@ -2113,6 +2308,7 @@ static int sdhci_execute_tuning(struct m
 						msecs_to_jiffies(50));
 			spin_lock_irqsave(&host->lock, flags);
 		}
+#endif
 
 		if (!host->tuning_done) {
 			pr_info(DRIVER_NAME ": Timeout waiting for "
@@ -2124,9 +2320,10 @@ static int sdhci_execute_tuning(struct m
 			ctrl &= ~SDHCI_CTRL_EXEC_TUNING;
 			sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
 
+#ifdef CONFIG_X86_PUMA7
 			sdhci_reset(host, SDHCI_RESET_CMD);
 			sdhci_reset(host, SDHCI_RESET_DATA);
-
+#endif
 			err = -EIO;
 			goto out;
 		}
@@ -2134,25 +2331,44 @@ static int sdhci_execute_tuning(struct m
 		host->tuning_done = 0;
 
 		ctrl = sdhci_readw(host, SDHCI_HOST_CONTROL2);
-
+#ifndef CONFIG_X86_PUMA7
+		tuning_loop_counter--;
+		timeout--;
+		mdelay(1);
+#else
 		/* eMMC spec does not require a delay between tuning cycles */
 		if (opcode == MMC_SEND_TUNING_BLOCK)
 			mdelay(1);
+#endif
 	} while (ctrl & SDHCI_CTRL_EXEC_TUNING);
 
 	/*
 	 * The Host Driver has exhausted the maximum number of loops allowed,
 	 * so use fixed sampling frequency.
 	 */
+#ifndef CONFIG_X86_PUMA7
+	if (!tuning_loop_counter || !timeout) {
+#else
 	if (tuning_loop_counter < 0) {
+#endif
 		ctrl &= ~SDHCI_CTRL_TUNED_CLK;
 		sdhci_writew(host, ctrl, SDHCI_HOST_CONTROL2);
+#ifndef CONFIG_X86_PUMA7
+	} else {
+		if (!(ctrl & SDHCI_CTRL_TUNED_CLK)) {
+			pr_info(DRIVER_NAME ": Tuning procedure"
+				" failed, falling back to fixed sampling"
+				" clock\n");
+			err = -EIO;
+		}
+#else
 		err = -EIO;
 	}
 	if (!(ctrl & SDHCI_CTRL_TUNED_CLK)) {
 		pr_info(DRIVER_NAME ": Tuning procedure"
 			" failed, falling back to fixed sampling"
 			" clock\n");
+#endif
 	}
 
 out:
@@ -2169,14 +2385,24 @@ out:
 			host->tuning_count * HZ);
 		/* Tuning mode 1 limits the maximum data length to 4MB */
 		mmc->max_blk_count = (4 * 1024 * 1024) / mmc->max_blk_size;
+#ifndef CONFIG_X86_PUMA7
+	} else {
+#else
 	} else if (err && host->mmc->card && (host->mmc->card->quirks &
 				MMC_QUIRK_NO_TUNING_IN_SLEEP)) {
 		pr_debug("%s: will do retuning\n", mmc_hostname(host->mmc));
 	} else if (host->flags & SDHCI_USING_RETUNING_TIMER) {
+#endif
 		host->flags &= ~SDHCI_NEEDS_RETUNING;
 		/* Reload the new initial value for timer */
+#ifndef CONFIG_X86_PUMA7
+		if (host->tuning_mode == SDHCI_TUNING_MODE_1)
+			mod_timer(&host->tuning_timer, jiffies +
+				host->tuning_count * HZ);
+#else
 		mod_timer(&host->tuning_timer, jiffies +
 			  host->tuning_count * HZ);
+#endif
 	}
 
 	/*
@@ -2191,7 +2417,12 @@ out:
 		err = 0;
 
 	sdhci_clear_set_irqs(host, SDHCI_INT_DATA_AVAIL, ier);
+#ifndef CONFIG_X86_PUMA7
+	spin_unlock(&host->lock);
+	enable_irq(host->irq);
+#else
 	spin_unlock_irqrestore(&host->lock, flags);
+#endif
 	sdhci_runtime_pm_put(host);
 
 	return err;
@@ -2282,7 +2513,11 @@ static void sdhci_tasklet_card(unsigned
 	mmc_detect_change(host->mmc, msecs_to_jiffies(200));
 }
 
+#ifndef CONFIG_X86_PUMA7
+static void sdhci_tasklet_finish(unsigned long param)
+#else
 static void sdhci_tasklet_finish_async_data(unsigned long param)
+#endif
 {
 	struct sdhci_host *host;
 	unsigned long flags;
@@ -2296,13 +2531,18 @@ static void sdhci_tasklet_finish_async_d
          * If this tasklet gets rescheduled while running, it will
          * be run again afterwards but without any active request.
          */
+#ifndef CONFIG_X86_PUMA7
+	if (!host->mrq) {
+#else
 	if (!host->mmc->areq || !host->mmc->areq->mrq->data) {
+#endif
 		spin_unlock_irqrestore(&host->lock, flags);
 		return;
 	}
 
 	del_timer(&host->timer);
 
+#ifdef CONFIG_X86_PUMA7
 	mrq = host->mmc->areq->mrq;
 
 	/*
@@ -2354,13 +2594,16 @@ static void sdhci_tasklet_finish(unsigne
 		return;
 	}
 
+#endif
 	mrq = host->mrq;
+#ifdef CONFIG_X86_PUMA7
 	BUG_ON(!mrq->cmd);
 	opcode = mrq->cmd->opcode;
 
 	/* for CMD46/47, doesn't delete timer */
 	if (!mmc_op_cmdq_execute_task(opcode))
 		del_timer(&host->timer);
+#endif
 
 	/*
 	 * The controller needs a reset of internal state machines
@@ -2381,31 +2624,43 @@ static void sdhci_tasklet_finish(unsigne
 		   controllers do not like that. */
 		sdhci_reset(host, SDHCI_RESET_CMD);
 		sdhci_reset(host, SDHCI_RESET_DATA);
+#ifdef CONFIG_X86_PUMA7
 		/* clear data as DATA is reset */
 		host->data = NULL;
+#endif
 	}
 
 	host->mrq = NULL;
 	host->cmd = NULL;
+#ifndef CONFIG_X86_PUMA7
+	host->data = NULL;
+#endif
 
+#ifdef CONFIG_X86_PUMA7
 	/* CMD46/47 sill have pending data */
 	if (!mmc_op_cmdq_execute_task(opcode)) {
+#endif
 #ifndef SDHCI_USE_LEDS_CLASS
-		sdhci_deactivate_led(host);
+	sdhci_deactivate_led(host);
 #endif
+#ifdef CONFIG_X86_PUMA7
 	}
+#endif
 
 	mmiowb();
 	spin_unlock_irqrestore(&host->lock, flags);
 
 	mmc_request_done(host->mmc, mrq);
-
+#ifndef CONFIG_X86_PUMA7
+	sdhci_runtime_pm_put(host);
+#else
 	/*
 	 * host will be put in D0i3 when pending data is done
 	 * for CMD46/47
 	 */
 	if (!mmc_op_cmdq_execute_task(opcode))
 		sdhci_runtime_pm_put(host);
+#endif
 }
 
 static void sdhci_timeout_timer(unsigned long data)
@@ -2471,6 +2726,20 @@ static void sdhci_cmd_irq(struct sdhci_h
 		return;
 	}
 
+#ifdef CONFIG_X86_PUMA6
+	/* Manually return timeout to CMD8(SD_SEND_IF_COND) and CMD5(SD_IO_SEND_OP_COND),
+	 * as AEP doesn't support them
+	 */
+	if (host->aep_enabled) {
+		if ((host->cmd->opcode == 8) && (host->cmd->flags == (MMC_RSP_SPI_R7 |
+			MMC_RSP_R7 | MMC_CMD_BCR)))
+			host->cmd->error = -ETIMEDOUT;
+		else if ((host->cmd->opcode == 5) && (host->cmd->flags == (MMC_RSP_SPI_R4 |
+			MMC_RSP_R4 | MMC_CMD_BCR)))
+			host->cmd->error = -ETIMEDOUT;
+	}
+#endif
+
 	if (intmask & SDHCI_INT_TIMEOUT)
 		host->cmd->error = -ETIMEDOUT;
 	else if (intmask & (SDHCI_INT_CRC | SDHCI_INT_END_BIT |
@@ -2497,12 +2766,18 @@ static void sdhci_cmd_irq(struct sdhci_h
 		if (host->cmd->data)
 			DBG("Cannot wait for busy signal when also "
 				"doing a data transfer");
+#ifndef CONFIG_X86_PUMA7
+		else if (!(host->quirks & SDHCI_QUIRK_NO_BUSY_IRQ))
+#else
 		else if (!(host->quirks & SDHCI_QUIRK_NO_BUSY_IRQ)
 				&& !host->busy_handle) {
 			/* Mark that command complete before busy is ended */
 			host->busy_handle = 1;
+#endif
 			return;
+#ifdef CONFIG_X86_PUMA7
 		}
+#endif
 
 		/* The controller does not support the end-of-busy IRQ,
 		 * fall through and take the SDHCI_INT_RESPONSE */
@@ -2565,6 +2840,9 @@ static void sdhci_data_irq(struct sdhci_
 		 */
 		if (host->cmd && (host->cmd->flags & MMC_RSP_BUSY)) {
 			if (intmask & SDHCI_INT_DATA_END) {
+#ifndef CONFIG_X86_PUMA7
+				sdhci_finish_command(host);
+#else
 				/*
 				 * Some cards handle busy-end interrupt
 				 * before the command completed, so make
@@ -2574,6 +2852,7 @@ static void sdhci_data_irq(struct sdhci_
 					sdhci_finish_command(host);
 				else
 					host->busy_handle = 1;
+#endif
 				return;
 			}
 		}
@@ -2636,8 +2915,12 @@ static void sdhci_data_irq(struct sdhci_
 		}
 
 		if (intmask & SDHCI_INT_DATA_END) {
+#ifndef CONFIG_X86_PUMA7
+			if (host->cmd) {
+#else
 			if (!host->mmc->context_info.is_cmdq_busy &&
 					host->cmd) {
+#endif
 				/*
 				 * Data managed to finish before the
 				 * command completed. Make sure we do
@@ -2656,6 +2939,7 @@ static irqreturn_t sdhci_irq(int irq, vo
 	struct sdhci_host *host = dev_id;
 	u32 intmask, unexpected = 0;
 	int cardint = 0, max_loops = 16;
+	u32 aep_int;
 
 #ifdef CONFIG_HW_MUTEXES
 	/* eMMC card interrupt can be classified as:
@@ -2665,19 +2949,47 @@ static irqreturn_t sdhci_irq(int irq, vo
 	 * It is assumed that interrupts happen only when a task owns the 
 	 * HW Mutex
 	 */
-	
+
+#ifdef CONFIG_X86_PUMA7
     if (MMC_HOST_SUPPORTS_HW_MUTEX(host->mmc)) {
 	  if (!EMMC_HW_MUTEX_IS_LOCKED()) {
 	      return IRQ_NONE;
 	  }
 	}
+#elif defined(CONFIG_X86_PUMA6)
+		if (host->flags & SDHCI_SUPPORT_HW_MUTEX) {
+			if (!EMMC_HW_MUTEX_IS_LOCKED(host->mmc)) 
+				return IRQ_NONE;
+		}
 #endif
 
+#endif /* CONFIG_HW_MUTEXES */
+
 	spin_lock(&host->lock);
 
+#ifdef CONFIG_X86_PUMA6
+	/* Check if it's an AEP interrupt */
+	if (host->aep_enabled) {
+		aep_int = sdhci_readl(host, PV2ATOM_SW_INT);
+		if (aep_int & EMMC_SW_INT) {
+			/* W1C */
+			sdhci_writel(host, aep_int, PV2ATOM_SW_INT);
+		} else {
+			result = IRQ_NONE;
+			goto out;
+		}
+	}
+#endif
+
 	if (host->runtime_suspended) {
 		spin_unlock(&host->lock);
+#ifndef CONFIG_X86_PUMA7
+		pr_warning("%s: got irq while runtime suspended\n",
+		       mmc_hostname(host->mmc));
+		return IRQ_HANDLED;
+#else
 		return IRQ_NONE;
+#endif
 	}
 
 	intmask = sdhci_readl(host, SDHCI_INT_STATUS);
@@ -2753,7 +3065,7 @@ again:
 	result = IRQ_HANDLED;
 
 	intmask = sdhci_readl(host, SDHCI_INT_STATUS);
-
+#ifdef CONFIG_X86_PUMA7
 	/*
 	 * If we know we'll call the driver to signal SDIO IRQ, disregard
 	 * further indications of Card Interrupt in the status to avoid a
@@ -2761,6 +3073,7 @@ again:
 	 */
 	if (cardint)
 		intmask &= ~SDHCI_INT_CARD_INT;
+#endif
 	if (intmask && --max_loops)
 		goto again;
 out:
@@ -2816,6 +3129,13 @@ EXPORT_SYMBOL_GPL(sdhci_disable_irq_wake
 
 int sdhci_suspend_host(struct sdhci_host *host)
 {
+	int ret;
+
+#ifdef CONFIG_X86_PUMA6
+	if (host->quirks2 & SDHCI_QUIRK2_NO_SUSPEND)
+	return 0;
+#endif
+
 	if (host->ops->platform_suspend)
 		host->ops->platform_suspend(host);
 
@@ -2827,6 +3147,21 @@ int sdhci_suspend_host(struct sdhci_host
 		host->flags &= ~SDHCI_NEEDS_RETUNING;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	ret = mmc_suspend_host(host->mmc);
+	if (ret) {
+		if (host->flags & SDHCI_USING_RETUNING_TIMER) {
+			host->flags |= SDHCI_NEEDS_RETUNING;
+			mod_timer(&host->tuning_timer, jiffies +
+					host->tuning_count * HZ);
+		}
+
+		sdhci_enable_card_detection(host);
+
+		return ret;
+	}
+#endif
+
 	if (!device_may_wakeup(mmc_dev(host->mmc))) {
 		sdhci_mask_irqs(host, SDHCI_INT_ALL_MASK);
 		free_irq(host->irq, host);
@@ -2834,7 +3169,11 @@ int sdhci_suspend_host(struct sdhci_host
 		sdhci_enable_irq_wakeups(host);
 		enable_irq_wake(host->irq);
 	}
+#ifndef CONFIG_X86_PUMA7
+	return ret;
+#else
 	return 0;
+#endif
 }
 
 EXPORT_SYMBOL_GPL(sdhci_suspend_host);
@@ -2843,6 +3182,11 @@ int sdhci_resume_host(struct sdhci_host
 {
 	int ret = 0;
 
+#ifdef CONFIG_X86_PUMA6
+	if (host->quirks2 & SDHCI_QUIRK2_NO_SUSPEND)
+	return 0;
+#endif
+
 	if (host->flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
 		if (host->ops->enable_dma)
 			host->ops->enable_dma(host);
@@ -2870,6 +3214,9 @@ int sdhci_resume_host(struct sdhci_host
 		mmiowb();
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	ret = mmc_resume_host(host->mmc);
+#endif
 	sdhci_enable_card_detection(host);
 
 	if (host->ops->platform_resume)
@@ -2925,6 +3272,11 @@ int sdhci_runtime_suspend_host(struct sd
 		host->flags &= ~SDHCI_NEEDS_RETUNING;
 	}
 
+#ifndef CONFIG_X86_PUMA7
+	spin_lock_irqsave(&host->lock, flags);
+	sdhci_mask_irqs(host, SDHCI_INT_ALL_MASK);
+	spin_unlock_irqrestore(&host->lock, flags);
+#else
     if (MMC_HOST_SUPPORTS_HW_MUTEX(host->mmc))
     {
         /*
@@ -2940,9 +3292,14 @@ int sdhci_runtime_suspend_host(struct sd
         spin_lock_irqsave(&host->lock, flags);
         sdhci_mask_irqs(host, SDHCI_INT_ALL_MASK);
         spin_unlock_irqrestore(&host->lock, flags);
+#endif
 
+#ifndef CONFIG_X86_PUMA7
+	synchronize_irq(host->irq);
+#else
         synchronize_irq(host->irq);
     }
+#endif
 
 	spin_lock_irqsave(&host->lock, flags);
 	host->runtime_suspended = true;
@@ -2957,6 +3314,7 @@ int sdhci_runtime_resume_host(struct sdh
 	unsigned long flags;
 	int ret = 0, host_flags = host->flags;
 
+#ifdef CONFIG_X86_PUMA7
     if (MMC_HOST_SUPPORTS_HW_MUTEX(host->mmc))
     {
         /*
@@ -2966,6 +3324,7 @@ int sdhci_runtime_resume_host(struct sdh
         enable_irq(host->irq);
     }
 
+#endif
 	if (host_flags & (SDHCI_USE_SDMA | SDHCI_USE_ADMA)) {
 		if (host->ops->enable_dma)
 			host->ops->enable_dma(host);
@@ -3030,10 +3389,11 @@ struct sdhci_host *sdhci_alloc_host(stru
 	host = mmc_priv(mmc);
 	host->mmc = mmc;
 
+#ifdef CONFIG_X86_PUMA7
 #ifdef CONFIG_HW_MUTEXES
 	host->irq_enable_count = 0;
 #endif
-
+#endif
 	return host;
 }
 
@@ -3072,6 +3432,10 @@ int sdhci_add_host(struct sdhci_host *ho
 	caps[0] = (host->quirks & SDHCI_QUIRK_MISSING_CAPS) ? host->caps :
 		sdhci_readl(host, SDHCI_CAPABILITIES);
 
+#ifdef CONFIG_X86_PUMA6
+	if(host->flags & SDHCI_SUPPORT_HW_MUTEX)
+		caps[0] |= SDHCI_CAN_VDD_330;
+#endif
 	if (host->version >= SDHCI_SPEC_300)
 		caps[1] = (host->quirks & SDHCI_QUIRK_MISSING_CAPS) ?
 			host->caps1 :
@@ -3233,7 +3597,11 @@ int sdhci_add_host(struct sdhci_host *ho
 	 * won't assume 8-bit width for hosts without that CAP.
 	 */
 	if (!(host->quirks & SDHCI_QUIRK_FORCE_1_BIT_DATA))
+#ifndef CONFIG_X86_PUMA6
 		mmc->caps |= MMC_CAP_4_BIT_DATA;
+#else
+		mmc->caps |= MMC_CAP_4_BIT_DATA | MMC_CAP_8_BIT_DATA;
+#endif
 
 	if (host->quirks2 & SDHCI_QUIRK2_HOST_NO_CMD23)
 		mmc->caps &= ~MMC_CAP_CMD23;
@@ -3241,6 +3609,10 @@ int sdhci_add_host(struct sdhci_host *ho
 	if (caps[0] & SDHCI_CAN_DO_HISPD)
 		mmc->caps |= MMC_CAP_SD_HIGHSPEED | MMC_CAP_MMC_HIGHSPEED;
 
+#ifdef CONFIG_X86_PUMA6
+	if(host->flags & SDHCI_SUPPORT_DDR)
+		mmc->caps |= MMC_CAP_1_8V_DDR;
+#endif
 	if ((host->quirks & SDHCI_QUIRK_BROKEN_CARD_DETECTION) &&
 	    !(host->mmc->caps & MMC_CAP_NONREMOVABLE))
 		mmc->caps |= MMC_CAP_NEEDS_POLL;
@@ -3284,9 +3656,11 @@ int sdhci_add_host(struct sdhci_host *ho
 		 */
 		if (!(host->quirks2 & SDHCI_QUIRK2_BROKEN_HS200)) {
 			mmc->caps2 |= MMC_CAP2_HS200;
+#ifdef CONFIG_X86_PUMA7
 			if (!host->vqmmc || !regulator_is_supported_voltage
 					(host->vqmmc, 1100000, 1300000))
 				mmc->caps2 &= ~MMC_CAP2_HS200_1_2V_SDR;
+#endif
 		}
 	} else if (caps[1] & SDHCI_SUPPORT_SDR50)
 		mmc->caps |= MMC_CAP_UHS_SDR50;
@@ -3300,7 +3674,11 @@ int sdhci_add_host(struct sdhci_host *ho
 		host->flags |= SDHCI_SDR50_NEEDS_TUNING;
 
 	/* Does the host need tuning for SDR104 / HS200? */
+#ifndef CONFIG_X86_PUMA7
+	if (mmc->caps2 & MMC_CAP2_HS200)
+#else
 	if (mmc->caps2 & (MMC_CAP2_HS200 | MMC_CAP2_HS400))
+#endif
 		host->flags |= SDHCI_SDR104_NEEDS_TUNING;
 
 	/* Driver Type(s) (A, C, D) supported by the host */
@@ -3365,6 +3743,7 @@ int sdhci_add_host(struct sdhci_host *ho
 	 */
 	max_current_caps = sdhci_readl(host, SDHCI_MAX_CURRENT);
 	if (!max_current_caps && host->vmmc) {
+
 		int curr = regulator_get_current_limit(host->vmmc);
 		if (curr > 0) {
 
@@ -3380,10 +3759,12 @@ int sdhci_add_host(struct sdhci_host *ho
 		}
 	}
 
+#ifdef CONFIG_X86_PUMA7
 	if (host->quirks2 & SDHCI_QUIRK2_FAKE_VDD)
 		caps[0] |= SDHCI_CAN_VDD_330 | SDHCI_CAN_VDD_300 |
 			SDHCI_CAN_VDD_180;
 
+#endif
 	if (caps[0] & SDHCI_CAN_VDD_330) {
 		ocr_avail |= MMC_VDD_32_33 | MMC_VDD_33_34;
 
@@ -3494,8 +3875,10 @@ int sdhci_add_host(struct sdhci_host *ho
 		sdhci_tasklet_card, (unsigned long)host);
 	tasklet_init(&host->finish_tasklet,
 		sdhci_tasklet_finish, (unsigned long)host);
+#ifdef CONFIG_X86_PUMA7
 	tasklet_init(&host->finish_async_data_tasklet,
 		sdhci_tasklet_finish_async_data, (unsigned long)host);
+#endif
 
 	setup_timer(&host->timer, sdhci_timeout_timer, (unsigned long)host);
 
--- a/drivers/mmc/host/sdhci.h
+++ b/drivers/mmc/host/sdhci.h
@@ -155,6 +155,15 @@
 
 #define SDHCI_ACMD12_ERR	0x3C
 
+/* AEP registers */
+#define  PV_CONTROL		0
+#define  PV_CNTL_AEP_EN		(1 << 0)
+
+#define  PV2ATOM_SW_INT		0x410
+#define  EMMC_SW_INT		(1 << 0)
+#define  EMMC_SW_INT_EN		(1 << 1)
+#define  ATOM_DRBL_INT_EN	(1 << 2)
+
 #define SDHCI_HOST_CONTROL2		0x3E
 #define  SDHCI_CTRL_UHS_MASK		0x0007
 #define   SDHCI_CTRL_UHS_SDR12		0x0000
@@ -162,8 +171,12 @@
 #define   SDHCI_CTRL_UHS_SDR50		0x0002
 #define   SDHCI_CTRL_UHS_SDR104		0x0003
 #define   SDHCI_CTRL_UHS_DDR50		0x0004
+#ifndef CONFIG_X86_PUMA7
+#define   SDHCI_CTRL_HS_SDR200		0x0005 /* reserved value in SDIO spec */
+#else
 #define   SDHCI_CTRL_HS_SDR200		SDHCI_CTRL_UHS_SDR104
 #define   SDHCI_CTRL_MMC_HS400		0x0005
+#endif
 #define  SDHCI_CTRL_VDD_180		0x0008
 #define  SDHCI_CTRL_DRV_TYPE_MASK	0x0030
 #define   SDHCI_CTRL_DRV_TYPE_B		0x0000
--- /dev/null
+++ b/include/linux/mmc/bp.h
@@ -0,0 +1,91 @@
+/*
+ *  GPL LICENSE SUMMARY
+ *
+ *  Copyright(c) 2011-2012 Intel Corporation. All rights reserved.
+ *
+ *  This program is free software; you can redistribute it and/or modify
+ *  it under the terms of version 2 of the GNU General Public License as
+ *  published by the Free Software Foundation.
+ *
+ *  This program is distributed in the hope that it will be useful, but
+ *  WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *  General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *  The full GNU General Public License is included in this distribution
+ *  in the file called LICENSE.GPL.
+ *
+ *  Contact Information:
+ *    Intel Corporation
+ *    2200 Mission College Blvd.
+ *    Santa Clara, CA  97052
+ *
+ */
+
+
+
+#ifndef MMC_BP_H
+#define MMC_BP_H
+
+
+#define BP_DIR_READ	0x0	/* Read */
+#define BP_DIR_WRITE	0x1	/* Write */
+
+#define MMC_BLK_IOCTL_BP_GETINFO	0x8820	/* Get boot partition info */
+#define MMC_BLK_IOCTL_BP_RDWR		0x8821	/* Read/write boot partition */
+#define MMC_BLK_IOCTL_GP_GETINFO	0x8822	/* Get general purpose partition info */
+#define MMC_BLK_IOCTL_GP_RDWR		0x8823	/* Read/write general purpose partition */
+#define MMC_BLK_IOCTL_ARB_CMD		0x8830	/* Arbitrary command */
+#define MMC_BLK_IOCTL_CARD_INFO 	0x8831	/* Get card info, such as RCA */
+
+
+#define MMC_BP_UNIT_SIZE		(128 * 1024) /*Boot partition is an integer multiple of 128 kB in size */
+#define MMC_SECTOR_SIZE			512	/*A sector size is 512Byte*/
+#define MAX_NUM_OF_SECTORS_TRANSFERD	128	/*Only 128 sectors can be transfered at one time*/
+#define MAX_NUM_OF_BOOT_PARTITIONS	1	/*Only 2 boot partitions are supported, partition 0 & partition 1*/
+
+#define MMC_BOOT_EN_USER	0
+#define MMC_BOOT_EN_BP0		1
+#define MMC_BOOT_EN_BP1		2
+#define MMC_BOOT_EN_NONE	3
+#define MMC_BOOT_EN_RESV	4
+
+struct mmc_bp_info {
+	unsigned long  sectors;
+	unsigned long  booten;
+};
+
+struct mmc_gp_info {
+	unsigned long  sectors[4];
+};
+
+
+struct mmc_bp_rw {
+	unsigned char  which;
+	unsigned char  dir;
+	void           *buf;
+	unsigned long  st_sector;
+	unsigned long  nr_sectors; /* max 128 */
+};
+
+struct mmc_card_info {
+	unsigned int  rca;
+};
+
+struct mmc_arb_cmd {
+	unsigned int  opcode;    /* Command index */
+	unsigned int  arg;       /* Command argument */
+	unsigned int  cmdflags;  /* Command flags */
+	void          *resp;     /* Command response, this buffer should be four 32 bits, i.e. 16 bytes */
+	void          *databuf;  /* Data buffer for read/write */
+	unsigned int  datalen;   /* Data length in byte, should be multiples of 512, max is 64K */
+	unsigned int  datadir;   /* Data transfer direction, 0 is read, >0 is write */
+	unsigned int  dataflags; /* Data transfer flags */
+	unsigned int  dataready; /* Whether check for card program finish and ready for data, 0 is not check, >0 is check */
+	unsigned int  stop;      /* Whether should issue stop command, 0 is not issue, >0 is issue */
+};
+
+#endif
--- a/include/linux/mmc/card.h
+++ b/include/linux/mmc/card.h
@@ -69,6 +69,7 @@ struct mmc_ext_csd {
 #define MMC_HIGH_DDR_MAX_DTR	52000000
 #define MMC_HS200_MAX_DTR	200000000
 	unsigned int		sectors;
+	unsigned int		card_type;
 	unsigned int		hc_erase_size;		/* In sectors */
 	unsigned int		hc_erase_timeout;	/* In milliseconds */
 	unsigned int		sec_trim_mult;	/* Secure trim multiplier  */
@@ -77,6 +78,9 @@ struct mmc_ext_csd {
 	bool			enhanced_area_en;	/* enable bit */
 	unsigned long long	enhanced_area_offset;	/* Units: Byte */
 	unsigned int		enhanced_area_size;	/* Units: KB */
+	unsigned char		boot_size_mult;
+	unsigned char		boot_config;
+	unsigned long		gp_size[4];
 	unsigned int		cache_size;		/* Units: KB */
 	bool			hpi_en;			/* HPI enablebit */
 	bool			hpi;			/* HPI support bit */
@@ -218,6 +222,7 @@ enum mmc_blk_status {
 };
 
 /* The number of MMC physical partitions.  These consist of:
+ * boot partitions (2), general purpose partitions (4) in MMC v4.4.
  * boot partitions (2), general purpose partitions (4) and
  * RPMB partition (1) in MMC v4.4.
  */
@@ -257,11 +262,22 @@ struct mmc_card {
 	unsigned int		state;		/* (our) card state */
 #define MMC_STATE_PRESENT	(1<<0)		/* present in sysfs */
 #define MMC_STATE_READONLY	(1<<1)		/* card is read-only */
+#ifndef CONFIG_X86_PUMA7
+#define MMC_STATE_HIGHSPEED	(1<<2)		/* card is in high speed mode */
+#define MMC_STATE_BLOCKADDR	(1<<3)		/* card uses block-addressing */
+#define MMC_STATE_HIGHSPEED_DDR (1<<4)		/* card is in high speed mode */
+#define MMC_STATE_ULTRAHIGHSPEED (1<<5)		/* card is in ultra high speed mode */
+#define MMC_CARD_SDXC		(1<<6)		/* card is SDXC */
+#define MMC_CARD_REMOVED	(1<<7)		/* card has been removed */
+#define MMC_STATE_HIGHSPEED_200	(1<<8)		/* card is in HS200 mode */
+#define MMC_STATE_DOING_BKOPS	(1<<10)		/* card is doing BKOPS */
+#else
 #define MMC_STATE_BLOCKADDR	(1<<2)		/* card uses block-addressing */
 #define MMC_CARD_SDXC		(1<<3)		/* card is SDXC */
 #define MMC_CARD_REMOVED	(1<<4)		/* card has been removed */
 #define MMC_STATE_DOING_BKOPS	(1<<5)		/* card is doing BKOPS */
 #define MMC_STATE_SUSPENDED	(1<<6)		/* card is suspended */
+#endif
 	unsigned int		quirks; 	/* card quirks */
 #define MMC_QUIRK_LENIENT_FN0	(1<<0)		/* allow SDIO FN0 writes outside of the VS CCCR range */
 #define MMC_QUIRK_BLKSZ_FOR_BYTE_MODE (1<<1)	/* use func->cur_blksize */
@@ -277,6 +293,7 @@ struct mmc_card {
 						/* byte mode */
 #define MMC_QUIRK_LONG_READ_TIME (1<<9)		/* Data read time > CSD says */
 #define MMC_QUIRK_SEC_ERASE_TRIM_BROKEN (1<<10)	/* Skip secure for erase/trim */
+						/* byte mode */
 #define MMC_QUIRK_BROKEN_IRQ_POLLING	(1<<11)	/* Polling SDIO_CCCR_INTx could create a fake interrupt */
 #define MMC_QUIRK_NO_TUNING_IN_SLEEP	(1<<12) /* no tuning before sdio card is wakeup */
 
@@ -423,21 +440,43 @@ static inline void __maybe_unused remove
 
 #define mmc_card_present(c)	((c)->state & MMC_STATE_PRESENT)
 #define mmc_card_readonly(c)	((c)->state & MMC_STATE_READONLY)
+#ifndef CONFIG_X86_PUMA7
+#define mmc_card_highspeed(c)	((c)->state & MMC_STATE_HIGHSPEED)
+#define mmc_card_hs200(c)	((c)->state & MMC_STATE_HIGHSPEED_200)
+#endif
 #define mmc_card_blockaddr(c)	((c)->state & MMC_STATE_BLOCKADDR)
+#ifndef CONFIG_X86_PUMA7
+#define mmc_card_ddr_mode(c)	((c)->state & MMC_STATE_HIGHSPEED_DDR)
+#define mmc_card_uhs(c)		((c)->state & MMC_STATE_ULTRAHIGHSPEED)
+#define mmc_sd_card_uhs(c)	((c)->state & MMC_STATE_ULTRAHIGHSPEED)
+#endif
 #define mmc_card_ext_capacity(c) ((c)->state & MMC_CARD_SDXC)
 #define mmc_card_removed(c)	((c) && ((c)->state & MMC_CARD_REMOVED))
 #define mmc_card_doing_bkops(c)	((c)->state & MMC_STATE_DOING_BKOPS)
+#ifdef CONFIG_X86_PUMA7
 #define mmc_card_suspended(c)	((c)->state & MMC_STATE_SUSPENDED)
+#endif
 
 #define mmc_card_set_present(c)	((c)->state |= MMC_STATE_PRESENT)
 #define mmc_card_set_readonly(c) ((c)->state |= MMC_STATE_READONLY)
+#ifndef CONFIG_X86_PUMA7
+#define mmc_card_set_highspeed(c) ((c)->state |= MMC_STATE_HIGHSPEED)
+#define mmc_card_set_hs200(c)	((c)->state |= MMC_STATE_HIGHSPEED_200)
+#endif
 #define mmc_card_set_blockaddr(c) ((c)->state |= MMC_STATE_BLOCKADDR)
+#ifndef CONFIG_X86_PUMA7
+#define mmc_card_set_ddr_mode(c) ((c)->state |= MMC_STATE_HIGHSPEED_DDR)
+#define mmc_card_set_uhs(c) ((c)->state |= MMC_STATE_ULTRAHIGHSPEED)
+#define mmc_sd_card_set_uhs(c) ((c)->state |= MMC_STATE_ULTRAHIGHSPEED)
+#endif
 #define mmc_card_set_ext_capacity(c) ((c)->state |= MMC_CARD_SDXC)
 #define mmc_card_set_removed(c) ((c)->state |= MMC_CARD_REMOVED)
 #define mmc_card_set_doing_bkops(c)	((c)->state |= MMC_STATE_DOING_BKOPS)
 #define mmc_card_clr_doing_bkops(c)	((c)->state &= ~MMC_STATE_DOING_BKOPS)
+#ifdef CONFIG_X86_PUMA7
 #define mmc_card_set_suspended(c) ((c)->state |= MMC_STATE_SUSPENDED)
 #define mmc_card_clr_suspended(c) ((c)->state &= ~MMC_STATE_SUSPENDED)
+#endif
 
 /*
  * Quirk add/remove for MMC products.
--- a/include/linux/mmc/core.h
+++ b/include/linux/mmc/core.h
@@ -41,7 +41,6 @@ struct mmc_command {
 #define MMC_RSP_SPI_BUSY (1 << 10)		/* card may send busy */
 
 #define MMC_SKIP_TUNING (1 << 11)		/* skip tuning for this cmd */
-
 /*
  * These are the native response types, and correspond to valid bit
  * patterns of the above flags.  One additional valid pattern
@@ -129,6 +128,7 @@ struct mmc_data {
 
 struct mmc_host;
 struct mmc_request {
+	struct mmc_command	*sbc;		/* SET_BLOCK_COUNT for multiblock */
 	struct mmc_command	*precmd;
 	struct mmc_command	*cmd;
 	struct mmc_command	*postcmd;
@@ -156,8 +156,12 @@ extern int mmc_app_cmd(struct mmc_host *
 extern int mmc_wait_for_app_cmd(struct mmc_host *, struct mmc_card *,
 	struct mmc_command *, int);
 extern void mmc_start_bkops(struct mmc_card *card, bool from_exception);
+#ifndef CONFIG_X86_PUMA7
+extern int __mmc_switch(struct mmc_card *, u8, u8, u8, unsigned int, bool);
+#else
 extern int __mmc_switch(struct mmc_card *, u8, u8, u8, unsigned int, bool,
 			bool);
+#endif
 extern int mmc_switch(struct mmc_card *, u8, u8, u8, unsigned int);
 extern int mmc_send_ext_csd(struct mmc_card *card, u8 *ext_csd);
 
@@ -194,6 +198,9 @@ extern unsigned int mmc_align_data_size(
 
 extern int __mmc_claim_host(struct mmc_host *host, atomic_t *abort);
 extern void mmc_release_host(struct mmc_host *host);
+#ifndef CONFIG_X86_PUMA7
+extern int mmc_try_claim_host(struct mmc_host *host);
+#endif
 
 extern void mmc_get_card(struct mmc_card *card);
 extern void mmc_put_card(struct mmc_card *card);
@@ -217,6 +224,25 @@ struct device_node;
 extern u32 mmc_vddrange_to_ocrmask(int vdd_min, int vdd_max);
 extern int mmc_of_parse_voltage(struct device_node *np, u32 *mask);
 
+#ifdef CONFIG_X86_PUMA7
 extern int mmc_busy_wait(struct mmc_host *host);
+#endif
+
+#ifdef CONFIG_X86_PUMA6
+extern int __mmc_claim_host_no_hwmutex(struct mmc_host *host, atomic_t *abort);
+extern void mmc_release_host_no_hwmutex(struct mmc_host *host);
+extern void mmc_do_release_host_no_hwmutex(struct mmc_host *host);
+
+/**
+ *	mmc_claim_host_no_hwmutex - exclusively claim a host without lock hw mutex
+ *	@host: mmc host to claim
+ *
+ *	Claim a host for a set of operations.
+ */
+static inline void mmc_claim_host_no_hwmutex(struct mmc_host *host)
+{
+	__mmc_claim_host_no_hwmutex(host, NULL);
+}
+#endif
 
 #endif /* LINUX_MMC_CORE_H */
--- a/include/linux/mmc/host.h
+++ b/include/linux/mmc/host.h
@@ -15,10 +15,14 @@
 #include <linux/sched.h>
 #include <linux/device.h>
 #include <linux/fault-inject.h>
+#ifdef CONFIG_X86_PUMA7
 #include <linux/pm_qos.h>
+#endif
 
 #include <linux/mmc/core.h>
+#ifdef CONFIG_X86_PUMA7
 #include <linux/mmc/card.h>
+#endif
 #include <linux/mmc/pm.h>
 
 struct mmc_ios {
@@ -60,9 +64,19 @@ struct mmc_ios {
 #define MMC_TIMING_UHS_SDR50	5
 #define MMC_TIMING_UHS_SDR104	6
 #define MMC_TIMING_UHS_DDR50	7
+#ifndef CONFIG_X86_PUMA7
+#define MMC_TIMING_MMC_HS200	8
+
+#define MMC_SDR_MODE		0
+#define MMC_1_2V_DDR_MODE	1
+#define MMC_1_8V_DDR_MODE	2
+#define MMC_1_2V_SDR_MODE	3
+#define MMC_1_8V_SDR_MODE	4
+#else
 #define MMC_TIMING_MMC_DDR52	8
 #define MMC_TIMING_MMC_HS200	9
 #define MMC_TIMING_MMC_HS400	10
+#endif
 
 	unsigned char	signal_voltage;		/* signalling voltage (1.8V or 3.3V) */
 
@@ -134,9 +148,11 @@ struct mmc_host_ops {
 
 	/* The tuning command opcode value is different for SD and eMMC cards */
 	int	(*execute_tuning)(struct mmc_host *host, u32 opcode);
+#ifdef CONFIG_X86_PUMA7
 
 	/* Prepare HS400 target operating frequency depending host driver */
 	int	(*prepare_hs400_tuning)(struct mmc_host *host, struct mmc_ios *ios);
+#endif
 	int	(*select_drive_strength)(unsigned int max_dtr, int host_drv, int card_drv);
 	void	(*hw_reset)(struct mmc_host *host);
 	void	(*card_event)(struct mmc_host *host);
@@ -148,7 +164,9 @@ struct device;
 struct mmc_async_req {
 	/* active mmc request */
 	struct mmc_request	*mrq;
+#ifdef CONFIG_X86_PUMA7
 	bool	success;
+#endif
 	/*
 	 * Check error status of completed mmc request.
 	 * Returns 0 if success otherwise non zero.
@@ -186,9 +204,11 @@ struct mmc_context_info {
 	bool			is_done_rcv;
 	bool			is_new_req;
 	bool			is_waiting_last_req;
+#ifdef CONFIG_X86_PUMA7
 	bool			is_last_cmdq;
 	bool			is_cmdq_busy;
 	bool			is_pending_cmdq;
+#endif
 	wait_queue_head_t	wait;
 	spinlock_t		lock;
 };
@@ -259,7 +279,9 @@ struct mmc_host {
 #define MMC_CAP_UHS_SDR50	(1 << 17)	/* Host supports UHS SDR50 mode */
 #define MMC_CAP_UHS_SDR104	(1 << 18)	/* Host supports UHS SDR104 mode */
 #define MMC_CAP_UHS_DDR50	(1 << 19)	/* Host supports UHS DDR50 mode */
+#ifdef CONFIG_X86_PUMA7
 #define MMC_CAP_RUNTIME_RESUME	(1 << 20)	/* Resume at runtime_resume. */
+#endif
 #define MMC_CAP_DRIVER_TYPE_A	(1 << 23)	/* Host supports Driver Type A */
 #define MMC_CAP_DRIVER_TYPE_C	(1 << 24)	/* Host supports Driver Type C */
 #define MMC_CAP_DRIVER_TYPE_D	(1 << 25)	/* Host supports Driver Type D */
@@ -287,12 +309,14 @@ struct mmc_host {
 				 MMC_CAP2_PACKED_WR)
 #define MMC_CAP2_NO_PRESCAN_POWERUP (1 << 14)	/* Don't power up before scan */
 #define MMC_CAP2_SANITIZE	(1 << 15)		/* Support Sanitize */
+#ifdef CONFIG_X86_PUMA7
 #define MMC_CAP2_POLL_R1B_BUSY	(1 << 16)	/* host poll R1B busy*/
 #define MMC_CAP2_HS400_1_8V	(1 << 17)	/* Can support HS400 1.8V */
 #define MMC_CAP2_HS400_1_2V	(1 << 18)	/* Can support HS400 1.2V */
 #define MMC_CAP2_HS400		(MMC_CAP2_HS400_1_8V | \
 				 MMC_CAP2_HS400_1_2V)
 #define MMC_CAP2_CAN_DO_CMDQ	(1 << 19)
+#endif
 
 	mmc_pm_flag_t		pm_caps;	/* supported pm features */
 
@@ -321,6 +345,9 @@ struct mmc_host {
 	spinlock_t		lock;		/* lock for claim and bus ops */
 
 	struct mmc_ios		ios;		/* current io bus settings */
+#ifndef CONFIG_X86_PUMA7
+	u32			ocr;		/* the current OCR setting */
+#endif
 
 	/* group bitfields together to minimize padding */
 	unsigned int		use_spi_crc:1;
@@ -373,6 +400,7 @@ struct mmc_host {
 
 	unsigned int		slotno;	/* used for sdio acpi binding */
 
+#ifdef CONFIG_X86_PUMA7
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 	struct {
 		struct sdio_cis			*cis;
@@ -384,6 +412,7 @@ struct mmc_host {
 
 	struct pm_qos_request *qos;
 
+#endif
 	unsigned long		private[0] ____cacheline_aligned;
 };
 
@@ -393,6 +422,7 @@ void mmc_remove_host(struct mmc_host *);
 void mmc_free_host(struct mmc_host *);
 int mmc_of_parse(struct mmc_host *host);
 
+#ifdef CONFIG_X86_PUMA7
 #ifdef CONFIG_MMC_EMBEDDED_SDIO
 extern void mmc_set_embedded_sdio_data(struct mmc_host *host,
 				       struct sdio_cis *cis,
@@ -401,6 +431,7 @@ extern void mmc_set_embedded_sdio_data(s
 				       int num_funcs);
 #endif
 
+#endif
 static inline void *mmc_priv(struct mmc_host *host)
 {
 	return (void *)host->private;
@@ -517,6 +548,7 @@ static inline unsigned int mmc_host_clk_
 	return host->ios.clock;
 }
 #endif
+#ifdef CONFIG_X86_PUMA7
 
 static inline int mmc_card_hs(struct mmc_card *card)
 {
@@ -545,4 +577,5 @@ static inline bool mmc_card_hs400(struct
 	return card->host->ios.timing == MMC_TIMING_MMC_HS400;
 }
 
+#endif
 #endif /* LINUX_MMC_HOST_H */
--- a/include/linux/mmc/mmc.h
+++ b/include/linux/mmc/mmc.h
@@ -84,6 +84,7 @@
 #define MMC_APP_CMD              55   /* ac   [31:16] RCA        R1  */
 #define MMC_GEN_CMD              56   /* adtc [0] RD/WR          R1  */
 
+#ifdef CONFIG_X86_PUMA7
 /* class 11 */
 #define MMC_QUE_TASK_PARAMS	44	/* ac R1 */
 #define MMC_QUE_TASK_ADDR	45	/* ac R1 */
@@ -91,18 +92,21 @@
 #define MMC_EXECUTE_WRITE_TASK	47	/* adtc R1 */
 #define MMC_DISCARD_CMDQ	48	/* ac R1B */
 
+#endif
 static inline bool mmc_op_multi(u32 opcode)
 {
 	return opcode == MMC_WRITE_MULTIPLE_BLOCK ||
 	       opcode == MMC_READ_MULTIPLE_BLOCK;
 }
 
+#ifdef CONFIG_X86_PUMA7
 static inline bool mmc_op_cmdq_execute_task(u32 opcode)
 {
 	return opcode == MMC_EXECUTE_READ_TASK ||
 		opcode == MMC_EXECUTE_WRITE_TASK;
 }
 
+#endif
 /*
  * MMC_SWITCH argument format:
  *
@@ -285,7 +289,9 @@ struct _mmc_csd {
  * EXT_CSD fields
  */
 
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_CMDQ_MODE_EN		15	/* R/W/E_P */
+#endif
 #define EXT_CSD_FLUSH_CACHE		32      /* W */
 #define EXT_CSD_CACHE_CTRL		33      /* R/W */
 #define EXT_CSD_POWER_OFF_NOTIFICATION	34	/* R/W */
@@ -295,7 +301,9 @@ struct _mmc_csd {
 #define EXT_CSD_EXP_EVENTS_CTRL		56	/* R/W, 2 bytes */
 #define EXT_CSD_DATA_SECTOR_SIZE	61	/* R */
 #define EXT_CSD_GP_SIZE_MULT		143	/* R/W */
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_PART_SET_COMPLETE	155	/* R/W */
+#endif
 #define EXT_CSD_PARTITION_ATTRIBUTE	156	/* R/W */
 #define EXT_CSD_PARTITION_SUPPORT	160	/* RO */
 #define EXT_CSD_HPI_MGMT		161	/* R/W */
@@ -340,9 +348,11 @@ struct _mmc_csd {
 #define EXT_CSD_POWER_OFF_LONG_TIME	247	/* RO */
 #define EXT_CSD_GENERIC_CMD6_TIME	248	/* RO */
 #define EXT_CSD_CACHE_SIZE		249	/* RO, 4 bytes */
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_PWR_CL_DDR_200_360	253	/* RO */
 #define EXT_CSD_CMDQ_SUPPORT		308	/* RO */
 #define EXT_CSD_CMDQ_DEPTH		307	/* RO */
+#endif
 #define EXT_CSD_TAG_UNIT_SIZE		498	/* RO */
 #define EXT_CSD_DATA_TAG_SUPPORT	499	/* RO */
 #define EXT_CSD_MAX_PACKED_WRITES	500	/* RO */
@@ -350,6 +360,10 @@ struct _mmc_csd {
 #define EXT_CSD_BKOPS_SUPPORT		502	/* RO */
 #define EXT_CSD_HPI_FEATURES		503	/* RO */
 
+// FIXME - value clash with EXT_CSD_PART_CONFIG
+// Make our symbol point to the one in kernel already
+#define EXT_CSD_BOOT_CONFIG	EXT_CSD_PART_CONFIG /* R/W */
+
 /*
  * EXT_CSD field definitions
  */
@@ -362,7 +376,9 @@ struct _mmc_csd {
 #define EXT_CSD_BOOT_WP_B_PWR_WP_EN	(0x01)
 
 #define EXT_CSD_PART_CONFIG_ACC_MASK	(0x7)
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_PART_CONFIG_USER	(0x0)
+#endif
 #define EXT_CSD_PART_CONFIG_ACC_BOOT0	(0x1)
 #define EXT_CSD_PART_CONFIG_ACC_RPMB	(0x3)
 #define EXT_CSD_PART_CONFIG_ACC_GP0	(0x4)
@@ -373,25 +389,38 @@ struct _mmc_csd {
 #define EXT_CSD_CMD_SET_SECURE		(1<<1)
 #define EXT_CSD_CMD_SET_CPSECURE	(1<<2)
 
+#ifndef CONFIG_X86_PUMA7
+#define EXT_CSD_CARD_TYPE_26	(1<<0)	/* Card can run at 26MHz */
+#define EXT_CSD_CARD_TYPE_52	(1<<1)	/* Card can run at 52MHz */
+#define EXT_CSD_CARD_TYPE_MASK	0x3F	/* Mask out reserved bits */
+#else
 #define EXT_CSD_CARD_TYPE_HS_26	(1<<0)	/* Card can run at 26MHz */
 #define EXT_CSD_CARD_TYPE_HS_52	(1<<1)	/* Card can run at 52MHz */
 #define EXT_CSD_CARD_TYPE_HS	(EXT_CSD_CARD_TYPE_HS_26 | \
 				 EXT_CSD_CARD_TYPE_HS_52)
+#endif
 #define EXT_CSD_CARD_TYPE_DDR_1_8V  (1<<2)   /* Card can run at 52MHz */
 					     /* DDR mode @1.8V or 3V I/O */
 #define EXT_CSD_CARD_TYPE_DDR_1_2V  (1<<3)   /* Card can run at 52MHz */
 					     /* DDR mode @1.2V I/O */
 #define EXT_CSD_CARD_TYPE_DDR_52       (EXT_CSD_CARD_TYPE_DDR_1_8V  \
 					| EXT_CSD_CARD_TYPE_DDR_1_2V)
+#ifndef CONFIG_X86_PUMA7
+#define EXT_CSD_CARD_TYPE_SDR_1_8V	(1<<4)	/* Card can run at 200MHz */
+#define EXT_CSD_CARD_TYPE_SDR_1_2V	(1<<5)	/* Card can run at 200MHz */
+#else
 #define EXT_CSD_CARD_TYPE_HS200_1_8V	(1<<4)	/* Card can run at 200MHz */
 #define EXT_CSD_CARD_TYPE_HS200_1_2V	(1<<5)	/* Card can run at 200MHz */
+#endif
 						/* SDR mode @1.2V I/O */
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_CARD_TYPE_HS200		(EXT_CSD_CARD_TYPE_HS200_1_8V | \
 					 EXT_CSD_CARD_TYPE_HS200_1_2V)
 #define EXT_CSD_CARD_TYPE_HS400_1_8V	(1<<6)	/* Card can run at 200MHz DDR, 1.8V */
 #define EXT_CSD_CARD_TYPE_HS400_1_2V	(1<<7)	/* Card can run at 200MHz DDR, 1.2V */
 #define EXT_CSD_CARD_TYPE_HS400		(EXT_CSD_CARD_TYPE_HS400_1_8V | \
 					 EXT_CSD_CARD_TYPE_HS400_1_2V)
+#endif
 
 #define EXT_CSD_BUS_WIDTH_1	0	/* Card is in 1 bit mode */
 #define EXT_CSD_BUS_WIDTH_4	1	/* Card is in 4 bit mode */
@@ -399,11 +428,13 @@ struct _mmc_csd {
 #define EXT_CSD_DDR_BUS_WIDTH_4	5	/* Card is in 4 bit DDR mode */
 #define EXT_CSD_DDR_BUS_WIDTH_8	6	/* Card is in 8 bit DDR mode */
 
+#ifdef CONFIG_X86_PUMA7
 #define EXT_CSD_TIMING_BC	0	/* Backwards compatility */
 #define EXT_CSD_TIMING_HS	1	/* High speed */
 #define EXT_CSD_TIMING_HS200	2	/* HS200 */
 #define EXT_CSD_TIMING_HS400	3	/* HS400 */
 
+#endif
 #define EXT_CSD_SEC_ER_EN	BIT(0)
 #define EXT_CSD_SEC_BD_BLK_EN	BIT(2)
 #define EXT_CSD_SEC_GB_CL_EN	BIT(4)
@@ -440,10 +471,12 @@ struct _mmc_csd {
  */
 #define EXT_CSD_BKOPS_LEVEL_2		0x2
 
+#ifdef CONFIG_X86_PUMA7
 /* CMDQ enable level */
 #define EXT_CSD_CMDQ_MODE_OFF		0
 #define EXT_CSD_CMDQ_MODE_ON		1
 
+#endif
 /*
  * MMC_SWITCH access modes
  */
--- a/include/linux/mmc/pm.h
+++ b/include/linux/mmc/pm.h
@@ -26,7 +26,9 @@ typedef unsigned int mmc_pm_flag_t;
 
 #define MMC_PM_KEEP_POWER	(1 << 0)	/* preserve card power during suspend */
 #define MMC_PM_WAKE_SDIO_IRQ	(1 << 1)	/* wake up host system on SDIO IRQ assertion */
+#ifdef CONFIG_X86_PUMA7
 #define MMC_PM_IGNORE_PM_NOTIFY	(1 << 2)	/* ignore mmc pm notify */
 #define MMC_PM_TUNING_AFTER_RTRESUME	(1 << 3)
+#endif
 
 #endif /* LINUX_MMC_PM_H */
--- a/include/linux/mmc/sdhci.h
+++ b/include/linux/mmc/sdhci.h
@@ -16,8 +16,13 @@
 #include <linux/types.h>
 #include <linux/io.h>
 #include <linux/mmc/host.h>
+
 #ifdef CONFIG_HW_MUTEXES
+#ifdef CONFIG_X86_PUMA7
 #include <linux/netip_subsystem.h>
+#elif defined(CONFIG_X86_PUMA6)
+#include <linux/hw_mutex.h>
+#endif
 #endif
 
 struct sdhci_host {
@@ -111,6 +116,10 @@ struct sdhci_host {
 /* Controller does not support DDR50 */
 #define SDHCI_QUIRK2_BROKEN_DDR50			(1<<10)
 
+#ifdef CONFIG_X86_PUMA6
+/* SDHCI could not suspend in CE2600 platform */
+#define SDHCI_QUIRK2_NO_SUSPEND                 (1<<31)
+#endif
 
 	int irq;		/* Device IRQ */
 	void __iomem *ioaddr;	/* Mapped address */
@@ -144,7 +153,21 @@ struct sdhci_host {
 #define SDHCI_SDIO_IRQ_ENABLED	(1<<9)	/* SDIO irq enabled */
 #define SDHCI_SDR104_NEEDS_TUNING (1<<10)	/* SDR104/HS200 needs tuning */
 #define SDHCI_USING_RETUNING_TIMER (1<<11)	/* Host is using a retuning timer for the card */
+
+#ifdef CONFIG_X86_PUMA6
+#define SDHCI_SUPPORT_DDR	(1<<14)	/* Support DDR */
+#ifdef CONFIG_HW_MUTEXES
+/* Two or more processors access the controller, HW Mutex is necessary to avoid conflict*/
+#define SDHCI_SUPPORT_HW_MUTEX	(1<<15)
+#endif
+	void __iomem *aep_base;	/* AEP mapped address */
+	bool aep_enabled;
+#endif
+
+#ifdef CONFIG_X86_PUMA7
 #define SDHCI_DISABLE_REGISTER_WRITE  (1<<16)
+#endif
+
 	unsigned int version;	/* SDHCI spec. version */
 
 	unsigned int max_clk;	/* Max possible freq (MHz) */
@@ -161,7 +184,9 @@ struct sdhci_host {
 	struct mmc_command *cmd;	/* Current command */
 	struct mmc_data *data;	/* Current data request */
 	unsigned int data_early:1;	/* Data finished before cmd */
+#ifdef CONFIG_X86_PUMA7
 	unsigned int busy_handle:1;	/* Handling the order of Busy-end */
+#endif
 
 	struct sg_mapping_iter sg_miter;	/* SG state for PIO */
 	unsigned int blocks;	/* remaining PIO blocks */
@@ -176,7 +201,9 @@ struct sdhci_host {
 
 	struct tasklet_struct card_tasklet;	/* Tasklet structures */
 	struct tasklet_struct finish_tasklet;
+#ifdef CONFIG_X86_PUMA7
 	struct tasklet_struct finish_async_data_tasklet;
+#endif
 
 	struct timer_list timer;	/* Timer for timeouts */
 
@@ -193,18 +220,20 @@ struct sdhci_host {
 
 	unsigned int		tuning_count;	/* Timer count for re-tuning */
 	unsigned int		tuning_mode;	/* Re-tuning mode supported by host */
+#ifdef CONFIG_X86_PUMA7
 
 #ifdef CONFIG_HW_MUTEXES
     unsigned int irq_enable_count; /* Count to enable recursive locking */
 #endif
 
+#endif
 #define SDHCI_TUNING_MODE_1	0
 	struct timer_list	tuning_timer;	/* Timer for tuning */
 
 	unsigned long private[0] ____cacheline_aligned;
 };
 
-#ifdef CONFIG_HW_MUTEXES
+#if defined(CONFIG_X86_PUMA7) && defined(CONFIG_HW_MUTEXES)
 
 #define SDHCI_HOST_SUPPORTS_HW_MUTEX(sdhci) \
 		((sdhci)->quirks2 & SDHCI_QUIRK2_HW_MUTEX)
@@ -241,6 +270,43 @@ do{
   }                                                                          \
 } while(0)
 
-#endif /* CONFIG_HW_MUTEXES */
+#endif /* CONFIG_X86_PUMA7 */
+
+#if defined(CONFIG_X86_PUMA6) && defined(CONFIG_HW_MUTEXES)
+static DEFINE_MUTEX(mmc_access_lock);
+static void lock_emmc_access(void)
+{
+    might_sleep();
+    mutex_lock(&mmc_access_lock);
+}
+
+static void unlock_emmc_access(void)
+{
+    mutex_unlock(&mmc_access_lock);
+}
+
+#define EMMC_HW_MUTEX_IS_LOCKED(host) (hw_mutex_is_locked(HW_MUTEX_EMMC))
+#define LOCK_EMMC_HW_MUTEX(host) do{\
+		if(((struct sdhci_host *)host->private)->flags & SDHCI_SUPPORT_HW_MUTEX)\
+		{\
+				hw_mutex_lock(HW_MUTEX_EMMC);\
+				lock_emmc_access();\
+				enable_irq(((struct sdhci_host *)host->private)->irq);\
+		}\
+	} while(0)
+
+
+#define UNLOCK_EMMC_HW_MUTEX(host) do{\
+	if(((struct sdhci_host *)host->private)->flags & SDHCI_SUPPORT_HW_MUTEX)\
+		{\
+			disable_irq(((struct sdhci_host *)host->private)->irq);\
+			unlock_emmc_access();\
+			hw_mutex_unlock(HW_MUTEX_EMMC);\
+		}\
+	} while(0)
+
+#define SDHCI_HOST_HAS_HW_MUTEX(host) ((host)->flags & SDHCI_SUPPORT_HW_MUTEX)
+
+#endif /* CONFIG_X86_PUMA6 */
 
 #endif /* LINUX_MMC_SDHCI_H */
