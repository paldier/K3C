From af0e9ec258abbd435fe6013b663496b3cd94788f Mon Sep 17 00:00:00 2001
From: Tomas Winkler <tomas.winkler@intel.com>
Date: Tue, 29 Apr 2014 16:14:14 +0300
Subject: [PATCH 347/441] mei: txe: add dma support

Change-Id: I6765e4c60ad48fe6c805b72e3585eab686f2bf7c
Signed-off-by: Tomas Winkler <tomas.winkler@intel.com>
(cherry picked from commit 67f7e036f3001e20320b6dd526a82a235e3cee3f)

Signed-off-by: Nagaraj S <sivasankaranx.nagaraj@intel.com>
---
 drivers/misc/mei/Makefile  |   2 +
 drivers/misc/mei/dma-txe.c | 206 +++++++++++++++++++++
 drivers/misc/mei/hw-txe.h  |  14 ++
 drivers/misc/mei/mm-txe.c  | 448 +++++++++++++++++++++++++++++++++++++++++++++
 drivers/misc/mei/mm-txe.h  | 118 ++++++++++++
 drivers/misc/mei/pci-txe.c |  15 ++
 6 files changed, 803 insertions(+)
 create mode 100644 drivers/misc/mei/dma-txe.c
 create mode 100644 drivers/misc/mei/mm-txe.c
 create mode 100644 drivers/misc/mei/mm-txe.h

--- a/drivers/misc/mei/Makefile
+++ b/drivers/misc/mei/Makefile
@@ -21,3 +21,5 @@ mei-me-objs += hw-me.o
 obj-$(CONFIG_INTEL_MEI_TXE) += mei-txe.o
 mei-txe-objs := pci-txe.o
 mei-txe-objs += hw-txe.o
+mei-txe-objs += dma-txe.o
+mei-txe-objs += mm-txe.o
--- /dev/null
+++ b/drivers/misc/mei/dma-txe.c
@@ -0,0 +1,206 @@
+/*
+ *
+ * Intel Management Engine Interface (Intel MEI) Linux driver
+ * Copyright (c) 2003-2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ */
+
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/kernel.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/aio.h>
+#include <linux/pci.h>
+#include <linux/init.h>
+#include <linux/ioctl.h>
+#include <linux/sched.h>
+#include <linux/compat.h>
+#include <linux/jiffies.h>
+#include <linux/dma-mapping.h>
+#include <linux/sizes.h>
+
+#include <linux/mei.h>
+#include <linux/acpi.h>
+#include <acpi/acpi_bus.h>
+
+#include "mei_dev.h"
+#include "hw-txe.h"
+
+static acpi_status txei_walk_resource(struct acpi_resource *res, void *data)
+{
+	struct mei_device *dev = (struct mei_device *)data;
+	struct mei_txe_hw *hw = to_txe_hw(dev);
+	struct acpi_resource_fixed_memory32 *fixmem32;
+
+	if (res->type != ACPI_RESOURCE_TYPE_FIXED_MEMORY32)
+		return AE_OK;
+
+	fixmem32 = &res->data.fixed_memory32;
+
+	dev_dbg(&dev->pdev->dev, "TXE8086 MEMORY32 addr 0x%x len %d\n",
+		fixmem32->address, fixmem32->address_length);
+
+	if (!fixmem32->address || !fixmem32->address_length) {
+		dev_err(&dev->pdev->dev, "TXE8086 MEMORY32 addr 0x%x len %d\n",
+			fixmem32->address, fixmem32->address_length);
+		return AE_NO_MEMORY;
+	}
+
+	hw->pool_paddr = fixmem32->address;
+	hw->pool_size  = fixmem32->address_length;
+
+	return AE_OK;
+}
+
+static void mei_release_dma_acpi(struct mei_txe_hw *hw)
+{
+	if (hw->pool_vaddr)
+		iounmap(hw->pool_vaddr);
+
+	hw->pool_vaddr = NULL;
+	hw->pool_paddr = 0;
+	hw->pool_size  = 0;
+}
+
+static int mei_reserver_dma_acpi(struct mei_device *dev)
+{
+	struct mei_txe_hw *hw = to_txe_hw(dev);
+	acpi_handle handle;
+	acpi_status ret;
+
+	handle = ACPI_HANDLE(&dev->pdev->dev);
+	if (!handle) {
+		dev_err(&dev->pdev->dev, "TXE8086 acpi NULL handle received\n");
+		return -ENODEV;
+	}
+
+	dev_dbg(&dev->pdev->dev, "TXE8086 acpi handle received\n");
+	ret = acpi_walk_resources(handle, METHOD_NAME__CRS,
+				txei_walk_resource, dev);
+
+	if (ACPI_FAILURE(ret)) {
+		dev_err(&dev->pdev->dev, "TXE8086: acpi_walk_resources FAILURE\n");
+		return -ENOMEM;
+	}
+
+	if (!hw->pool_size) {
+		dev_err(&dev->pdev->dev, "TXE8086: acpi __CRS resource not found\n");
+		return -ENOMEM;
+	}
+
+	dev_dbg(&dev->pdev->dev, "DMA Memory reserved memory usage: size=%zd\n",
+		hw->pool_size);
+
+	/* limit the pool_size to SATT_RANGE_MAX */
+	hw->pool_size = min_t(size_t, hw->pool_size, SATT_RANGE_MAX);
+
+	hw->pool_vaddr = ioremap(hw->pool_paddr, hw->pool_size);
+	/* FIXME: is this fatal ? */
+	if (!hw->pool_vaddr)
+		dev_err(&dev->pdev->dev, "TXE8086: acpi __CRS cannot remap\n");
+
+	hw->pool_release = mei_release_dma_acpi;
+
+	return 0;
+}
+
+
+static void mei_free_dma(struct  mei_txe_hw *hw)
+{
+	struct mei_device *dev = hw_txe_to_mei(hw);
+	if (hw->pool_vaddr)
+		dma_free_coherent(&dev->pdev->dev,
+			hw->pool_size, hw->pool_vaddr, hw->pool_paddr);
+	hw->pool_vaddr = NULL;
+	hw->pool_paddr = 0;
+	hw->pool_size  = 0;
+}
+
+static int mei_alloc_dma(struct mei_device *dev)
+{
+	struct mei_txe_hw *hw = to_txe_hw(dev);
+	hw->pool_size = SZ_4M;
+	dev_dbg(&dev->pdev->dev, "MEIMM: dma size %zd\n", hw->pool_size);
+
+	if (hw->pool_size == 0)
+		return 0;
+
+	/*  Limit pools size to satt max range */
+	hw->pool_size = min_t(size_t, hw->pool_size, SATT_RANGE_MAX);
+
+	hw->pool_vaddr = dma_alloc_coherent(&dev->pdev->dev, hw->pool_size,
+		&hw->pool_paddr, GFP_KERNEL);
+
+	dev_dbg(&dev->pdev->dev, "DMA Memory Allocated vaddr=%p, paddr=%lu, size=%zd\n",
+			hw->pool_vaddr,
+			(unsigned long)hw->pool_paddr, hw->pool_size);
+
+	if (!hw->pool_vaddr) {
+		dev_err(&dev->pdev->dev, "DMA Memory Allocation failed for size %zd\n",
+			hw->pool_size);
+		return -ENOMEM;
+	}
+
+	if (hw->pool_paddr & ~DMA_BIT_MASK(36)) {
+		dev_err(&dev->pdev->dev, "Phys Address is beyond DMA_MASK(32) 0x%0lX\n",
+			(unsigned long)hw->pool_paddr);
+	}
+
+	hw->pool_release = mei_free_dma;
+
+	return 0;
+}
+
+int mei_txe_dma_setup(struct mei_device *dev)
+{
+	struct mei_txe_hw *hw = to_txe_hw(dev);
+	int err;
+
+	err = mei_reserver_dma_acpi(dev);
+	if (err)
+		err = mei_alloc_dma(dev);
+
+	if (err)
+		return err;
+
+	err = mei_txe_setup_satt2(dev,
+		dma_to_phys(&dev->pdev->dev, hw->pool_paddr), hw->pool_size);
+
+	if (err) {
+		if (hw->pool_release)
+			hw->pool_release(hw);
+		return err;
+	}
+
+	hw->mdev = mei_mm_init(&dev->pdev->dev,
+		hw->pool_vaddr, hw->pool_paddr, hw->pool_size);
+
+	if (IS_ERR_OR_NULL(hw->mdev))
+		return PTR_ERR(hw->mdev);
+
+	return 0;
+}
+
+void mei_txe_dma_unset(struct mei_device *dev)
+{
+	struct mei_txe_hw *hw = to_txe_hw(dev);
+
+	mei_mm_deinit(hw->mdev);
+
+	/* FIXME: do we need to unset satt2 ? */
+	if (hw->pool_release)
+		hw->pool_release(hw);
+}
--- a/drivers/misc/mei/hw-txe.h
+++ b/drivers/misc/mei/hw-txe.h
@@ -21,6 +21,7 @@
 
 #include "hw.h"
 #include "hw-txe-regs.h"
+#include "mm-txe.h"
 
 #define MEI_TXI_RPM_TIMEOUT    500 /* ms */
 
@@ -52,6 +53,16 @@ struct mei_txe_hw {
 	wait_queue_head_t wait_aliveness_resp;
 
 	unsigned long intr_cause;
+
+	/** mei mm support */
+	struct mei_mm_device *mdev;
+
+	/** dma support */
+	void *pool_vaddr;
+	dma_addr_t pool_paddr;
+	size_t pool_size;
+
+	void (*pool_release)(struct mei_txe_hw *hw);
 };
 
 #define to_txe_hw(dev) (struct mei_txe_hw *)((dev)->hw)
@@ -70,5 +81,8 @@ int mei_txe_aliveness_set_sync(struct me
 
 int mei_txe_setup_satt2(struct mei_device *dev, phys_addr_t addr, u32 range);
 
+int mei_txe_dma_setup(struct mei_device *dev);
+void mei_txe_dma_unset(struct mei_device *dev);
+
 
 #endif /* _MEI_HW_TXE_H_ */
--- /dev/null
+++ b/drivers/misc/mei/mm-txe.c
@@ -0,0 +1,448 @@
+#undef pr_fmt
+#define pr_fmt(fmt) "mm :" fmt
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/ioctl.h>
+#include <linux/miscdevice.h>
+#include <linux/mm.h>
+#include <linux/fs.h>
+#include <linux/debugfs.h>
+#include <linux/types.h>
+#include <linux/compat.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include <linux/uaccess.h>
+
+#include "mei_dev.h"
+#include "mm-txe.h"
+
+
+
+#ifndef __phys_to_pfn
+#define __phys_to_pfn(phys) ((phys) >> PAGE_SHIFT)
+#endif
+
+#ifndef VM_DONTDUMP
+#define VM_DONTDUMP VM_RESERVED
+#endif
+
+struct mei_mm_pool {
+	void *vaddr;
+	phys_addr_t paddr;
+	size_t size;
+	size_t offset;
+};
+
+struct mei_mm_client {
+	size_t size;
+	phys_addr_t paddr;
+	bool q;
+};
+struct mei_mm_device {
+	struct miscdevice dev;
+	struct mutex lock;
+	struct mei_mm_client client;
+#if IS_ENABLED(CONFIG_DEBUG_FS)
+	struct dentry *dbgfs;
+#endif /* CONFIG_DEBUG_FS */
+	struct mei_mm_pool pool;
+};
+
+
+#define meimm_warn(__dev, fmt, ...) \
+	dev_warn((__dev)->dev.parent, "Warn: %s[%d]: " pr_fmt(fmt),  \
+		__func__, __LINE__, ##__VA_ARGS__)
+
+#define meimm_info(__dev, fmt, ...) \
+	dev_info((__dev)->dev.parent, "Info: " pr_fmt(fmt), ##__VA_ARGS__)
+
+#define meimm_err(__dev, fmt, ...) \
+	dev_err((__dev)->dev.parent, "Error: " pr_fmt(fmt), ##__VA_ARGS__)
+
+#define meimm_dbg(__dev, fmt, ...) \
+	dev_dbg((__dev)->dev.parent, "%s[%d]: " pr_fmt(fmt), \
+		__func__, __LINE__, ##__VA_ARGS__)
+
+/**
+ * mei_mm_open - the open function
+ *
+ * @inode: pointer to inode structure
+ * @file: pointer to file structure
+ *
+ * returns 0 on success, <0 on error
+ */
+static int mei_mm_open(struct inode *inode, struct file *file)
+{
+	struct miscdevice *miscdev = file->private_data;
+	struct mei_mm_device *mdev =
+			container_of(miscdev, struct mei_mm_device, dev);
+
+	mutex_lock(&mdev->lock);
+	if (mdev->client.q) {
+		mutex_unlock(&mdev->lock);
+		return -EBUSY;
+	}
+	mdev->client.q = true;
+	mutex_unlock(&mdev->lock);
+
+	file->private_data = &mdev->client;
+
+	meimm_info(mdev, "device opened\n");
+
+	return nonseekable_open(inode, file);
+
+}
+
+/**
+ * mei_mm_release - the release function
+ *
+ * @inode: pointer to inode structure
+ * @file: pointer to file structure
+ *
+ * returns 0 on success, <0 on error
+ */
+static int mei_mm_release(struct inode *inode, struct file *file)
+{
+	struct mei_mm_client *client = file->private_data;
+	struct mei_mm_device *mdev =
+			container_of(client, struct mei_mm_device, client);
+	size_t len =  client->size;
+
+	mutex_lock(&mdev->lock);
+
+	if (!client->q)
+		goto out;
+
+	if (mdev->pool.offset < len)  {
+		meimm_info(mdev, "pool smaller then requested size...truncating");
+		len = mdev->pool.offset;
+	}
+	mdev->pool.offset -= len;
+
+	client->q = false;
+	meimm_info(mdev, "meimm: release %zd\n", len);
+out:
+	mutex_unlock(&mdev->lock);
+	return 0;
+}
+/**
+ * mei_mm_alloc - distributing memory chunk to Sec Application (shim library)
+ *
+ * @file: pointer to file structure
+ * @cmd: ioctl command
+ * @data: pointer to shim memory structure
+ *
+ * returns 0 on success , <0 on error
+ */
+
+static int mei_mm_alloc(struct mei_mm_device *mdev, unsigned long arg)
+{
+
+	struct mei_mm_data req;
+	phys_addr_t paddr;
+	int ret;
+	size_t aligned_size; /* for mmap to work we need page multipliers */
+
+	if (copy_from_user(&req, (char __user *)arg, sizeof(req))) {
+		meimm_err(mdev, "failed to copy data from userland\n");
+		ret = -EFAULT;
+		goto err;
+	}
+
+	aligned_size = PAGE_ALIGN(req.size);
+
+	mutex_lock(&mdev->lock);
+
+	if (aligned_size > mdev->pool.size - mdev->pool.offset) {
+		meimm_err(mdev, "can't allocate mem from chunk: %zd > %zd - %zd\n",
+			aligned_size, mdev->pool.size, mdev->pool.offset);
+		ret = -ENOMEM;
+		goto err_unlock;
+	}
+
+	paddr = mdev->pool.paddr + mdev->pool.offset;
+	req.size = aligned_size;
+
+	meimm_info(mdev, "Allocate mem from chunk: paddr=%llud size=%llu\n",
+			(unsigned long long)paddr, req.size);
+
+	if (copy_to_user((char __user *)arg, &req, sizeof(req))) {
+		meimm_err(mdev, "failed to copy data to userland\n");
+		ret = -EFAULT;
+		goto err_unlock;
+	}
+
+	mdev->pool.offset += aligned_size;
+	mdev->client.size = aligned_size;
+	mdev->client.paddr = paddr;
+
+	mutex_unlock(&mdev->lock);
+
+	return 0;
+
+err_unlock:
+	mutex_unlock(&mdev->lock);
+err:
+	return ret;
+}
+
+/**
+ * mei_mm_free - returns memory chunk from Sec Application (shim library
+ *
+ * @file: pointer to file structure
+ * @cmd: ioctl command
+ * @data: pointer to shim memory structure
+ *
+ * returns 0 on success , <0 on error
+ */
+static int mei_mm_free(struct mei_mm_device *mdev, unsigned long arg)
+{
+	struct mei_mm_data req;
+	int ret;
+
+	if (copy_from_user(&req, (char __user *)arg, sizeof(req))) {
+		meimm_err(mdev, "failed to copy data from userland\n");
+		return -EFAULT;
+	}
+
+	mutex_lock(&mdev->lock);
+
+	if (mdev->pool.offset < req.size) {
+		meimm_err(mdev, "cannot free 0x%lld bytes - offset=0x%zd\n",
+			  req.size, mdev->pool.offset);
+		ret = -EINVAL;
+		goto out;
+	}
+
+	mdev->pool.offset -= req.size;
+	mdev->client.size = 0;
+	mdev->client.paddr = 0LL;
+	ret = 0;
+out:
+	mutex_unlock(&mdev->lock);
+	return ret;
+
+}
+
+/**
+ * mei_ioctl - the IOCTL function
+ *
+ * @file: pointer to file structure
+ * @cmd: ioctl command
+ * @data: pointer to mei message structure
+ *
+ * returns 0 on success , <0 on error
+ */
+
+static long mei_mm_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct mei_mm_client *client = file->private_data;
+	struct mei_mm_device *mdev =
+			container_of(client, struct mei_mm_device, client);
+	int ret;
+
+	/* don't even decode wrong cmds: better returning  ENOTTY than EFAULT */
+	if (_IOC_TYPE(cmd) != 'H') {
+		meimm_err(mdev, "Wrong IOCTL type: Got %c wanted %c\n",
+					_IOC_TYPE(cmd), 'H');
+		ret = -ENOTTY;
+		goto out;
+	}
+	if (_IOC_NR(cmd) > MEI_IOC_MAXNR) {
+		meimm_err(mdev, "%s: Wrong IOCTL num. Got %d wanted max %d\n",
+			"mei_mm", _IOC_NR(cmd), MEI_IOC_MAXNR);
+		ret = -ENOTTY;
+		goto out;
+	}
+	if (!access_ok(VERIFY_WRITE, (void __user *)arg, _IOC_SIZE(cmd))) {
+		ret = -EFAULT;
+		goto out;
+	}
+
+	switch (cmd) {
+	case IOCTL_MEI_MM_ALLOC:
+		meimm_dbg(mdev, "IOCTL_MEI_ALLOC_MEM_CALL\n");
+		ret = mei_mm_alloc(mdev, arg);
+	break;
+	case IOCTL_MEI_MM_FREE:
+		meimm_dbg(mdev, "IOCTL_MEI_FREE_MEM_CALL\n");
+		ret = mei_mm_free(mdev, arg);
+	break;
+	default:
+		ret = -EINVAL;
+		meimm_err(mdev, "Invalid IOCTL command %d\n", cmd);
+		break;
+	}
+out:
+	return ret;
+}
+
+static int mei_mm_mmap(struct file *file, struct vm_area_struct *vma)
+{
+	struct mei_mm_client *client = file->private_data;
+	struct mei_mm_device *mdev =
+			container_of(client, struct mei_mm_device, client);
+	size_t vsize = vma->vm_end - vma->vm_start;
+	size_t off = vma->vm_pgoff << PAGE_SHIFT;
+	int ret;
+
+	meimm_dbg(mdev, "vm_start=0x%016lX vm_end=0x%016lX vm_pgoff=0x%016lX off=%zd\n",
+		vma->vm_start,  vma->vm_end, vma->vm_pgoff, off);
+
+	mutex_lock(&mdev->lock);
+	if (vsize > client->size || off > client->paddr + client->size) {
+		meimm_err(mdev, "%s: trying to map larger area than available r.size=%zd a.size=%zd vm->pg_off=%ld\n",
+			__func__, vsize, client->size, vma->vm_pgoff);
+		ret = -EINVAL;
+		goto err;
+	}
+
+
+	vma->vm_flags |= VM_DONTDUMP | VM_READ |
+			VM_WRITE | VM_SHARED | VM_DONTEXPAND;
+	vma->vm_page_prot = vm_get_page_prot(vma->vm_flags);
+	if (remap_pfn_range(vma, vma->vm_start,
+			__phys_to_pfn(client->paddr) + vma->vm_pgoff,
+			vsize, vma->vm_page_prot)) {
+		ret = -EAGAIN;
+		goto err;
+	}
+
+	mutex_unlock(&mdev->lock);
+
+	vma->vm_private_data = client;
+	return 0;
+
+err:
+	mutex_unlock(&mdev->lock);
+	return ret;
+}
+
+#if IS_ENABLED(CONFIG_DEBUG_FS)
+static ssize_t mei_mm_dbgfs_pool_read(struct file *file,
+			char __user *user_buf,
+			size_t count, loff_t *ppos)
+{
+	struct mei_mm_device *mdev = file->private_data;
+	/* if the buffer is not mapped into kernel space */
+	if (!mdev->pool.vaddr)
+		return 0;
+	return simple_read_from_buffer(user_buf, count, ppos,
+				mdev->pool.vaddr, 256);
+}
+static const struct file_operations mei_mm_dbgfs_pool_ops = {
+	.read = mei_mm_dbgfs_pool_read,
+	.open = simple_open,
+	.llseek = generic_file_llseek,
+};
+#endif /* CONFIG_DEBUG_FS */
+
+
+/**
+ * mei_compat_ioctl - the compat IOCTL function
+ *
+ * @file: pointer to file structure
+ * @cmd: ioctl command
+ * @data: pointer to mei message structure
+ *
+ * returns 0 on success , <0 on error
+ */
+#ifdef CONFIG_COMPAT
+static long mei_mm_compat_ioctl(struct file *file,
+		      unsigned int cmd, unsigned long data)
+{
+	return mei_mm_ioctl(file, cmd, (unsigned long)compat_ptr(data));
+}
+#endif
+/*
+ * file operations structure will be used for mei char device.
+ */
+static const struct file_operations mei_mm_fops = {
+	.owner = THIS_MODULE,
+	.unlocked_ioctl = mei_mm_ioctl,
+#ifdef CONFIG_COMPAT
+	.compat_ioctl = mei_mm_compat_ioctl,
+#endif /* CONFIG_COMPAT */
+	.open = mei_mm_open,
+	.release = mei_mm_release,
+	.mmap = mei_mm_mmap,
+	/*	.poll = mei_mmpoll,*/
+	.llseek = no_llseek
+};
+
+struct mei_mm_device *mei_mm_init(struct device *dev, void *vaddr,
+				dma_addr_t paddr, size_t size)
+{
+
+	struct mei_mm_device *mdev;
+	int ret;
+
+	if (!dev || !paddr || size == 0)
+		return ERR_PTR(-EINVAL);
+
+	mdev = kzalloc(sizeof(struct mei_mm_device), GFP_KERNEL);
+	if (!mdev)
+		return ERR_PTR(-ENOMEM);
+
+	mdev->dev.minor = MISC_DYNAMIC_MINOR;
+	mdev->dev.name = "meimm";
+	mdev->dev.fops = &mei_mm_fops;
+	mdev->dev.parent = dev;
+	/* init pci module */
+	ret = misc_register(&mdev->dev);
+	if (ret) {
+		kzfree(mdev);
+		dev_err(dev, "can't register misc device.\n");
+		return ERR_PTR(ret);
+	}
+
+	mutex_init(&mdev->lock);
+
+	mdev->pool.vaddr = vaddr;
+	mdev->pool.paddr = paddr;
+	mdev->pool.size = size;
+
+#if IS_ENABLED(CONFIG_DEBUG_FS)
+	mdev->dbgfs = debugfs_create_dir("meimm", NULL);
+	if (IS_ERR_OR_NULL(mdev->dbgfs)) {
+		meimm_err(mdev, "failed to create debug files.\n");
+		goto out;
+	}
+
+
+	debugfs_create_file("pool", S_IRUSR, mdev->dbgfs,
+			mdev, &mei_mm_dbgfs_pool_ops);
+
+	debugfs_create_size_t("size", S_IRUSR, mdev->dbgfs, &mdev->pool.size);
+out:
+#endif /* CONFIG_DEBUG_FS */
+
+	return mdev;
+}
+
+
+
+/**
+ * mei_dma_deinit - De-Init Routine for mei_dma misc device
+ *
+ * mei_dma_deinit is called by release function of mei module.
+ */
+void mei_mm_deinit(struct mei_mm_device *mdev)
+{
+
+	if (!mdev)
+		return;
+
+#if IS_ENABLED(CONFIG_DEBUG_FS)
+	debugfs_remove_recursive(mdev->dbgfs);
+	mdev->dbgfs = NULL;
+#endif /* CONFIG_DEBUG_FS */
+
+	misc_deregister(&mdev->dev);
+	kfree(mdev);
+}
+
+
--- /dev/null
+++ b/drivers/misc/mei/mm-txe.h
@@ -0,0 +1,118 @@
+ /* Intel Management Engine Interface (Intel MEI) Linux driver
+  Intel MEI Interface Header
+
+  This file is provided under a dual BSD/GPLv2 license.  When using or
+  redistributing this file, you may do so under either license.
+
+  GPL LICENSE SUMMARY
+
+  Copyright(c) 2003-2012 Intel Corporation. All rights reserved.
+
+  This program is free software; you can redistribute it and/or modify
+  it under the terms of version 2 of the GNU General Public License as
+  published by the Free Software Foundation.
+
+  This program is distributed in the hope that it will be useful, but
+  WITHOUT ANY WARRANTY; without even the implied warranty of
+  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  General Public License for more details.
+
+  Contact Information:
+	  Intel Corporation.
+	  linux-mei@linux.intel.com
+	  http://www.intel.com
+
+
+  BSD LICENSE
+
+  Copyright(c) 2003-2011 Intel Corporation. All rights reserved.
+  All rights reserved.
+
+  Redistribution and use in source and binary forms, with or without
+  modification, are permitted provided that the following conditions
+  are met:
+
+    * Redistributions of source code must retain the above copyright
+      notice, this list of conditions and the following disclaimer.
+    * Redistributions in binary form must reproduce the above copyright
+      notice, this list of conditions and the following disclaimer in
+      the documentation and/or other materials provided with the
+      distribution.
+    * Neither the name of Intel Corporation nor the names of its
+      contributors may be used to endorse or promote products derived
+      from this software without specific prior written permission.
+
+  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+  "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+  LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+  A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+  OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+  SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+  LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+  DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+  THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+  (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+  OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+
+*/
+
+#ifndef _MEI_MM_H_
+#define _MEI_MM_H_
+
+#ifdef __KERNEL__
+
+/*
+ * Structure type definition for  DMA physical memory
+ * @kvaddr - kernel virtual address of the buffer
+ * @cpaddr - physical address (CPU centric)
+ * @dmaddr - address as seen by the PCI device
+ * @offset - bytes, already allocated from the chunk
+ * @bytes  - total size
+ */
+struct mei_mm_desc {
+	void *kvaddr;
+	unsigned long cpaddr;
+	dma_addr_t    dmaddr;
+	unsigned long offset;
+	unsigned long bytes;
+};
+
+/**
+ * mei_dma_init -  Init Routine mei_dma misc device
+ *
+ * mei_dma_init is called by probe function of mei module.
+ * @mm_desc - ptr to ddma_chunk_t, containing information about allocated memory chunk
+ */
+struct mei_mm_device *mei_mm_init(struct device *dev,
+	void *vaddr, dma_addr_t paddr, size_t size);
+
+/**
+ * mei_dma_deinit - De-Init Routine for mei_dma misc device
+ *
+ * mei_dma_deinit is called by release function of mei module.
+ */
+void mei_mm_deinit(struct mei_mm_device *mdev);
+
+#endif /*__KERNEL__ */
+
+/* structure is used to supply DMA chunk distribution to SEC application*/
+struct mei_mm_data {
+	__u64 size;
+};
+
+/* IOCTL number of commands */
+#define MEI_IOC_MAXNR 3
+
+/*
+ * This IOCTLs are used allocate/free memory from/to DMA chunk -
+ * physical contiguous memory chunk, allocated in mei driver init
+ */
+
+#define IOCTL_MEI_MM_ALLOC \
+	_IOWR('H' , 0x02, struct mei_mm_data)
+
+#define IOCTL_MEI_MM_FREE \
+	_IOWR('H' , 0x03, struct mei_mm_data)
+
+
+#endif /* _MEI_MM_H_ */
--- a/drivers/misc/mei/pci-txe.c
+++ b/drivers/misc/mei/pci-txe.c
@@ -145,6 +145,10 @@ static int mei_txe_probe(struct pci_dev
 		goto release_irq;
 	}
 
+	err = mei_txe_dma_setup(dev);
+	if (err)
+		goto release_irq;
+
 	pm_runtime_set_autosuspend_delay(&pdev->dev, MEI_TXI_RPM_TIMEOUT);
 	pm_runtime_use_autosuspend(&pdev->dev);
 
@@ -168,6 +172,8 @@ static int mei_txe_probe(struct pci_dev
 
 release_irq:
 
+	mei_txe_dma_unset(dev);
+
 	mei_cancel_work(dev);
 
 	/* disable interrupts */
@@ -222,6 +228,8 @@ static void mei_txe_remove(struct pci_de
 	free_irq(pdev->irq, dev);
 	pci_disable_msi(pdev);
 
+	mei_txe_dma_unset(dev);
+
 	pci_set_drvdata(pdev, NULL);
 
 	mei_txe_pci_iounmap(pdev, hw);
@@ -260,6 +268,7 @@ static int mei_txe_pci_resume(struct dev
 {
 	struct pci_dev *pdev = to_pci_dev(device);
 	struct mei_device *dev;
+	struct mei_txe_hw *hw;
 	int err;
 
 	dev = pci_get_drvdata(pdev);
@@ -287,6 +296,12 @@ static int mei_txe_pci_resume(struct dev
 		return err;
 	}
 
+	hw = to_txe_hw(dev);
+	err = mei_txe_setup_satt2(dev,
+		dma_to_phys(&dev->pdev->dev, hw->pool_paddr), hw->pool_size);
+	if (err)
+		return err;
+
 	err = mei_restart(dev);
 
 	return err;
