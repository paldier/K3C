VRX320 end point driver support for PUMA

--- a/drivers/net/ethernet/Kconfig
+++ b/drivers/net/ethernet/Kconfig
@@ -35,6 +35,7 @@ source "drivers/net/ethernet/chelsio/Kco
 source "drivers/net/ethernet/cirrus/Kconfig"
 source "drivers/net/ethernet/cisco/Kconfig"
 source "drivers/net/ethernet/davicom/Kconfig"
+source "drivers/net/ethernet/lantiq/Kconfig"
 
 config DNET
 	tristate "Dave ethernet support (DNET)"
--- a/drivers/net/ethernet/Makefile
+++ b/drivers/net/ethernet/Makefile
@@ -78,3 +78,4 @@ obj-$(CONFIG_NET_VENDOR_VIA) += via/
 obj-$(CONFIG_NET_VENDOR_WIZNET) += wiznet/
 obj-$(CONFIG_NET_VENDOR_XILINX) += xilinx/
 obj-$(CONFIG_NET_VENDOR_XIRCOM) += xircom/
+obj-$(CONFIG_NET_VENDOR_LANTIQ) += lantiq/
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/Kconfig
@@ -0,0 +1,25 @@
+
+
+config NET_VENDOR_LANTIQ
+        bool "Lantiq network devices"
+        default y
+        ---help---
+          If you have a network (Ethernet) card belonging to this class, say Y
+          and read the Ethernet-HOWTO, available from
+          <http://www.tldp.org/docs.html#howto>.
+
+if NET_VENDOR_LANTIQ
+
+config LANTIQ_VRX320
+	tristate "VRX320 SmartPHY PCIe EP driver"
+	default n
+	---help---
+	Supported VRX320 smartPHY PCIe EP
+
+config LANTIQ_VRX320_TEST
+	tristate "VRX320 SmartPHY PCIe EP driver test module"
+	default n
+	---help---
+	VRX320 smartPHY PCIe EP test module
+
+endif # NET_VENDOR_LANTIQ
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/Makefile
@@ -0,0 +1,2 @@
+obj-$(CONFIG_LANTIQ_VRX320) += ltq_vrx320.o 
+obj-$(CONFIG_LANTIQ_VRX320_TEST) += lantiq_pcie_ep_vrx320_test.o 
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/lantiq_pcie.h
@@ -0,0 +1,107 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2011~2013 Lei Chuanhua <chuanhua.lei@lantiq.com>
+ */
+
+/** \defgroup IFX_PCIE_EP_VRX320 PCIE EP Functions Reference
+    This chapter describes the entire interfaces to the PCIE EP interface.
+*/
+#ifndef LANTIQ_PCIE_H
+#define LANTIQ_PCIE_H
+#include <linux/types.h>
+#include <linux/pci.h>
+
+/* @{ */
+
+/*! \def IFX_PCIE_EP_MAX_PEER
+    \brief how many EP partners existed. In most cases, this number should be
+    one for bonding application For the future extension, it could be bigger
+    value. For example, multiple bonding
+ */
+#define IFX_PCIE_EP_MAX_PEER     1
+
+/** Structure used to specify interrupt source so that EP can assign unique
+    interruot to it */
+typedef enum ltq_pcie_ep_int_module {
+	IFX_PCIE_EP_INT_PPE, /*!< PPE2HOST_INT 0/1 */
+	IFX_PCIE_EP_INT_MEI, /*!< DSL MEI_IRQ */
+	IFX_PCIE_EP_INT_DYING_GASP, /*!< DSL Dying_Gasp */
+	IFX_PCIE_EP_INT_EDMA, /*!< PCIe eDMA */
+	IFX_PCIE_EP_INT_FPI_BCU, /*!< FPI BUC */
+	IFX_PCIE_EP_INT_ARC_LED0, /*!< ARC LED0 */
+	IFX_PCIE_EP_INT_ARC_LED1, /*!< ARC LED1 */
+	IFX_PCIE_EP_INT_DMA, /*!< Central DMA */
+	IFX_PCIE_EP_INT_MODULE_MAX,
+} ltq_pcie_ep_int_module_t;
+
+/** Structure used to extract attached EP detailed information
+    for PPE/DSL_MEI driver/Bonding */
+typedef struct pcie_ep_dev {
+	u32 irq;          /*!< MSI interrupt number for this device */
+	/*!< The EP inbound memory base address derived from BAR0, SoC
+	     virtual address for PPE/DSL_MEI driver */
+	u8 __iomem *membase;
+	u32 phy_membase;  /*!< The EP inbound memory base address derived
+				from BAR0, physical address for PPE FW */
+	u32 peer_num;    /*!< Bonding peer number available */
+	/*!< The bonding peer EP inbound memory base address derived from
+	     its BAR0, SoC virtual address for PPE/DSL_MEI driver */
+	u8 __iomem *peer_membase[IFX_PCIE_EP_MAX_PEER];
+	/*!< The bonding peer EP inbound memory base address derived from
+	     its BAR0, physical address for PPE FW */
+	u32 peer_phy_membase[IFX_PCIE_EP_MAX_PEER];
+} ltq_pcie_ep_dev_t;
+
+/**
+   This function returns the total number of EPs attached. Normally,
+   the number should be one <standard smartPHY EP> or two <smartPHY
+   off-chip bonding cases>. Extended case is also considered
+
+   \param[in/out]  dev_num   Pointer to detected EP numbers in total.
+   \return         -EIO      Invalid total EP number which means this
+			     module is not initialized properly
+   \return         0         Successfully return the detected EP numbers
+*/
+int ltq_pcie_ep_dev_num_get(int *dev_num);
+
+/**
+   This function returns detailed EP device information for PPE/DSL/Bonding
+   partner by its logical index obtained
+   by \ref ltq_pcie_ep_dev_num_get and its interrupt module number
+   \ref ltq_pcie_ep_int_module_t
+
+   \param[in]      dev_idx   Logical device index referred to the related
+			     device
+   \param[in]      module    EP interrupt module user<PPE/MEI/eDMA/CDMA>
+   \param[in/out]  dev       Pointer to returned detail device structure
+			     \ref ltq_pcie_ep_dev_t
+   \return         -EIO      Invalid logical device index or too many modules
+			     referred to this module
+   \return         0         Successfully return required device information
+
+   \remarks This function normally will be called to trace the detailed device
+	    information after calling \ref ltq_pcie_ep_dev_num_get
+*/
+int ltq_pcie_ep_dev_info_req(int dev_idx, ltq_pcie_ep_int_module_t module,
+			ltq_pcie_ep_dev_t *dev);
+
+/**
+   This function releases the usage of this module by PPE/DSL
+
+   \param[in]  dev_idx   Logical device index referred to the related device
+   \return     -EIO      Invalid logical device index or release too many
+			 times to refer to this module
+   \return     0         Successfully release the usage of this module
+
+   \remarks This function should be called once their reference is over.
+	    The reference usage must matches \ref ltq_pcie_ep_dev_info_req
+*/
+int ltq_pcie_ep_dev_info_release(int dev_idx);
+
+/* @} */
+#endif /* LANTIQ_PCIE_H */
+
+
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/lantiq_pcie_ep_vrx320_test.c
@@ -0,0 +1,694 @@
+/****************************************************************************
+                              Copyright (c) 2011
+                            Lantiq Deutschland GmbH
+                     Am Campeon 3; 85579 Neubiberg, Germany
+
+  For licensing information, see the file 'LICENSE' in the root folder of
+  this software module.
+
+ *****************************************************************************/
+#ifndef EXPORT_SYMTAB
+#define EXPORT_SYMTAB
+#endif
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/init.h>
+#include <asm/types.h>
+#include <linux/interrupt.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+#include <linux/byteorder/generic.h>
+#include <linux/dma-mapping.h>
+#include <linux/dma-direction.h>
+#include <asm/dma-mapping.h>
+
+
+#include "lantiq_pcie.h"
+#include "lantiq_pcie_ep_vrx320_test.h"
+
+/* compilation fixes ...*/
+#include <asm/io.h>
+#define IFX_REG_R32(_r)                    __raw_readl((volatile unsigned int *)(_r))
+#define IFX_REG_W32(_v, _r)               __raw_writel((_v), (volatile unsigned int *)(_r))
+#define IFX_REG_W32_MASK(_clr, _set, _r)   IFX_REG_W32((IFX_REG_R32((_r)) & ~(_clr)) | (_set), (_r))
+#define CPHYSADDR		__virt_to_phys
+int read_c0_count() 
+{
+	return 0;
+}
+
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,11)
+#define MODULE_PARM(a, b)         module_param(a, int, 0)
+#endif
+
+#define REG32(addr)         (*((volatile u32*)(addr)))
+void *tx=NULL, *rx=NULL;
+void *txphy, *rxphy;
+extern struct dma_map_ops arm_dma_ops;
+static int test_module = CDMA_TEST;
+static int dma_data_length = 1024;
+static int dma_mode = 0;
+static int dma_burst = 8;
+static int desc_num = 32;
+static int tx_byte_offset = 0;
+static int rx_byte_offset = 0;
+static int byte_enabled = 1;
+
+static ltq_pcie_ep_dev_t pcie_dev[2] = {{0}, {0}};
+static int ppe_irq_num = 0;
+
+static int txw1 = 0xb0000400;
+static int txw0 = 0x8e7a0000;
+static int rxw1 = 0xb0000400;
+static int rxw0 = 0x1e08c000;
+
+module_param(txw1, int, S_IRUGO);
+module_param(txw0, int, S_IRUGO);
+module_param(rxw1, int, S_IRUGO);
+module_param(rxw0, int, S_IRUGO);
+
+MODULE_PARM(test_module, "i");
+MODULE_PARM_DESC(test_module, "0 -- PPE, 1 -- CDMA");
+
+MODULE_PARM(dma_data_length, "i");
+MODULE_PARM_DESC(dma_data_length, "Single packet length");
+
+MODULE_PARM(dma_mode,"i");
+MODULE_PARM_DESC(dma_mode, "mode 0 -- Soc->EP, mode 1-- EP->SoC");
+
+MODULE_PARM(dma_burst,"i");
+MODULE_PARM_DESC(dma_burst, "dma burst 2, 4, 8");
+
+MODULE_PARM(desc_num,"i");
+MODULE_PARM_DESC(desc_num, "desc number 8, 16, 32");
+
+MODULE_PARM(tx_byte_offset,"i");
+MODULE_PARM_DESC(tx_byte_offset, "DMA tx byte offset 1, 2, 3");
+
+MODULE_PARM(rx_byte_offset,"i");
+MODULE_PARM_DESC(rx_byte_offset, "DMA rx byte offset 1, 2, 3");
+
+MODULE_PARM(byte_enabled,"i");
+MODULE_PARM_DESC(byte_enabled, "DMA byte enabled or not");
+mydump(void * desc, int len)
+{
+	int i;
+	char *c =desc;
+	printk("dumping desc located at virtual=%#x\n", c);
+	for(i=0; i<len; i+=8) {
+		printk("%02x %02x %02x %02x %02x %02x %02x %02x\n", 
+			c[i], c[i+1], c[i+2], c[i+3], c[i+4], c[i+5], c[i+6], c[i+7]);
+	}
+		
+}
+
+
+static irqreturn_t
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,19)
+ltq_pcie_ep_ppe_intr(int irq, void *dev_id)
+#else
+ltq_pcie_ep_ppe_intr(int irq, void *dev_id, struct pt_regs *regs)
+#endif
+{
+    ltq_pcie_ep_dev_t *dev = dev_id;
+    u32 membase = (u32)(dev->membase);
+    ppe_irq_num++;
+    if (IFX_REG_R32(PPE_MBOX_IGU0_ISR(membase)) == 0) {
+        printk("Fatal error, dummy interrupt\n");
+    }
+    IFX_REG_W32(PPE_MBOX_TEST_BIT, PPE_MBOX_IGU0_ISRC(membase));
+    return IRQ_HANDLED;
+}
+
+static void ppe_mbox_reg_dump(u32 membase)
+{
+    printk("PPE_MBOX_IGU0_ISRS addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU0_ISRS(membase), IFX_REG_R32(PPE_MBOX_IGU0_ISRS(membase)));
+    printk("PPE_MBOX_IGU0_ISRC addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU0_ISRC(membase), IFX_REG_R32(PPE_MBOX_IGU0_ISRC(membase)));
+    printk("PPE_MBOX_IGU0_ISR  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU0_ISR(membase), IFX_REG_R32(PPE_MBOX_IGU0_ISR(membase)));
+    printk("PPE_MBOX_IGU0_IER  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU0_IER(membase), IFX_REG_R32(PPE_MBOX_IGU0_IER(membase)));
+    printk("PPE_MBOX_IGU1_ISRS addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU1_ISRS(membase), IFX_REG_R32(PPE_MBOX_IGU1_ISRS(membase)));
+    printk("PPE_MBOX_IGU1_ISRC addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU1_ISRC(membase), IFX_REG_R32(PPE_MBOX_IGU1_ISRC(membase)));
+    printk("PPE_MBOX_IGU1_ISR  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU1_ISR(membase), IFX_REG_R32(PPE_MBOX_IGU1_ISR(membase)));                    
+    printk("PPE_MBOX_IGU1_IER  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU1_IER(membase), IFX_REG_R32(PPE_MBOX_IGU1_IER(membase)));
+    printk("PPE_MBOX_IGU2_ISRS addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU2_ISRS(membase), IFX_REG_R32(PPE_MBOX_IGU2_ISRS(membase)));
+    printk("PPE_MBOX_IGU2_ISRC addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU2_ISRC(membase), IFX_REG_R32(PPE_MBOX_IGU2_ISRC(membase)));
+    printk("PPE_MBOX_IGU2_ISR  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU2_ISR(membase), IFX_REG_R32(PPE_MBOX_IGU2_ISR(membase)));
+    printk("PPE_MBOX_IGU2_IER  addr 0x%08x data 0x%08x\n", PPE_MBOX_IGU2_IER(membase), IFX_REG_R32(PPE_MBOX_IGU2_IER(membase)));
+}
+
+#define PPE_INT_TIMEOUT 100
+static int ppe_mbox_int_stress_test(ltq_pcie_ep_dev_t *dev)
+{
+    int i;
+    int j;
+    int ret;
+    u32 membase = (u32)(dev->membase);
+    
+    IFX_REG_W32(PPE_MBOX_TEST_BIT, PPE_MBOX_IGU0_IER(membase));
+    /* Clear it first */
+    IFX_REG_W32(PPE_MBOX_TEST_BIT, PPE_MBOX_IGU0_ISRC(membase));
+
+    ret = request_irq(dev->irq, ltq_pcie_ep_ppe_intr, IRQF_DISABLED, "PPE_MSI", dev);
+    if (ret) {
+        printk(KERN_ERR "%s request irq %d failed\n", __func__, dev->irq);
+        return -1;
+    }
+    printk("PPE test\n");
+    /* Purposely trigger interrupt */
+    for (i = 0; i < PPE_MBOX_IRQ_TEST_NUM; i++) {
+        j = 0;
+        while((IFX_REG_R32(PPE_MBOX_IGU0_ISR(membase)) & PPE_MBOX_TEST_BIT)) {
+            udelay(10);
+            j++;
+            if (j > PPE_INT_TIMEOUT) {
+                break;
+            }
+        }
+        IFX_REG_W32(PPE_MBOX_TEST_BIT, PPE_MBOX_IGU0_ISRS(membase));
+    }
+    udelay(100);
+    printk("irq triggered %d expected %d\n", ppe_irq_num, PPE_MBOX_IRQ_TEST_NUM);
+    ppe_mbox_reg_dump(membase);
+    ppe_irq_num = 0;
+    return 0;
+}
+
+static void icu_im_enable(u32 membase, int module)
+{
+    u32 reg;
+    
+    reg = REG32(ICU_IM_ER(membase));
+
+    reg |= (1 << module);
+    
+    REG32(ICU_IM_ER(membase)) = reg;
+}
+
+static void cdma_module_reset (u32 membase)
+{
+    REG32(PMU_PWDCR(membase)) &= ~CGU_DMA_CLK_EN;
+    printk("PMU_SR addr 0x%08x data 0x%08x\n", (u32)PMU_SR(membase), REG32(PMU_SR(membase)));
+    /* Enable/disable the DMA*/
+    REG32(RCU_RST_REQ(membase)) |= (0x00000200) ;  /*DMA(9) */
+    udelay(10);
+    REG32(CDMA_CTRL(membase)) |= (1);  /*Reset DMA module */
+    udelay(10);
+    REG32(CDMA_CLC(membase)) = 0x00000000;
+    printk("CDMA_CLC addr 0x%08x data 0x%08x\n", (u32)CDMA_CLC(membase), REG32(CDMA_CLC(membase)));
+
+    /* Enable central DMA interrupts */
+    icu_im_enable(membase, CDMA_CH0);
+    icu_im_enable(membase, CDMA_CH1);
+    printk("Reset DMA module done\n");
+}
+
+static void cdma_flush_memcopy_buf (u32 membase)
+{
+    REG32(CDMA_PS(membase)) = CDMA_MEMCOPY_PORT;
+    REG32(CDMA_PCTRL(membase)) |= 0x10000; 
+    udelay(2);
+    REG32(CDMA_PCTRL(membase)) &= ~(0x10000); 
+}
+
+static void reset_cdma_channel(u32 membase, int channel)
+{
+    /*reset all DMA channel to PPE Switch*/
+    REG32(CDMA_CS(membase)) = channel;
+    REG32(CDMA_CCTRL(membase)) = 0x2; 
+    while ( REG32(CDMA_CCTRL(membase)) & 0x01 ) { 
+        udelay(10);
+        printk("Reset DMA channel not done\n");
+    } 
+}   
+
+static void cdma_memory_port_cfg(u32 membase, int burstlen)
+{
+    REG32(CDMA_PS(membase)) = CDMA_MEMCOPY_PORT;
+    REG32(CDMA_PCTRL(membase)) &= ~0xf3F;  
+    
+    if (burstlen == 2 ) { 
+        REG32(CDMA_PCTRL(membase)) |= 0x14;  
+    } 
+    else if (burstlen == 4 ) { 
+        REG32(CDMA_PCTRL(membase)) |= 0x28;  
+    } 
+    else if (burstlen == 8) {
+        REG32(CDMA_PCTRL(membase)) |= 0x3c; 
+    }
+}  
+
+static void cdma_byte_enable_cfg(u32 membase, int enable)
+{
+    if (enable) {
+        REG32(CDMA_CTRL(membase)) |= (1 << 9); /* Default one */
+    }
+    else {
+        REG32(CDMA_CTRL(membase)) &= ~(1 << 9); /* Disable byte enable bit */
+    }
+}
+
+static void cdma_memory_copy_init(u32 membase)
+{
+    cdma_module_reset(membase);
+    reset_cdma_channel(membase, CDMA_MEMCOPY_TX_CHAN); /* TX */
+    reset_cdma_channel(membase, CDMA_MEMCOPY_RX_CHAN); /* RX */
+    cdma_flush_memcopy_buf(membase);
+}
+static void cdma_tx_ch_cfg (u32 membase, int dir, int ch_num, u32 desc_ptr_base, u32 data_ptr_base, int desc_num) 
+{
+    unsigned int i;
+    cdma_tx_descriptor_t *tx_desc;
+    printk("txphy = %#x\n", txphy);
+
+    for (i = 0; i < desc_num; i++) {
+        tx_desc = (cdma_tx_descriptor_t *)(desc_ptr_base + (i * sizeof(cdma_tx_descriptor_t)));
+        /* Trick !!! */
+#if 0
+        tx_desc->status.word = 0;
+        tx_desc->status.field.OWN = 1;
+        tx_desc->status.field.C = 0;
+        tx_desc->status.field.Sop = 1;
+        tx_desc->status.field.Eop = 1;
+        tx_desc->status.field.Byteoffset = tx_byte_offset;
+        tx_desc->status.field.DataLen = cpu_to_be16(dma_data_length);
+	/* tx_desc->status.word = cpu_to_be32(0xb0000400); */
+        if (dir == SOC_TO_EP) { /* src is SoC, dst is VRX218 */
+            tx_desc->DataPtr = cpu_to_be32(((((u32)(txphy + ( i * dma_data_length ))) + PCIE_EP_OUTBOUND_INTERNAL_BASE)));
+        }
+        else {
+            tx_desc->DataPtr = VRX218_ADDR(((u32)(txphy + ( i * dma_data_length ))));
+        }
+#else
+	/*FIXME tx/rx dma descriptors are defined for bigendian
+	 reorder descriptor structure for little endian */
+	memset(tx_desc, '\0', 8);
+	memcpy((char *)tx_desc, &txw1, 4);
+        if (dir == SOC_TO_EP) { /* src is SoC, dst is VRX218 */
+		int txaddr=(PCIE_EP_OUTBOUND_INTERNAL_BASE + txphy + i*dma_data_length);
+		memcpy((char *)tx_desc+4, &txaddr, 4);
+	} else {
+            	int txaddr = VRX218_ADDR(((u32)(data_ptr_base + ( i * dma_data_length ))));
+		memcpy((char *)tx_desc+4, &txaddr, 4);
+        }
+#endif
+	
+        printk("Tx desc num %d word 0x%08x data pointer 0x%08x\n",
+            i, tx_desc->status.word, tx_desc->DataPtr);
+    }
+    
+    REG32(CDMA_CS(membase)) = ch_num;
+#if 0
+    REG32(CDMA_CDBA(membase)) = VRX218_ADDR(CPHYSADDR(desc_ptr_base));
+#else
+    REG32(CDMA_CDBA(membase)) = VRX218_ADDR((desc_ptr_base));
+#endif
+    REG32(CDMA_CDLEN(membase)) = desc_num;
+    REG32(CDMA_CIE(membase)) = 0;
+    REG32(CDMA_CPOLL(membase)) = 0x80000020;
+    REG32(CDMA_CCTRL(membase)) |= (0x1 << 8); /* TX DIR */
+}
+
+static void cdma_rx_ch_cfg (u32 membase, int dir, int ch, u32 desc_ptr_base, unsigned int data_ptr_base, int desc_num) 
+{
+
+    unsigned int i;
+    cdma_rx_descriptor_t *rx_desc;
+    
+    for(i = 0; i < desc_num; i++) {
+        /* Trick !!! */
+        rx_desc = (cdma_rx_descriptor_t *)(desc_ptr_base + (i * sizeof(cdma_rx_descriptor_t)));
+        rx_desc->status.word = 0; 
+#if 0
+        rx_desc->status.field.OWN = 1;
+        rx_desc->status.field.Sop = 1;
+        rx_desc->status.field.Eop = 1;
+        rx_desc->status.field.Byteoffset = rx_byte_offset;
+        rx_desc->status.field.DataLen = roundup(dma_data_length, dma_burst << 2);
+        /* rx_desc->status.word = cpu_to_be32(0xb0000400); */
+        if (dir == SOC_TO_EP) { /* src is VRX218, dst is SoC */
+	    u32	rx_data_addr = (u32)(membase + VRX218_MASK_ADDR(REMOTE_RX1_DATA_LOC));
+            rx_desc->DataPtr = cpu_to_be32(VRX218_ADDR(((u32)(rx_data_addr + (i * roundup(dma_data_length, dma_burst << 2))))));
+        }
+        else {
+            rx_desc->DataPtr = ((u32)(rxphy + (i * roundup(dma_data_length, dma_burst << 2)))) + PCIE_EP_OUTBOUND_INTERNAL_BASE;
+        }
+
+#else
+	memset(rx_desc, '\0', 8);
+	memcpy((char *)rx_desc, &rxw1, 4);
+        if (dir == SOC_TO_EP) { /* src is VRX218, dst is SoC */
+		u32	rx_data_addr = (u32)(membase + VRX218_MASK_ADDR(REMOTE_RX1_DATA_LOC));
+		u32	dataptr = VRX218_ADDR(((u32)(rx_data_addr + (i * roundup(dma_data_length, dma_burst << 2)))));
+		memcpy((char *)rx_desc+4, &dataptr, 4);
+	} else {
+		int rxaddr = ((u32)(rxphy + (i * roundup(dma_data_length, dma_burst << 2)))) + PCIE_EP_OUTBOUND_INTERNAL_BASE;
+		memcpy((char *)rx_desc+4, &rxaddr, 4);
+	}
+#endif
+         printk("Rx desc num %d word 0x%08x data pointer 0x%08x\n",
+            i, rx_desc->status.word, rx_desc->DataPtr);       
+	//mydump(rx_desc, sizeof(cdma_rx_descriptor_t));
+    }
+    REG32(CDMA_CS(membase)) = ch;
+    REG32(CDMA_CDBA(membase)) = VRX218_ADDR((desc_ptr_base));
+    REG32(CDMA_CDLEN(membase)) = desc_num;
+    REG32(CDMA_CIE(membase)) = 0;
+    REG32(CDMA_CPOLL(membase)) = 0x80000020;
+    REG32(CDMA_CCTRL(membase)) &= ~(0x1 << 8); /* RX DIR */
+    return;
+}
+
+static void cdma_reg_dump(u32 membase)
+{
+    printk("CDMA_CLC   addr 0x%08x data 0x%08x\n", (u32)CDMA_CLC(membase), REG32(CDMA_CLC(membase)));
+    printk("CDMA_ID    addr 0x%08x data 0x%08x\n", (u32)CDMA_ID(membase), REG32(CDMA_ID(membase)));
+    printk("CDMA_CTRL  addr 0x%08x data 0x%08x\n", (u32)CDMA_CTRL(membase), REG32(CDMA_CTRL(membase)));
+    printk("CDMA_CPOLL addr 0x%08x data 0x%08x\n", (u32)CDMA_CPOLL(membase), REG32(CDMA_CPOLL(membase)));
+    printk("CDMA_CS    addr 0x%08x data 0x%08x\n", (u32)CDMA_CS(membase), REG32(CDMA_CS(membase)));
+    printk("CDMA_CCTRL addr 0x%08x data 0x%08x\n", (u32)CDMA_CCTRL(membase), REG32(CDMA_CCTRL(membase)));
+    printk("CDMA_CDBA  addr 0x%08x data 0x%08x\n", (u32)CDMA_CDBA(membase), REG32(CDMA_CDBA(membase)));
+    printk("CDMA_CDLEN addr 0x%08x data 0x%08x\n", (u32)CDMA_CDLEN(membase), REG32(CDMA_CDLEN(membase)));
+    printk("CDMA_CIS   addr 0x%08x data 0x%08x\n", (u32)CDMA_CIS(membase), REG32(CDMA_CIS(membase)));
+    printk("CDMA_CIE   addr 0x%08x data 0x%08x\n", (u32)CDMA_CIE(membase), REG32(CDMA_CIE(membase)));
+    printk("CDMA_CGBL  addr 0x%08x data 0x%08x\n", (u32)CDMA_CGBL(membase), REG32(CDMA_CGBL(membase)));
+    printk("CDMA_PS    addr 0x%08x data 0x%08x\n", (u32)CDMA_PS(membase), REG32(CDMA_PS(membase)));
+    printk("CDMA_PCTRL addr 0x%08x data 0x%08x\n", (u32)CDMA_PCTRL(membase), REG32(CDMA_PCTRL(membase)));
+    printk("CDMA_IRNEN addr 0x%08x data 0x%08x\n", (u32)CDMA_IRNEN(membase), REG32(CDMA_IRNEN(membase)));
+    printk("CDMA_IRNCR addr 0x%08x data 0x%08x\n", (u32)CDMA_IRNCR(membase), REG32(CDMA_IRNCR(membase)));
+    printk("CDMA_IRNICR addr 0x%08x data 0x%08x\n", (u32)CDMA_CLC(membase), REG32(CDMA_IRNICR(membase)));
+}
+
+/* Trigger MSI interrupt */
+static void cdma_channel_irq_en(u32 membase, u8 channel)
+{
+    u32 reg = DMA_CIE_DEFAULT;
+
+    REG32(CDMA_CS(membase)) = channel;
+    REG32(CDMA_CIS(membase)) = DMA_CIS_ALL;
+    REG32(CDMA_CIE(membase)) = reg;
+
+    reg = REG32(CDMA_IRNEN(membase));
+    reg |= (1 << channel);
+    REG32(CDMA_IRNEN(membase)) = reg;
+
+    //printk("CDMA_IRNEN addr 0x%08x data 0x%08x\n", (u32)CDMA_IRNEN(membase), REG32(CDMA_IRNEN(membase))); 
+}
+
+static void cdma_channel_irq_dis(u32 membase, u8 channel)
+{
+    u32 reg = DMA_CIE_DEFAULT;
+    
+    REG32(CDMA_CS(membase)) = channel;
+    REG32(CDMA_CIE(membase)) = DMA_CIE_DISABLE_ALL;
+    REG32(CDMA_CIS(membase)) = DMA_CIS_ALL;
+    reg = REG32(CDMA_IRNEN(membase));
+    reg &= ~(1 << channel);
+    REG32(CDMA_IRNEN(membase)) = reg;
+    //printk("CDMA_IRNEN addr 0x%08x data 0x%08x\n", (u32)CDMA_IRNEN(membase), REG32(CDMA_IRNEN(membase)));
+}
+
+static void cdma_channel_on(u32 membase, u8 channel)
+{
+    REG32(CDMA_CS(membase)) = channel;
+    REG32(CDMA_CCTRL(membase)) |= ((0x3<<16)| 0x1);
+    cdma_channel_irq_en(membase, channel);
+}
+
+static void cdma_channel_off(u32 membase, u8 channel)
+{
+    REG32(CDMA_CS(membase)) = channel;
+    REG32(CDMA_CCTRL(membase)) &= ~0x1;
+    udelay(10);
+    while (REG32(CDMA_CCTRL(membase)) & 0x01 ) { 
+        REG32(CDMA_CS(membase)) = channel;
+        udelay(10);
+    } 
+    cdma_channel_irq_dis(membase, channel);
+}
+
+#define DEFAULT_TEST_PATTEN 0x12345678
+
+static void cdma_sdram_preload(u32 sdram_data_tx_ptr, u32 sdram_data_rx_ptr )
+{
+    u32 i=0,j;
+    u32 testaddr = sdram_data_tx_ptr;
+
+    for (i = 0; i < desc_num; i++) {
+        for (j = 0; j <dma_data_length; j = j + 4 ) {
+            REG32(testaddr + i * dma_data_length + j) = DEFAULT_TEST_PATTEN;
+        }
+    }
+    
+    printk("SDR Preload(0x55aa00ff) with Data on Memcopy Tx location done\n");
+
+    testaddr = sdram_data_rx_ptr; 
+    printk("RX Preload start address:0x%08x\n",(u32)(testaddr));
+
+    for (i = 0; i < desc_num; i++) {
+        for (j = 0; j <roundup(dma_data_length, dma_burst << 2); j = j + 4 ) {
+            REG32(testaddr + i * dma_data_length + j) = 0xcccccccc;
+        }
+    }
+    printk("SDR locations for Memcopy RX preset to 0xcccccccc done\n");
+}
+
+static int memcopy_data_check(u32 rx_data_addr)
+{
+    int i, j;
+    u32 read_data;
+    int count=0;
+    int c=0;
+    int tc=0;
+    
+    for (i = 0; i < desc_num; i++) {
+        for(j = 0; j < dma_data_length; j = j + 4) {
+            read_data = REG32(rx_data_addr + i * dma_data_length + j);
+            if(read_data != DEFAULT_TEST_PATTEN) {
+		if(count <= 10 ) {
+                	printk("\nMemcopy ERROR at addr 0x%08x data 0x%08x\n", (rx_data_addr + j),(read_data));;
+		}
+		count++;
+
+            }  else { 
+		if(c <= 10) {
+		printk("Memory copied successfully : content at %#x = %#x \n", (rx_data_addr + j), read_data);
+		}
+		 c++;
+	}
+	tc++;
+		
+        }
+    }
+    printk("total dwords = %d , error dwords=%d, success dwords=%d\n", tc, count, c);
+    return 0;
+}
+
+static irqreturn_t
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,19)
+ltq_pcie_ep_cdma_intr(int irq, void *dev_id)
+#else
+ltq_pcie_ep_cdma_intr(int irq, void *dev_id, struct pt_regs *regs)
+#endif
+{
+    printk("DMA interrupt %d received\n", irq);
+    return IRQ_HANDLED;
+}
+
+static void vrx218_central_dma_test(ltq_pcie_ep_dev_t *dev)
+{
+    int ret;
+    u8 burstlen;
+    u32 delay = 0;
+    u32 tx_data_addr, rx_data_addr;
+    u32 start, end;
+    u32 cycles;
+    u32 rx_desc_base;
+    u32 tx_desc_base;
+    u32 last_tx_desc_base;
+    u32 last_rx_desc_base;
+    u32 membase = (u32)(dev->membase);
+    int count=0;
+    int k=0;
+    int r=-1;
+
+    tx = pci_alloc_consistent(NULL, 64*1024, &txphy);
+    if(tx == NULL) {
+	printk("Unable to allocate tx memory\n");
+	return;
+    }
+    rx = pci_alloc_consistent(NULL, 64*1024, &rxphy);
+    if(rx == NULL) {
+	printk("Unable to allocate rx memory\n");
+	pci_free_consistent(NULL, 64*1024, tx, txphy);
+	return;
+    }
+    printk("*******************************************\n");
+    printk("  tx=%#x, txphy=%#x, rx=%#x & rxphy=%#x\n", tx,txphy, rx,rxphy);
+    printk("*******************************************\n");
+
+    if (dma_mode == SOC_TO_EP) { /* Read from SoC DDR to local PDBRAM  */
+        tx_desc_base = (u32)(membase + VRX218_MASK_ADDR(VRX218_TX_DESC));
+        rx_desc_base = (u32)(membase + VRX218_MASK_ADDR(VRX218_RX_DESC));
+        tx_data_addr = (u32)tx;
+        rx_data_addr = (u32)(membase + VRX218_MASK_ADDR(REMOTE_RX1_DATA_LOC));
+    }
+    else if (dma_mode == EP_TO_SOC) { /* Write from local PDBRAM to remote DDR */
+        tx_desc_base = (u32)(membase + VRX218_MASK_ADDR(VRX218_TX_DESC));
+        rx_desc_base = (u32)(membase + VRX218_MASK_ADDR(VRX218_RX_DESC));
+        tx_data_addr = (u32)(membase + VRX218_MASK_ADDR(REMOTE_TX1_DATA_LOC));
+        rx_data_addr = (u32) rx;
+    }
+    else {
+        return;
+    }
+
+    printk("tx_desc_base 0x%08x tx_data_addr 0x%08x rx_desc_base 0x%08x rx_data_addr 0x%08x\n",
+        tx_desc_base, tx_data_addr, rx_desc_base, rx_data_addr);
+
+
+    printk("dma burst %d desc number %d packet size %d\n", dma_burst, desc_num, dma_data_length);
+    burstlen = dma_burst;
+    last_tx_desc_base = tx_desc_base + (desc_num - 1) * sizeof (cdma_tx_descriptor_t);
+    last_rx_desc_base = rx_desc_base + (desc_num - 1) * sizeof (cdma_tx_descriptor_t);
+
+    cdma_memory_copy_init(membase);
+    cdma_memory_port_cfg(membase, burstlen);
+    cdma_byte_enable_cfg(membase, byte_enabled);
+    
+    cdma_sdram_preload(tx_data_addr, rx_data_addr);
+
+    cdma_tx_ch_cfg(membase, dma_mode, CDMA_MEMCOPY_TX_CHAN, tx_desc_base, tx_data_addr, desc_num);
+    cdma_rx_ch_cfg(membase, dma_mode, CDMA_MEMCOPY_RX_CHAN, rx_desc_base, rx_data_addr, desc_num);
+   
+    ret = request_irq(dev->irq, ltq_pcie_ep_cdma_intr, IRQF_DISABLED, "CDMA_MSI", dev);
+    if (ret) {
+        printk(KERN_ERR "%s request irq %d failed\n", __func__, dev->irq);
+        return;
+    }
+    printk("request irq %d is successfull\n", dev->irq);
+    udelay(5); /* Make sure that RX descriptor prefetched */
+    
+    start = read_c0_count();
+    cdma_channel_on(membase, CDMA_MEMCOPY_RX_CHAN);        
+    cdma_channel_on(membase, CDMA_MEMCOPY_TX_CHAN);
+   
+    while((REG32(last_tx_desc_base) & 0x80000000) == 0x80000000){
+        
+        delay++;
+        udelay(1);
+    }
+    end = read_c0_count();
+    cycles = end - start;
+    printk("cylces %d data amount %dbytes\n", cycles, ((u32)(dma_data_length *desc_num * 8 * 1000 )) >> 2);
+    printk("loop times %d\n", delay);
+    while((REG32(last_rx_desc_base) & 0x80000000) == 0x80000000){
+        delay++;
+        udelay(1);
+    }
+
+    r = memcopy_data_check(rx_data_addr);
+    if(r==0) {
+	printk("******Memory Copy Successfull******\n");
+    }
+    
+    printk(" Before stopping DMA\n");
+    cdma_reg_dump(membase);
+    cdma_channel_off(membase, CDMA_MEMCOPY_RX_CHAN);
+    cdma_channel_off(membase, CDMA_MEMCOPY_TX_CHAN);
+    printk(" After stopping DMA\n");
+    cdma_reg_dump(membase);
+}
+
+static int __init 
+ltq_pcie_ep_test_init(void)
+{
+    int i;
+    int j;
+    char ver_str[128] = {0};
+    int dev_num;
+    ltq_pcie_ep_dev_t dev;
+    int module;
+    
+    if (ltq_pcie_ep_dev_num_get(&dev_num)) {
+        printk("%s failed to get total device number\n", __func__);
+        return -EIO;
+    }
+
+    printk(KERN_INFO "%s: total %d EPs found\n", __func__, dev_num);
+
+    for (i = 0; i < dev_num; i++) {
+        if (test_module == PPE_TEST) {
+            module = IFX_PCIE_EP_INT_PPE;
+        }
+        else if (test_module == CDMA_TEST) {
+            module = IFX_PCIE_EP_INT_DMA;
+        }
+        else {
+            module = IFX_PCIE_EP_INT_PPE;
+        }
+        if (ltq_pcie_ep_dev_info_req(i, module, &dev)) {
+            printk("%s failed to get pcie ep %d information\n", __func__, i);
+        }
+        printk("irq %d\n", dev.irq);
+        printk("phyiscal membase 0x%08x virtual membase 0x%p\n", dev.phy_membase, dev.membase);
+        if (dev_num > 1) {
+            for (j = 0; j < dev.peer_num; j++) {
+                printk("phyiscal peer membase 0x%08x virtual peer membase 0x%p\n", 
+                    dev.peer_phy_membase[j], dev.peer_membase[j]);
+            }
+        }
+
+        pcie_dev[i].irq = dev.irq;
+        pcie_dev[i].membase = dev.membase;
+        pcie_dev[i].phy_membase = dev.phy_membase;
+        if (module == IFX_PCIE_EP_INT_PPE) {
+            ppe_mbox_int_stress_test(&pcie_dev[i]);
+        }
+        else if (module == IFX_PCIE_EP_INT_DMA) {
+            vrx218_central_dma_test(&pcie_dev[i]);
+        }
+    }
+    printk(KERN_INFO "%s", ver_str);
+    return 0;
+}
+
+static void __exit 
+ltq_pcie_ep_test_exit(void)
+{
+    int i;
+    int dev_num;
+    if(rx != NULL) {
+	printk("freeing rx memory\n");
+	pci_free_consistent(NULL, 64*1024, rx, rxphy);
+    }
+
+    if(tx != NULL) {
+	printk("freeing tx memory\n");
+	pci_free_consistent(NULL, 64*1024, tx, txphy);
+    }
+
+    if (ltq_pcie_ep_dev_num_get(&dev_num)) {
+        printk("%s failed to get total device number\n", __func__);
+        return;
+    }    
+    printk(KERN_INFO "%s: total %d EPs found\n", __func__, dev_num);
+    for (i = 0; i < dev_num; i++) {
+        
+        free_irq(pcie_dev[i].irq, &pcie_dev[i]);
+
+        if (ltq_pcie_ep_dev_info_release(i)) {
+            printk("%s failed to release pcie ep %d information\n", __func__, i);
+        }
+    }
+}
+
+module_init(ltq_pcie_ep_test_init);
+module_exit(ltq_pcie_ep_test_exit);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("LeiChuanhua <Chuanhua.lei@lantiq.com>");
+MODULE_DESCRIPTION("Lantiq VRX218 PCIe EP Address Mapping test driver");
+MODULE_SUPPORTED_DEVICE ("Lantiq VRX218 SmartPHY PCIe EP");
+
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/lantiq_pcie_ep_vrx320_test.h
@@ -0,0 +1,264 @@
+#ifndef IFXMIPS_PCIE_EP_VRX320_TEST_H
+#define IFXMIPS_PCIE_EP_VRX320_TEST_H
+#include <linux/types.h>
+
+/* PPE interrupt */
+#define PPE_MBOX_TEST_BIT     0x1
+#define PPE_MBOX_IRQ_TEST_NUM 10000
+
+#define PPE_MBOX_OFFSET       0x200000
+#define PEE_MBOX_ATU(X)       (((X) - 0x7000 + 0xd000) << 2)
+
+#define PPE_MBOX_IGU0_ISRS(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0x7200))
+#define PPE_MBOX_IGU0_ISRC(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7201))
+#define PPE_MBOX_IGU0_ISR(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7202))
+#define PPE_MBOX_IGU0_IER(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7203))
+#define PPE_MBOX_IGU1_ISRS(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7204))
+#define PPE_MBOX_IGU1_ISRC(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7205))
+#define PPE_MBOX_IGU1_ISR(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7206))
+#define PPE_MBOX_IGU1_IER(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7207))
+#define PPE_MBOX_IGU2_ISRS(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7210))
+#define PPE_MBOX_IGU2_ISRC(__mem_base)   ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7211))
+#define PPE_MBOX_IGU2_ISR(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7212))
+#define PPE_MBOX_IGU2_IER(__mem_base)    ((__mem_base) + PPE_MBOX_OFFSET + PEE_MBOX_ATU(0X7213))
+
+/* Central DMA */
+
+/* Inbound address translation for iATU0 */
+#define PCIE_EP_INBOUND_INTERNAL_BASE          0x1E000000
+#define PCIE_EP_OUTBOUND_INTERNAL_BASE         0x20000000
+#define PCIE_EP_OUTBOUND_MEMSIZE               0x80000000
+
+#define VRX218_MASK_ADDR(X)  (0x00FFFFFF & (X))
+#define VRX218_ADDR(X)       ((0x00FFFFFF & (X)) | 0x1e000000)
+
+/* VRX218 internal address */
+#define VRX218_PDRAM_BASE    0x1e080000
+#define PPE_SB_RAM_BLOCK0    (0x1e200000 + (0x8000 << 2))
+#define PPE_SB_RAM_BLOCK1    (0x1e200000 + (0x9000 << 2))
+#define PPE_SB_RAM_BLOCK2    (0x1e200000 + (0xa000 << 2))
+#define PPE_SB_RAM_BLOCK3    (0x1e200000 + (0xb000 << 2))
+
+#define LOCAL_DRAMBASE  0x40800000
+
+#define DATA_DDR /* SoC data in DDR instead of SRAM */
+
+#ifdef DATA_DDR
+#define LOCAL_TX1_DATA_LOC  (LOCAL_DRAMBASE + 0x00000) 
+#define LOCAL_RX1_DATA_LOC  (LOCAL_DRAMBASE + 0x10000) /* 64K */
+#else
+#define LOCAL_TX1_DATA_LOC  (0xBF107400) 
+#define LOCAL_RX1_DATA_LOC  (0xBF107400) /* 16K */
+#endif
+
+/* Special test case for bonding */
+#define BONDING_TX1_DATA_LOC  (VRX218_PDRAM_BASE + 0x0000) 
+#define BONDING_RX1_DATA_LOC  (VRX218_PDRAM_BASE + 0x8000) /* 64K */
+
+#define DESC_SB /* Descriptor in VRX218 PPE SB, instead of PDRAM */
+//#define DESC_DATA_SB /* Descriptor/ Data in VRX218 PPE SB */
+
+#ifdef DESC_SB
+#define REMOTE_TX1_DATA_LOC    VRX218_PDRAM_BASE
+#define REMOTE_RX1_DATA_LOC    VRX218_PDRAM_BASE + 0xc000
+#define VRX218_TX_DESC         PPE_SB_RAM_BLOCK0
+#define VRX218_RX_DESC         PPE_SB_RAM_BLOCK1
+#elif defined (DESC_DATA_SB)
+#define REMOTE_TX1_DATA_LOC    PPE_SB_RAM_BLOCK0
+#define REMOTE_RX1_DATA_LOC    PPE_SB_RAM_BLOCK1
+#define VRX218_TX_DESC         PPE_SB_RAM_BLOCK2
+#define VRX218_RX_DESC         PPE_SB_RAM_BLOCK2 + 0x800
+#else
+#define REMOTE_TX1_DATA_LOC    VRX218_PDRAM_BASE
+#define REMOTE_RX1_DATA_LOC    VRX218_PDRAM_BASE + 0x8000
+#define VRX218_TX_DESC         VRX218_PDRAM_BASE + 0x10000
+#define VRX218_RX_DESC         VRX218_PDRAM_BASE + 0x11000
+#endif
+
+#define VRX218_CDMA_OFFSET                0x00104100
+#define CDMA_CLC(__membase)                   ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0000))
+#define CDMA_ID(__membase)                    ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0008))
+#define CDMA_CTRL(__membase)                  ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0010))
+
+#define CDMA_PS(__membase)                    ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0040))
+#define CDMA_PCTRL(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0044))
+#define CDMA_IRNEN(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x00F4))
+#define CDMA_IRNCR(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x00F8))
+#define CDMA_IRNICR(__membase)                ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x00FC))
+
+#define CDMA_CS(__membase)                    ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0018))
+#define CDMA_CCTRL(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x001C))
+#define CDMA_CDBA(__membase)                  ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0020))
+#define CDMA_CGBL(__membase)                  ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0030))
+#define CDMA_CDPTNRD(__membase)               ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0034))
+#define CDMA_CDPTNRD1(__membase)              ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0038))
+#define CDMA_CIE(__membase)                   ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x002C))
+#define CDMA_CIS(__membase)                   ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0028))
+#define CDMA_CDLEN(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0024))
+#define CDMA_CPOLL(__membase)                 ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0014))
+#define CDMA_CPDCNT(__membase)                ((volatile u32*)((__membase) + VRX218_CDMA_OFFSET + 0x0080))
+
+#define CDMA_MEMCOPY_PORT         0
+
+#define CDMA_MEMCOPY_RX_CHAN      0
+#define CDMA_MEMCOPY_TX_CHAN      1
+
+
+/** End of packet interrupt */
+#define DMA_CIS_EOP  	 				0x00000002	
+/** Descriptor Under-Run Interrupt  */
+#define DMA_CIS_DUR 					0x00000004	
+/** Descriptor Complete Interrupt  */
+#define DMA_CIS_DESCPT 					0x00000008	
+/** Channel Off Interrupt  */
+#define DMA_CIS_CHOFF   				0x00000010	
+/** SAI Read Error Interrupt */
+#define DMA_CIS_RDERR 					0x00000020	
+/** all interrupts */
+#define DMA_CIS_ALL     				( DMA_CIS_EOP		\
+										| DMA_CIS_DUR 		\
+										| DMA_CIS_DESCPT 	\
+										| DMA_CIS_CHOFF 	\
+										| DMA_CIS_RDERR	)
+
+/** End of packet interrupt enable */
+#define DMA_CIE_EOP 	 	 			0x00000002	
+/** Descriptor Under-Run Interrupt enable  */
+#define DMA_CIE_DUR                     0x00000004	
+/** Descriptor Complete Interrupt  enable*/
+#define DMA_CIE_DESCPT 					0x00000008
+/** Channel Off Interrupt enable */
+#define DMA_CIE_CHOFF   				0x00000010	
+/** SAI Read Error Interrupt enable*/
+#define DMA_CIE_RDERR 					0x00000020
+
+
+#define DMA_CIE_ALL                     (DMA_CIE_EOP 		\
+										| DMA_CIE_DUR 		\
+										| DMA_CIE_DESCPT 	\
+										| DMA_CIE_CHOFF		\
+										| DMA_CIE_RDERR	)
+
+/** default enabled interrupts */
+#define DMA_CIE_DEFAULT                     ( DMA_CIE_DESCPT    \
+                                            | DMA_CIE_EOP )
+/** disable all interrupts */
+#define DMA_CIE_DISABLE_ALL                 0 
+
+typedef struct
+{
+    union {
+        struct {
+            volatile u32 OWN                 :1;
+            volatile u32 C                   :1;
+            volatile u32 Sop                 :1;
+            volatile u32 Eop                 :1;
+            volatile u32 reserved            :3;
+            volatile u32 Byteoffset          :2;
+            volatile u32 rx_sideband         :4;
+            volatile u32 reserve             :3;
+            volatile u32 DataLen             :16;
+        }field;
+
+        volatile u32 word;
+    }status;
+
+    volatile u32 DataPtr;
+} cdma_rx_descriptor_t;
+typedef struct
+{
+    union {
+        struct {
+            volatile u32 OWN                 :1;
+            volatile u32 C                   :1;
+            volatile u32 Sop                 :1;
+            volatile u32 Eop                 :1;
+            volatile u32 Byteoffset          :5;
+            volatile u32 reserved            :7;
+            volatile u32 DataLen             :16;
+        }field;
+
+        volatile u32 word;
+    }status;
+
+    volatile u32 DataPtr;
+} cdma_tx_descriptor_t;
+
+enum {
+    SOC_TO_EP = 0,
+    EP_TO_SOC,
+};
+
+/* ICU */
+#define VRX218_ICU_OFFSET 0x00000000
+
+#define ICU_IM_SR(__membase)    ((volatile u32*)((__membase) + VRX218_ICU_OFFSET + 0x0040))
+#define ICU_IM_ER(__membase)    ((volatile u32*)((__membase) + VRX218_ICU_OFFSET + 0x0044))
+#define ICU_IM_OSR(__membase)   ((volatile u32*)((__membase) + VRX218_ICU_OFFSET + 0x0048))
+
+
+#define PPE2HOST_INT_0      0
+#define PPE2HOST_INT_1      1
+#define DSL_DYING_GASP      3
+
+#define DSL_MEI_IRQ         8
+#define EDMA_INT            9
+#define FPI_BCU_INT         12
+#define ARC_LED0            13
+#define ARC_LED1            14
+#define CDMA_CH0            16
+#define CDMA_CH1            17
+#define CDMA_CH2            18
+#define CDMA_CH3            19
+#define CDMA_CH4            20
+#define CDMA_CH5            21
+#define CDMA_CH6            22
+#define CDMA_CH7            23
+
+#define VRX218_CGU_OFFSET 0x00003000
+
+#define PMU_PWDCR(__membase)    ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x011C))
+#define PMU_SR(__membase)       ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0120))
+#define CGU_CLKFSR(__membase)   ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0010))
+#define CGU_CLKGSR(__membase)   ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0014))
+#define CGU_CLKGCR0(__membase)  ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0018))
+#define CGU_CLKGCR1(__membase)  ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x001C))
+#define CGU_IF_CLK(__membase)   ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0024))
+#define CGU_PLL_CFG(__membase)  ((volatile u32*)((__membase) + VRX218_CGU_OFFSET + 0x0060))
+
+#define CGU_DMA_CLK_EN      0x00000004
+
+#define VRX218_RCU_OFFSET 0x00002000
+
+#define RCU_RST_REQ(__membase)    ((volatile u32*)((__membase) + VRX218_RCU_OFFSET + 0x0010))
+#define RCU_RST_STAT(__membase)   ((volatile u32*)((__membase) + VRX218_RCU_OFFSET + 0x0014))
+
+#define RCU_RST_REQ_DMA          (1 << 9)
+
+#define RCU_AHB_ENDIAN(__membase) ((volatile u32*)((__membase) + VRX218_RCU_OFFSET + 0x004C))
+
+/* Endian control bit for enable or pin strapping */
+#define VRX218_XBAR_AHB_PCIEM_EN   0x00010000
+#define VRX218_XBAR_AHBM_PCIE_EN   0x00020000
+#define VRX218_XBAR_AHBS_DSL_EN    0x00040000
+#define VRX218_XBAR_AHBS_PCIE_EN   0x00080000
+#define VRX218_XBAR_AHB_PCIES_EN   0x00100000
+#define VRX218_XBAR_AHB_DBI_EN     0x00200000
+
+#define VRX218_XBAR_AHB_PCI_EN_ALL (VRX218_XBAR_AHB_PCIEM_EN | VRX218_XBAR_AHBM_PCIE_EN | \
+                                    VRX218_XBAR_AHBS_PCIE_EN |  VRX218_XBAR_AHB_PCIES_EN | \
+                                    VRX218_XBAR_AHB_DBI_EN | VRX218_XBAR_AHBS_DSL_EN)
+
+#define VRX218_XBAR_AHB_PCIEM   0x00000001
+#define VRX218_XBAR_AHBM_PCIE   0x00000002
+#define VRX218_XBAR_AHBS_DSL    0x00000004
+#define VRX218_XBAR_AHBS_PCIE   0x00000008
+#define VRX218_XBAR_AHB_PCIES   0x00000010
+#define VRX218_XBAR_AHB_DBI     0x00000020
+
+enum {
+    PPE_TEST = 0,
+    CDMA_TEST,
+};
+
+#endif /* IFXMIPS_PCIE_EP_VRX320_TEST_H */
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/ltq_vrx320.c
@@ -0,0 +1,657 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2011~2013 Lei Chuanhua <chuanhua.lei@lantiq.com>
+ */
+/*!
+  \defgroup VRX320_INTERNAL Internal functions
+  \ingroup VRX320
+  \brief IFX PCIe EP internal driver functions
+*/
+
+/*!
+  \defgroup VRX320_OS OS APIs
+  \ingroup VRX320
+  \brief IFX PCIe EP OS APIs for driver interface
+*/
+
+/*!
+   \file ltqmips_pcie_ep_vrx320.c
+   \ingroup VRX320
+   \brief SmartPHY PCIe EP address mapping driver source file
+*/
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/atomic.h>
+#include <linux/uaccess.h>
+#include <linux/io.h>
+#include <linux/pci.h>
+#include <linux/pci_regs.h>
+#include <linux/slab.h>
+#include <linux/platform_device.h>
+
+#include "lantiq_pcie.h"
+#include "ltq_vrx320.h"
+#include "ltq_wrapper.h"
+
+#define ltq_vrx320_r32    ltq_r32
+#define ltq_vrx320_w32    ltq_w32
+#define MS(_v, _f)  (((_v) & (_f)) >> _f##_S)
+#define SM(_v, _f)  (((_v) << _f##_S) & (_f))
+
+#define LTQ_EP_DBG
+
+#define VRX320_DRV_VERSION "2.0.0 "
+const char vrx320_driver_version[] = VRX320_DRV_VERSION;
+
+static struct pcie_ep_info g_pcie_ep_info;
+static const char ltq_pcie_driver_name[] = "ltq_pcie";
+static DEFINE_SPINLOCK(pcie_ep_lock);
+
+int ltq_pcie_ep_dev_num_get(int *dev_num)
+{
+	if ((g_pcie_ep_info.dev_num <= 0)
+		|| (g_pcie_ep_info.dev_num > IFX_PCIE_EP_MAX_NUM)) {
+		return -EIO;
+	}
+
+	*dev_num = g_pcie_ep_info.dev_num;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ltq_pcie_ep_dev_num_get);
+
+int ltq_pcie_ep_dev_info_req(int dev_idx, ltq_pcie_ep_int_module_t module,
+			ltq_pcie_ep_dev_t *dev)
+{
+	int i;
+
+	if ((dev_idx < 0) || (dev_idx >= IFX_PCIE_EP_MAX_NUM)) {
+		pr_err("%s invalid device index %d\n",
+			__func__, dev_idx);
+		return -EIO;
+	}
+
+	if (atomic_read(&g_pcie_ep_info.pcie_ep[dev_idx].refcnt) >=
+		PCIE_EP_MAX_REFCNT) {
+		pr_err("%s mismatch request/release module usage\n",
+			__func__);
+		return -EIO;
+	}
+
+	switch (module) {
+	case IFX_PCIE_EP_INT_PPE:
+		dev->irq = g_pcie_ep_info.pcie_ep[dev_idx].irq_base;
+		break;
+
+	case IFX_PCIE_EP_INT_MEI:
+		dev->irq = g_pcie_ep_info.pcie_ep[dev_idx].irq_base + 1;
+		/* XXX, Hardcode workaround for PCIe switch bonding for RC0 */
+		if (dev->irq == 158)
+			dev->irq = 30;
+		else if (dev->irq == 166)
+			dev->irq = 38;
+
+		break;
+
+	case IFX_PCIE_EP_INT_DYING_GASP:
+	case IFX_PCIE_EP_INT_EDMA:
+	case IFX_PCIE_EP_INT_FPI_BCU:
+	case IFX_PCIE_EP_INT_ARC_LED0:
+	case IFX_PCIE_EP_INT_ARC_LED1:
+		dev->irq = g_pcie_ep_info.pcie_ep[dev_idx].irq_base + 2;
+		break;
+
+	case IFX_PCIE_EP_INT_DMA:
+		dev->irq =
+			g_pcie_ep_info.pcie_ep[dev_idx].irq_base + 3;
+		if (dev->irq == 158)
+			dev->irq = 30;
+		else if (dev->irq == 166)
+			dev->irq = 38;
+
+		break;
+
+	default:
+		dev->irq = g_pcie_ep_info.pcie_ep[dev_idx].irq_base;
+		break;
+	}
+
+	dev->membase = g_pcie_ep_info.pcie_ep[dev_idx].membase;
+	dev->phy_membase = g_pcie_ep_info.pcie_ep[dev_idx].phy_membase;
+	dev->peer_num = g_pcie_ep_info.pcie_ep[dev_idx].peer_num;
+	for (i = 0; i < dev->peer_num; i++) {
+		dev->peer_membase[i] =
+			g_pcie_ep_info.pcie_ep[dev_idx].peer_membase[i];
+		dev->peer_phy_membase[i] =
+			g_pcie_ep_info.pcie_ep[dev_idx].peer_phy_membase[i];
+	}
+	atomic_inc(&g_pcie_ep_info.pcie_ep[dev_idx].refcnt);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ltq_pcie_ep_dev_info_req);
+
+int ltq_pcie_ep_dev_info_release(int dev_idx)
+{
+	if ((dev_idx < 0) || (dev_idx >= IFX_PCIE_EP_MAX_NUM)) {
+		pr_err("%s invalid device index %d\n",
+			__func__, dev_idx);
+		return -EIO;
+	}
+
+	if (atomic_read(&g_pcie_ep_info.pcie_ep[dev_idx].refcnt) <= 0) {
+		pr_err("%s mismatch request/release module usage\n",
+			__func__);
+		return -EIO;
+	}
+	atomic_dec(&g_pcie_ep_info.pcie_ep[dev_idx].refcnt);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(ltq_pcie_ep_dev_info_release);
+
+static DEFINE_PCI_DEVICE_TABLE(ltq_pcie_id_table) = {
+	{0x1bef, 0x0020, PCI_ANY_ID, PCI_ANY_ID}, /* SmartPHY */
+	{0},
+};
+
+/**
+ * \fn  static int pci_msi_max_vector_get(struct pci_dev *dev, int *nvec)
+ *
+ * \brief  This function tries to get device's MSI interrupt vector number
+ *
+ * \param  dev      Device to operate
+ * \param  nvec     Numer of interrupts to get
+ * \return 0        on success
+ * \return -EINVAL  The device doesn't support MSI capability
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_INTERNAL
+ */
+static int pci_msi_max_vector_get(struct pci_dev *dev, int *nvec)
+{
+	int pos, maxvec;
+	u16 msgctl;
+
+	pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
+	if (!pos)
+		return -EINVAL;
+
+	pci_read_config_word(dev, pos + PCI_MSI_FLAGS, &msgctl);
+	maxvec = 1 << ((msgctl & PCI_MSI_FLAGS_QMASK) >> 1);
+	*nvec = maxvec;
+	return 0;
+}
+
+/**
+ * \fn  static int pci_msi_max_vector_set(struct pci_dev *dev, int nvec)
+ *
+ * \brief  This function tries to set device's MSI interrupt vector number
+ *
+ * \param  dev      Device to operate
+ * \param  nvec     Numer of interrupts to set
+ * \return 0        on success
+ * \return -EINVAL  The device doesn't support MSI capability or invalid
+ *                  interrupt number
+ *
+ * \remark smartPHY only supports 1 or 2 or 4 interrupts depend on other
+ *         module usage
+ * \ingroup IFX_PCIE_EP_VRX320_INTERNAL
+ */
+static int pci_msi_max_vector_set(struct pci_dev *dev, int nvec)
+{
+	int pos;
+	u16 msgctl;
+
+	if ((nvec != 1) && (nvec != 2) && (nvec != 4))
+		return -EINVAL;
+
+	pos = pci_find_capability(dev, PCI_CAP_ID_MSI);
+	if (!pos)
+		return -EINVAL;
+
+	pci_read_config_word(dev, pos + PCI_MSI_FLAGS, &msgctl);
+	msgctl &= ~PCI_MSI_FLAGS_QSIZE;
+	msgctl |= (nvec >> 1) << 4;
+	pci_write_config_word(dev, pos + PCI_MSI_FLAGS, msgctl);
+	pci_read_config_word(dev, pos + PCI_MSI_FLAGS, &msgctl);
+	/* ICU control if necessary */
+	return 0;
+}
+
+#ifdef LTQ_EP_DBG
+static void ltq_pcie_iatu_dump(struct pci_dev *pdev, int outbound)
+{
+	u32 val;
+
+	switch (outbound) {
+	case 0:
+		/* Inbound iATU0 */
+		pci_read_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, &val);
+		val &= ~PCIE_PL_IATU_REGION_IDX;
+		/* Inbound, region0 */
+		val |= PCIE_PL_IATU_REGION_INBOUND |
+			SM(PCIE_PL_IATU_REGION0, PCIE_PL_IATU_REGION_IDX);
+		pci_write_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, val);
+		break;
+	case 1:
+	default:
+		pci_read_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, &val);
+		val &= ~PCIE_PL_IATU_REGION_IDX;
+		/* Outbound, region1 */
+		val &= ~PCIE_PL_IATU_REGION_INBOUND;
+		val |= SM(PCIE_PL_IATU_REGION0, PCIE_PL_IATU_REGION_IDX);
+		pci_write_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, val);
+		break;
+	}
+	pr_info("iATU %s\n", outbound ? "Outbound" : "Inbound");
+	pci_read_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, &val);
+	pr_info("PCIE_PL_IATU_VIEWPORT: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_LOWER_BASE_ADDR, &val);
+	pr_info("PCIE_PL_IATU_REGION_LOWER_BASE_ADDR: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_UPPER_BASE_ADDR, &val);
+	pr_info("PCIE_PL_IATU_REGION_UPPER_BASE_ADDR: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_LIMIT, &val);
+	pr_info("PCIE_PL_IATU_REGION_LIMIT: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_LOWER_TARGET_ADDR,
+			&val);
+	pr_info("PCIE_PL_IATU_REGION_LOWER_TARGET_ADDR: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_UPPER_TARGET_ADDR,
+			&val);
+	pr_info("PCIE_PL_IATU_REGION_UPPER_TARGET_ADDR: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL1, &val);
+	pr_info("PCIE_PL_IATU_REGION_CTRL1: %08x\n", val);
+	pci_read_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL2, &val);
+	pr_info("PCIE_PL_IATU_REGION_CTRL2: %08x\n", val);
+}
+#endif /* LTQ_EP_DBG */
+
+/**
+ * \fn  static void  ltq_pcie_iatu_setup(struct pci_dev *pdev)
+ *
+ * \brief  This function configures smartPHY PCIe EP inbound address
+ *         translation iATU0 and Outbound address translation <iATU1>.
+ *         Detailed information, please refer to related design
+ *         documentation.
+ *
+ * \param  dev      PCI device to configure
+ * \return none
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_INTERNAL
+ */
+static void ltq_pcie_iatu_setup(struct pci_dev *pdev)
+{
+	u32 val;
+
+	/* Inbound iATU0 */
+	pci_read_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, &val);
+	val &= ~PCIE_PL_IATU_REGION_IDX;
+	/* Inbound, region0 */
+	val |= PCIE_PL_IATU_REGION_INBOUND | SM(PCIE_PL_IATU_REGION0,
+		PCIE_PL_IATU_REGION_IDX);
+	pci_write_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, val);
+
+	/* BAR match used, there is no need to configure
+	 * base and limit register
+	 */
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_LOWER_TARGET_ADDR,
+		(u32) PCIE_EP_INBOUND_INTERNAL_BASE);
+
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_UPPER_TARGET_ADDR, 0);
+
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL1, 0);
+	/* Inbound BAR match, BAR0 used only */
+	val = PCIE_PL_IATU_REGION_MATCH_EN | PCIE_PL_IATU_REGION_EN |
+		SM(PCIE_PL_IATU_REGION_BAR0, PCIE_PL_IATU_REGION_BAR);
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL2, val);
+
+	/* Outbound iATU1 */
+	pci_read_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, &val);
+	val &= ~PCIE_PL_IATU_REGION_IDX;
+	/* Outbound, region0 */
+	val &= ~PCIE_PL_IATU_REGION_INBOUND;
+	val |= SM(PCIE_PL_IATU_REGION0, PCIE_PL_IATU_REGION_IDX);
+	pci_write_config_dword(pdev, PCIE_PL_IATU_VIEWPORT, val);
+
+	/* 32 bit only, base address  */
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_LOWER_BASE_ADDR,
+		(u32) PCIE_EP_OUTBOUND_INTERNAL_BASE);
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_UPPER_BASE_ADDR,
+		0);
+
+	/* Region limit from phymem to phymem + memsize -1 */
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_LIMIT,
+		(u32) PCIE_EP_OUTBOUND_INTERNAL_BASE +
+		PCIE_EP_OUTBOUND_MEMSIZE - 1);
+
+	/* Mapped to 0x00000000 ~ 0x7FFFFFFF, total 2GB */
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_LOWER_TARGET_ADDR, 0);
+
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_UPPER_TARGET_ADDR, 0);
+
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL1, 0);
+	/* Outbound, address match */
+	val = PCIE_PL_IATU_REGION_EN;
+	pci_write_config_dword(pdev, PCIE_PL_IATU_REGION_CTRL2, val);
+
+#ifdef LTQ_EP_DBG
+	ltq_pcie_iatu_dump(pdev, 0); /* Inbound */
+	ltq_pcie_iatu_dump(pdev, 1); /* Outbound */
+#endif /* LTQ_EP_DBG */
+}
+
+/**
+ * \fn  static int ltq_pcie_probe(struct pci_dev *pdev,
+ *	const struct pci_device_id *id)
+ *
+ * \brief This function initializes an adapter identified by
+ *	  a pci_dev structure. The OS initialization, configuring
+ *	  of the adapter private structure.
+ *
+ * \param  pdev     PCI device information struct
+ * \param  id       entry in ltq_pcie_id_table
+ * \return 0        OK
+ * \return -ENODEV  Failed to initialize an adapter identified by pci_dev
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_OS
+ */
+static int
+ltq_pcie_probe(struct pci_dev *pdev, const struct pci_device_id *id)
+{
+	int i;
+	int j;
+	int k;
+	unsigned long phymem;
+	void __iomem *mem;
+	size_t memsize;
+	static int cards_found;
+	int nvec, err;
+	struct pcie_ep_adapter *adapter;
+	struct pci_bus *bus;
+	int peer_num;
+	u32 reg;
+
+	bus = pdev->bus;
+
+	err = pci_enable_device(pdev);
+	if (err)
+		return err;
+
+	/* XXX 32-bit addressing only */
+	if (pci_set_dma_mask(pdev, DMA_BIT_MASK(32))) {
+		pr_err("%s: 32-bit DMA not available\n",
+			__func__);
+		err = -ENODEV;
+		goto bad;
+	}
+
+	pci_set_master(pdev);
+
+	/* Physical address */
+	phymem = pci_resource_start(pdev, 0); /* BAR zero */
+	memsize = pci_resource_len(pdev, 0);
+	if (!request_mem_region(phymem, memsize, ltq_pcie_driver_name)) {
+		pr_err("%s: cannot reserve PCI memory region\n",
+			__func__);
+		err = -ENOMEM;
+		goto bad;
+	}
+
+	/* Virtual address */
+	mem = ioremap_nocache(phymem, memsize);
+	if (!mem) {
+		pr_err("%s: cannot remap PCI memory region\n",
+			__func__);
+		err = -ENOMEM;
+		goto bad1;
+	}
+
+	adapter = kmalloc(sizeof(struct pcie_ep_adapter), GFP_KERNEL);
+	if (adapter == NULL) {
+		err = -ENOMEM;
+		goto err_mem;
+	}
+
+	pci_set_drvdata(pdev, adapter);
+
+	err = pci_msi_max_vector_get(pdev, &nvec);
+	if (err) {
+		pr_err("%s: device doesn't support MSI, error code: %d",
+			__func__, err);
+		goto err_msi;
+	}
+
+	/* Overwrite maximum vector number according to
+	 * the specific requirement
+	 */
+	if (nvec > PCIE_EP_DEFAULT_MSI_VECTOR)
+		nvec = PCIE_EP_DEFAULT_MSI_VECTOR;
+
+	pci_msi_max_vector_set(pdev, nvec);
+
+	/* err = pci_enable_msi_block(pdev, nvec); */ /*Puma(x86) native_setup_msi_irqs: Multiple MSI vectors only supported with interrupt remapping */
+	err = pci_enable_msi(pdev); 
+	if (err) {
+		pr_err("%s: Failed to enable MSI interrupts for the device error code: %d\n",
+			__func__, err);
+		goto err_msi;
+	}
+
+	pci_msi_max_vector_set(pdev, nvec);
+
+	/* Enough information to configure address translation */
+	ltq_pcie_iatu_setup(pdev);
+
+	adapter->pdev = pdev;
+	adapter->device_id = pdev->device;
+	adapter->mem = mem;
+	adapter->phy_mem = phymem;
+	adapter->memsize = memsize;
+	adapter->msi_nvec = nvec;
+	adapter->irq_base = pdev->irq;
+	adapter->card_num = cards_found++; /* Logical index */
+	/* EMI control stuff */
+	reg = ltq_vrx320_r32(adapter->mem + PCIE_EP_IF_CLK);
+	reg |= PCIE_EP_IF_CLK_NO_36MHZ_CLKOUT;
+	ltq_vrx320_w32(reg, adapter->mem + PCIE_EP_IF_CLK);
+
+	reg = ltq_vrx320_r32(adapter->mem + PCIE_EP_P0_ALTSEL1);
+	reg &= ~PCIE_EP_P0_ALTSEL1_PIN1_SET;
+	ltq_vrx320_w32(reg, adapter->mem + PCIE_EP_P0_ALTSEL1);
+
+	spin_lock(&pcie_ep_lock);
+	g_pcie_ep_info.dev_num = cards_found; /* Existing cards */
+	atomic_set(&g_pcie_ep_info.pcie_ep[adapter->card_num].refcnt, 0);
+	g_pcie_ep_info.pcie_ep[adapter->card_num].card_idx =
+		adapter->card_num;
+	g_pcie_ep_info.pcie_ep[adapter->card_num].membase = adapter->mem;
+	g_pcie_ep_info.pcie_ep[adapter->card_num].phy_membase =
+		adapter->phy_mem;
+	g_pcie_ep_info.pcie_ep[adapter->card_num].memsize =
+		adapter->memsize;
+	g_pcie_ep_info.pcie_ep[adapter->card_num].irq_base =
+		adapter->irq_base;
+	g_pcie_ep_info.pcie_ep[adapter->card_num].irq_num =
+		adapter->msi_nvec;
+
+	/* More cards supported, exchange address information
+	 * For example, suppose three cards dected.
+	 * 0, <1, 2>
+	 * 1, <0, 2>
+	 * 2, <0, 1>
+	 * For four cards detected
+	 * 0, <1, 2, 3>
+	 * 1, <0, 2, 3>
+	 * 2, <0, 1, 3>
+	 * 3, <0, 1, 2>
+	 * and etc
+	 */
+	if (cards_found > 1) {
+		peer_num = cards_found - 1;
+		for (i = 0; i < cards_found; i++) {
+			j = 0;
+			k = 0;
+			g_pcie_ep_info.pcie_ep[i].peer_num = peer_num;
+			do {
+				if (j == i) {
+					j++;
+					continue;
+				}
+				g_pcie_ep_info.pcie_ep[i].peer_membase[k] =
+					g_pcie_ep_info.pcie_ep[j].membase;
+				g_pcie_ep_info.pcie_ep[i].peer_phy_membase[k] =
+					g_pcie_ep_info.pcie_ep[j].phy_membase;
+				g_pcie_ep_info.pcie_ep[i].peer_memsize[k] =
+					g_pcie_ep_info.pcie_ep[j].memsize;
+				k++;
+				j++;
+			} while ((k < peer_num) && (j < cards_found));
+		}
+	}
+	spin_unlock(&pcie_ep_lock);
+
+/* for device tree create a device there */
+#ifndef CONFIG_OF
+	adapter->mei_dev = platform_device_register_data(&pdev->dev, "mei_cpe",
+							 PLATFORM_DEVID_AUTO,
+							 NULL, 0);
+	if (IS_ERR(adapter->mei_dev)) {
+		dev_err(&pdev->dev, "can not register mei device, err: %li, ignore this\n",
+			PTR_ERR(adapter->mei_dev));
+		err = PTR_ERR(adapter->mei_dev);
+		goto err_msi;
+	}
+#endif
+
+#ifdef LTQ_EP_DBG
+	pr_info("Total cards found %d\n", cards_found);
+	/* Dump detailed debug information */
+	for (i = 0; i < cards_found; i++) {
+		pr_info("card %d attached\n",
+			g_pcie_ep_info.pcie_ep[i].card_idx);
+		pr_info("irq base %d irq numbers %d\n",
+			g_pcie_ep_info.pcie_ep[i].irq_base,
+			g_pcie_ep_info.pcie_ep[i].irq_num);
+		pr_info("its own phy membase  0x%08x virtual membase 0x%p size 0x%08x\n",
+			g_pcie_ep_info.pcie_ep[i].phy_membase,
+			g_pcie_ep_info.pcie_ep[i].membase,
+			g_pcie_ep_info.pcie_ep[i].memsize);
+		if (cards_found > 1) {
+			for (j = 0; j < g_pcie_ep_info.pcie_ep[i].peer_num;
+				j++)
+				pr_info("its peer phy membase 0x%08x virtual membase 0x%p size 0x%08x\n",
+				g_pcie_ep_info.pcie_ep[i].peer_phy_membase[j],
+				g_pcie_ep_info.pcie_ep[i].peer_membase[j],
+				g_pcie_ep_info.pcie_ep[i].peer_memsize[j]);
+		}
+	}
+#endif /* LTQ_EP_DBG */
+	return 0;
+err_msi:
+	kfree(adapter);
+err_mem:
+	iounmap(mem);
+bad1:
+	release_mem_region(phymem, memsize);
+bad:
+	pci_disable_device(pdev);
+	return err;
+}
+
+/**
+ * \fn  static void ltq_pcie_remove(struct pci_dev *pdev)
+ *
+ * \brief  This function is called by the PCI subsystem to alert the driver
+ *         that it should release a PCI device because the driver is going
+ *         to be removed from memory.
+ *
+ * \param  pdev     PCI device information struct
+ * \return none
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_OS
+ */
+static void ltq_pcie_remove(struct pci_dev *pdev)
+{
+	struct pcie_ep_adapter *adapter =
+		(struct pcie_ep_adapter *) pci_get_drvdata(pdev);
+
+#ifndef CONFIG_OF
+	platform_device_unregister(adapter->mei_dev);
+#endif
+
+	if (atomic_read(&g_pcie_ep_info.pcie_ep[adapter->card_num].refcnt)
+		!= 0) {
+		pr_err("%s still being used, can't remove\n",
+			__func__);
+	}
+
+	iounmap(adapter->mem);
+	release_mem_region(adapter->phy_mem, adapter->memsize);
+	pci_disable_msi(pdev);
+	pci_disable_device(pdev);
+	kfree(adapter);
+	adapter = NULL;
+}
+
+MODULE_DEVICE_TABLE(pci, ltq_pcie_id_table);
+
+static struct pci_driver ltq_pcie_driver = {
+	.name = (char *) ltq_pcie_driver_name,
+	.id_table = ltq_pcie_id_table,
+	.probe = ltq_pcie_probe,
+	.remove = ltq_pcie_remove,
+	/* PM not supported */
+	/* AER is controlled by RC */
+};
+
+/**
+ * \fn  static int __init init_ltq_pcie(void)
+ *
+ * \brief  This function registered PCIe EP device driver with OS PCI subsystem
+ *         and initializes PCIe EP address mapping driver.
+ *
+ * \return 0 on success
+ * \return -ENODEV No related PCIe EP found
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_OS
+ */
+static int __init init_ltq_pcie(void)
+{
+	memset(&g_pcie_ep_info, 0, sizeof(struct pcie_ep_info));
+
+	if (pci_register_driver(&ltq_pcie_driver) < 0) {
+		pr_err("%s: No devices found, driver not installed.\n",
+			__func__);
+		return -ENODEV;
+	}
+	pr_info("Lantiq VRX320 Version %s", vrx320_driver_version);
+	return 0;
+}
+
+module_init(init_ltq_pcie);
+
+/**
+ * \fn  static void __exit exit_ltq_pcie(void)
+ *
+ * \brief  This function unregister PCIe EP device driver with OS PCI subsystem
+ *
+ * \return none
+ *
+ * \ingroup IFX_PCIE_EP_VRX320_OS
+ */
+static void __exit exit_ltq_pcie(void)
+{
+	pci_unregister_driver(&ltq_pcie_driver);
+
+	pr_info("%s: %s driver unloaded\n", __func__,
+		ltq_pcie_driver_name);
+}
+
+module_exit(exit_ltq_pcie);
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Chuanhua.Lei@lantiq.com");
+MODULE_SUPPORTED_DEVICE("Lantiq SmartPHY PCIe EP");
+MODULE_DESCRIPTION("Lantiq SmartPHY PCIe EP address mapping driver");
+
+
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/ltq_vrx320.h
@@ -0,0 +1,157 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2011~2013 Lei Chuanhua <chuanhua.lei@lantiq.com>
+ */
+ /*!
+ \file ltq_vrx320.h
+ \ingroup VRX320
+ \brief header file for SmartPHY PCIe EP address mapping driver internal
+  definition
+*/
+#ifndef LTQ_VRX320_H
+#define LTQ_VRX320_H
+
+#include <linux/types.h>
+#include <linux/pci.h>
+
+#include "lantiq_pcie.h"
+
+#define IFX_PCIE_EP_MAX_NUM                    (IFX_PCIE_EP_MAX_PEER + 1)
+
+/* Maximum 4, if PCIe switch attached, 2 is used. 2 is also default one */
+#ifdef CONFIG_LANITQ_VRX320_PCIE_SWITCH_DSL_BONDING
+#define PCIE_EP_DEFAULT_MSI_VECTOR         2
+#else
+#define PCIE_EP_DEFAULT_MSI_VECTOR         4
+#endif /*  CONFIG_LANITQ_VRX320_PCIE_SWITCH_DSL_BONDING */
+
+#define PCIE_EP_MAX_REFCNT                 IFX_PCIE_EP_INT_MODULE_MAX
+
+/* iATU specific register offset definition */
+
+/* View Point Register */
+#define PCIE_PL_IATU_VIEWPORT                  0x900
+
+#define PCIE_PL_IATU_REGION_IDX                0x0000000F
+#define PCIE_PL_IATU_REGION_IDX_S              0
+
+/* Inbound and outbound has seperate regions,
+ * each one has 8 regions from index 0
+ */
+enum {
+	PCIE_PL_IATU_REGION0 = 0,
+	PCIE_PL_IATU_REGION1,
+	PCIE_PL_IATU_REGION2,
+	PCIE_PL_IATU_REGION3,
+	PCIE_PL_IATU_REGION4,
+	PCIE_PL_IATU_REGION5,
+	PCIE_PL_IATU_REGION6,
+	PCIE_PL_IATU_REGION7,
+};
+#define PCIE_PL_IATU_REGION_INBOUND            0x80000000
+
+/* Region control registe for all kinds of types */
+#define PCIE_PL_IATU_REGION_CTRL1              0x904
+
+#define PCIE_PL_IATU_REGION_CTRL2              0x908
+#define PCIE_PL_IATU_REGION_BAR                0x00000700
+#define PCIE_PL_IATU_REGION_BAR_S              8
+
+enum {
+	PCIE_PL_IATU_REGION_BAR0 = 0,
+	PCIE_PL_IATU_REGION_BAR1,
+	PCIE_PL_IATU_REGION_BAR2,
+	PCIE_PL_IATU_REGION_BAR3,
+	PCIE_PL_IATU_REGION_BAR4,
+	PCIE_PL_IATU_REGION_BAR5,
+};
+#define PCIE_PL_IATU_REGION_MATCH_EN           0x40000000
+#define PCIE_PL_IATU_REGION_EN                 0x80000000
+
+#define PCIE_PL_IATU_REGION_LOWER_BASE_ADDR    0x90C
+#define PCIE_PL_IATU_REGION_UPPER_BASE_ADDR    0x910
+#define PCIE_PL_IATU_REGION_LIMIT              0x914
+#define PCIE_PL_IATU_REGION_LOWER_TARGET_ADDR  0x918
+#define PCIE_PL_IATU_REGION_UPPER_TARGET_ADDR  0x91C
+
+/* Target & Base address definition for Inbound/Outbound */
+
+/* Inbound address translation for iATU0 */
+#define PCIE_EP_INBOUND_INTERNAL_BASE          0x1E000000
+#define PCIE_EP_OUTBOUND_INTERNAL_BASE         0x20000000
+#define PCIE_EP_OUTBOUND_MEMSIZE               0x80000000
+
+/* EMI control stuff */
+/* 36MHz clockout */
+#define PCIE_EP_IF_CLK                         0x00003024
+#define PCIE_EP_IF_CLK_NO_36MHZ_CLKOUT         0x00000400
+
+/* GPIO 1 Alternate1 Set/Clear */
+#define PCIE_EP_P0_ALTSEL1                     0x00102B20
+#define PCIE_EP_P0_ALTSEL1_PIN1_SET            0x00000002
+
+/* Structure used to extract attached EP detailed information for
+ * PPE/DSL_MEI driver/Bonding
+ */
+struct pcie_ep_dev_priv {
+	u32 card_idx; /*!< EP logical index, the first found one will be 0
+			regardless of RC physical index
+			*/
+	u32 irq_base; /*!< The first MSI interrupt number */
+	u32 irq_num; /*!< How many MSI interrupt supported */
+	u8 __iomem *membase;  /*!< The EP inbound memory base address
+				derived from BAR0, SoC virtual address
+				for PPE/DSL_MEI driver
+				*/
+	u32 phy_membase; /*!< The EP inbound memory base address
+				derived from BAR0, physical address for
+				PPE FW
+				*/
+	size_t memsize; /*!< The EP inbound memory window size */
+	u32 peer_num;  /*!< Bonding peer number available */
+	/*!< The bonding peer EP inbound memory base address derived from
+	 * its BAR0, SoC virtual address for PPE/DSL_MEI driver
+	 */
+
+	u8 __iomem *peer_membase[IFX_PCIE_EP_MAX_PEER];
+
+	/*!< The bonding peer EP inbound memory base address derived from
+	 * its BAR0, physical address for PPE FW
+	 */
+	u32 peer_phy_membase[IFX_PCIE_EP_MAX_PEER];
+
+	/*!< The bonding peer inbound memory window size */
+	size_t peer_memsize[IFX_PCIE_EP_MAX_PEER];
+	atomic_t refcnt; /*!< The EP mapping driver referenced times
+				by other modules
+				*/
+};
+
+struct pcie_ep_info {
+	int dev_num;
+	struct pcie_ep_dev_priv pcie_ep[IFX_PCIE_EP_MAX_NUM];
+};
+
+/* Card specific private data structure */
+struct pcie_ep_adapter {
+	/* OS defined structs */
+	struct pci_dev *pdev;
+	unsigned long phy_mem; /* Physical address */
+	u8 __iomem *mem;       /* Virtual address */
+	size_t memsize;
+	u32 card_num;          /* EP card index */
+	u32 rc_phy_idx;        /* Attached which RC */
+
+	/* PCI config space info */
+	u16 device_id;
+	u16 irq_base;          /* irq base for multiple MSI */
+	u32 msi_nvec;          /* MSI vector number supported */
+	struct platform_device *mei_dev; /* the mei driver */
+};
+
+#endif /* LTQ_VRX320_H */
+
+
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/ltq_wrapper.h
@@ -0,0 +1,28 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2010 John Crispin <blogic@openwrt.org>
+ *  Copyright (C) 2013 Lei Chuanhua <chuanhua.lei@lantiq.com>
+ */
+#ifndef _LTQ_WRAPPER_H__
+#define _LTQ_WRAPPER_H__
+
+#include <linux/irq.h>
+#include <linux/device.h>
+#include <linux/clk.h>
+
+/* generic reg access functions */
+#define ltq_r32(reg)            __raw_readl(reg)
+#define ltq_w32(val, reg)       __raw_writel(val, reg)
+
+#define ltq_r16(reg)            __raw_readw(reg)
+#define ltq_w16(val, reg)       __raw_writew(val, reg)
+
+#define ltq_w32_mask(clear, set, reg)   \
+        ltq_w32((ltq_r32(reg) & ~(clear)) | (set), reg)
+#define ltq_r8(reg)             __raw_readb(reg)
+#define ltq_w8(val, reg)        __raw_writeb(val, reg)
+
+#endif
--- /dev/null
+++ b/drivers/net/ethernet/lantiq/pcie-lantiq.h
@@ -0,0 +1,1378 @@
+/*
+ *  This program is free software; you can redistribute it and/or modify it
+ *  under the terms of the GNU General Public License version 2 as published
+ *  by the Free Software Foundation.
+ *
+ *  Copyright (C) 2009~2013 Lei Chuanhua <chuanhua.lei@lantiq.com>
+ */
+#ifndef PCIE_LANTIQ_H
+#define PCIE_LANTIQ_H
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/of.h>
+
+#include <linux/pci.h>
+#include <linux/interrupt.h>
+#include <linux/spinlock.h>
+
+//#include <lantiq.h>
+#include <linux/gpio.h>
+//#include <lantiq_soc.h>
+
+
+/*!
+ \defgroup PCIE  PCI Express bus driver module
+ \brief  PCI Express IP module support VRX200/ARX300/HN
+*/
+
+/*!
+ \defgroup PCIE_OS OS APIs
+ \ingroup PCIE
+ \brief PCIe bus driver OS interface functions
+*/
+
+/*!
+ \file pcie-lantiq.h
+ \ingroup PCIE
+ \brief header file for PCIe module common header file
+*/
+
+#define MS(_v, _f)  (((_v) & (_f)) >> _f##_S)
+#define SM(_v, _f)  (((_v) << _f##_S) & (_f))
+
+
+#define PCIE_MSG_MSI		0x00000001
+#define PCIE_MSG_ISR		0x00000002
+#define PCIE_MSG_FIXUP		0x00000004
+#define PCIE_MSG_READ_CFG	0x00000008
+#define PCIE_MSG_WRITE_CFG	0x00000010
+#define PCIE_MSG_CFG		(PCIE_MSG_READ_CFG | PCIE_MSG_WRITE_CFG)
+#define PCIE_MSG_REG		0x00000020
+#define PCIE_MSG_INIT		0x00000040
+#define PCIE_MSG_ERR		0x00000080
+#define PCIE_MSG_PHY		0x00000100
+#define PCIE_MSG_ANY		0x000001ff
+
+/* Debug option, more will be coming */
+
+/* #define LTQ_PCIE_DBG */
+
+/* Reuse kernel stuff, but we need to differentiate baseline
+ * error reporting and AEE */
+#ifdef CONFIG_PCIEAER
+#define LTQ_PCIE_BASIC_ERROR_INT
+#endif /* CONFIG_PCIEAER */
+
+/* XXX, should be only enabled after LTQ_PCIE_BASIC_ERROR_INT */
+#define LTQ_PCIE_AER_REPORT
+
+/* Always report fatal error */
+#define PCIE_KASSERT(exp, msg) do {	\
+	if (unlikely(!(exp))) {	\
+		printk msg;		\
+		BUG();			\
+	}				\
+} while (0)
+
+/* Port number definition */
+enum {
+	LTQ_PCIE_PORT0 = 0,
+	LTQ_PCIE_PORT1,
+	LTQ_PCIE_PORT2,
+};
+
+#if defined(LTQ_PCIE_DBG)
+#define pcie_dbg(_m, _fmt, args...) do {	\
+	if (g_pcie_debug_flag & (_m))		\
+		pcie_debug((_fmt), ##args);	\
+} while (0)
+
+#else
+#define pcie_dbg(_m, _fmt, args...)	do {} while (0)
+#endif
+
+#define MSI_IRQ_NUM    16
+
+enum {
+	PCIE_MSI_IDX0 = 0,
+	PCIE_MSI_IDX1,
+	PCIE_MSI_IDX2,
+	PCIE_MSI_IDX3,
+};
+
+/* Interrupt related stuff */
+#define PCIE_LEGACY_DISABLE		0
+#define PCIE_LEGACY_INTA		1
+#define PCIE_LEGACY_INTB		2
+#define PCIE_LEGACY_INTC		3
+#define PCIE_LEGACY_INTD		4
+#define PCIE_LEGACY_INT_MAX		PCIE_LEGACY_INTD
+
+#if 0
+/** Structure used to extract physical Root Complex index number,
+ * it is shared between RC and EP */
+struct ltq_pcie_controller {
+	/*!< PCI controller information used as system specific information */
+	struct pci_controller pcic;
+	spinlock_t lock; /*!< Per controller lock */
+	 /*!< RC specific, per host bus information,
+	  * port 0 -- RC 0, port 1 -- RC1 */
+	const u32 port;
+};
+#endif
+
+/* The structure will store mapping address to support multiple RC */
+struct pcie_addr_map {
+	const u32 cfg_base;
+	const u32 mem_base;
+	const u32 io_base;
+	const u32 mem_phy_base;
+	const u32 mem_phy_end;
+	const u32 io_phy_base;
+	const u32 io_phy_end;
+	const u32 app_logic_base;
+	const u32 rc_addr_base;
+	const u32 phy_base;
+};
+
+struct msi_irq_idx {
+	const int irq;
+	const int idx;
+};
+
+struct ltq_msi_pic {
+	volatile u32 pic_table[MSI_IRQ_NUM];
+	volatile u32 pic_endian; /* 0x40  */
+};
+
+struct msi_irq {
+	struct ltq_msi_pic * const msi_pic_p;
+	const u32 msi_phy_base;
+	const struct msi_irq_idx msi_irq_idx[MSI_IRQ_NUM];
+	spinlock_t msi_lock;
+	/*
+	 * Each bit in msi_free_irq_bitmask represents a MSI interrupt that is
+	 * in use.
+	 */
+	u16 msi_free_irq_bitmask;
+
+	/*
+	 * Each bit in msi_multiple_irq_bitmask tells that the device using
+	 * this bit in msi_free_irq_bitmask is also using the next bit. This
+	 * is used so we can disable all of the MSI interrupts when a device
+	 * uses multiple.
+	 */
+	u16 msi_multiple_irq_bitmask;
+};
+
+struct pcie_ir_irq {
+	const unsigned int irq;
+	const char name[16];
+};
+
+struct pcie_legacy_irq {
+	const u32 irq_bit;
+	const int irq;
+};
+
+struct pcie_irq {
+	struct pcie_ir_irq ir_irq;
+	struct pcie_legacy_irq legacy_irq[PCIE_LEGACY_INT_MAX];
+};
+
+#if 0
+struct ltq_pcie_port {
+	struct pcie_addr_map port_to_addr;
+	struct ltq_pcie_controller controller;
+	struct pcie_irq legacy_irqs;
+	struct msi_irq msi_irqs;
+	int rc_physical_port;
+};
+#endif
+
+
+/* Port number defined in platform specific file */
+
+#define PCIE_CFG_PORT_TO_BASE(X) (g_pcie_port_defs[(X)].port_to_addr.cfg_base)
+
+#define PCIE_MEM_PORT_TO_BASE(X) (g_pcie_port_defs[(X)].port_to_addr.mem_base)
+
+#define PCIE_IO_PORT_TO_BASE(X)  (g_pcie_port_defs[(X)].port_to_addr.io_base)
+
+#define PCIE_MEM_PHY_PORT_TO_BASE(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.mem_phy_base)
+
+#define PCIE_MEM_PHY_PORT_TO_END(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.mem_phy_end)
+
+#define PCIE_IO_PHY_PORT_TO_BASE(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.io_phy_base)
+
+#define PCIE_IO_PHY_PORT_TO_END(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.io_phy_end)
+
+#define PCIE_APP_PORT_TO_BASE(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.app_logic_base)
+
+#define PCIE_RC_PORT_TO_BASE(X)		\
+	(g_pcie_port_defs[(X)].port_to_addr.rc_addr_base)
+
+#define PCIE_PHY_PORT_TO_BASE(X)	\
+	(g_pcie_port_defs[(X)].port_to_addr.phy_base)
+
+/* PCIe Application Logic Register */
+/* RC Core Control Register */
+#define PCIE_RC_CCR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x10)
+
+/* This should be enabled after initializing configuratin registers
+ * Also should check link status retraining bit
+ */
+/* Enable LTSSM to continue link establishment */
+#define PCIE_RC_CCR_LTSSM_ENABLE		0x00000001
+/* RC Core Debug Register */
+#define PCIE_RC_DR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x14)
+
+#define PCIE_RC_DR_DLL_UP			0x00000001
+#define PCIE_RC_DR_CURRENT_POWER_STATE		0x0000000E
+#define PCIE_RC_DR_CURRENT_POWER_STATE_S	1
+#define PCIE_RC_DR_CURRENT_LTSSM_STATE		0x000001F0
+#define PCIE_RC_DR_CURRENT_LTSSM_STATE_S	4
+
+#define PCIE_RC_DR_PM_DEV_STATE			0x00000E00
+#define PCIE_RC_DR_PM_DEV_STATE_S		9
+
+#define PCIE_RC_DR_PM_ENABLED			0x00001000
+#define PCIE_RC_DR_PME_EVENT_ENABLED		0x00002000
+#define PCIE_RC_DR_AUX_POWER_ENABLED		0x00004000
+
+/* Current Power State Definition */
+enum {
+	PCIE_RC_DR_D0 = 0,
+	PCIE_RC_DR_D1, /* Not supported */
+	PCIE_RC_DR_D2, /* Not supported */
+	PCIE_RC_DR_D3,
+	PCIE_RC_DR_UN,
+};
+
+/* PHY Link Status Register */
+#define PCIE_PHY_SR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x18)
+
+#define PCIE_PHY_SR_PHY_LINK_UP		0x00000001
+
+/* Electromechanical Control Register */
+#define PCIE_EM_CR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x1C)
+
+#define PCIE_EM_CR_CARD_IS_PRESENT		0x00000001
+#define PCIE_EM_CR_MRL_OPEN			0x00000002
+#define PCIE_EM_CR_POWER_FAULT_SET		0x00000004
+#define PCIE_EM_CR_MRL_SENSOR_SET		0x00000008
+#define PCIE_EM_CR_PRESENT_DETECT_SET		0x00000010
+#define PCIE_EM_CR_CMD_CPL_INT_SET		0x00000020
+#define PCIE_EM_CR_SYS_INTERLOCK_SET		0x00000040
+#define PCIE_EM_CR_ATTENTION_BUTTON_SET		0x00000080
+
+/* Interrupt Status Register */
+#define PCIE_IR_SR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x20)
+
+#define PCIE_IR_SR_PME_CAUSE_MSI		0x00000002
+#define PCIE_IR_SR_HP_PME_WAKE_GEN		0x00000004
+#define PCIE_IR_SR_HP_MSI			0x00000008
+#define PCIE_IR_SR_AHB_LU_ERR			0x00000030
+#define PCIE_IR_SR_AHB_LU_ERR_S			4
+#define PCIE_IR_SR_INT_MSG_NUM			0x00003E00
+#define PCIE_IR_SR_INT_MSG_NUM_S		9
+#define PCIE_IR_SR_AER_INT_MSG_NUM		0xF8000000
+#define PCIE_IR_SR_AER_INT_MSG_NUM_S		27
+
+/* Message Control Register */
+#define PCIE_MSG_CR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x30)
+
+#define PCIE_MSG_CR_GEN_PME_TURN_OFF_MSG	0x00000001
+#define PCIE_MSG_CR_GEN_UNLOCK_MSG		0x00000002
+
+#define PCIE_VDM_DR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x34)
+
+/* Vendor-Defined Message Requester ID Register */
+#define PCIE_VDM_RID(X)		(PCIE_APP_PORT_TO_BASE(X) + 0x38)
+
+#define PCIE_VDM_RID_VENROR_MSG_REQ_ID		0x0000FFFF
+#define PCIE_VDM_RID_VDMRID_S			0
+
+/* ASPM Control Register */
+#define PCIE_ASPM_CR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x40)
+
+#define PCIE_ASPM_CR_HOT_RST			0x00000001
+#define PCIE_ASPM_CR_REQ_EXIT_L1		0x00000002
+#define PCIE_ASPM_CR_REQ_ENTER_L1		0x00000004
+
+/* Vendor Message DW0 Register */
+#define PCIE_VM_MSG_DW0(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x50)
+
+#define PCIE_VM_MSG_DW0_TYPE		0x0000001F /* Message type */
+#define PCIE_VM_MSG_DW0_TYPE_S		0
+#define PCIE_VM_MSG_DW0_FORMAT		0x00000060 /* Format */
+#define PCIE_VM_MSG_DW0_FORMAT_S	5
+#define PCIE_VM_MSG_DW0_TC		0x00007000 /* Traffic Class */
+#define PCIE_VM_MSG_DW0_TC_S		12
+#define PCIE_VM_MSG_DW0_ATTR		0x000C0000 /* Atrributes */
+#define PCIE_VM_MSG_DW0_ATTR_S		18
+#define PCIE_VM_MSG_DW0_EP_TLP		0x00100000 /* Poisoned TLP */
+#define PCIE_VM_MSG_DW0_TD		0x00200000 /* TLP Digest */
+#define PCIE_VM_MSG_DW0_LEN		0xFFC00000 /* Length */
+#define PCIE_VM_MSG_DW0_LEN_S		22
+
+/* Format Definition */
+enum {
+	PCIE_VM_MSG_FORMAT_00 = 0, /* 3DW Hdr, no data */
+	PCIE_VM_MSG_FORMAT_01, /* 4DW Hdr, no data */
+	PCIE_VM_MSG_FORMAT_10, /* 3DW Hdr, with data */
+	PCIE_VM_MSG_FORMAT_11, /* 4DW Hdr, with data */
+};
+
+/* Traffic Class Definition */
+enum {
+	PCIE_VM_MSG_TC0 = 0,
+	PCIE_VM_MSG_TC1,
+	PCIE_VM_MSG_TC2,
+	PCIE_VM_MSG_TC3,
+	PCIE_VM_MSG_TC4,
+	PCIE_VM_MSG_TC5,
+	PCIE_VM_MSG_TC6,
+	PCIE_VM_MSG_TC7,
+};
+
+/* Attributes Definition */
+enum {
+	PCIE_VM_MSG_ATTR_00 = 0, /* RO and No Snoop cleared */
+	PCIE_VM_MSG_ATTR_01, /* RO cleared , No Snoop set */
+	PCIE_VM_MSG_ATTR_10, /* RO set, No Snoop cleared */
+	PCIE_VM_MSG_ATTR_11, /* RO and No Snoop set */
+};
+
+/* Payload Size Definition */
+#define PCIE_VM_MSG_LEN_MIN		0
+#define PCIE_VM_MSG_LEN_MAX		1024
+
+/* Vendor Message DW1 Register */
+#define PCIE_VM_MSG_DW1(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x54)
+
+#define PCIE_VM_MSG_DW1_FUNC_NUM	0x00000070 /* Function Number */
+#define PCIE_VM_MSG_DW1_FUNC_NUM_S	8
+#define PCIE_VM_MSG_DW1_CODE		0x00FF0000 /* Message Code */
+#define PCIE_VM_MSG_DW1_CODE_S		16
+#define PCIE_VM_MSG_DW1_TAG		0xFF000000 /* Tag */
+#define PCIE_VM_MSG_DW1_TAG_S		24
+
+#define PCIE_VM_MSG_DW2(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x58)
+
+#define PCIE_VM_MSG_DW3(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x5C)
+
+/* Vendor Message Request Register */
+#define PCIE_VM_MSG_REQR(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x60)
+
+#define PCIE_VM_MSG_REQR_REQ		0x00000001
+
+
+/* AHB Slave Side Band Control Register */
+#define PCIE_AHB_SSB(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x70)
+
+#define PCIE_AHB_SSB_REQ_BCM		0x00000001
+#define PCIE_AHB_SSB_REQ_EP		0x00000002
+#define PCIE_AHB_SSB_REQ_TD		0x00000004
+#define PCIE_AHB_SSB_REQ_ATTR		0x00000018
+#define PCIE_AHB_SSB_REQ_ATTR_S		3
+#define PCIE_AHB_SSB_REQ_TC		0x000000E0
+#define PCIE_AHB_SSB_REQ_TC_S		5
+
+/* AHB Master SideBand Ctrl Register */
+#define PCIE_AHB_MSB(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x74)
+
+#define PCIE_AHB_MSB_RESP_ATTR		0x00000003
+#define PCIE_AHB_MSB_RESP_ATTR_S	0
+#define PCIE_AHB_MSB_RESP_BAD_EOT	0x00000004
+#define PCIE_AHB_MSB_RESP_BCM		0x00000008
+#define PCIE_AHB_MSB_RESP_EP		0x00000010
+#define PCIE_AHB_MSB_RESP_TD		0x00000020
+#define PCIE_AHB_MSB_RESP_FUN_NUM	0x000003C0
+#define PCIE_AHB_MSB_RESP_FUN_NUM_S	6
+
+/* AHB Control Register, fixed bus enumeration exception */
+#define PCIE_AHB_CTRL(X)	(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0x78)
+
+#define PCIE_AHB_CTRL_BUS_ERROR_SUPPRESS	0x00000001
+
+/* Interrupt Enalbe Register */
+#define PCIE_IRNEN(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0xF4)
+
+#define PCIE_IRNCR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0xF8)
+
+#define PCIE_IRNICR(X)		(u32 *)(PCIE_APP_PORT_TO_BASE(X) + 0xFC)
+
+/* PCIe interrupt enable/control/capture register definition */
+#define PCIE_IRN_AER_REPORT		0x00000001
+#define PCIE_IRN_AER_MSIX		0x00000002
+#define PCIE_IRN_PME			0x00000004
+#define PCIE_IRN_HOTPLUG		0x00000008
+#define PCIE_IRN_RX_VDM_MSG		0x00000010
+#define PCIE_IRN_RX_CORRECTABLE_ERR_MSG	0x00000020
+#define PCIE_IRN_RX_NON_FATAL_ERR_MSG	0x00000040
+#define PCIE_IRN_RX_FATAL_ERR_MSG	0x00000080
+#define PCIE_IRN_RX_PME_MSG		0x00000100
+#define PCIE_IRN_RX_PME_TURNOFF_ACK	0x00000200
+#define PCIE_IRN_AHB_BR_FATAL_ERR	0x00000400
+#define PCIE_IRN_LINK_AUTO_BW_STATUS	0x00000800
+#define PCIE_IRN_BW_MGT			0x00001000
+#define PCIE_IRN_INTA			0x00002000 /* INTA */
+#define PCIE_IRN_INTB			0x00004000 /* INTB */
+#define PCIE_IRN_INTC			0x00008000 /* INTC */
+#define PCIE_IRN_INTD			0x00010000 /* INTD */
+#define PCIE_IRN_WAKEUP			0x00020000 /* Wake up Interrupt */
+
+#define PCIE_RC_CORE_COMBINED_INT  (PCIE_IRN_AER_REPORT | PCIE_IRN_AER_MSIX \
+		| PCIE_IRN_PME | PCIE_IRN_HOTPLUG | PCIE_IRN_RX_VDM_MSG \
+		| PCIE_IRN_RX_CORRECTABLE_ERR_MSG \
+		| PCIE_IRN_RX_NON_FATAL_ERR_MSG | PCIE_IRN_RX_FATAL_ERR_MSG \
+		| PCIE_IRN_RX_PME_MSG | PCIE_IRN_RX_PME_TURNOFF_ACK \
+		| PCIE_IRN_AHB_BR_FATAL_ERR | PCIE_IRN_LINK_AUTO_BW_STATUS\
+		| PCIE_IRN_BW_MGT)
+
+/* PCIe RC Configuration Register */
+#define PCIE_VDID(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x00)
+
+/* Bit definition from pci_reg.h */
+#define PCIE_PCICMDSTS(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x04)
+#define PCIE_CCRID(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x08)
+
+#define PCIE_CLSLTHTBR(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x0C)
+
+/* BAR0, BAR1,Only necessary if the bridges implements a device-specific
+   register set or memory buffer */
+#define PCIE_BAR0(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x10)
+
+#define PCIE_BAR1(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x14)
+
+#define PCIE_BNR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x18)
+/* Bus Number Register bits */
+#define PCIE_BNR_PRIMARY_BUS_NUM	0x000000FF
+#define PCIE_BNR_PRIMARY_BUS_NUM_S	0
+#define PCIE_PNR_SECONDARY_BUS_NUM	0x0000FF00
+#define PCIE_PNR_SECONDARY_BUS_NUM_S	8
+#define PCIE_PNR_SUB_BUS_NUM	0x00FF0000
+#define PCIE_PNR_SUB_BUS_NUM_S	16
+
+/* IO Base/Limit Register bits */
+#define PCIE_IOBLSECS(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x1C)
+
+#define PCIE_IOBLSECS_32BIT_IO_ADDR	0x00000001
+#define PCIE_IOBLSECS_IO_BASE_ADDR	0x000000F0
+#define PCIE_IOBLSECS_IO_BASE_ADDR_S	4
+#define PCIE_IOBLSECS_32BIT_IOLIMT	0x00000100
+#define PCIE_IOBLSECS_IO_LIMIT_ADDR	0x0000F000
+#define PCIE_IOBLSECS_IO_LIMIT_ADDR_S	12
+
+/* Non-prefetchable Memory Base/Limit Register bit */
+#define PCIE_MBML(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x20)
+
+#define PCIE_MBML_MEM_BASE_ADDR		0x0000FFF0
+#define PCIE_MBML_MEM_BASE_ADDR_S	4
+#define PCIE_MBML_MEM_LIMIT_ADDR	0xFFF00000
+#define PCIE_MBML_MEM_LIMIT_ADDR_S	20
+
+/* Prefetchable Memory Base/Limit Register bit */
+#define PCIE_PMBL(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x24)
+#define PCIE_PMBL_64BIT_ADDR		0x00000001
+#define PCIE_PMBL_UPPER_12BIT		0x0000FFF0
+#define PCIE_PMBL_UPPER_12BIT_S		4
+#define PCIE_PMBL_E64MA			0x00010000
+#define PCIE_PMBL_END_ADDR		0xFFF00000
+#define PCIE_PMBL_END_ADDR_S		20
+
+#define PCIE_PMBU32(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x28)
+
+#define PCIE_PMLU32(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x2C)
+
+/* I/O Base/Limit Upper 16 bits register */
+#define PCIE_IO_BANDL(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x30)
+
+#define PCIE_IO_BANDL_UPPER_16BIT_IO_BASE	0x0000FFFF
+#define PCIE_IO_BANDL_UPPER_16BIT_IO_BASE_S	0
+#define PCIE_IO_BANDL_UPPER_16BIT_IO_LIMIT	0xFFFF0000
+#define PCIE_IO_BANDL_UPPER_16BIT_IO_LIMIT_S	16
+
+#define PCIE_CPR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x34)
+
+#define PCIE_EBBAR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x38)
+
+/* Interrupt and Secondary Bridge Control Register */
+#define PCIE_INTRBCTRL(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x3C)
+
+#define PCIE_INTRBCTRL_INT_LINE			0x000000FF
+#define PCIE_INTRBCTRL_INT_LINE_S		0
+#define PCIE_INTRBCTRL_INT_PIN			0x0000FF00
+#define PCIE_INTRBCTRL_INT_PIN_S		8
+#define PCIE_INTRBCTRL_PARITY_ERR_RESP_ENABLE	0x00010000
+#define PCIE_INTRBCTRL_SERR_ENABLE		0x00020000
+#define PCIE_INTRBCTRL_ISA_ENABLE		0x00040000
+#define PCIE_INTRBCTRL_VGA_ENABLE		0x00080000
+#define PCIE_INTRBCTRL_VGA_16BIT_DECODE		0x00100000
+#define PCIE_INTRBCTRL_RST_SECONDARY_BUS	0x00400000
+/* Others are read only */
+enum {
+	PCIE_INTRBCTRL_INT_NON = 0,
+	PCIE_INTRBCTRL_INTA,
+	PCIE_INTRBCTRL_INTB,
+	PCIE_INTRBCTRL_INTC,
+	PCIE_INTRBCTRL_INTD,
+};
+
+#define PCIE_PM_CAPR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x40)
+
+/* Power Management Control and Status Register */
+#define PCIE_PM_CSR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x44)
+
+#define PCIE_PM_CSR_POWER_STATE		0x00000003 /* Power State */
+#define PCIE_PM_CSR_POWER_STATE_S	0
+#define PCIE_PM_CSR_SW_RST		0x00000008 /* Soft Reset Enabled */
+#define PCIE_PM_CSR_PME_ENABLE		0x00000100 /* PME Enable */
+#define PCIE_PM_CSR_PME_STATUS		0x00008000 /* PME status */
+
+/* MSI Capability Register for EP */
+#define PCIE_MCAPR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x50)
+
+#define PCIE_MCAPR_MSI_CAP_ID		0x000000FF
+#define PCIE_MCAPR_MSI_CAP_ID_S		0
+#define PCIE_MCAPR_MSI_NEXT_CAP_PTR	0x0000FF00
+#define PCIE_MCAPR_MSI_NEXT_CAP_PTR_S	8
+#define PCIE_MCAPR_MSI_ENABLE		0x00010000
+#define PCIE_MCAPR_MULTI_MSG_CAP	0x000E0000
+#define PCIE_MCAPR_MULTI_MSG_CAP_S	17
+#define PCIE_MCAPR_MULTI_MSG_ENABLE	0x00700000
+#define PCIE_MCAPR_MULTI_MSG_ENABLE_S	20
+#define PCIE_MCAPR_ADDR64_CAP		0X00800000
+
+/* MSI Message Address Register */
+#define PCIE_MA(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x54)
+
+#define PCIE_MA_ADDR_MASK		0xFFFFFFFC /* Message Address */
+
+/* MSI Message Upper Address Register */
+#define PCIE_MUA(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x58)
+
+/* MSI Message Data Register */
+#define PCIE_MD(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x5C)
+
+#define PCIE_MD_DATA			0x0000FFFF /* Message Data */
+#define PCIE_MD_DATA_S			0
+
+/* PCI Express Capability Register */
+#define PCIE_XCAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x70)
+
+#define PCIE_XCAP_ID			0x000000FF
+#define PCIE_XCAP_ID_S			0
+#define PCIE_XCAP_NEXT_CAP		0x0000FF00
+#define PCIE_XCAP_NEXT_CAP_S		8
+#define PCIE_XCAP_VER			0x000F0000
+#define PCIE_XCAP_VER_S			16
+#define PCIE_XCAP_DEV_PORT_TYPE		0x00F00000
+#define PCIE_XCAP_DEV_PORT_TYPE_S	20
+#define PCIE_XCAP_SLOT_IMPLEMENTED	0x01000000
+#define PCIE_XCAP_MSG_INT_NUM		0x3E000000
+#define PCIE_XCAP_MSG_INT_NUM_S		25
+
+/* Device Capability Register */
+#define PCIE_DCAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x74)
+
+#define PCIE_DCAP_MAX_PAYLOAD_SIZE	0x00000007
+#define PCIE_DCAP_MAX_PAYLOAD_SIZE_S	0
+#define PCIE_DCAP_PHANTOM_FUNC		0x00000018
+#define PCIE_DCAP_PHANTOM_FUNC_S	3
+#define PCIE_DCAP_EXT_TAG		0x00000020
+#define PCIE_DCAP_EP_L0S_LATENCY	0x000001C0
+#define PCIE_DCAP_EP_L0S_LATENCY_S	6
+#define PCIE_DCAP_EP_L1_LATENCY		0x00000E00
+#define PCIE_DCAP_EP_L1_LATENCY_S	9
+#define PCIE_DCAP_ROLE_BASE_ERR_REPORT	0x00008000
+
+/* Maximum payload size supported */
+enum {
+	PCIE_MAX_PAYLOAD_128 = 0,
+	PCIE_MAX_PAYLOAD_256,
+	PCIE_MAX_PAYLOAD_512,
+	PCIE_MAX_PAYLOAD_1024,
+	PCIE_MAX_PAYLOAD_2048,
+	PCIE_MAX_PAYLOAD_4096,
+};
+
+/* Device Control and Status Register */
+#define PCIE_DCTLSTS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x78)
+
+#define PCIE_DCTLSTS_CORRECTABLE_ERR_EN		0x00000001
+#define PCIE_DCTLSTS_NONFATAL_ERR_EN		0x00000002
+#define PCIE_DCTLSTS_FATAL_ERR_EN		0x00000004
+#define PCIE_DCTLSYS_UR_REQ_EN			0x00000008
+#define PCIE_DCTLSTS_RELAXED_ORDERING_EN	0x00000010
+#define PCIE_DCTLSTS_MAX_PAYLOAD_SIZE		0x000000E0
+#define PCIE_DCTLSTS_MAX_PAYLOAD_SIZE_S		5
+#define PCIE_DCTLSTS_EXT_TAG_EN			0x00000100
+#define PCIE_DCTLSTS_PHANTOM_FUNC_EN		0x00000200
+#define PCIE_DCTLSTS_AUX_PM_EN			0x00000400
+#define PCIE_DCTLSTS_NO_SNOOP_EN		0x00000800
+#define PCIE_DCTLSTS_MAX_READ_SIZE		0x00007000
+#define PCIE_DCTLSTS_MAX_READ_SIZE_S		12
+#define PCIE_DCTLSTS_CORRECTABLE_ERR		0x00010000
+#define PCIE_DCTLSTS_NONFATAL_ERR		0x00020000
+#define PCIE_DCTLSTS_FATAL_ER			0x00040000
+#define PCIE_DCTLSTS_UNSUPPORTED_REQ		0x00080000
+#define PCIE_DCTLSTS_AUX_POWER			0x00100000
+#define PCIE_DCTLSTS_TRANSACT_PENDING	0x00200000
+
+#define PCIE_DCTLSTS_ERR_EN	(PCIE_DCTLSTS_CORRECTABLE_ERR_EN | \
+		PCIE_DCTLSTS_NONFATAL_ERR_EN | PCIE_DCTLSTS_FATAL_ERR_EN \
+		| PCIE_DCTLSYS_UR_REQ_EN)
+
+/* Link Capability Register */
+#define PCIE_LCAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x7C)
+#define PCIE_LCAP_MAX_LINK_SPEED		0x0000000F
+#define PCIE_LCAP_MAX_LINK_SPEED_S		0
+#define PCIE_LCAP_MAX_LENGTH_WIDTH		0x000003F0
+#define PCIE_LCAP_MAX_LENGTH_WIDTH_S		4
+#define PCIE_LCAP_ASPM_LEVEL			0x00000C00
+#define PCIE_LCAP_ASPM_LEVEL_S			10
+#define PCIE_LCAP_L0S_EIXT_LATENCY		0x00007000
+#define PCIE_LCAP_L0S_EIXT_LATENCY_S		12
+#define PCIE_LCAP_L1_EXIT_LATENCY		0x00038000
+#define PCIE_LCAP_L1_EXIT_LATENCY_S		15
+#define PCIE_LCAP_CLK_PM			0x00040000
+#define PCIE_LCAP_SDER				0x00080000
+#define PCIE_LCAP_DLL_ACTIVE_REPROT		0x00100000
+#define PCIE_LCAP_PORT_NUM			0xFF000000
+#define PCIE_LCAP_PORT_NUM_S			24
+
+/* Maximum Length width definition */
+#define PCIE_MAX_LENGTH_WIDTH_RES		0x00
+#define PCIE_MAX_LENGTH_WIDTH_X1		0x01 /* Default */
+#define PCIE_MAX_LENGTH_WIDTH_X2		0x02
+#define PCIE_MAX_LENGTH_WIDTH_X4		0x04
+#define PCIE_MAX_LENGTH_WIDTH_X8		0x08
+#define PCIE_MAX_LENGTH_WIDTH_X12		0x0C
+#define PCIE_MAX_LENGTH_WIDTH_X16		0x10
+#define PCIE_MAX_LENGTH_WIDTH_X32		0x20
+
+/* Active State Link PM definition */
+enum {
+	PCIE_ASPM_RES0 = 0,
+	PCIE_ASPM_L0S_ENTRY_SUPPORT, /* L0s */
+	PCIE_ASPM_RES1,
+	PCIE_ASPM_L0S_L1_ENTRY_SUPPORT, /* L0s and L1, default */
+};
+
+/* L0s Exit Latency definition */
+enum {
+	PCIE_L0S_EIXT_LATENCY_L64NS = 0, /* < 64 ns */
+	PCIE_L0S_EIXT_LATENCY_B64A128,  /* > 64 ns < 128 ns */
+	PCIE_L0S_EIXT_LATENCY_B128A256, /* > 128 ns < 256 ns */
+	PCIE_L0S_EIXT_LATENCY_B256A512, /* > 256 ns < 512 ns */
+	PCIE_L0S_EIXT_LATENCY_B512TO1U, /* > 512 ns < 1 us */
+	PCIE_L0S_EIXT_LATENCY_B1A2U, /* > 1 us < 2 us */
+	PCIE_L0S_EIXT_LATENCY_B2A4U, /* > 2 us < 4 us */
+	PCIE_L0S_EIXT_LATENCY_M4US, /* > 4 us  */
+};
+
+/* L1 Exit Latency definition */
+enum {
+	PCIE_L1_EXIT_LATENCY_L1US = 0, /* < 1 us */
+	PCIE_L1_EXIT_LATENCY_B1A2,     /* > 1 us < 2 us */
+	PCIE_L1_EXIT_LATENCY_B2A4,     /* > 2 us < 4 us */
+	PCIE_L1_EXIT_LATENCY_B4A8,     /* > 4 us < 8 us */
+	PCIE_L1_EXIT_LATENCY_B8A16,    /* > 8 us < 16 us */
+	PCIE_L1_EXIT_LATENCY_B16A32,   /* > 16 us < 32 us */
+	PCIE_L1_EXIT_LATENCY_B32A64,   /* > 32 us < 64 us */
+	PCIE_L1_EXIT_LATENCY_M64US,    /* > 64 us */
+};
+
+/* Link Control and Status Register */
+#define PCIE_LCTLSTS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x80)
+#define PCIE_LCTLSTS_ASPM_ENABLE		0x00000003
+#define PCIE_LCTLSTS_ASPM_ENABLE_S		0
+#define PCIE_LCTLSTS_RCB128			0x00000008
+#define PCIE_LCTLSTS_LINK_DISABLE		0x00000010
+#define PCIE_LCTLSTS_RETRIAN_LINK		0x00000020
+#define PCIE_LCTLSTS_COM_CLK_CFG		0x00000040
+#define PCIE_LCTLSTS_EXT_SYNC			0x00000080
+#define PCIE_LCTLSTS_CLK_PM_EN			0x00000100
+#define PCIE_LCTLSTS_LINK_SPEED			0x000F0000
+#define PCIE_LCTLSTS_LINK_SPEED_S		16
+#define PCIE_LCTLSTS_NEGOTIATED_LINK_WIDTH	0x03F00000
+#define PCIE_LCTLSTS_NEGOTIATED_LINK_WIDTH_S	20
+#define PCIE_LCTLSTS_RETRAIN_PENDING		0x08000000
+#define PCIE_LCTLSTS_SLOT_CLK_CFG		0x10000000
+#define PCIE_LCTLSTS_DLL_ACTIVE			0x20000000
+
+/* Slot Capabilities Register */
+#define PCIE_SLCAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x84)
+
+/* Slot Capabilities */
+#define PCIE_SLCTLSTS(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x88)
+
+/* Root Control and Capability Register */
+#define PCIE_RCTLCAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x8C)
+
+#define PCIE_RCTLCAP_SERR_ON_CORRECTABLE_ERR	0x00000001
+#define PCIE_RCTLCAP_SERR_ON_NONFATAL_ERR	0x00000002
+#define PCIE_RCTLCAP_SERR_ON_FATAL_ERR		0x00000004
+#define PCIE_RCTLCAP_PME_INT_EN	0x00000008
+#define PCIE_RCTLCAP_SERR_ENABLE	(PCIE_RCTLCAP_SERR_ON_CORRECTABLE_ERR \
+		| PCIE_RCTLCAP_SERR_ON_NONFATAL_ERR \
+		| PCIE_RCTLCAP_SERR_ON_FATAL_ERR)
+/* Root Status Register */
+#define PCIE_RSTS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x90)
+
+#define PCIE_RSTS_PME_REQ_ID		0x0000FFFF
+#define PCIE_RSTS_PME_REQ_ID_S		0
+#define PCIE_RSTS_PME_STATUS		0x00010000
+#define PCIE_RSTS_PME_PENDING		0x00020000
+
+/* PCI Express Enhanced Capability Header */
+#define PCIE_ENHANCED_CAP(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x100)
+
+#define PCIE_ENHANCED_CAP_ID			0x0000FFFF
+#define PCIE_ENHANCED_CAP_ID_S			0
+#define PCIE_ENHANCED_CAP_VER			0x000F0000
+#define PCIE_ENHANCED_CAP_VER_S			16
+#define PCIE_ENHANCED_CAP_NEXT_OFFSET		0xFFF00000
+#define PCIE_ENHANCED_CAP_NEXT_OFFSET_S		20
+
+/* Uncorrectable Error Status Register */
+#define PCIE_UES_R(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x104)
+
+#define PCIE_DATA_LINK_PROTOCOL_ERR		0x00000010
+#define PCIE_SURPRISE_DOWN_ERROR		0x00000020
+#define PCIE_POISONED_TLP			0x00001000
+#define PCIE_FC_PROTOCOL_ERR			0x00002000
+#define PCIE_COMPLETION_TIMEOUT			0x00004000
+#define PCIE_COMPLETOR_ABORT			0x00008000
+#define PCIE_UNEXPECTED_COMPLETION		0x00010000
+#define PCIE_RECEIVER_OVERFLOW			0x00020000
+#define PCIE_MALFORNED_TLP			0x00040000
+#define PCIE_ECRC_ERR				0x00080000
+#define PCIE_UR_REQ				0x00100000
+#define PCIE_ALL_UNCORRECTABLE_ERR	(PCIE_DATA_LINK_PROTOCOL_ERR |\
+		PCIE_SURPRISE_DOWN_ERROR | PCIE_POISONED_TLP |\
+		PCIE_FC_PROTOCOL_ERR | PCIE_COMPLETION_TIMEOUT | \
+		PCIE_COMPLETOR_ABORT | PCIE_UNEXPECTED_COMPLETION |\
+		PCIE_RECEIVER_OVERFLOW | PCIE_MALFORNED_TLP | \
+		PCIE_ECRC_ERR | PCIE_UR_REQ)
+
+/* Uncorrectable Error Mask Register, Mask means no report */
+#define PCIE_UEMR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x108)
+
+/* Uncorrectable Error Severity Register */
+#define PCIE_UESR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x10C)
+
+/* Correctable Error Status Register */
+#define PCIE_CESR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x110)
+#define PCIE_RX_ERR			0x00000001
+#define PCIE_BAD_TLP			0x00000040
+#define PCIE_BAD_DLLP			0x00000080
+#define PCIE_REPLAY_NUM_ROLLOVER	0x00000100
+#define PCIE_REPLAY_TIMER_TIMEOUT_ERR	0x00001000
+#define PCIE_ADVISORY_NONFTAL_ERR	0x00002000
+#define PCIE_CORRECTABLE_ERR	(PCIE_RX_ERR | PCIE_BAD_TLP | PCIE_BAD_DLLP \
+		| PCIE_REPLAY_NUM_ROLLOVER | PCIE_REPLAY_TIMER_TIMEOUT_ERR\
+		| PCIE_ADVISORY_NONFTAL_ERR)
+
+/* Correctable Error Mask Register */
+#define PCIE_CEMR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x114)
+
+/* Advanced Error Capabilities and Control Register */
+#define PCIE_AECCR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x118)
+
+#define PCIE_AECCR_FIRST_ERR_PTR		0x0000001F
+#define PCIE_AECCR_FIRST_ERR_PTR_S		0
+#define PCIE_AECCR_ECRC_GEN_CAP			0x00000020
+#define PCIE_AECCR_ECRC_GEN_EN			0x00000040
+#define PCIE_AECCR_ECRC_CHECK_CAP		0x00000080
+#define PCIE_AECCR_ECRC_CHECK_EN		0x00000100
+
+/* Header Log Register 1 */
+#define PCIE_HLR1(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x11C)
+
+/* Header Log Register 2 */
+#define PCIE_HLR2(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x120)
+
+/* Header Log Register 3 */
+#define PCIE_HLR3(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x124)
+
+/* Header Log Register 4 */
+#define PCIE_HLR4(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x128)
+
+/* Root Error Command Register */
+#define PCIE_RECR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x12C)
+
+#define PCIE_RECR_CORRECTABLE_ERR_REPORT_EN	0x00000001 /* COR-ERR */
+#define PCIE_RECR_NONFATAL_ERR_REPORT_EN	0x00000002 /* Non-Fatal ERR */
+#define PCIE_RECR_FATAL_ERR_REPORT_EN		0x00000004 /* Fatal ERR */
+#define PCIE_RECR_ERR_REPORT_EN	(PCIE_RECR_CORRECTABLE_ERR_REPORT_EN\
+		| PCIE_RECR_NONFATAL_ERR_REPORT_EN |\
+		PCIE_RECR_FATAL_ERR_REPORT_EN)
+
+/* Root Error Status Register */
+#define PCIE_RESR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x130)
+
+#define PCIE_RESR_CORRECTABLE_ERR		0x00000001
+#define PCIE_RESR_MULTI_CORRECTABLE_ERR		0x00000002
+#define PCIE_RESR_FATAL_NOFATAL_ERR		0x00000004
+#define PCIE_RESR_MULTI_FATAL_NOFATAL_ERR	0x00000008
+#define PCIE_RESR_FIRST_UNCORRECTABLE_FATAL_ERR	0x00000010
+#define PCIR_RESR_NON_FATAL_ERR			0x00000020
+#define PCIE_RESR_FATAL_ERR			0x00000040
+#define PCIE_RESR_AER_INT_MSG_NUM		0xF8000000
+#define PCIE_RESR_AER_INT_MSG_NUM_S		27
+
+/* Error Source Indentification Register */
+#define PCIE_ESIR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x134)
+
+#define PCIE_ESIR_CORRECTABLE_ERR_SRC_ID	0x0000FFFF
+#define PCIE_ESIR_CORRECTABLE_ERR_SRC_ID_S	0
+#define PCIE_ESIR_FATAL_NON_FATAL_SRC_ID	0xFFFF0000
+#define PCIE_ESIR_FATAL_NON_FATAL_SRC_ID_S	16
+
+/* VC Enhanced Capability Header */
+#define PCIE_VC_ECH(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x140)
+
+/* Port VC Capability Register */
+#define PCIE_PVC1(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x144)
+
+#define PCIE_PVC1_EXT_VC_CNT			0x00000007
+#define PCIE_PVC1_EXT_VC_CNT_S			0
+#define PCIE_PVC1_LOW_PRI_EXT_VC_CNT		0x00000070
+#define PCIE_PVC1_LOW_PRI_EXT_VC_CNT_S		4
+#define PCIE_PVC1_REF_CLK			0x00000300
+#define PCIE_PVC1_REF_CLK_S			8
+#define PCIE_PVC1_PORT_ARB_TAB_ENTRY_SIZE	0x00000C00
+#define PCIE_PVC1_PORT_ARB_TAB_ENTRY_SIZE_S	10
+
+/* Extended Virtual Channel Count Defintion */
+#define PCIE_EXT_VC_CNT_MIN		0
+#define PCIE_EXT_VC_CNT_MAX		7
+
+/* Port Arbitration Table Entry Size Definition */
+enum {
+	PCIE_PORT_ARB_TAB_ENTRY_SIZE_S1BIT = 0,
+	PCIE_PORT_ARB_TAB_ENTRY_SIZE_S2BIT,
+	PCIE_PORT_ARB_TAB_ENTRY_SIZE_S4BIT,
+	PCIE_PORT_ARB_TAB_ENTRY_SIZE_S8BIT,
+};
+
+/* Port VC Capability Register 2 */
+#define PCIE_PVC2(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x148)
+
+#define PCIE_PVC2_VC_ARB_16P_FIXED_WRR		0x00000001
+#define PCIE_PVC2_VC_ARB_32P_WRR		0x00000002
+#define PCIE_PVC2_VC_ARB_64P_WRR		0x00000004
+#define PCIE_PVC2_VC_ARB_128P_WRR		0x00000008
+#define PCIE_PVC2_VC_ARB_WRR			0x0000000F
+#define PCIE_PVC2_VC_ARB_TAB_OFFSET		0xFF000000
+#define PCIE_PVC2_VC_ARB_TAB_OFFSET_S		24
+
+/* Port VC Control and Status Register */
+#define PCIE_PVCCRSR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x14C)
+
+#define PCIE_PVCCRSR_LOAD_VC_ARB_TAB		0x00000001
+#define PCIE_PVCCRSR_VC_ARB_SEL			0x0000000E
+#define PCIE_PVCCRSR_VC_ARB_SEL_S		1
+#define PCIE_PVCCRSR_VC_ARB_TAB_STATUS		0x00010000
+
+/* VC0 Resource Capability Register */
+#define PCIE_VC0_RC(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x150)
+
+#define PCIE_VC0_RC_PORT_ARB_HW_FIXED		0x00000001
+#define PCIE_VC0_RC_PORT_ARB_32P_WRR		0x00000002
+#define PCIE_VC0_RC_PORT_ARB_64P_WRR		0x00000004
+#define PCIE_VC0_RC_PORT_ARB_128P_WRR		0x00000008
+#define PCIE_VC0_RC_PORT_ARB_TM_128P_WRR	0x00000010
+#define PCIE_VC0_RC_PORT_ARB_TM_256P_WRR	0x00000020
+#define PCIE_VC0_RC_PORT_ARB	(PCIE_VC0_RC_PORT_ARB_HW_FIXED |\
+		PCIE_VC0_RC_PORT_ARB_32P_WRR | PCIE_VC0_RC_PORT_ARB_64P_WRR |\
+		PCIE_VC0_RC_PORT_ARB_128P_WRR |\
+		PCIE_VC0_RC_PORT_ARB_TM_128P_WRR |\
+		PCIE_VC0_RC_PORT_ARB_TM_256P_WRR)
+
+#define PCIE_VC0_RC_REJECT_SNOOP		0x00008000
+#define PCIE_VC0_RC_MAX_TIMESLOTS		0x007F0000
+#define PCIE_VC0_RC_MAX_TIMESLOTS_S		16
+#define PCIE_VC0_RC_PORT_ARB_TAB_OFFSET		0xFF000000
+#define PCIE_VC0_RC_PORT_ARB_TAB_OFFSET_S	24
+
+/* VC0 Resource Control Register */
+#define PCIE_VC0_RC0(X)			(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x154)
+
+#define PCIE_VC0_RC0_TVM0			0x00000001
+#define PCIE_VC0_RC0_TVM1			0x00000002
+#define PCIE_VC0_RC0_TVM2			0x00000004
+#define PCIE_VC0_RC0_TVM3			0x00000008
+#define PCIE_VC0_RC0_TVM4			0x00000010
+#define PCIE_VC0_RC0_TVM5			0x00000020
+#define PCIE_VC0_RC0_TVM6			0x00000040
+#define PCIE_VC0_RC0_TVM7			0x00000080
+#define PCIE_VC0_RC0_TC_VC			0x000000FF
+
+#define PCIE_VC0_RC0_LOAD_PORT_ARB_TAB		0x00010000
+#define PCIE_VC0_RC0_PORT_ARB_SEL		0x000E0000
+#define PCIE_VC0_RC0_PORT_ARB_SEL_S		17
+#define PCIE_VC0_RC0_VC_ID			0x07000000
+#define PCIE_VC0_RC0_VC_ID_S			24
+#define PCIE_VC0_RC0_VC_EN			0x80000000
+
+/* VC0 Resource Status Register */
+#define PCIE_VC0_RSR0(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x158)
+
+#define PCIE_VC0_RSR0_PORT_ARB_TAB_STATUS	0x00010000
+#define PCIE_VC0_RSR0_VC_NEG_PENDING		0x00020000
+
+/* Ack Latency Timer and Replay Timer Register */
+#define PCIE_ALTRT(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x700)
+
+#define PCIE_ALTRT_ROUND_TRIP_LATENCY_LIMIT	0x0000FFFF
+#define PCIE_ALTRT_ROUND_TRIP_LATENCY_LIMIT_S	0
+#define PCIE_ALTRT_REPLAY_TIME_LIMIT		0xFFFF0000
+#define PCIE_ALTRT_REPLAY_TIME_LIMIT_S		16
+
+/* Other Message Register */
+#define PCIE_OMR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x704)
+
+/* Port Force Link Register */
+#define PCIE_PFLR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x708)
+
+#define PCIE_PFLR_LINK_NUM			0x000000FF
+#define PCIE_PFLR_LINK_NUM_S			0
+#define PCIE_PFLR_FORCE_LINK			0x00008000
+#define PCIE_PFLR_LINK_STATE			0x003F0000
+#define PCIE_PFLR_LINK_STATE_S			16
+#define PCIE_PFLR_LOW_POWER_ENTRY_CNT		0xFF000000
+#define PCIE_PFLR_LOW_POWER_ENTRY_CNT_S		24
+
+/* Ack Frequency Register */
+#define PCIE_AFR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x70C)
+
+#define PCIE_AFR_AF			0x000000FF
+#define PCIE_AFR_AF_S			0
+#define PCIE_AFR_FTS_NUM		0x0000FF00
+#define PCIE_AFR_FTS_NUM_S		8
+#define PCIE_AFR_COM_FTS_NUM		0x00FF0000
+#define PCIE_AFR_COM_FTS_NUM_S		16
+#define PCIE_AFR_L0S_ENTRY_LATENCY	0x07000000
+#define PCIE_AFR_L0S_ENTRY_LATENCY_S	24
+#define PCIE_AFR_L1_ENTRY_LATENCY	0x38000000
+#define PCIE_AFR_L1_ENTRY_LATENCY_S	27
+#define PCIE_AFR_FTS_NUM_DEFAULT	32
+#define PCIE_AFR_L0S_ENTRY_LATENCY_DEFAULT	7
+#define PCIE_AFR_L1_ENTRY_LATENCY_DEFAULT	5
+
+/* Port Link Control Register */
+#define PCIE_PLCR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x710)
+
+#define PCIE_PLCR_OTHER_MSG_REQ		0x00000001
+#define PCIE_PLCR_SCRAMBLE_DISABLE	0x00000002
+#define PCIE_PLCR_LOOPBACK_EN		0x00000004
+#define PCIE_PLCR_LTSSM_HOT_RST		0x00000008
+#define PCIE_PLCR_DLL_LINK_EN		0x00000020
+#define PCIE_PLCR_FAST_LINK_SIM_EN	0x00000080
+#define PCIE_PLCR_LINK_MODE		0x003F0000
+#define PCIE_PLCR_LINK_MODE_S		16
+#define PCIE_PLCR_CORRUPTED_CRC_EN	0x02000000
+
+/* Lane Skew Register */
+#define PCIE_LSR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x714)
+
+#define PCIE_LSR_LANE_SKEW_NUM		0x00FFFFFF
+#define PCIE_LSR_LANE_SKEW_NUM_S	0
+#define PCIE_LSR_FC_DISABLE		0x01000000
+#define PCIE_LSR_ACKNAK_DISABLE		0x02000000
+#define PCIE_LSR_LANE_DESKEW_DISABLE	0x80000000
+
+/* Symbol Number Register */
+#define PCIE_SNR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x718)
+
+#define PCIE_SNR_TS			0x0000000F
+#define PCIE_SNR_TS_S			0
+#define PCIE_SNR_SKP			0x00000700
+#define PCIE_SNR_SKP_S			8
+#define PCIE_SNR_REPLAY_TIMER		0x0007C000
+#define PCIE_SNR_REPLAY_TIMER_S		14
+#define PCIE_SNR_ACKNAK_LATENCY_TIMER	0x00F80000
+#define PCIE_SNR_ACKNAK_LATENCY_TIMER_S	19
+#define PCIE_SNR_FC_TIMER		0x1F000000
+#define PCIE_SNR_FC_TIMER_S		28
+
+/* Symbol Timer Register and Filter Mask Register 1 */
+#define PCIE_STRFMR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x71C)
+
+#define PCIE_STRFMR_SKP_INTERVAL		0x000007FF
+#define PCIE_STRFMR_SKP_INTERVAL_S		0
+#define PCIE_STRFMR_FC_WDT_DISABLE		0x00008000
+#define PCIE_STRFMR_TLP_FUNC_MISMATCH_OK	0x00010000
+#define PCIE_STRFMR_POISONED_TLP_OK		0x00020000
+#define PCIE_STRFMR_BAR_MATCH_OK		0x00040000
+#define PCIE_STRFMR_TYPE1_CFG_REQ_OK		0x00080000
+#define PCIE_STRFMR_LOCKED_REQ_OK		0x00100000
+#define PCIE_STRFMR_CPL_TAG_ERR_RULES_OK	0x00200000
+#define PCIE_STRFMR_CPL_REQUESTOR_ID_MISMATCH_OK	0x00400000
+#define PCIE_STRFMR_CPL_FUNC_MISMATCH_OK	0x00800000
+#define PCIE_STRFMR_CPL_TC_MISMATCH_OK		0x01000000
+#define PCIE_STRFMR_CPL_ATTR_MISMATCH_OK	0x02000000
+#define PCIE_STRFMR_CPL_LENGTH_MISMATCH_OK	0x04000000
+#define PCIE_STRFMR_TLP_ECRC_ERR_OK		0x08000000
+#define PCIE_STRFMR_CPL_TLP_ECRC_OK		0x10000000
+#define PCIE_STRFMR_RX_TLP_MSG_NO_DROP		0x20000000
+#define PCIE_STRFMR_RX_IO_TRANS_ENABLE		0x40000000
+#define PCIE_STRFMR_RX_CFG_TRANS_ENABLE		0x80000000
+
+#define PCIE_DEF_SKP_INTERVAL	700 /* 1180 ~1538 , 125MHz * 2, 250MHz * 1 */
+
+/* Filter Masker Register 2 */
+#define PCIE_FMR2(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x720)
+
+#define PCIE_FMR2_VENDOR_MSG0_PASSED_TO_TRGT1	0x00000001
+#define PCIE_FMR2_VENDOR_MSG1_PASSED_TO_TRGT1	0x00000002
+
+/* Debug Register 0 */
+#define PCIE_DBR0(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x728)
+
+/* Debug Register 1 */
+#define PCIE_DBR1(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x72C)
+
+/* Transmit Posted FC Credit Status Register */
+#define PCIE_TPFCS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x730)
+
+#define PCIE_TPFCS_TX_P_DATA_FC_CREDITS		0x00000FFF
+#define PCIE_TPFCS_TX_P_DATA_FC_CREDITS_S	0
+#define PCIE_TPFCS_TX_P_HDR_FC_CREDITS		0x000FF000
+#define PCIE_TPFCS_TX_P_HDR_FC_CREDITS_S	12
+
+/* Transmit Non-Posted FC Credit Status */
+#define PCIE_TNPFCS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x734)
+
+#define PCIE_TNPFCS_TX_NP_DATA_FC_CREDITS	0x00000FFF
+#define PCIE_TNPFCS_TX_NP_DATA_FC_CREDITS_S	0
+#define PCIE_TNPFCS_TX_NP_HDR_FC_CREDITS	0x000FF000
+#define PCIE_TNPFCS_TX_NP_HDR_FC_CREDITS_S	12
+
+/* Transmit Complete FC Credit Status Register */
+#define PCIE_TCFCS(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x738)
+
+#define PCIE_TCFCS_TX_CPL_DATA_FC_CREDITS	0x00000FFF
+#define PCIE_TCFCS_TX_CPL_DATA_FC_CREDITS_S	0
+#define PCIE_TCFCS_TX_CPL_HDR_FC_CREDITS	0x000FF000
+#define PCIE_TCFCS_TX_CPL_HDR_FC_CREDITS_S	12
+
+/* Queue Status Register */
+#define PCIE_QSR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x73C)
+
+#define PCIE_QSR_WAIT_UPDATE_FC_DLL		0x00000001
+#define PCIE_QSR_TX_RETRY_BUF_NOT_EMPTY		0x00000002
+#define PCIE_QSR_RX_QUEUE_NOT_EMPTY		0x00000004
+
+/* VC Transmit Arbitration Register 1 */
+#define PCIE_VCTAR1(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x740)
+
+#define PCIE_VCTAR1_WRR_WEIGHT_VC0		0x000000FF
+#define PCIE_VCTAR1_WRR_WEIGHT_VC1		0x0000FF00
+#define PCIE_VCTAR1_WRR_WEIGHT_VC2		0x00FF0000
+#define PCIE_VCTAR1_WRR_WEIGHT_VC3		0xFF000000
+
+/* VC Transmit Arbitration Register 2 */
+#define PCIE_VCTAR2(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x744)
+
+#define PCIE_VCTAR2_WRR_WEIGHT_VC4		0x000000FF
+#define PCIE_VCTAR2_WRR_WEIGHT_VC5		0x0000FF00
+#define PCIE_VCTAR2_WRR_WEIGHT_VC6		0x00FF0000
+#define PCIE_VCTAR2_WRR_WEIGHT_VC7		0xFF000000
+
+/* VC0 Posted Receive Queue Control Register */
+#define PCIE_VC0_PRQCR(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x748)
+
+#define PCIE_VC0_PRQCR_P_DATA_CREDITS		0x00000FFF
+#define PCIE_VC0_PRQCR_P_DATA_CREDITS_S		0
+#define PCIE_VC0_PRQCR_P_HDR_CREDITS		0x000FF000
+#define PCIE_VC0_PRQCR_P_HDR_CREDITS_S		12
+#define PCIE_VC0_PRQCR_P_TLP_QUEUE_MODE		0x00E00000
+#define PCIE_VC0_PRQCR_P_TLP_QUEUE_MODE_S	20
+#define PCIE_VC0_PRQCR_TLP_RELAX_ORDER		0x40000000
+#define PCIE_VC0_PRQCR_VC_STRICT_ORDER		0x80000000
+
+/* VC0 Non-Posted Receive Queue Control */
+#define PCIE_VC0_NPRQCR(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x74C)
+
+#define PCIE_VC0_NPRQCR_NP_DATA_CREDITS		0x00000FFF
+#define PCIE_VC0_NPRQCR_NP_DATA_CREDITS_S	0
+#define PCIE_VC0_NPRQCR_NP_HDR_CREDITS		0x000FF000
+#define PCIE_VC0_NPRQCR_NP_HDR_CREDITS_S	12
+#define PCIE_VC0_NPRQCR_NP_TLP_QUEUE_MODE	0x00E00000
+#define PCIE_VC0_NPRQCR_NP_TLP_QUEUE_MODE_S	20
+
+/* VC0 Completion Receive Queue Control */
+#define PCIE_VC0_CRQCR(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x750)
+
+#define PCIE_VC0_CRQCR_CPL_DATA_CREDITS		0x00000FFF
+#define PCIE_VC0_CRQCR_CPL_DATA_CREDITS_S	0
+#define PCIE_VC0_CRQCR_CPL_HDR_CREDITS		0x000FF000
+#define PCIE_VC0_CRQCR_CPL_HDR_CREDITS_S	12
+#define PCIE_VC0_CRQCR_CPL_TLP_QUEUE_MODE	0x00E00000
+#define PCIE_VC0_CRQCR_CPL_TLP_QUEUE_MODE_S	21
+
+/* Applicable to the above three registers */
+enum {
+	PCIE_VC0_TLP_QUEUE_MODE_STORE_FORWARD = 1,
+	PCIE_VC0_TLP_QUEUE_MODE_CUT_THROUGH = 2,
+	PCIE_VC0_TLP_QUEUE_MODE_BYPASS = 4,
+};
+
+/* VC0 Posted Buffer Depth Register */
+#define PCIE_VC0_PBD(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x7A8)
+
+#define PCIE_VC0_PBD_P_DATA_QUEUE_ENTRIES	0x00003FFF
+#define PCIE_VC0_PBD_P_DATA_QUEUE_ENTRIES_S	0
+#define PCIE_VC0_PBD_P_HDR_QUEUE_ENTRIES	0x03FF0000
+#define PCIE_VC0_PBD_P_HDR_QUEUE_ENTRIES_S	16
+
+/* VC0 Non-Posted Buffer Depth Register */
+#define PCIE_VC0_NPBD(X)	(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x7AC)
+
+#define PCIE_VC0_NPBD_NP_DATA_QUEUE_ENTRIES	0x00003FFF
+#define PCIE_VC0_NPBD_NP_DATA_QUEUE_ENTRIES_S	0
+#define PCIE_VC0_NPBD_NP_HDR_QUEUE_ENTRIES	0x03FF0000
+#define PCIE_VC0_NPBD_NP_HDR_QUEUE_ENTRIES_S	16
+
+/* VC0 Completion Buffer Depth Register */
+#define PCIE_VC0_CBD(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x7B0)
+
+#define PCIE_VC0_CBD_CPL_DATA_QUEUE_ENTRIES	0x00003FFF
+#define PCIE_VC0_CBD_CPL_DATA_QUEUE_ENTRIES_S	0
+#define PCIE_VC0_CBD_CPL_HDR_QUEUE_ENTRIES	0x03FF0000
+#define PCIE_VC0_CBD_CPL_HDR_QUEUE_ENTRIES_S	16
+
+/* PHY Status Register,*/
+#define PCIE_PHYSR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x810)
+
+/* PHY Control Register */
+#define PCIE_PHYCR(X)		(u32 *)(PCIE_RC_PORT_TO_BASE(X) + 0x814)
+
+/*
+ * PCIe PDI PHY register definition, suppose all the following
+ * stuff is confidential.
+ * XXX, detailed bit definition
+ */
+#define	PCIE_PHY_PLL_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x22 << 1))
+#define	PCIE_PHY_PLL_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x23 << 1))
+#define	PCIE_PHY_PLL_CTRL3(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x24 << 1))
+#define	PCIE_PHY_PLL_CTRL4(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x25 << 1))
+#define	PCIE_PHY_PLL_CTRL5(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x26 << 1))
+#define	PCIE_PHY_PLL_CTRL6(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x27 << 1))
+#define	PCIE_PHY_PLL_CTRL7(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x28 << 1))
+#define	PCIE_PHY_PLL_A_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x29 << 1))
+#define	PCIE_PHY_PLL_A_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x2A << 1))
+#define	PCIE_PHY_PLL_A_CTRL3(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x2B << 1))
+#define	PCIE_PHY_PLL_STATUS(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x2C << 1))
+
+#define PCIE_PHY_TX1_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x30 << 1))
+#define PCIE_PHY_TX1_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x31 << 1))
+#define PCIE_PHY_TX1_CTRL3(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x32 << 1))
+#define PCIE_PHY_TX1_A_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x33 << 1))
+#define PCIE_PHY_TX1_A_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x34 << 1))
+#define PCIE_PHY_TX1_MOD1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x35 << 1))
+#define PCIE_PHY_TX1_MOD2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x36 << 1))
+#define PCIE_PHY_TX1_MOD3(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x37 << 1))
+
+#define PCIE_PHY_TX2_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x38 << 1))
+#define PCIE_PHY_TX2_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x39 << 1))
+#define PCIE_PHY_TX2_A_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x3B << 1))
+#define PCIE_PHY_TX2_A_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x3C << 1))
+#define PCIE_PHY_TX2_MOD1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x3D << 1))
+#define PCIE_PHY_TX2_MOD2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x3E << 1))
+#define PCIE_PHY_TX2_MOD3(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x3F << 1))
+
+#define PCIE_PHY_RX1_CTRL1(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x50 << 1))
+#define PCIE_PHY_RX1_CTRL2(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x51 << 1))
+#define PCIE_PHY_RX1_CDR(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x52 << 1))
+#define PCIE_PHY_RX1_EI(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x53 << 1))
+#define PCIE_PHY_RX1_A_CTRL(X)	(u32 *)(PCIE_PHY_PORT_TO_BASE(X) + (0x55 << 1))
+
+/* MSI PIC */
+#define MSI_PIC_REG_BASE		(KSEG1 | 0x1F700000)
+#define MSI1_PIC_REG_BASE		(KSEG1 | 0x1F500000)
+#define MSI2_PIC_REG_BASE		(KSEG1 | 0x1F700600)
+
+#define MSI_PIC_BIG_ENDIAN		1
+#define MSI_PIC_LITTLE_ENDIAN		0
+
+#define MSI_PCI_INT_DISABLE		0x80000000
+#define MSI_PIC_INT_LINE		0x30000000
+#define MSI_PIC_INT_LINE_S		28
+#define MSI_PIC_MSG_ADDR		0x0FFF0000
+#define MSI_PIC_MSG_ADDR_S		16
+#define MSI_PIC_MSG_DATA		0x0000FFFF
+#define MSI_PIC_MSG_DATA_S		0x0
+
+#define PCIE_INTA			(INT_NUM_IM4_IRL0 + 8)
+#define PCIE_INTB			(INT_NUM_IM4_IRL0 + 9)
+#define PCIE_INTC			(INT_NUM_IM4_IRL0 + 10)
+#define PCIE_INTD			(INT_NUM_IM4_IRL0 + 11)
+#define PCIE_IR				(INT_NUM_IM4_IRL0 + 25)
+#define PCIE_WAKE			(INT_NUM_IM4_IRL0 + 26)
+#define PCIE_MSI_IR0			(INT_NUM_IM4_IRL0 + 27)
+#define PCIE_MSI_IR1			(INT_NUM_IM4_IRL0 + 28)
+#define PCIE_MSI_IR2			(INT_NUM_IM4_IRL0 + 29)
+#define PCIE_MSI_IR3			(INT_NUM_IM0_IRL0 + 30)
+#define PCIE_L3_INT			(INT_NUM_IM3_IRL0 + 16)
+
+#define PCIE1_INTA			(INT_NUM_IM0_IRL0 + 9)
+#define PCIE1_INTB			(INT_NUM_IM0_IRL0 + 10)
+#define PCIE1_INTC			(INT_NUM_IM0_IRL0 + 11)
+#define PCIE1_INTD			(INT_NUM_IM0_IRL0 + 12)
+#define PCIE1_IR			(INT_NUM_IM1_IRL0 + 17)
+#define PCIE1_WAKE			(INT_NUM_IM1_IRL0 + 18)
+#define PCIE1_MSI_IR0			(INT_NUM_IM1_IRL0 + 9)
+#define PCIE1_MSI_IR1			(INT_NUM_IM1_IRL0 + 10)
+#define PCIE1_MSI_IR2			(INT_NUM_IM1_IRL0 + 11)
+#define PCIE1_MSI_IR3			(INT_NUM_IM1_IRL0 + 12)
+#define PCIE1_L3_INT			(INT_NUM_IM1_IRL0 + 13)
+
+#define PCIE2_INTA			(INT_NUM_IM0_IRL0 + 19)
+#define PCIE2_INTB			(INT_NUM_IM1_IRL0 + 31)
+#define PCIE2_INTC			(INT_NUM_IM2_IRL0 + 17)
+#define PCIE2_INTD			(INT_NUM_IM2_IRL0 + 18)
+#define PCIE2_IR			(INT_NUM_IM1_IRL0 + 21)
+#define PCIE2_WAKE			(INT_NUM_IM1_IRL0 + 23)
+#define PCIE2_MSI_IR0			(INT_NUM_IM2_IRL0 + 12)
+#define PCIE2_MSI_IR1			(INT_NUM_IM2_IRL0 + 13)
+#define PCIE2_MSI_IR2			(INT_NUM_IM2_IRL0 + 14)
+#define PCIE2_MSI_IR3			(INT_NUM_IM2_IRL0 + 15)
+#define PCIE2_L3_INT			(INT_NUM_IM2_IRL0 + 30)
+
+#define INT_NUM_IM4_IRL31		(INT_NUM_IM4_IRL0 + 31)
+
+#define RCU_AHB_ENDIAN			0x004C
+#define RCU_RST_REQ			0x0010
+#define RCU_AHB_BE_PCIE_PDI		0x00000080
+#define RCU_RST_STAT2			0x0024
+#define RCU_RST_REQ2			0x0048
+
+#define RCU_PCIE_ARBITER_MASK		0x00000C00
+#define RCU_PCIE_ARBITER_RC0		0x00000000
+#define RCU_PCIE_ARBITER_RC0_RC1	0x00000800
+#define RCU_PCIE_ARBITER_RC0_RC1_RC2	0x00000400
+
+#define RCU_BE_AHB4S			0x00000001
+#define RCU_BE_AHB3M			0x00000002
+#define RCU_BE_USIF			0x00000004
+#define RCU_BE_AHB2S			0x00000008
+#define RCU_BE_PCIE0S			0x00000010
+#define RCU_BE_PCIE0_DBI		0x00000020
+#define RCU_BE_DCDC_PDI			0x00000040
+#define RCU_BE_PCIE0_PDI		0x00000080
+#define RCU_BE_PCIE1S			0x00000100
+#define RCU_BE_PCIE1_DBI		0x00000200
+#define RCU_BE_PCIE1_PDI		0x00000400
+#define RCU_BE_AHB1S			0x00000800
+#define RCU_BE_PCIE0M			0x00001000
+#define RCU_BE_PCIE1M			0x00002000
+
+#define RCU_BE_PCIE2M			0x00004000
+#define RCU_BE_PCIE2_DBI		0x00008000
+#define RCU_BE_PCIE2_PDI		0x00010000
+#define RCU_BE_PCIE2S			0x00020000
+
+#define RCU_VR9_BE_PCIE0M		0x00000001
+#define RCU_VR9_BE_AHB1S		0x00000008
+#define RCU_VR9_BE_PCIE0S		0x00000010
+#define RCU_VR9_BE_AHB2M		0x00000002
+
+/* PCIe Address Mapping Base */
+#if defined(CONFIG_LANTIQ_PCIE_1ST_CORE)
+#define PCIE_CFG_PHY_BASE	0x1D000000UL
+#define PCIE_CFG_BASE		(KSEG1 + PCIE_CFG_PHY_BASE)
+#define PCIE_CFG_SIZE		(8 * 1024 * 1024)
+
+#define PCIE_MEM_PHY_BASE	0x1C000000UL
+#define PCIE_MEM_BASE		(KSEG1 + PCIE_MEM_PHY_BASE)
+#define PCIE_MEM_SIZE		(16 * 1024 * 1024)
+#define PCIE_MEM_PHY_END	(PCIE_MEM_PHY_BASE + PCIE_MEM_SIZE - 1)
+
+#define PCIE_IO_PHY_BASE	0x1D800000UL
+#define PCIE_IO_BASE		(KSEG1 + PCIE_IO_PHY_BASE)
+#define PCIE_IO_SIZE		(1 * 1024 * 1024)
+#define PCIE_IO_PHY_END		(PCIE_IO_PHY_BASE + PCIE_IO_SIZE - 1)
+
+#define PCIE_RC_CFG_BASE	(KSEG1 + 0x1D900000)
+#define PCIE_APP_LOGIC_REG	(KSEG1 + 0x1E100900)
+#define PCIE_MSI_PHY_BASE	0x1F600000UL
+
+#define PCIE_PDI_PHY_BASE	0x1F106800UL
+#define PCIE_PDI_BASE		(KSEG1 + PCIE_PDI_PHY_BASE)
+#define PCIE_PDI_SIZE		0x200
+#endif /* CONFIG_LANTIQ_PCIE_1ST_CORE */
+
+#if defined(CONFIG_LANTIQ_PCIE_2ND_CORE)
+#define PCIE1_CFG_PHY_BASE	0x19000000UL
+#define PCIE1_CFG_BASE		(KSEG1 + PCIE1_CFG_PHY_BASE)
+#define PCIE1_CFG_SIZE		(8 * 1024 * 1024)
+
+#define PCIE1_MEM_PHY_BASE	0x18000000UL
+#define PCIE1_MEM_BASE		(KSEG1 + PCIE1_MEM_PHY_BASE)
+#define PCIE1_MEM_SIZE		(16 * 1024 * 1024)
+#define PCIE1_MEM_PHY_END	(PCIE1_MEM_PHY_BASE + PCIE1_MEM_SIZE - 1)
+
+#define PCIE1_IO_PHY_BASE	0x19800000UL
+#define PCIE1_IO_BASE		(KSEG1 + PCIE1_IO_PHY_BASE)
+#define PCIE1_IO_SIZE		(1 * 1024 * 1024)
+#define PCIE1_IO_PHY_END	(PCIE1_IO_PHY_BASE + PCIE1_IO_SIZE - 1)
+
+#define PCIE1_RC_CFG_BASE	(KSEG1 + 0x19900000)
+#define PCIE1_APP_LOGIC_REG	(KSEG1 + 0x1E100700)
+#define PCIE1_MSI_PHY_BASE	0x1F400000UL
+
+#define PCIE1_PDI_PHY_BASE	0x1F700400UL
+#define PCIE1_PDI_BASE		(KSEG1 + PCIE1_PDI_PHY_BASE)
+#define PCIE1_PDI_SIZE		0x200
+#endif /* CONFIG_LANTIQ_PCIE_2ND_CORE */
+
+#if defined(CONFIG_LANTIQ_PCIE_3RD_CORE)
+#define PCIE2_CFG_PHY_BASE	0x1A800000UL
+#define PCIE2_CFG_BASE		(KSEG1 + PCIE2_CFG_PHY_BASE)
+#define PCIE2_CFG_SIZE		(8 * 1024 * 1024)
+
+#define PCIE2_MEM_PHY_BASE	0x1B000000UL
+#define PCIE2_MEM_BASE		(KSEG1 + PCIE2_MEM_PHY_BASE)
+#define PCIE2_MEM_SIZE		(16 * 1024 * 1024)
+#define PCIE2_MEM_PHY_END	(PCIE2_MEM_PHY_BASE + PCIE2_MEM_SIZE - 1)
+
+#define PCIE2_IO_PHY_BASE	0x19A00000UL
+#define PCIE2_IO_BASE		(KSEG1 + PCIE2_IO_PHY_BASE)
+#define PCIE2_IO_SIZE		(1 * 1024 * 1024)
+#define PCIE2_IO_PHY_END	(PCIE2_IO_PHY_BASE + PCIE2_IO_SIZE - 1)
+
+#define PCIE2_RC_CFG_BASE	(KSEG1 + 0x19B00000)
+#define PCIE2_APP_LOGIC_REG	(KSEG1 + 0x1E100400)
+#define PCIE2_MSI_PHY_BASE	0x1F700A00UL
+
+#define PCIE2_PDI_PHY_BASE	0x1F106A00UL
+#define PCIE2_PDI_BASE		(KSEG1 + PCIE2_PDI_PHY_BASE)
+#define PCIE2_PDI_SIZE		0x200
+#endif /* CONFIG_LANTIQ_PCIE_3RD_CORE */
+
+/* Subject to change, DT is preferred */
+#define PCIE_GPIO_RESET		238 /* VR9 */
+#define PCIE_RC0_LED_RST	181
+#define PCIE_RC1_LED_RST	182
+
+#define PCIE_RC2_LED_RST	171
+
+static int pcie_port_to_rst_pin[] = {
+	PCIE_RC0_LED_RST,
+	PCIE_RC1_LED_RST,
+	PCIE_RC2_LED_RST,
+};
+
+
+#endif /* PCIE_LANTIQ_H */
